{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Aaq4vTX6lxUS",
   "metadata": {
    "id": "Aaq4vTX6lxUS"
   },
   "source": [
    "# 𝔻𝕖𝕔𝕖𝕟𝕥ℕ𝕖𝕥: 𝕕𝕚𝕤-𝕖𝕟𝕥-𝕒𝕟𝕘𝕝𝕖𝕕 𝕟𝕖𝕥\n",
    "Goal: create a neural network with disentangled early hidden layers. We want to analyse which textures contribute to the predictions.\n",
    "\n",
    "In this notebook you can\n",
    "\n",
    "1) train one or multiple DecentBlocks\n",
    "  * we use a supervised contrastive loss function\n",
    "\n",
    "2) train a DecentNet\n",
    "  * we use the cross entropy loss\n",
    "  * we freeze and use the DecentBlocks as part of the DecentNet\n",
    "  * a fusion layer is the bridge between the DecentBlocks and the combined layers\n",
    "\n",
    "3) Baseline\n",
    "\n",
    "4) NOT HERE RIGHT NOW visualise the DecentBlocks and DecentNet (work in progress)\n",
    "  * DeepDreams\n",
    "  * Feature maps\n",
    "  * Filters\n",
    "\n",
    "Todos:\n",
    "* [ ] metrics / tensorboard\n",
    "\n",
    "\n",
    "MIL: https://www.sciencedirect.com/science/article/pii/S0010482522004930"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pYryiJ8XKkm4",
   "metadata": {
    "id": "pYryiJ8XKkm4"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae53756",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eae53756",
    "outputId": "1392d54c-c059-4187-80fb-2bbb803edb84"
   },
   "outputs": [],
   "source": [
    "# basics\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import shufflenet_v2_x1_0, resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb816ef-1359-474a-a4d2-f5806e886b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "from helper.dataset.transform.transform import ToTensor, ResizeCrop, RandomAugmentations, Normalise\n",
    "from helper.dataset.transform.two_crop import *\n",
    "from helper.compute.loss.supcon import SupConLoss\n",
    "from helper.sampler.mixed_batch import MixedBatchSampler\n",
    "from helper.dataset.concept import ClusterConceptDataset, PosNegConceptDataset\n",
    "from helper.model.decentblock import *\n",
    "\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "try:\n",
    "    from torchvision.models import ShuffleNet_V2_X1_0_Weights\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244d212",
   "metadata": {
    "id": "4244d212"
   },
   "source": [
    "# Experiment Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "TMN4hZi_yFAD",
   "metadata": {
    "id": "TMN4hZi_yFAD"
   },
   "outputs": [],
   "source": [
    "class Configs():\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # general (half of these not in use)\n",
    "        self.num_workers = 0\n",
    "        self.epochs = 50\n",
    "        self.n_samples_per_class_per_batch = 10\n",
    "\n",
    "        # optimisation\n",
    "        self.learning_rate = 0.01\n",
    "        self.weight_decay = 1e-4\n",
    "        self.momentum = 0.9\n",
    "\n",
    "        # data - make sure it is the same size for quilted images\n",
    "        self.image_size = 500\n",
    "\n",
    "        self.prefix = \"tmp\"\n",
    "        \n",
    "        self.device = \"cpu\" # \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Paths\n",
    "        # =============================================================================\n",
    "        \n",
    "        # we read and write to an external directory!!\n",
    "        self.base_path = r\"C:/Users/Prinzessin/projects/decentnet\"\n",
    "        if not os.path.exists(self.base_path):\n",
    "            os.makedirs(self.base_path)\n",
    "        os.chdir(self.base_path) # this is now the main directory !!!!!!!!!!!!!!!!!!!!\n",
    "        \n",
    "        # input for decentblock\n",
    "        self.csv_filenames =     [f\"results/{self.prefix}/masks_info_label.csv\"]\n",
    "        self.concepts_path =     f\"data/{self.prefix}/concepts\"\n",
    "        \n",
    "        # input for decentnet\n",
    "        self.train_path =        r\"data/images/train\"\n",
    "        self.val_path =          r\"data/images/val\"\n",
    "        self.test_path =         r\"data/images/test\"\n",
    "\n",
    "        # output\n",
    "        self.ckpt_net_path =     f\"results/{self.prefix}/ckpts/decentnet\"\n",
    "        self.ckpt_blocks_path =  f\"results/{self.prefix}/ckpts/decentblock\"\n",
    "        self.results_path =      f\"results/{self.prefix}\"\n",
    "        \n",
    "        if not os.path.exists(self.ckpt_net_path):\n",
    "            os.makedirs(self.ckpt_net_path)\n",
    "        if not os.path.exists(self.ckpt_blocks_path):\n",
    "            os.makedirs(self.ckpt_blocks_path)\n",
    "            \n",
    "        # =============================================================================\n",
    "        # activate function calls\n",
    "        # =============================================================================    \n",
    "            \n",
    "        self.run_decentblocks = True\n",
    "        self.run_decentnet = False\n",
    "        self.run_baseline = False\n",
    "        self.run_visualisation = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZKOheDtVvdYn",
   "metadata": {
    "id": "ZKOheDtVvdYn"
   },
   "source": [
    "# 𝔻𝕖𝕔𝕖𝕟𝕥𝕌𝕟𝕚𝕥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ATBINCQDj5nY",
   "metadata": {
    "id": "ATBINCQDj5nY"
   },
   "source": [
    "## DecentBlock Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18c174",
   "metadata": {
    "id": "0f18c174"
   },
   "outputs": [],
   "source": [
    "class DecentBlock_MLP_routine():\n",
    "    \n",
    "    def __init__(self, configs):\n",
    "        \n",
    "        self.configs = configs\n",
    "        \n",
    "    def set_loader(self, mode=\"train\", ci_concept=0):\n",
    "        # =============================================================================\n",
    "        # construct data loader\n",
    "        # =============================================================================\n",
    "        \n",
    "        p_aug = 0.5\n",
    "            \n",
    "        if mode == \"train\":\n",
    "            dataset = PosNegConceptDataset(mode=\"train\", channels=3, index_col=0, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames, ci_concept=ci_concept, concepts_path=self.configs.concepts_path, p_aug=p_aug)\n",
    "            # dataset = EyeDataset(mode=\"train\", ci_concept=ci_concept, image_size=self.configs.image_size)\n",
    "            mbs = MixedBatchSampler(dataset.get_class_labels(), n_samples_per_class_per_batch=self.configs.n_samples_per_class_per_batch)\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                dataset, \n",
    "                batch_sampler = mbs,\n",
    "                num_workers=self.configs.num_workers)\n",
    "        elif mode == \"val\":\n",
    "            dataset = PosNegConceptDataset(mode=\"val\", channels=3, index_col=0, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames, ci_concept=ci_concept, concepts_path=self.configs.concepts_path, p_aug=p_aug)\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                dataset, \n",
    "                batch_size=1, # should be 1\n",
    "                shuffle=False,\n",
    "                num_workers=self.configs.num_workers)\n",
    "\n",
    "        return loader\n",
    "\n",
    "    def set_optimizer(self, model):\n",
    "        # =============================================================================\n",
    "        # =============================================================================\n",
    "\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                                lr=self.configs.learning_rate,\n",
    "                                momentum=self.configs.momentum,\n",
    "                                weight_decay=self.configs.weight_decay)\n",
    "        \n",
    "        return optimizer\n",
    "\n",
    "\n",
    "\n",
    "    def save_model(self, model, optimizer, epoch, save_file):\n",
    "        # =============================================================================\n",
    "        # =============================================================================\n",
    "\n",
    "        state = {\n",
    "            'model': model.encoder.state_dict(),\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        torch.save(state, save_file)\n",
    "        del state\n",
    "\n",
    "    def train(self, loader, model, criterion, optimizer, epoch):\n",
    "        # =============================================================================\n",
    "        # DecentBlock\n",
    "        # one epoch training\n",
    "        # trainings pair (2) - 2 augmented versions\n",
    "        # batch size (8)\n",
    "        # image size (256 x 256)\n",
    "        # (8 x (2 x (256 x 256) ) )\n",
    "        \n",
    "        model.train()\n",
    "        loss_epoch = []    \n",
    "        for idx, batch in enumerate(loader):\n",
    "\n",
    "            #print(\"train \"*10)\n",
    "            \n",
    "            images, labels = batch[\"img\"], batch[\"lbl\"]\n",
    "            \n",
    "            images = torch.cat([images[0], images[1]], dim=0)\n",
    "\n",
    "            batch_size = labels.shape[0]\n",
    "            \n",
    "            features = model(images.to(self.configs.device))\n",
    "            f1, f2 = torch.split(features, [batch_size, batch_size], dim=0)\n",
    "            features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)        \n",
    "            loss = criterion(features, labels)\n",
    "\n",
    "            # SGD\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                    \n",
    "            loss_epoch.append(loss.detach().cpu().numpy().item())\n",
    "\n",
    "            #print(\"+\"*50)\n",
    "            \n",
    "        return np.mean(loss_epoch)\n",
    "\n",
    "\n",
    "    def val(self, loader, model, criterion, epoch):\n",
    "        # =============================================================================\n",
    "        # validation decentblock\n",
    "        # trainings pair (2) - 2 augmented versions\n",
    "        # batch size (8)\n",
    "        # image size (256 x 256)\n",
    "        # (8 x (2 x (256 x 256) ) )\n",
    "        # =============================================================================\n",
    "        \n",
    "        model.eval()\n",
    "        loss_epoch = []    \n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(loader):\n",
    "            \n",
    "                images, labels = batch[\"image\"], batch[\"label\"]\n",
    "                \n",
    "                images = torch.cat([images[0], images[1]], dim=0)\n",
    "\n",
    "                batch_size = labels.shape[0]\n",
    "\n",
    "                features = model(images.to(self.configs.device))\n",
    "                f1, f2 = torch.split(features, [batch_size, batch_size], dim=0)\n",
    "                features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)        \n",
    "                loss = criterion(features, labels)\n",
    "\n",
    "                loss_epoch.append(loss.detach().cpu().numpy().item())\n",
    "\n",
    "        return np.mean(loss_epoch)\n",
    "\n",
    "def decentblock_routine(configs):\n",
    "    \n",
    "    \n",
    "    temp = 0.07\n",
    "    criterion = SupConLoss(temperature=temp)\n",
    "\n",
    "    run = DecentBlock_MLP_routine(configs=configs)\n",
    "\n",
    "    # todo\n",
    "    concept_list = list(range(7))\n",
    "\n",
    "    for ci_concept in concept_list:\n",
    "        print(configs.concepts_path)\n",
    "        # for ci_concept in concept_list:\n",
    "\n",
    "        #print(\"concept\", ci_concept)\n",
    "\n",
    "        decent_block_mlp = DecentBlock(None, None, 128, device=configs.device, mode=\"train_mlp\")\n",
    "        decent_block_mlp = decent_block_mlp.to(configs.device)\n",
    "        criterion = criterion.to(configs.device)\n",
    "\n",
    "        # build data loader\n",
    "        train_loader = run.set_loader(mode=\"train\", ci_concept=ci_concept)\n",
    "        # val_loader = run.set_loader(mode=\"val\", batch_size=1, ci_concept=ci_concept)\n",
    "\n",
    "        # print(\"train_loader:\", train_loader.__len__())\n",
    "        # print(\"val_loader:\", val_loader.__len__())\n",
    "        \n",
    "        # build optimizer\n",
    "        optimizer = run.set_optimizer(decent_block_mlp)\n",
    "\n",
    "        best_loss = 0\n",
    "        # training routine\n",
    "        for epoch in range(1, configs.epochs + 1):\n",
    "\n",
    "            # train for one epoch\n",
    "            loss_train_epoch = run.train(train_loader, decent_block_mlp, criterion, optimizer, epoch)        \n",
    "            #loss_val_epoch = run.val(val_loader, decent_block_mlp, criterion, iterations)\n",
    "\n",
    "            #print(\"iter: \", iter)\n",
    "            #print(\"loss_train_epoch\", loss_train_epoch)\n",
    "            #print(\"loss_val_epoch\", loss_val_epoch)\n",
    "            \n",
    "            #if epoch < 5: # for the first 5 epochs\n",
    "            #    best_loss = loss_val_epoch\n",
    "            #elif best_loss > loss_val_epoch: # then if loss is lower than best loss (aka better)\n",
    "            #    best_loss = loss_val_epoch\n",
    "\n",
    "            best_loss = loss_train_epoch\n",
    "            save_file = os.path.join(ckpt_blocks_path, f'{prefix}_mlp_{ci_concept}_ep{iter}_{round(best_loss, 4)}.ckpt')\n",
    "            run.save_model(decent_block_mlp, optimizer, iter, save_file)\n",
    "\n",
    "        # save the last model\n",
    "        #save_file = os.path.join(ckpt_net_path, f'mlp_{ci_concept}_last_{round(loss_val_epoch, 4)}.ckpt')\n",
    "        #run.save_model(decent_block_mlp, optimizer, iter, save_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ktmPY-WevwxD",
   "metadata": {
    "id": "ktmPY-WevwxD"
   },
   "source": [
    "# 𝔻𝕖𝕔𝕖𝕟𝕥ℕ𝕖𝕥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11567602",
   "metadata": {
    "id": "11567602"
   },
   "source": [
    "**How to freeze layers**\n",
    "\n",
    "The layers of DecentBlocks need to be frozen while training the DecentNet\n",
    "\n",
    "* Just adding this here for completeness. You can also freeze parameters in place without iterating over them with requires_grad_ (API).\n",
    "\n",
    "* For example say you have a RetinaNet and want to just fine-tune on the heads\n",
    "\n",
    "```\n",
    "class RetinaNet(torch.nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        self.backbone = ResNet(...)\n",
    "        self.fpn = FPN(...)\n",
    "        self.box_head = torch.nn.Sequential(...)\n",
    "        self.cls_head = torch.nn.Sequential(...)\n",
    "```\n",
    "\n",
    "Then you could freeze the backbone and FPN like this:\n",
    "\n",
    "* Getting the model\n",
    "```\n",
    "retinanet = RetinaNet(...)\n",
    "```\n",
    "\n",
    "* Freezing backbone and FPN\n",
    "```\n",
    "retinanet.backbone.requires_grad_(False)\n",
    "retinanet.fpn.requires_grad_(False)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a7359",
   "metadata": {
    "id": "908a7359"
   },
   "source": [
    "**Fusing** \n",
    "\n",
    "Fusing methods: mostly element-wise sum or maximum operations have been studied for fusing CNN feature maps from multiple views for the purpose of classification. Correspondence between multiple views is thereby lost, while fusion by concatenation or convolution were found to efficiently model correspondences between different views for other learning tasks. Comparative evaluations of different strategies for image classification are either missing or yield contradicting results.\n",
    "\n",
    "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0245230\n",
    "\n",
    "In early fusion, convolutional feature maps from the different CNN branches are stacked and subsequently processed together. \n",
    "\n",
    "\n",
    "We consider two different approaches for depth reduction: \n",
    "* (1) early fusion (max): max-pooling of the stacked feature map across the nV views\n",
    "* (2) early fusion (conv): 1 × 1 convolution across the depth of the stacked feature maps.\n",
    "\n",
    "stacking, 1x1 conv || max\n",
    "\n",
    "\n",
    "\n",
    "* In order to further achieve effective fusion of local and global features of images, this paper uses gated fusion sub-networks to adaptively fuse multiple feature maps obtained based on branch networks\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/sheryl-ai/MVGCN/blob/master/models.py\n",
    "```\n",
    "    def _view_pool(self, view_features, name, method='max'):\n",
    "        \"\"\"Max pooling of size p. Should be a power of 2.\"\"\"\n",
    "\n",
    "        vp = tf.expand_dims(view_features[0], 0) # eg. [100] -> [1, 100]\n",
    "        for v in view_features[1:]:\n",
    "            v = tf.expand_dims(v, 0)\n",
    "            vp = tf.concat([vp, v], axis=0)\n",
    "        print ('vp before reducing:', vp.get_shape().as_list())\n",
    "        if method == 'max':\n",
    "            vp = tf.reduce_max(vp, [0], name=name)\n",
    "        elif method == 'mean':\n",
    "            vp = tf.reduce_mean(vp, [0], name=name)\n",
    "        return vp\n",
    "```    \n",
    "    \n",
    "    \n",
    "https://github.com/VChristlein/dgmp/blob/master/clamm/pooling.py\n",
    "\n",
    "\n",
    "Fusion of features after layer three of a CNN. The features from two streams are passed through max pooling, convolution, batch normalization and ReLU layers. The two outputs are then concatenated and form the input for the fourth layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bR00xLAQw0Am",
   "metadata": {
    "id": "bR00xLAQw0Am"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a65599",
   "metadata": {
    "id": "f3a65599"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import resnet50, shufflenet_v2_x1_0\n",
    "import os\n",
    "\n",
    "class DecentNet_v1(nn.Module):\n",
    "    \n",
    "    # for freezing in train code: retinanet.backbone.requires_grad_(False)\n",
    "        \n",
    "    def __init__(self, num_classes=3, plot=False):\n",
    "        super(DecentNet_v1, self).__init__()\n",
    "        \n",
    "        print(\"init decentnet start\")\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # get ckpt files\n",
    "        block_ckpts = os.listdir(ckpt_blocks_path)\n",
    "\n",
    "        # loads blocks\n",
    "        self.decent_blocks = nn.ModuleList([])\n",
    "\n",
    "        decent_block_116 = \"\"\n",
    "        \n",
    "        amount_of_blocks = 0\n",
    "        for block_ckpt in block_ckpts:\n",
    "            \n",
    "            # we use a shufflenet pretrained on data from a previous step\n",
    "            # these layer should be frozen during training of this model\n",
    "            decent_block = shufflenet_v2_x1_0()\n",
    "            decent_block.fc = nn.Identity()\n",
    "\n",
    "            # load shuffle net weights here\n",
    "            checkpoint = torch.load(os.path.join(ckpt_blocks_path, block_ckpt))\n",
    "            decent_block.load_state_dict(checkpoint['model'])\n",
    "\n",
    "            if True:\n",
    "              # remove layers - this line might be wrong too\n",
    "              decent_block_116 = nn.Sequential(*(list(decent_block.children())[:-4]), \n",
    "                                              nn.Conv2d(116, 5, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1)),\n",
    "                                              nn.BatchNorm2d(5),\n",
    "                                              nn.ReLU()\n",
    "                                              ).to(device)\n",
    "            else:\n",
    "              # not working for some reason ... needs to be in nn.Seq\n",
    "              decent_block_116 = nn.Sequential(*(list(decent_block.children())[:-4])).to(device)\n",
    "              self.decent_block_reduction = nn.Conv2d(116, 5, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1))\n",
    "            \n",
    "            self.decent_blocks.append(decent_block_116) # 116 output filters\n",
    "            amount_of_blocks += 1\n",
    "\n",
    "\n",
    "        if plot:\n",
    "            print(\"original\")\n",
    "            print(\"*\"*50)\n",
    "            print(decent_block)\n",
    "            print(\"116\")\n",
    "            print(\"*\"*50)\n",
    "            print(decent_block_116)\n",
    "                \n",
    "        # layer between decent blocks and combined layers\n",
    "        if False:\n",
    "          # single conv 1x1 ??\n",
    "          self.fusion_layer = nn.Conv2d(5*amount_of_blocks, 512, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1))\n",
    "        else:\n",
    "          # conv, batchnorm and relu\n",
    "          self.fusion_layer = nn.Sequential(\n",
    "                nn.Conv2d(5*amount_of_blocks, 512, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1)),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU()\n",
    "          )\n",
    "        \n",
    "        # combined layers\n",
    "        r50 = resnet50(pretrained=True)\n",
    "        \n",
    "        # remove early layers\n",
    "        r50.conv1 = nn.Identity()\n",
    "        r50.bn1 = nn.Identity()\n",
    "        r50.relu = nn.Identity()\n",
    "        r50.maxpool = nn.Identity()\n",
    "        r50.layer1 = nn.Identity()\n",
    "        r50.layer2 = nn.Identity()  \n",
    "                \n",
    "        # change classification head\n",
    "        in_features = r50.fc.in_features\n",
    "        r50.fc = nn.Linear(in_features, self.num_classes)\n",
    "\n",
    "        self.combined_layers = r50 \n",
    "        \n",
    "        print(\"init decentnet done\")\n",
    "        \n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        \n",
    "        # idea: use combined very early layers (pretrained on any dataset): edges\n",
    "        # (maybe for later, needs to be taken into account for the decent block training)\n",
    "        \n",
    "        \n",
    "        # get output for each decent block\n",
    "        block_outputs = []\n",
    "        for i, block in enumerate(self.decent_blocks):\n",
    "            block_output = block(image)\n",
    "            # block_output = self.decent_block_reduction(block_output)\n",
    "            block_outputs.append(block_output)\n",
    "            \n",
    "            # print(\"block output shape:\", block_output.shape)\n",
    "            \n",
    "        # concat features\n",
    "        concat = torch.cat(block_outputs, dim=1)\n",
    "        # print(\"concat shape:\", concat.shape)\n",
    "\n",
    "        # fusion layer\n",
    "        fusion = self.fusion_layer(concat)\n",
    "\n",
    "        # print(\"fusion output:\", fusion.shape)\n",
    "        \n",
    "        # combined layers\n",
    "        feature_vector = self.combined_layers(fusion)\n",
    "            \n",
    "        # print(\"combined layers output shape\", feature_vector.shape) \n",
    "        # print(feature_vector.shape) \n",
    "                        \n",
    "        return feature_vector\n",
    "    \n",
    "\n",
    "class DecentNet_v2(nn.Module):\n",
    "    \n",
    "    # for freezing in train code: retinanet.backbone.requires_grad_(False)\n",
    "        \n",
    "    def __init__(self, num_classes=3, plot=False):\n",
    "        super(DecentNet_v2, self).__init__()\n",
    "        \n",
    "        print(\"init decentnet start\")\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # get ckpt files\n",
    "        block_ckpts = os.listdir(ckpt_blocks_path)\n",
    "\n",
    "        # loads blocks\n",
    "        self.decent_blocks = nn.ModuleList([])\n",
    "\n",
    "        decent_block_116 = \"\"\n",
    "        \n",
    "        amount_of_blocks = 0\n",
    "        for block_ckpt in block_ckpts:\n",
    "            \n",
    "            # we use a shufflenet pretrained on data from a previous step\n",
    "            # these layer should be frozen during training of this model\n",
    "            decent_block = shufflenet_v2_x1_0()\n",
    "            decent_block.fc = nn.Identity()\n",
    "\n",
    "            # load shuffle net weights here\n",
    "            checkpoint = torch.load(os.path.join(ckpt_blocks_path, block_ckpt))\n",
    "            decent_block.load_state_dict(checkpoint['model'])\n",
    "\n",
    "            # remove layers - this line might be wrong too\n",
    "            decent_block_116 = nn.Sequential(*(list(decent_block.children())[:-4])).to(device)\n",
    "\n",
    "            \n",
    "            \n",
    "            self.decent_blocks.append(decent_block_116) # 116 output filters\n",
    "            amount_of_blocks += 1\n",
    "\n",
    "        if plot:\n",
    "            print(\"original\")\n",
    "            print(\"*\"*50)\n",
    "            print(decent_block)\n",
    "            print(\"116\")\n",
    "            print(\"*\"*50)\n",
    "            print(decent_block_116)\n",
    "                \n",
    "        # layer between decent blocks and combined layers\n",
    "        # todo, figure out how to get the 116 automatically - 58 * 2\n",
    "        # fusion_conv\n",
    "        if True:\n",
    "            self.fusion_layer = nn.Conv2d(116*amount_of_blocks, 512, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1))\n",
    "        else:\n",
    "            self.fusion_layer = nn.Sequential(\n",
    "                nn.Conv2d(116*amount_of_blocks, 512, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1)),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        # combined layers\n",
    "        r50 = resnet50(pretrained=True)\n",
    "        \n",
    "        # remove early layers\n",
    "        r50.conv1 = nn.Identity()\n",
    "        r50.bn1 = nn.Identity()\n",
    "        r50.relu = nn.Identity()\n",
    "        r50.maxpool = nn.Identity()\n",
    "        r50.layer1 = nn.Identity()\n",
    "        r50.layer2 = nn.Identity()  \n",
    "        \n",
    "        # torch.nn.Sequential(*list(r50.children())[3:]) - this is not working\n",
    "        \n",
    "        # change classification head\n",
    "        in_features = r50.fc.in_features\n",
    "        r50.fc = nn.Linear(in_features, self.num_classes)\n",
    "      \n",
    "        self.combined_layers = r50 \n",
    "        \n",
    "        print(\"init decentnet done\")\n",
    "        \n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        \n",
    "        # idea: use combined very early layers (pretrained on any dataset): edges\n",
    "        # (maybe for later, needs to be taken into account for the decent block training)\n",
    "        \n",
    "        \n",
    "        # get output for each decent block\n",
    "        block_outputs = []\n",
    "        for i, block in enumerate(self.decent_blocks):\n",
    "            block_output = block(image)\n",
    "            block_outputs.append(block_output)\n",
    "            # print(\"block output shape:\", block_output.shape)\n",
    "            \n",
    "        # concat features\n",
    "        concat = torch.cat(block_outputs, dim=1)\n",
    "        # print(\"concat shape:\", concat.shape)\n",
    "\n",
    "        # fusion layer\n",
    "        fusion = self.fusion_layer(concat)\n",
    "        \n",
    "        # combined layers\n",
    "        feature_vector = self.combined_layers(fusion)\n",
    "            \n",
    "        # print(\"combined layers output shape\", feature_vector.shape) \n",
    "        # print(feature_vector.shape) \n",
    "                        \n",
    "        return feature_vector\n",
    "    \n",
    "    \n",
    "\n",
    "class DecentNet_v3(nn.Module):\n",
    "    \n",
    "    # for freezing in train code: retinanet.backbone.requires_grad_(False)\n",
    "        \n",
    "    def __init__(self, num_classes=3):\n",
    "        super(DecentNet_v1, self).__init__()\n",
    "        \n",
    "        print(\"init decentnet start\")\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # prepare early blocks list\n",
    "        ckpt_early_blocks = os.listdir(ckpt_early_blocks_path)\n",
    "        self.early_blocks = nn.ModuleList([])\n",
    "        early_block_116 = None\n",
    "        for i, early_block in enumerate(ckpt_early_blocks):            \n",
    "            early_block_116 = DecentBlock_Shuffle_EarlyBlock(ckpt_early_blocks_path, early_block, out_channels=5)\n",
    "            self.early_blocks.append(early_block_116) # 116 output filters\n",
    "                \n",
    "        # prepare early fusion (optional)\n",
    "        self.early_fusion_module = None\n",
    "        \n",
    "        # prepare late blocks list (optional)\n",
    "        self.late_blocks = nn.ModuleList([])\n",
    "        self.late_blocks.append(DecentBlock_ResNet_LateBlock())\n",
    "        \n",
    "        # prepare late fusion (optional)\n",
    "        self.late_fusion_module = None\n",
    "        \n",
    "        # prepare head blocks list\n",
    "        self.head_blocks = nn.ModuleList([])\n",
    "        self.late_blocks.append(DecentBlock_ResNet_LateBlock())\n",
    "\n",
    "        print(\"init decentnet done\")\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # early block(s)\n",
    "        block_outputs = []\n",
    "        for i, block in enumerate(self.early_blocks):\n",
    "            block_output = block(x)\n",
    "            block_outputs.append(block_output)\n",
    "            \n",
    "        # concat + fusion\n",
    "        if block_outputs:\n",
    "            x = torch.cat(block_outputs, dim=1)\n",
    "            x = self.early_fusion_module(x)\n",
    "        \n",
    "        # late block(s)\n",
    "        block_outputs = []\n",
    "        for i, block in enumerate(self.late_blocks):\n",
    "            block_output = block(x)\n",
    "            block_outputs.append(block_output)\n",
    "            \n",
    "        # concat + fusion\n",
    "        if block_outputs:\n",
    "            x = torch.cat(block_outputs, dim=1)\n",
    "            x = self.late_fusion_module(x)\n",
    "        \n",
    "        # head block(s) (multi-task)            \n",
    "        model_outputs = {}\n",
    "        for i, block in enumerate(self.head_blocks):\n",
    "            # model output of head = pass feature vector through head\n",
    "            model_outputs[type(head).__name__] = fc_layer(x)\n",
    "        \n",
    "        return model_outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EZ6CElCnj-nL",
   "metadata": {
    "id": "EZ6CElCnj-nL"
   },
   "source": [
    "## DecentNet Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oCM5QGTfyd-d",
   "metadata": {
    "id": "oCM5QGTfyd-d"
   },
   "outputs": [],
   "source": [
    "class DecentNet_routine():\n",
    "\n",
    "    def set_loader(self, mode=\"train\", batch_size=2, num_workers=0, image_size=500):\n",
    "        # construct data loader\n",
    "                    \n",
    "        if mode == \"train\":\n",
    "                train_transform = transforms.Compose([\n",
    "                    ResizeCrop(image_size=image_size),\n",
    "                    RandomAugmentations(),\n",
    "                    ToTensor(),\n",
    "                    Normalise()\n",
    "                ])\n",
    "\n",
    "                train_dataset = datasets.ImageFolder(root=train_path, transform=train_transform)\n",
    "\n",
    "                print(set(train_dataset.targets))\n",
    "\n",
    "                loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True,\n",
    "                    num_workers=num_workers)\n",
    "            \n",
    "        elif mode == \"val\":\n",
    "\n",
    "            val_transform = transforms.Compose([\n",
    "                    ResizeCrop(image_size=image_size),\n",
    "                    ToTensor(),\n",
    "                    Normalise()\n",
    "            ])\n",
    "\n",
    "            val_dataset = datasets.ImageFolder(root=val_path, transform=val_transform)\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                    val_dataset, \n",
    "                    batch_size=batch_size, # should be 1\n",
    "                    shuffle=False,\n",
    "                    num_workers=num_workers)\n",
    "\n",
    "        elif mode == \"test\":\n",
    "\n",
    "            test_transforms = transforms.Compose([\n",
    "                    ResizeCrop(image_size=image_size),\n",
    "                    ToTensor(),\n",
    "                    Normalise()\n",
    "            ])\n",
    "\n",
    "            test_dataset = datasets.ImageFolder(root=test_path, transform=test_transforms)\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                    test_dataset, \n",
    "                    batch_size=batch_size, # should be 1 \n",
    "                    shuffle=False,\n",
    "                    num_workers=num_workers)\n",
    "            \n",
    "\n",
    "        return loader\n",
    "\n",
    "    def set_optimizer(self, model):\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                                lr=learning_rate,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "        \n",
    "        return optimizer\n",
    "\n",
    "    def save_model(self, model, optimizer, epoch, save_file):\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        torch.save(state, save_file)\n",
    "        del state\n",
    "\n",
    "    def train(self, loader, model, criterion, optimizer, epoch):\n",
    "        \"\"\"one epoch training\"\"\"\n",
    "        \n",
    "        model.train()\n",
    "        loss_epoch = []\n",
    "        ground_truth_all = []\n",
    "        model_output_all = []  \n",
    "        for idx, (images, labels) in enumerate(loader):\n",
    "            \n",
    "\n",
    "            # images, labels = batch[\"image\"], batch[\"label\"]\n",
    "                        \n",
    "            model_output = model(images.to(device))\n",
    "            loss = criterion(model_output, labels.to(device))\n",
    "\n",
    "            # SGD\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                    \n",
    "            loss_epoch.append(loss.detach().cpu().numpy().item())\n",
    "\n",
    "            _, highest_class = torch.max(model_output, 1)    \n",
    "            highest_class = highest_class.detach().cpu().numpy()    \n",
    "\n",
    "            ground_truth_all.extend(labels.detach().cpu().numpy())\n",
    "            model_output_all.extend(highest_class)\n",
    "\n",
    "        print(ground_truth_all)\n",
    "        print(model_output_all)\n",
    "            \n",
    "        f_score_epoch = f1_score(y_true = ground_truth_all, y_pred = model_output_all, average=\"weighted\", labels=[0,1,2])\n",
    "\n",
    "        return np.mean(loss_epoch), f_score_epoch\n",
    "\n",
    "\n",
    "    def val(self, loader, model, criterion, epoch):\n",
    "        # decentnet\n",
    "        # with labels\n",
    "        \"\"\"validation\"\"\"\n",
    "        \n",
    "        model.eval()\n",
    "        loss_epoch = []   \n",
    "        ground_truth_all = []\n",
    "        model_output_all = [] \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, (images, labels) in enumerate(loader):\n",
    "            \n",
    "                # images, labels = batch[\"image\"], batch[\"label\"]\n",
    "                        \n",
    "                model_output = model(images.to(device))\n",
    "                loss = criterion(model_output, labels.to(device))\n",
    "                        \n",
    "                loss_epoch.append(loss.detach().cpu().numpy().item())\n",
    "\n",
    "                _, highest_class = torch.max(model_output, 1)    \n",
    "                highest_class = highest_class.detach().cpu().numpy()    \n",
    "\n",
    "                ground_truth_all.extend(labels.detach().cpu().numpy())\n",
    "                model_output_all.extend(highest_class)\n",
    "\n",
    "        print(ground_truth_all)\n",
    "        print(model_output_all)\n",
    "\n",
    "        f_score_epoch = f1_score(y_true = ground_truth_all, y_pred = model_output_all, average=\"weighted\", labels=[0,1,2])\n",
    "\n",
    "        return np.mean(loss_epoch), f_score_epoch\n",
    "\n",
    "\n",
    "    def test(self, loader, model):\n",
    "        # decentnet - results for non existant labels\n",
    "        # without labels\n",
    "        \n",
    "        model.eval()\n",
    "        highest_classes = [] \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, (images, labels) in enumerate(loader):\n",
    "            \n",
    "                # images, labels = batch[\"image\"], batch[\"label\"]\n",
    "                        \n",
    "                model_output = model(images.to(device))\n",
    "                _, highest_class = torch.max(model_output, 1)    \n",
    "                highest_class = highest_class.detach().cpu().numpy()\n",
    "\n",
    "                highest_classes.extend(highest_class)    \n",
    "\n",
    "\n",
    "        print(highest_classes)\n",
    "\n",
    "        df = pd.DataFrame({'Prediction': highest_classes})\n",
    "        df.to_csv(\"test_decentnet.csv\")\n",
    "\n",
    "\n",
    "    def visualise_with_labels(self, loader, model):\n",
    "        pass\n",
    "\n",
    "\n",
    "def decentnet_routine():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    run = DecentNet_routine()\n",
    "\n",
    "    decentnet = DecentNet_v2(num_classes=3).to(device)\n",
    "\n",
    "    # freeze decent blocks\n",
    "    if True:\n",
    "        for i, child in enumerate(decentnet.decent_blocks.children()):\n",
    "            # exclude the conv layer (or sequential???) - needs to be trainable\n",
    "            for param in child[:-1].parameters():\n",
    "                param.requires_grad = False\n",
    "    else:\n",
    "        # v1, without conv layer (that is trainable)\n",
    "        decentnet.decent_blocks.requires_grad_(False)\n",
    "\n",
    "    \n",
    "    decentnet = decentnet.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # set data loader\n",
    "    train_loader = run.set_loader(mode=\"train\", batch_size=8, num_workers=num_workers, image_size=image_size)\n",
    "    val_loader = run.set_loader(mode=\"val\", batch_size=1, num_workers=num_workers, image_size=image_size)\n",
    "\n",
    "    # set optimizer\n",
    "    optimizer = run.set_optimizer(decentnet)\n",
    "\n",
    "    best_loss = 0\n",
    "    iter = 0\n",
    "    # training routine\n",
    "    for iter in range(1, iterations + 1):\n",
    "\n",
    "            # train for one epoch\n",
    "            loss_train_epoch, fscore_train_epoch = run.train(loader=train_loader, model=decentnet, criterion=criterion, optimizer=optimizer, epoch=epoch)        \n",
    "            loss_val_epoch, fscore_val_epoch = run.val(loader=val_loader, model=decentnet, criterion=criterion, epoch=epoch)\n",
    "\n",
    "            print(\"iter: \", iter)\n",
    "            print(loss_train_epoch)\n",
    "            print(fscore_train_epoch)\n",
    "            print(loss_val_epoch)\n",
    "            print(fscore_val_epoch)\n",
    "            \n",
    "            if iter < 3: # for the first 3 epochs\n",
    "                best_loss = loss_val_epoch\n",
    "            elif best_loss > loss_val_epoch: # then if loss is lower than best loss (aka better)\n",
    "                best_loss = loss_val_epoch\n",
    "                save_file = os.path.join(ckpt_net_path, f'decentnet_epoch_{iter}_{round(best_loss, 4)}.ckpt')\n",
    "                run.save_model(decentnet, optimizer, iter, save_file)\n",
    "\n",
    "    # save the last model\n",
    "    save_file = os.path.join(ckpt_net_path, f'decentnet_last_{round(loss_val_epoch, 4)}.ckpt')\n",
    "    run.save_model(decentnet, optimizer, iter, save_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vg8CPRaSNdfv",
   "metadata": {
    "id": "Vg8CPRaSNdfv"
   },
   "source": [
    "# 𝔹𝕒𝕤𝕖𝕝𝕚𝕟𝕖 ℝ𝕖𝕤ℕ𝕖𝕥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aCIOrVGINkK-",
   "metadata": {
    "id": "aCIOrVGINkK-"
   },
   "source": [
    "## Model\n",
    "\n",
    "* early stopping: https://pythonguides.com/pytorch-early-stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "APta2MnINdA7",
   "metadata": {
    "id": "APta2MnINdA7"
   },
   "outputs": [],
   "source": [
    "class DecentBaseline(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=3):\n",
    "        super(DecentBaseline, self).__init__()\n",
    "        \n",
    "        print(\"init baseline start\")\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # resnet 50\n",
    "        r50 = resnet50(pretrained=True)\n",
    "\n",
    "        # change classification head\n",
    "        in_features = r50.fc.in_features\n",
    "        r50.fc = nn.Linear(in_features, self.num_classes)\n",
    "        \n",
    "        self.r50 = r50 \n",
    "        \n",
    "        print(\"init baseline done\")\n",
    "        \n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        # resnet 50\n",
    "        feature_vector = self.r50(image)\n",
    "                        \n",
    "        return feature_vector\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rAN0jFnCQC0y",
   "metadata": {
    "id": "rAN0jFnCQC0y"
   },
   "source": [
    "## Baseline Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TRVZHWPpQFFt",
   "metadata": {
    "id": "TRVZHWPpQFFt"
   },
   "outputs": [],
   "source": [
    "def baseline_routine():\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    run = DecentNet_routine()\n",
    "\n",
    "    ########## \n",
    "    # TRAIN and VAL Decent Baseline\n",
    "    ##########\n",
    "\n",
    "    baseline = DecentBaseline(num_classes=3).to(device)\n",
    "\n",
    "\n",
    "    baseline = baseline.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # build data loader\n",
    "    train_loader = run.set_loader(mode=\"train\", batch_size=8, num_workers=num_workers, image_size=image_size)\n",
    "    val_loader = run.set_loader(mode=\"val\", batch_size=1, num_workers=num_workers, image_size=image_size)\n",
    "\n",
    "    # build optimizer\n",
    "    optimizer = run.set_optimizer(baseline)\n",
    "\n",
    "    best_loss = 0\n",
    "    iter = 0\n",
    "    # training routine\n",
    "    for iter in range(1, iterations + 1):\n",
    "\n",
    "        # train for one epoch\n",
    "        loss_train_epoch, fscore_train_epoch = run.train(loader=train_loader, model=baseline, criterion=criterion, optimizer=optimizer, epoch=iter)        \n",
    "        loss_val_epoch, fscore_val_epoch = run.val(loader=val_loader, model=baseline, criterion=criterion, epoch=epoch)\n",
    "\n",
    "        print(\"iter: \", iter)\n",
    "        print(loss_train_epoch)\n",
    "        print(fscore_train_epoch)\n",
    "        print(loss_val_epoch)\n",
    "        print(fscore_val_epoch)\n",
    "        \n",
    "        if iter < 3: # for the first 3 epochs\n",
    "            best_loss = loss_val_epoch\n",
    "        elif best_loss > loss_val_epoch: # then if loss is lower than best loss (aka better)\n",
    "            best_loss = loss_val_epoch\n",
    "            save_file = os.path.join(ckpt_net_path, f'baseline_epoch_{iter}_{round(best_loss, 4)}.ckpt')\n",
    "            run.save_model(baseline, optimizer, iter, save_file)\n",
    "\n",
    "    # save the last model\n",
    "    save_file = os.path.join(ckpt_net_path, f'baseline_last_{round(loss_val_epoch, 4)}.ckpt')\n",
    "    run.save_model(baseline, optimizer, iter, save_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fab557-104b-4da0-a34d-986ea6c04e58",
   "metadata": {},
   "source": [
    "# 𝔹𝕣𝕒𝕚𝕟-𝕀𝕟𝕤𝕡𝕚𝕣𝕖𝕕 𝕄𝕠𝕕𝕦𝕝𝕒𝕣 𝕋𝕣𝕒𝕚𝕟𝕚𝕟𝕘 (𝔹𝕀𝕄𝕋)\n",
    "* https://github.com/KindXiaoming/BIMT/blob/main/mnist_3.5.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b3062-183f-4b34-86c6-defec7e04e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.patches import Ellipse, Circle\n",
    "\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0f106-921f-4b2b-afa0-1ce1693f0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "class BioLinear2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, in_fold=1, out_fold=1, out_ring=False):\n",
    "        super(BioLinear2D, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.in_fold = in_fold\n",
    "        self.out_fold = out_fold\n",
    "        assert in_dim % in_fold == 0\n",
    "        assert out_dim % out_fold == 0\n",
    "        \n",
    "        #compute in_cor, shape: (in_dim_sqrt, in_dim_sqrt)\n",
    "        in_dim_fold = int(in_dim/in_fold)\n",
    "        out_dim_fold = int(out_dim/out_fold)\n",
    "        in_dim_sqrt = int(np.sqrt(in_dim_fold))\n",
    "        out_dim_sqrt = int(np.sqrt(out_dim_fold))\n",
    "        x = np.linspace(1/(2*in_dim_sqrt), 1-1/(2*in_dim_sqrt), num=in_dim_sqrt)\n",
    "        X, Y = np.meshgrid(x, x)\n",
    "        self.in_coordinates = torch.tensor(np.transpose(np.array([X.reshape(-1,), Y.reshape(-1,)])), dtype=torch.float)\n",
    "        \n",
    "        # compute out_cor, shape: (out_dim_sqrt, out_dim_sqrt)\n",
    "        if out_ring:\n",
    "            thetas = np.linspace(1/(2*out_dim_fold)*2*np.pi, (1-1/(2*out_dim_fold))*2*np.pi, num=out_dim_fold)\n",
    "            self.out_coordinates = 0.5+torch.tensor(np.transpose(np.array([np.cos(thetas), np.sin(thetas)]))/4, dtype=torch.float)\n",
    "        else:\n",
    "            x = np.linspace(1/(2*out_dim_sqrt), 1-1/(2*out_dim_sqrt), num=out_dim_sqrt)\n",
    "            X, Y = np.meshgrid(x, x)\n",
    "            self.out_coordinates = torch.tensor(np.transpose(np.array([X.reshape(-1,), Y.reshape(-1,)])), dtype=torch.float)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d27cc-079f-4133-8f22-aeb59eacfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioMLP2D(nn.Module):\n",
    "    def __init__(self, in_dim=2, out_dim=2, w=2, depth=2, shp=None, token_embedding=False, embedding_size=None):\n",
    "        super(BioMLP2D, self).__init__()\n",
    "        \n",
    "        # example shp for 28x28 = (1st, 2nd, 3rd, number of classes) = (784, 100, 100, 4)\n",
    "        \n",
    "        if shp == None:\n",
    "            shp = [in_dim] + [w]*(depth-1) + [out_dim]\n",
    "            self.in_dim = in_dim\n",
    "            self.out_dim = out_dim\n",
    "            self.depth = depth\n",
    "                 \n",
    "        else:\n",
    "            self.in_dim = shp[0]\n",
    "            self.out_dim = shp[-1]\n",
    "            self.depth = len(shp) - 1\n",
    "        linear_list = []\n",
    "        for i in range(self.depth):\n",
    "            out_shape = 0\n",
    "            if i == 0:\n",
    "                # for modular addition\n",
    "                #linear_list.append(BioLinear(shp[i], shp[i+1], in_fold=2))\n",
    "                # for regression\n",
    "                linear_list.append(BioLinear2D(shp[i], shp[i+1], in_fold=1))\n",
    "            elif i == self.depth - 1:\n",
    "                linear_list.append(BioLinear2D(shp[i], shp[i+1], in_fold=1, out_ring=True))\n",
    "            else:\n",
    "                linear_list.append(BioLinear2D(shp[i], shp[i+1]))\n",
    "                \n",
    "            print(\"i\", i)\n",
    "            print(\"bio linear shape\", shp[i])\n",
    "                \n",
    "        \n",
    "        self.linears = nn.ModuleList(linear_list)\n",
    "        \n",
    "        print(\"shape\", shp)\n",
    "        print(\"in\", shp[-2])\n",
    "        print(\"out\", shp[-1])\n",
    "        \n",
    "        # self.conv1x1 = nn.Conv2d(in_channels=10, out_channels=shp[-1], kernel_size=1)\n",
    "        # nn.Conv2d(5*amount_of_blocks, 512, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1))\n",
    "        if True:\n",
    "            self.conv1x1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(1,1), stride=(1, 1), padding=(0, 0), dilation=(1, 1))\n",
    "            # self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "            import torch.nn.functional as F\n",
    "            \n",
    "        \n",
    "        \n",
    "        if token_embedding == True:\n",
    "            # embedding size: number of tokens * embedding dimension\n",
    "            self.embedding = torch.nn.Parameter(torch.normal(0,1,size=embedding_size))\n",
    "        \n",
    "        self.shp = shp\n",
    "        # parameters for the bio-inspired trick\n",
    "        self.l0 = 0.5 # distance between two nearby layers\n",
    "        self.in_perm = nn.Parameter(torch.tensor(np.arange(int(self.in_dim/self.linears[0].in_fold)), dtype=torch.float))\n",
    "        self.out_perm = nn.Parameter(torch.tensor(np.arange(int(self.out_dim/self.linears[-1].out_fold)), dtype=torch.float))\n",
    "        self.top_k = 30\n",
    "        self.token_embedding = token_embedding\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        print(\"************************************\")\n",
    "        print(\"next input\")\n",
    "        \n",
    "        print(\"input size\", x.shape)\n",
    "        \n",
    "        shp = x.shape\n",
    "        x = x.reshape(shp[0],-1)\n",
    "        print(\"reshape size 1\", x.shape)\n",
    "        \n",
    "        shp = x.shape\n",
    "        in_fold = self.linears[0].in_fold\n",
    "        x = x.reshape(shp[0], in_fold, int(shp[1]/in_fold))\n",
    "        print(\"reshape size 2\", x.shape)\n",
    "        \n",
    "        x = x[:,:,self.in_perm.long()]\n",
    "        print(\"reshape size 3\", x.shape)\n",
    "        \n",
    "        x = x.reshape(shp[0], shp[1])\n",
    "        print(\"more reshape size\", x.shape)\n",
    "        \n",
    "        f = torch.nn.SiLU()\n",
    "        for i in range(self.depth-1):\n",
    "            \n",
    "            print(\"linear itself shape\", self.linears[i](x).shape)\n",
    "            \n",
    "            x = f(self.linears[i](x))\n",
    "            print(\"i\", i)\n",
    "            print(\"linear output size\", x.shape)\n",
    "            \n",
    "        print(\"this shp\", x.shape)\n",
    "        # 30 x 10 x 10 \n",
    "        tmp_shape = x.shape\n",
    "        \n",
    "        # return x[0].reshape(22, 22)\n",
    "        \n",
    "        \n",
    "        if False:\n",
    "            # batch size x 100 filters x width x height\n",
    "            x = x.reshape(tmp_shape[0], 1, 20, 20) #  int(np.sqrt(tmp_shape[1])), int(np.sqrt(tmp_shape[1])))\n",
    "\n",
    "            print(\"reshape\", x.shape)\n",
    "\n",
    "            # 1x1 conv - for activation map\n",
    "            x = self.conv1x1(x)\n",
    "            \n",
    "            print(\"after conv\", x.shape)\n",
    "            \n",
    "            # then global max pooling\n",
    "            \n",
    "            # x = self.maxpool(x)\n",
    "            output = F.max_pool2d(x, kernel_size=x.size()[2:])\n",
    "            print(\"after maxpool\", x.shape)\n",
    "        \n",
    "        \n",
    "        # final linear layer\n",
    "        x = self.linears[-1](x)\n",
    "        print(\"final linear output size\", x.shape)\n",
    "        \n",
    "        out_perm_inv = torch.zeros(self.out_dim, dtype=torch.long)\n",
    "        out_perm_inv[self.out_perm.long()] = torch.arange(self.out_dim)\n",
    "        x = x[:,out_perm_inv]\n",
    "        \n",
    "        print(\"result\", x.shape)\n",
    "        \n",
    "        #x = x[:,self.out_perm]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_linear_layers(self):\n",
    "        return self.linears\n",
    "    \n",
    "    def get_cc(self, weight_factor=2.0, bias_penalize=True, no_penalize_last=False):\n",
    "        # compute connection cost\n",
    "        cc = 0\n",
    "        num_linear = len(self.linears)\n",
    "        for i in range(num_linear):\n",
    "            if i == num_linear - 1 and no_penalize_last:\n",
    "                weight_factor = 0.\n",
    "            biolinear = self.linears[i]\n",
    "            dist = torch.sum(torch.abs(biolinear.out_coordinates.unsqueeze(dim=1) - biolinear.in_coordinates.unsqueeze(dim=0)),dim=2)\n",
    "            \n",
    "            #print(\"biolinear.linear.weight\", biolinear.linear.weight)\n",
    "            #print(\"weight_factor\", weight_factor)\n",
    "            #print(\"dist\", dist)\n",
    "            #print(\"self.l0\", self.l0)\n",
    "            \n",
    "            \n",
    "            cc += torch.mean(torch.abs(biolinear.linear.weight)*(weight_factor*dist+self.l0).to(\"cuda:0\"))\n",
    "            if bias_penalize == True:\n",
    "                cc += torch.mean(torch.abs(biolinear.linear.bias)*(self.l0))\n",
    "        if self.token_embedding:\n",
    "            cc += torch.mean(torch.abs(self.embedding)*(self.l0))\n",
    "            #pass\n",
    "        return cc\n",
    "    \n",
    "    def swap_weight(self, weights, j, k, swap_type=\"out\"):\n",
    "        with torch.no_grad():  \n",
    "            if swap_type == \"in\":\n",
    "                temp = weights[:,j].clone()\n",
    "                weights[:,j] = weights[:,k].clone()\n",
    "                weights[:,k] = temp\n",
    "            elif swap_type == \"out\":\n",
    "                temp = weights[j].clone()\n",
    "                weights[j] = weights[k].clone()\n",
    "                weights[k] = temp\n",
    "            else:\n",
    "                raise Exception(\"Swap type {} is not recognized!\".format(swap_type))\n",
    "            \n",
    "    def swap_bias(self, biases, j, k):\n",
    "        with torch.no_grad():  \n",
    "            temp = biases[j].clone()\n",
    "            biases[j] = biases[k].clone()\n",
    "            biases[k] = temp\n",
    "    \n",
    "    def swap(self, i, j, k):\n",
    "        # in the ith layer (of neurons), swap the jth and the kth neuron. \n",
    "        # Note: n layers of weights means n+1 layers of neurons.\n",
    "        # (incoming, outgoing) * weights + biases are swapped. \n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        if i == 0:\n",
    "            return\n",
    "            # for images, do not allow input_perm\n",
    "            # input layer, only has outgoing weights; update in_perm\n",
    "            weights = linears[i].linear.weight\n",
    "            infold = linears[i].in_fold\n",
    "            fold_dim = int(weights.shape[1]/infold)\n",
    "            for l in range(infold):\n",
    "                self.swap_weight(weights, j+fold_dim*l, k+fold_dim*l, swap_type=\"in\")\n",
    "            # change input_perm. do not allow input_perm for images\n",
    "            self.swap_bias(self.in_perm, j, k)\n",
    "        elif i == num_linear:\n",
    "            # output layer, only has incoming weights and biases; update out_perm\n",
    "            weights = linears[i-1].linear.weight\n",
    "            biases = linears[i-1].linear.bias\n",
    "            self.swap_weight(weights, j, k, swap_type=\"out\")\n",
    "            self.swap_bias(biases, j, k)\n",
    "            # change output_perm\n",
    "            self.swap_bias(self.out_perm, j, k)\n",
    "        else:\n",
    "            # middle layer : (incoming, outgoing) * weights, and biases\n",
    "            weights_in = linears[i-1].linear.weight\n",
    "            weights_out = linears[i].linear.weight\n",
    "            biases = linears[i-1].linear.bias\n",
    "            self.swap_weight(weights_in, j, k, swap_type=\"out\")\n",
    "            self.swap_weight(weights_out, j, k, swap_type=\"in\")\n",
    "            self.swap_bias(biases, j, k)\n",
    "\n",
    "    def get_top_id(self, i, top_k=20):\n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        if i == 0:\n",
    "            # input layer\n",
    "            weights = linears[i].linear.weight\n",
    "            score = torch.sum(torch.abs(weights), dim=0)\n",
    "            in_fold = linears[0].in_fold\n",
    "            #print(score.shape)\n",
    "            score = torch.sum(score.reshape(in_fold, int(score.shape[0]/in_fold)), dim=0)\n",
    "        elif i == num_linear:\n",
    "            # output layer\n",
    "            weights = linears[i-1].linear.weight\n",
    "            score = torch.sum(torch.abs(weights), dim=1)\n",
    "        else:\n",
    "            weights_in = linears[i-1].linear.weight\n",
    "            weights_out = linears[i].linear.weight\n",
    "            score = torch.sum(torch.abs(weights_out), dim=0) + torch.sum(torch.abs(weights_in), dim=1)\n",
    "        #print(score.shape)\n",
    "        top_index = torch.flip(torch.argsort(score),[0])[:top_k]\n",
    "        return top_index, score\n",
    "    \n",
    "    def relocate_ij(self, i, j):\n",
    "        # In the ith layer (of neurons), relocate the jth neuron\n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        if i < num_linear:\n",
    "            num_neuron = int(linears[i].linear.weight.shape[1]/linears[i].in_fold)\n",
    "        else:\n",
    "            num_neuron = linears[i-1].linear.weight.shape[0]\n",
    "        ccs = []\n",
    "        for k in range(num_neuron):\n",
    "            self.swap(i,j,k)\n",
    "            ccs.append(self.get_cc())\n",
    "            self.swap(i,j,k)\n",
    "        k = torch.argmin(torch.stack(ccs))\n",
    "        self.swap(i,j,k)\n",
    "            \n",
    "    def relocate_i(self, i):\n",
    "        # Relocate neurons in the ith layer\n",
    "        top_id = self.get_top_id(i, top_k=self.top_k)\n",
    "        for j in top_id[0]:\n",
    "            self.relocate_ij(i,j)\n",
    "            \n",
    "    def relocate(self):\n",
    "        # Relocate neurons in the whole model\n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        for i in range(num_linear+1):\n",
    "            self.relocate_i(i)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19dc02-e2cb-4947-b7d0-4e77d542bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f46ac-1078-4c54-8478-144cfbb8125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# i think steps need to be smaller than data size\n",
    "steps_oct = 2000\n",
    "data_size_oct = 80000\n",
    "steps = 9000\n",
    "data_size = 7000\n",
    "batch_size = 30\n",
    "\n",
    "log = 1000\n",
    "lamb = 0.01\n",
    "swap_log = 1000\n",
    "plot_log = 1000\n",
    "\n",
    "\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# todo change here\n",
    "if True:\n",
    "    from medmnist import OCTMNIST\n",
    "    train = OCTMNIST(split=\"train\", transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    test = OCTMNIST(split=\"test\", transform=torchvision.transforms.ToTensor(), download=True) \n",
    "    class_amount = 4\n",
    "elif True:\n",
    "    from medmnist import RetinaMNIST\n",
    "    t = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "        torchvision.transforms.ToTensor()\n",
    "         ])\n",
    "    # torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "    train = RetinaMNIST(split=\"train\", transform=t, download=True)\n",
    "    test = RetinaMNIST(split=\"test\", transform=t, download=True) \n",
    "    class_amount = 5\n",
    "else:\n",
    "    train = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    test = torchvision.datasets.MNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    class_amount = 10\n",
    "\n",
    "    \n",
    "train = torch.utils.data.Subset(train, range(data_size))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(network, dataset, device, N=2000, batch_size=5):\n",
    "    dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, labels in islice(dataset_loader, N // batch_size):\n",
    "                \n",
    "        #print(x.shape)\n",
    "        logits = network(x.to(device))\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        correct += torch.sum(predicted_labels == labels.to(device))\n",
    "        total += x.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def loss_f(network, dataset, device, N=2000, batch_size=5):\n",
    "    dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    loss = 0\n",
    "    total = 0\n",
    "    for x, labels in islice(dataset_loader, N // batch_size):\n",
    "        labels = labels.squeeze().long()\n",
    "        logits = network(x.to(device))\n",
    "        #print(\"logits\", logits)\n",
    "        #print(\"torch eye\", torch.eye(10,)[labels]) \n",
    "        loss += torch.sum(( logits-torch.eye(class_amount,)[labels].to(device) )**2)\n",
    "        total += x.size(0)\n",
    "    return loss / total\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "if True:\n",
    "    import medmnist\n",
    "    #from medmnist import INFO\n",
    "    #info = INFO['retinamnist']\n",
    "    #DataClass = getattr(medmnist, info['python_class'])\n",
    "    #train = DataClass(split='train', download=True)    \n",
    "    #test = DataClass(split='test', download=True)    \n",
    "    from medmnist import RetinaMNIST\n",
    "    train = RetinaMNIST(split=\"train\", transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    test = RetinaMNIST(split=\"test\", transform=torchvision.transforms.ToTensor(), download=True)\n",
    "else:\n",
    "    #train = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    #test = torchvision.datasets.MNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    train = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    test = torchvision.datasets.MNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "train = torch.utils.data.Subset(train, range(data_size))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def L2(model):\n",
    "    L2_ = 0.\n",
    "    for p in mlp.parameters():\n",
    "        L2_ += torch.sum(p**2)\n",
    "    return L2_\n",
    "\n",
    "def rescale(model, alpha):\n",
    "    for p in mlp.parameters():\n",
    "        p.data = alpha * p.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9198d-93f5-4ebc-8033-2e07c8b2b455",
   "metadata": {},
   "source": [
    "## Init + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaba6b2-84a5-4f6a-ac2c-77a856f63eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "22*22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca76264-09ab-4a84-b393-407c53173593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# width = 200\n",
    "mlp = BioMLP2D(shp=(784, 484, 484, class_amount))\n",
    "mlp.to(device)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(mlp.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "\n",
    "one_hots = torch.eye(class_amount, class_amount).to(device)\n",
    "\n",
    "print(\"item\", next(iter(train_loader))[0].shape)\n",
    "\n",
    "\n",
    "pbar = tqdm(islice(cycle(train_loader), steps), total=steps)\n",
    "\n",
    "best_train_loss = 1e4\n",
    "best_test_loss = 1e4\n",
    "best_train_acc = 0.\n",
    "best_test_acc = 0.\n",
    "\n",
    "\n",
    "\n",
    "for x, label in pbar:\n",
    "\n",
    "    mlp.train()\n",
    "\n",
    "    a = mlp(x.to(device))\n",
    "    \n",
    "    plt.imshow(  a.detach().cpu().numpy()  )\n",
    "    \n",
    "    break\n",
    "\n",
    "if False:\n",
    "    mlp.eval()\n",
    "    print(\"Initial accuracy: {0:.4f}\".format(accuracy(mlp, test, device, batch_size=batch_size)))\n",
    "\n",
    "\n",
    "    # todo create this directory\n",
    "    # or change in all following\n",
    "    torch.save(mlp.state_dict(), \"../results/oct_mnist/init.cptk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03950dc0-5ead-42a5-807e-cf0ca78128ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "784*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf7e35-5bbd-4a65-b642-ff6aae4a4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(BioMLP2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99b13d-2bd4-4adf-8c5d-30183b02630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "6000/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdb4e6-11e7-4395-a523-188be91d18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b27ed-bab2-443a-a1d1-01e68adcef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "23520/6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4d320-e608-4797-a6e2-63629887cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "23520/156800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f86338-377d-46d6-8252-915b217bd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "200/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8c3ff-8514-4352-b8ec-6af1b51f2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a144d10-ef3c-48d0-8499-9d42ddb78c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "1200/30/10/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31270d80-dd9f-4e2b-a222-e2a6044be59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "4*4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd29611-a95c-4603-8d80-eef3bd56692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2dbcb-26c0-40b4-9bc5-1a902f6be086",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083aeb06-6ced-498d-ac39-089b48eafcc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_accuracies = []\n",
    "train_accuracies = []\n",
    "\n",
    "step = 0\n",
    "mlp.train()\n",
    "pbar = tqdm(islice(cycle(train_loader), steps), total=steps)\n",
    "\n",
    "best_train_loss = 1e4\n",
    "best_test_loss = 1e4\n",
    "best_train_acc = 0.\n",
    "best_test_acc = 0.\n",
    "\n",
    "\n",
    "\n",
    "if True:\n",
    "#for i_batch, (x, label) enumerate(train_loader):\n",
    "\n",
    "    for x, label in pbar:\n",
    "\n",
    "        if step == int(steps/4):\n",
    "            lamb *= class_amount\n",
    "        elif step == int(steps/2):\n",
    "            lamb *= class_amount\n",
    "\n",
    "        label = label.squeeze().long()\n",
    "\n",
    "        #print(\"image\", x.type)\n",
    "        #print(label)\n",
    "        #print(\"label\", label.shape)\n",
    "        #print(\"one_hots[label]\", one_hots[label])\n",
    "        #print(\"one_hots[label]\", one_hots[label].shape)\n",
    "\n",
    "        mlp.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print(label)\n",
    "        loss_train = loss_fn(mlp(x.to(device)), one_hots[label]) # .long()\n",
    "        cc = mlp.get_cc(weight_factor=2.0, no_penalize_last=True)\n",
    "        total_loss = loss_train + lamb*cc\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % log == 0:\n",
    "            with torch.no_grad():\n",
    "                mlp.eval()\n",
    "                train_acc = accuracy(mlp, train, device).item()\n",
    "                test_acc = accuracy(mlp, test, device).item()\n",
    "                train_loss = loss_f(mlp, train, device).item()\n",
    "                test_loss = loss_f(mlp, test, device).item()\n",
    "\n",
    "                if train_acc > best_train_acc:\n",
    "                    best_train_acc = train_acc\n",
    "                if test_acc > best_test_acc:\n",
    "                    best_test_acc = test_acc\n",
    "                if train_loss < best_train_loss:\n",
    "                    best_train_loss = train_loss\n",
    "                if test_loss < best_test_loss:\n",
    "                    best_test_loss = test_loss\n",
    "                mlp.train()\n",
    "                pbar.set_description(\"{:3.3f} | {:3.3f} | {:3.3f} | {:3.3f} | {:3.3f} \".format(train_acc, test_acc, train_loss, test_loss, cc))\n",
    "        step += 1\n",
    "\n",
    "        if step % swap_log == 0:\n",
    "            mlp.relocate()\n",
    "\n",
    "        if (step-1) % plot_log == 0:\n",
    "\n",
    "            fig=plt.figure(figsize=(30,15))\n",
    "            ax=fig.add_subplot(projection='3d')\n",
    "\n",
    "            ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([0.5, 0.5, 2, 1]))\n",
    "            ax.scatter(mlp.linears[0].in_coordinates[:,0].detach().cpu().numpy(), mlp.linears[0].in_coordinates[:,1].detach().cpu().numpy(),[0]*784, s=5, alpha=0.5, c=train[46][0][0].detach().cpu().numpy()[:,::-1].reshape(-1,))\n",
    "            ax.scatter(mlp.linears[1].in_coordinates[:,0].detach().cpu().numpy(), mlp.linears[1].in_coordinates[:,1].detach().cpu().numpy(),[1]*484, s=5, alpha=0.5, color=\"black\")\n",
    "            ax.scatter(mlp.linears[2].in_coordinates[:,0].detach().cpu().numpy(), mlp.linears[2].in_coordinates[:,1].detach().cpu().numpy(),[2]*484, s=5, alpha=0.5, color=\"black\")\n",
    "            ax.scatter(mlp.linears[2].out_coordinates[:,0].detach().cpu().numpy(), mlp.linears[2].out_coordinates[:,1].detach().cpu().numpy(),[3]*class_amount, s=5, alpha=0.5, color=\"black\")\n",
    "            ax.set_zlim(-0.5,5)\n",
    "            ax.set_xlim(-0.2,1.2)\n",
    "            ax.set_ylim(-0.2,1.2)\n",
    "\n",
    "\n",
    "            for ii in range(3):\n",
    "                biolinear = mlp.linears[ii]\n",
    "                p = biolinear.linear.weight.clone()\n",
    "                p_shp = p.shape\n",
    "                p = p/torch.abs(p).max()\n",
    "\n",
    "                for i in range(p_shp[0]):\n",
    "                    #if i % 20 == 0:\n",
    "                    #    print(i)\n",
    "                    for j in range(p_shp[1]):\n",
    "                        out_xy = biolinear.out_coordinates[i].detach().cpu().numpy()\n",
    "                        in_xy = biolinear.in_coordinates[j].detach().cpu().numpy()\n",
    "                        plt.plot([out_xy[0], in_xy[0]], [out_xy[1], in_xy[1]], [ii+1,ii], lw=1*np.abs(p[i,j].detach().cpu().numpy()), color=\"blue\" if p[i,j]>0 else \"red\")\n",
    "\n",
    "\n",
    "            ring = mlp.linears[2].out_coordinates.detach().cpu().numpy()\n",
    "            for i in range(class_amount):\n",
    "                ax.text(ring[i,0], ring[i,1], 3.05, \"{}\".format(mlp.out_perm.long()[i].detach().cpu().numpy()))\n",
    "\n",
    "\n",
    "            ax.view_init(30,class_amount)\n",
    "\n",
    "            ax.text(0.3,0.25,3.5,\"step={}\".format(step-1), fontsize=15)\n",
    "\n",
    "            ax.axis('off')\n",
    "\n",
    "            plt.savefig('../results/oct_mnist/{0:06d}.png'.format(step-1))\n",
    "            torch.save(mlp.state_dict(), \"../results/oct_mnist/{0:06d}.cptk\".format(step-1))\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    torch.save(mlp.state_dict(), \"../results/oct_mnist/final.cptk\")\n",
    "\n",
    "    # 50, 3, 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f058a-f91f-42bf-930f-2fe1c9f4028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    mlp.load_state_dict(torch.load(\"../results/oct_mnist/final.cptk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef3eca-ff20-4a99-9ce1-623acb50e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "\n",
    "for i in range(1,3):\n",
    "    top_k = 784\n",
    "    linears = mlp.get_linear_layers()\n",
    "    num_linear = len(linears)\n",
    "    if i == 0:\n",
    "        # input layer\n",
    "        weights = linears[i].linear.weight\n",
    "        score = torch.sum(torch.abs(weights), dim=0)\n",
    "        in_fold = linears[0].in_fold\n",
    "        #print(score.shape)\n",
    "        score = torch.sum(score.reshape(in_fold, int(score.shape[0]/in_fold)), dim=0)\n",
    "    elif i == num_linear:\n",
    "        # output layer\n",
    "        weights = linears[i-1].linear.weight\n",
    "        score = torch.sum(torch.abs(weights), dim=1)\n",
    "    else:\n",
    "        weights_in = linears[i-1].linear.weight\n",
    "        weights_out = linears[i].linear.weight\n",
    "        score = torch.sum(torch.abs(weights_out), dim=0) + torch.sum(torch.abs(weights_in), dim=1)\n",
    "    #print(score.shape)\n",
    "    top_index = torch.flip(torch.argsort(score),[0])[:top_k]\n",
    "    score = score[top_index]\n",
    "    \n",
    "    num = score.shape[0]\n",
    "    \n",
    "    plt.plot(np.arange(num)+1, score.detach().cpu().numpy(), marker=\"o\", markersize=3)\n",
    "    \n",
    "#plt.xscale('log')\n",
    "\n",
    "plt.legend([\"hidden layer 1\", \"hidden layer 2\"], fontsize=15)\n",
    "plt.xlabel(\"Rank\", fontsize=15)\n",
    "plt.ylabel(\"Score\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8169890-24c7-4737-840d-82ffa1163740",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d42893-2370-4a82-9700-7e14a9aaa604",
   "metadata": {},
   "source": [
    "### Seems like this is only one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8ff7b-23d2-462a-8048-f8b880aa5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "top_k = 784\n",
    "linears = mlp.get_linear_layers()\n",
    "num_linear = len(linears)\n",
    "if i == 0:\n",
    "    # input layer\n",
    "    weights = linears[i].linear.weight\n",
    "    score = torch.sum(torch.abs(weights), dim=0)\n",
    "    in_fold = linears[0].in_fold\n",
    "    #print(score.shape)\n",
    "    score = torch.sum(score.reshape(in_fold, int(score.shape[0]/in_fold)), dim=0)\n",
    "elif i == num_linear:\n",
    "    # output layer\n",
    "    weights = linears[i-1].linear.weight\n",
    "    score = torch.sum(torch.abs(weights), dim=1)\n",
    "else:\n",
    "    weights_in = linears[i-1].linear.weight\n",
    "    weights_out = linears[i].linear.weight\n",
    "    score = torch.sum(torch.abs(weights_out), dim=0) + torch.sum(torch.abs(weights_in), dim=1)\n",
    "#print(score.shape)\n",
    "top_index = torch.flip(torch.argsort(score),[0])[:top_k]\n",
    "score = score[top_index]\n",
    "\n",
    "num = score.shape[0]\n",
    "\n",
    "features = mlp.linears[0].linear.weight[top_index].reshape(100,28,28).detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "\n",
    "    plt.imshow(features[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"score=%.2f\"%(score[i]), color=\"red\", fontsize=15,y=0.8)\n",
    "    \n",
    "    \n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "plt.savefig(\"../results/oct_mnist/final_mnist_features.pdf\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a481a7-437e-4420-8506-7a36250e5a2a",
   "metadata": {},
   "source": [
    "### Seems like these are 3 layers combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd20982-b469-400b-b9a1-b66c4f0e4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# im_f2 = torch.argsort(mlp.linears[2].linear.weight[4])[-1]\n",
    "im_f2 = torch.argsort(mlp.linears[2].linear.weight[3])[-1] # [0, n_classes-1]\n",
    "im_f1 = torch.argsort(mlp.linears[1].linear.weight[im_f2,:])\n",
    "\n",
    "features = mlp.linears[0].linear.weight[im_f1].reshape(400,28,28).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "mlp.linears[1].linear.weight[im_f2,:]\n",
    "for i in range(400):\n",
    "    plt.subplot(20,20,i+1)\n",
    "\n",
    "    plt.imshow(features[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"weight=%.2f\"%(mlp.linears[1].linear.weight[im_f2,im_f1[i]]), color=\"red\", fontsize=15,y=0.8)\n",
    "    \n",
    "    \n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b6f07-f8a8-47e7-9199-7dc5eb497904",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17e28a-bb60-4650-8c9f-4e33fbb4b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "156800/28/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a7142-fef7-4a2b-96c7-260bf86eb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "156800/784/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88466d75-f7d5-438c-8448-20c3c701661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "40000/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb3a35-cfb7-4370-8ae2-2f10fcea3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efc443-2e67-4389-9997-bedb6930ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# im_f2 = torch.argsort(mlp.linears[2].linear.weight[4])[-1]\n",
    "im_f2 = torch.argsort(mlp.linears[2].linear.weight[0])[-1]\n",
    "features = torch.argsort(mlp.linears[1].linear.weight).reshape(400,20,20).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "mlp.linears[1].linear.weight[im_f2,:]\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "\n",
    "    plt.imshow(features[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"weight=%.2f\"%(mlp.linears[1].linear.weight[im_f2,im_f1[i]]), color=\"red\", fontsize=15,y=0.8)\n",
    "    \n",
    "    \n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd51290-418c-427a-b7e0-3c4a2f9d0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "160000/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504af1f1-fbde-47f3-8f7b-a35e10ff6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "20*20*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d272a-c600-4309-a0d7-c2cc82e31808",
   "metadata": {},
   "outputs": [],
   "source": [
    "200*20*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821209c0-e784-4415-9335-07cfdebd02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "40000/28/28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b837a2-3e45-49f7-95d9-62ab5ce69275",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argsort(mlp.linears[2].linear.weight[0]) # [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba48fe4-621e-4a93-b9ec-1f356ccd3a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268d6c3-0442-4ec2-b09b-e7c745e260e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.linears[2].linear.weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171bae8-5a6f-47f8-8513-28efc6a951b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.linears[2].linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3770f-e651-405c-a7d6-587d47063c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.linears[1].linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8fc2a6-1241-40ca-8776-fc12b1083117",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.linears[0].linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584a2445-d196-4adc-989b-80c0f20d4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe195d0-906d-4014-a0cd-d08a4ae1ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10f808-9c0b-40f4-9bbc-20c57110ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12439c4-2e31-4ee2-b900-70679baedbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchsummary.summary(mlp, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12f65c-9c61-4b36-8158-ee5dbf5b81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*1*10*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94048dbc-a31a-45e6-b6d5-db54bd31641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchsummary.summary(torchvision.models.resnet50().to(\"cuda\"), (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c39da-ad71-4f26-a88f-35eebb6cf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3633e4-7f7c-42c0-87bc-3974fb83da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1acc67-0b1f-430a-9fe5-a3bfa41575e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.linears[0].linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6f342-5dcf-43f5-9491-1a22dbd4b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d92ae2-ce87-4ad1-b5a9-a4b643f63a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f1928-5c97-40ed-88cf-cc1dee77091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_f1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f693bf-036f-44ea-a845-c7c568a2eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17ad99-f3a0-4015-b5ec-192f5827e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee3c7-d7f0-498c-a83b-216944d1f558",
   "metadata": {},
   "source": [
    "## Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd6dca-1789-4a03-a3b0-2b0c424a48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "\n",
    "nums = [2000,100,20]\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    plt.subplot(1,3,i+1)\n",
    "\n",
    "    weights = mlp.linears[i].linear.weight.reshape(-1,)\n",
    "    weights = weights[torch.argsort(weights)]\n",
    "    plt.plot(-weights[:nums[i]].detach().cpu().numpy(), marker=\"o\", markersize=3)\n",
    "    plt.plot(weights[-nums[i]:].detach().cpu().numpy()[::-1], marker=\"o\", markersize=3)\n",
    "    plt.xlabel(\"rank\", fontsize=15)\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"abs(weight)\", fontsize=15)\n",
    "        plt.legend([\"positive\", \"negative\"])\n",
    "    plt.title(\"Layer {}\".format(i+1))\n",
    "    \n",
    "    \n",
    "plt.savefig(\"../results/mnist/mnist_weights.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09300e-4f70-42b5-bc34-3b4ce3cf2c9e",
   "metadata": {},
   "source": [
    "# BIMT with convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93b3b05c-caa3-4795-86c2-b9a1ae9bded3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nloss_fn = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\\n \\nn_epochs = 20\\nfor epoch in range(n_epochs):\\n    for inputs, labels in trainloader:\\n        # forward, backward, and then weight update\\n        y_pred = model(inputs)\\n        loss = loss_fn(y_pred, labels)\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n \\n    acc = 0\\n    count = 0\\n    for inputs, labels in testloader:\\n        y_pred = model(inputs)\\n        acc += (torch.argmax(y_pred, 1) == labels).float().sum()\\n        count += len(labels)\\n    acc /= count\\n    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\\n \\ntorch.save(model.state_dict(), \"cifar10model.pth\")\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    " \n",
    "    \n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "    torchvision.transforms.ToTensor()\n",
    "     ])\n",
    "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    " \n",
    "#trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    " \n",
    "#batch_size = 32\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "#testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    " \n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        #self.drop1 = nn.Dropout(0.3)\n",
    " \n",
    "        self.conv2 = nn.Conv2d(6, 4, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.conv1x1 = nn.Conv2d(4, 5, kernel_size=(1,1))       \n",
    "        \n",
    "        # need global max pooling here??\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        #import torch.nn.functional as F\n",
    "        #output = F.max_pool2d(input, kernel_size=input.size()[2:])\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    " \n",
    "        #self.fc3 = nn.Linear(8192, 512)\n",
    "        #self.act3 = nn.ReLU()\n",
    "        #self.drop3 = nn.Dropout(0.5)\n",
    " \n",
    "        #self.fc4 = nn.Linear(512, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \n",
    "        print(\"shapes\")\n",
    "        print(\"***************\")\n",
    "        # input 3x32x32, output 32x32x32\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.act1(self.conv1(x))\n",
    "        #x = self.drop1(x)\n",
    "        # input 32x32x32, output 32x32x32\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.act2(self.conv2(x))\n",
    "        # input 32x32x32, output 32x16x16\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        # global max pooling\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size=x.size()[2:]).squeeze(-1).squeeze(-1)\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        # x = self.pool2(x)\n",
    "        # input 32x16x16, output 8192\n",
    "        x = self.flat(x)\n",
    "        # input 8192, output 512\n",
    "        #x = self.act3(self.fc3(x))\n",
    "        #x = self.drop3(x)\n",
    "        # input 512, output 10\n",
    "        #x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = CIFAR10Model()\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "\"\"\"\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    " \n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        # forward, backward, and then weight update\n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "    acc = 0\n",
    "    count = 0\n",
    "    for inputs, labels in testloader:\n",
    "        y_pred = model(inputs)\n",
    "        acc += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
    "        count += len(labels)\n",
    "    acc /= count\n",
    "    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n",
    " \n",
    "torch.save(model.state_dict(), \"cifar10model.pth\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f85dbafe-9e92-4858-b04f-6642de36aa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIFAR10Model(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (conv2): Conv2d(6, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (conv1x1): Conv2d(4, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7872dcc-56ec-42da-b745-97ca8eb9ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes\n",
      "***************\n",
      "torch.Size([2, 1, 100, 100])\n",
      "torch.Size([2, 6, 100, 100])\n",
      "torch.Size([2, 6, 50, 50])\n",
      "torch.Size([2, 4, 50, 50])\n",
      "torch.Size([2, 4, 25, 25])\n",
      "torch.Size([2, 5, 25, 25])\n",
      "torch.Size([2, 5])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 100, 100]              60\n",
      "              ReLU-2          [-1, 6, 100, 100]               0\n",
      "         MaxPool2d-3            [-1, 6, 50, 50]               0\n",
      "            Conv2d-4            [-1, 4, 50, 50]             220\n",
      "              ReLU-5            [-1, 4, 50, 50]               0\n",
      "         MaxPool2d-6            [-1, 4, 25, 25]               0\n",
      "            Conv2d-7            [-1, 5, 25, 25]              25\n",
      "           Flatten-8                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 305\n",
      "Trainable params: 305\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 1.23\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 1.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model, (1, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3401b5a0-14d8-4c0d-8675-2aa54eb525af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 3, 3])\n",
      "torch.Size([6])\n",
      "torch.Size([4, 6, 3, 3])\n",
      "torch.Size([4])\n",
      "torch.Size([5, 4, 1, 1])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "# print(params[0])\n",
    "for param in params:\n",
    "    print(param.size())\n",
    "#print(params[0].size())\n",
    "#print(params[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9931dbd3-3d17-4285-9a2d-136a819f2188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Conv2d(6, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "shapes\n",
      "***************\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 6, 128, 128])\n",
      "torch.Size([1, 6, 64, 64])\n",
      "torch.Size([1, 4, 64, 64])\n",
      "torch.Size([1, 4, 32, 32])\n",
      "torch.Size([1, 5, 32, 32])\n",
      "torch.Size([1, 5])\n",
      "amount of feature maps: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from helper.visualisation.feature_map import *\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('examples/example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "# tensor preparation\n",
    "#to_tensor = transforms.ToTensor()\n",
    "#img = to_tensor(img).to(device)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "    torchvision.transforms.Resize(350),\n",
    "    torchvision.transforms.CenterCrop((128,128)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "     ])\n",
    "\n",
    "img = transform(img).to(device)\n",
    "\n",
    "\n",
    "# layer to focus on\n",
    "#print(\"*\"*50)\n",
    "#print(\"example graph nodes:\", get_graph_node_names(model)[0][0:20])\n",
    "#print(\"*\"*50)\n",
    "layer = model.conv2 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "\n",
    "# run feature map\n",
    "dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "dd.run(img)\n",
    "dd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f079b3da-eb5c-48e7-817d-7d0aec486644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.66666666666667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "350/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50c9cba8-b5f9-41d9-acce-28eac21fb440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*2*2*2*2*2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4836f70-2a9c-4b65-9a10-cbbc1d38365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Conv2d(4, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "shapes\n",
      "***************\n",
      "torch.Size([1, 1, 128, 128])\n",
      "torch.Size([1, 6, 128, 128])\n",
      "torch.Size([1, 6, 64, 64])\n",
      "torch.Size([1, 4, 64, 64])\n",
      "torch.Size([1, 4, 32, 32])\n",
      "torch.Size([1, 5, 32, 32])\n",
      "torch.Size([1, 5])\n",
      "amount of feature maps: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from helper.visualisation.feature_map import *\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('examples/example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "# tensor preparation\n",
    "#to_tensor = transforms.ToTensor()\n",
    "#img = to_tensor(img).to(device)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "    torchvision.transforms.Resize(350),\n",
    "    torchvision.transforms.CenterCrop((128,128)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "     ])\n",
    "img = transform(img).to(device)\n",
    "\n",
    "\n",
    "# layer to focus on\n",
    "#print(\"*\"*50)\n",
    "#print(\"example graph nodes:\", get_graph_node_names(model)[0][0:20])\n",
    "#print(\"*\"*50)\n",
    "layer = model.conv1x1 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "\n",
    "# run feature map\n",
    "dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "dd.run(img)\n",
    "dd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "748cd6e2-0c0f-4330-86f8-b6900d56aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 3, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAABUCAYAAABUfVhoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEvklEQVR4nO3dUUjdZRjH8d8zGhs2Vywj5o1RIUXhdLvwcoEXMaHlWhfddyOCF16ZRrGL5t0YXQThVReCVqAjRCHCrsQYbaDDMTYcmUuIiBpubV3U08WOICc9Pscdn511vh84oP/z+7//V9Afr0ff8zd3FwBk2vOoJwCg9lA8ANJRPADSUTwA0lE8ANJRPADSUTyQJJnZHTN7ofDx52b28aOeE/6/KJ4aY2Y/mtm9QtGsPxrd/YC739wk/7qZ3dqFeXSY2TUz+9PMvjOzpkpfA9WL4qlNbxaKZv2xulsXMrMnNjnWIGlc0oeSDkn6QdIXuzUHVB+KB5IkM3Mze6no2JOSpiU1blwdmdkeM3vfzJbM7Dcz+9LMDhXOeb4w1ntm9pOkmU0u97akRXf/yt3vSzoj6YiZvby7XyWqBcWDLbn7XUknJK0WrY56JXVJOi6pUdLvkj4tOv24pFckvbHJ0K9Kmi+6zlLhOGoAxVObLpjZH4XHhR2c3y3pA3e/5e5/6cGK5Z2iX6vOuPtdd7+3yfkHJN0uOnZbUv0O5oLH0H9+/0ZN6HL3bx/i/CZJE2b2z4Zjf0t6bsPnKyXOvyPpYNGxg5LWHmJOeIyw4sF2Nnv7ghVJJ9z96Q2P/e7+8zbnrVuUdGT9k8JrSS8WjqMGUDzYzi+SnjGzpzYc+0zS2fU/gZvZs2b2VhljTkh6zcxOm9l+SR9JWnD3axWbNaoaxYOSCmUwKulm4TWhRkmfSPpa0jdmtibpe0ntZYz5q6TTks7qwQvT7ZLerfTcUb2MNwIDkI0VD4B0FA+AdBQPgHQUD4B0Jf+B0Mx45RnAjri7bfUcKx4A6SgeAOkoHgDpKB4A6SgeAOkoHgDpKB4A6SgeAOkoHgDpKB4A6Sr2nsu9vb3hbE9PTzjb1BS7z1tdXV14zLW1+Fv7nj9/Ppy9evVqODs2NhbOTkxMhLOdnZ3hbFdXVzg7PT0dyu3duzc85uzsbDh7+fLlcLa7uzucPXnyZDjb0tISzh47diycPXXqVCg3MjISHnN1NX6rtHLm2tHREc6WwooHQDqKB0A6igdAOooHQDqKB0A6igdAOooHQDqKB0A6igdAOooHQLqKbZm4ceNGOHv06NFwtpztAlErKyvh7Llz58LZpaWlcLacLRMLCwvhbF9fXzg7PDwczka3TIyOjobHbG8P325dbW1t4Ww5xsfHw9nDhw+Hs3NzczuZTknz8/Ph7KVLl8LZcn52K4UVD4B0FA+AdBQPgHQUD4B0FA+AdBQPgHQUD4B0FA+AdBQPgHQUD4B05u5bP2m29ZNF+vv7wxcdGhoKZ69cuRLKtba2hsfct29fODs1NRXOXrx4MZwdGBgIZ6N32pCk5eXlcLa5uTmcvX79eihnZuExZ2ZmwtlytiAMDg6Gs4uLi+Hs5ORkOFtfXx/ORu+6UupntVhDQ0M4W873eDnbXNx9y28GVjwA0lE8ANJRPADSUTwA0lE8ANJRPADSUTwA0lE8ANJRPADSUTwA0lVsywQAbMSWCQBVheIBkI7iAZCO4gGQjuIBkI7iAZCO4gGQjuIBkI7iAZCO4gGQruSWCQDYDax4AKSjeACko3gApKN4AKSjeACko3gApPsXc4okVAUgzuUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAABUCAYAAABUfVhoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEZElEQVR4nO3dT0jkdRjH8c8jYUIuRhHBiBrZRUFhD9JF3PUUq0R7yFu3Ll3Ci6DgxUPdSwhSUMKLEGHSJcrIy4Kd9uBB7OCSrf8hCmyRku3pMhtizvg4js+6+n7BwMz8Pr/fPIJ8+M4wv9+YuwsAMtU87QEAXD8UD4B0FA+AdBQPgHQUD4B0FA+AdBQPZGZ/mtnrxftfmNlHT3smXG0UzzViZr+Y2UGxaJ7cCu5e7+4PTsjfNrONKs9Qa2ZfFWdxM7tdzePj2UDxXD9vF4vmyW3rol7IzJ4rsemepPck7VzUa+Nyo3ig4srjjWPPvSDpW0mFo6sjM6sxsxEzWzOz38zsSzN7qbjPa8VjvW9mv0r68fhrufvf7v6Ju9+T9Djj78PlQ/HgRO7+SNIdSVvHVkcfSror6ZakgqTfJX12bPdbktokvZU3MZ4lFM/1M29mfxRv8xXs/4GkUXffcPe/JI1JevfY26oxd3/k7gdVmBdXUKn34Li67rr7D+fYv0XS12b2z5HnHkt69cjjh+c4Pq4BVjwo56RLFzyUdMfdXzxyq3P3zVP2A/5D8aCcXUkvm1nDkec+l/SxmbVIkpm9YmbvnOWgZva8mdUVH9aaWZ2ZWXVGxrOA4kFJ7r4qaVbSg+JnQgVJn0r6RtL3ZrYv6SdJb57x0D9LOpDUKOm74v2Wqg2OS8+4EBiAbKx4AKSjeACko3gApKN4AKQr+wVCM+OTZwAVcfeSX5FgxQMgHcUDIB3FAyAdxQMgHcUDIB3FAyAdxQMgHcUDIB3FAyAdxQMgXdWuudzc3BzOjo6OhrMTExOh3P3798PHnJqaCmd3d3fD2bW1tQuZoampKZzt7OwMZ3t6esLZ4eHhUG5hYSF8zM3NzdNDRb29veFsS0v8mmLd3d3h7Pj4eDi7sxP/ybC+vr5wNqqjoyOcPTw8DGdXV1crGed/WPEASEfxAEhH8QBIR/EASEfxAEhH8QBIR/EASEfxAEhH8QBIR/EASFe1Uybq6+vD2dra2nA2espEV1dX+Jitra3hbE1NvJsbGxvD2bOcMjE4OBjODg0NhbM3btwIZ6MWFxfD2bm5uXD25s2blYxzqunp6XC2UCiEs/v7+5WMU9bKyko4OzMzE87Ozs5WMs65sOIBkI7iAZCO4gGQjuIBkI7iAZCO4gGQjuIBkI7iAZCO4gGQjuIBkK5qp0z09/eHs0tLS+Hs2NhYBdOUt729Hc5ubW2Fs21tbZWMc6r29vZwdmRkJJzd29urZJyyzvKLGMvLy+Hs5ORkJeOcan5+PpwdGBgIZxsaGiqYpryz/H+d5TSbjY2NcHZ9fT2cLYcVD4B0FA+AdBQPgHQUD4B0FA+AdBQPgHQUD4B0FA+AdBQPgHQUD4B05u6lN5qV3ggAZbi7ldrGigdAOooHQDqKB0A6igdAOooHQDqKB0A6igdAOooHQDqKB0A6igdAurKnTADARWDFAyAdxQMgHcUDIB3FAyAdxQMgHcUDIN2/a5j6rz2CYvQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAABUCAYAAABUfVhoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEo0lEQVR4nO3c32vVdRzH8dcrvAgLqsUcLcQxQkl0iAgFaYYo4cVo/0AilBBq5mVXIbRuvAsMZCANUoYb2OhGLImgm7zyKuzCZOgmRPSD1g+Q1ruLjnEY+/E+8/h2c88HHDj7fl/fz/ezi/Pi8z18v8cRIQCo9MiDngCA1YfiAVCO4gFQjuIBUI7iAVCO4gFQjuKBbP9uu7fxftj24IOeEx5uFM8qYnvC9l+Norn76o6IxyPixhz5V2xPtnkOL9r+wvbPtn+0PWb7mXaeA8sfxbP69DeK5u7r9v06ke01c2x+StKQpB5JGyRNS/r4fs0ByxPFA9kO28/N2vaYpIuSuptXR7Yfsf2u7e9t/2R71HZH45iexlhv2L4p6cvZ54qIixExFhG/RcSfkk5Jeqng38QyQvFgThHxh6T9km7PWh29LWlA0m5J3ZJ+kfTRrMN3S3pe0quJU70s6dt2zRsrw1xLYTzcxm3/3Xj/VUQMtHj8W5KORsSkJNk+Iemm7debMicaxbUg232S3pP0WotzwApH8aw+AxFx+R6O3yDpU9v/NG2bkdTV9PetxQZpXNpdlPRORHx9D/PBCsSlFhYy108X3JK0PyKebHo9GhFTixz3P9sbJF2W9H5EfNLG+WKFoHiwkB8kPW37iaZtpyV90CgP2e60nb5Usv2s/vvS+VREnG7rbLFiUDyYV0R8J2lE0g3bv9rulvShpM8kfW57WtI3kl5oYdg3JfVKOtF8P1G7547lzfwQGIBqrHgAlKN4AJSjeACUo3gAlFvwBkLbfPMMYEkiwvPtY8UDoBzFA6AcxQOgHMUDoBzFA6AcxQOgHMUDoBzFA6AcxQOgHMUDoFzbfnN5ZmYmnd23b186e/78+VSus7MzPeauXbvS2bVr16azIyMj6WxHR0c6OzExkc6Oj4+ns604fvx4Krdjx470mFu2bElnt2/fns4eO3YsnT106FA6OzQ0lM6uWZP/aGU/OydPnkyPOTY2ls4eOXIknT148GA6uxBWPADKUTwAylE8AMpRPADKUTwAylE8AMpRPADKUTwAylE8AMpRPADKte2RibNnz6azZ86cSWdbufU8q5VHGwYGBtLZqampJcxmcUePHk1nDxw4kM5euXJlKdNZ0OHDh9PZVm7r37Nnz1Kms6iurq509tq1a+nsxo0b2z7u5ORkesz169ens729velsu7DiAVCO4gFQjuIBUI7iAVCO4gFQjuIBUI7iAVCO4gFQjuIBUI7iAVDOETH/Tnv+nbNs3bo1fdJWHoO4dOlSKrdu3br0mNPT0+ns6OhoOrtz5850dtOmTens3r1709mrV6+ms/39/ens8PBwKnfu3Ln0mNu2bUtnBwcH09lWHom5c+dOOnvhwoV0tq+vL53dvHlzOpt1/fr1dLaVz2NPT086GxGebx8rHgDlKB4A5SgeAOUoHgDlKB4A5SgeAOUoHgDlKB4A5SgeAOUoHgDl2vbIBAA045EJAMsKxQOgHMUDoBzFA6AcxQOgHMUDoBzFA6AcxQOgHMUDoBzFA6Dcgo9MAMD9wIoHQDmKB0A5igdAOYoHQDmKB0A5igdAuX8B4DYQLPDMcq4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAABUCAYAAABUfVhoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEpklEQVR4nO3dMWhVZxjG8eexDqUpVUxLIRVS2jgki3TKlnSpbYSqiDiLdeiQIDhItYuCKbgUSg04dmvtUqlDIUo3pUO0k7QOilQjprVobUULpm8HrxBC7vW98foazf8HB5Jzn/Odjwt5+O7NOfc6IgQAlVY87QkAWH4oHgDlKB4A5SgeAOUoHgDlKB4A5SgeyPY/tt9q/PyV7UNPe054vlE8y4jty7bvNorm4dYTES9HxKUF8u/avtrhOQzYnrJ9s7Gdsj3QyXNg6aN4lp8PG0XzcLv2pE5ke+UCu69J2iZpjaRXJX0v6ZsnNQcsTRQPZDts983b1yXpB0k9c1dHtlfY/sT2Rdt/2v7W9prGMW82xvrI9m+Sfpx/roi4FRGX48El85Y0K6lvfg7PN4oHC4qIO5JGJF2btzoak7RF0rCkHkk3JU3MO3xYUr+k95uNb/uWpHuSvpT0Wafnj6WN4ll+jtu+1diOL+L4jyV9GhFXI+JfSQckbZv3supARNyJiLvNBomI1ZJWSRqV9PMi5oFn2EKvwfF82xIRpx7j+F5J39n+b86+WUmvz/n9SmagiLhj+6ikP2z3R8TvjzEvPENY8aCVhT664IqkkYhYPWd7MSKmH3FcMyskvSTpjceZKJ4tFA9amZHUbXvVnH1HJY3b7pUk26/Z3pwd0PZ7tt+x/YLtVyR9rgfvE/3SyYljaaN40FRE/Crpa0mXGu8J9Uj6Qg/+BT5p+29JP0kabGPY1Y0x/5J0UdLbkj6IiHudnDuWNvNBYACqseIBUI7iAVCO4gFQjuIBUK7lBYS2eecZwKJEhJs9xooHQDmKB0A5igdAOYoHQDmKB0A5igdAOYoHQDmKB0A5igdAOYoHQLmOfeby7OxsOrt///50dmxsLJVbu3ZtesxNmzals+fPn09njxw5ks6OjIyks6Ojo+nshg0b0tl2ZJ+zzZvTH0aorVu3prN79+5NZ2dmZtLZ7du3p7M7duxIZ69fv57O7ty5M5Xr7u5Oj5n9u5GkkydPprOnT59OZ1thxQOgHMUDoBzFA6AcxQOgHMUDoBzFA6AcxQOgHMUDoBzFA6AcxQOgXMdumWjnkvbh4eF09tixY4uZTksXLlxIZ3ft2pXOtnPLRDvOnTuXzk5NTaWz2Uv127F79+509sSJE+ns5ORkOrt+/fp0duPGjelsV1dXOnv27Nl0Nqud22zGx8c7fv5OYsUDoBzFA6AcxQOgHMUDoBzFA6AcxQOgHMUDoBzFA6AcxQOgHMUDoFzHbpno7e1NZ8+cOZPO9vX1LWY6Le3bty+dbeebBe7fv5/OrlyZf+r7+/vT2Xa+5WFgYCCdzWrnOdizZ086u27dusVM55Fu376dzg4NDaWz09PT6ezExEQqd/jw4fSYBw8eTGcHBwfT2Rs3bqSzrbDiAVCO4gFQjuIBUI7iAVCO4gFQjuIBUI7iAVCO4gFQjuIBUI7iAVDOEdH8Qbv5gwDQQkS42WOseACUo3gAlKN4AJSjeACUo3gAlKN4AJSjeACUo3gAlKN4AJSjeACUa3nLBAA8Cax4AJSjeACUo3gAlKN4AJSjeACUo3gAlPsfrHsTyp3pf84AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "\n",
    "def visChannels(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.title(f\"Channels with index {ch}\")\n",
    "    plt.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "\n",
    "def visFilters(tensor, filt=0, allkernels=False, nrow=8, padding=1): \n",
    "    f,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(f*c, -1, w, h)\n",
    "    elif f != 3: tensor = tensor[filt,:,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.title(f\"Filter {filt}\")\n",
    "    plt.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    \n",
    "layer = 1\n",
    "filter = model.conv2.weight.data.clone()\n",
    "\n",
    "print(model.conv2.weight.shape)\n",
    "\n",
    "in_channels = 6\n",
    "out_filters = 4\n",
    "\n",
    "for filt in range(0, out_filters):\n",
    "    \n",
    "    visFilters(filter, filt=filt, allkernels=False)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    \n",
    "for ch in range(0, in_channels):\n",
    "    \n",
    "    visChannels(filter, ch=ch, allkernels=False)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2de06-6894-4661-8d63-155e87e6ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "\n",
    "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "\n",
    "layer = 1\n",
    "filter = model.conv2.weight.data.clone()\n",
    "\n",
    "print(model.conv2.weight.shape)\n",
    "\n",
    "for ch in range(0,9):\n",
    "    visTensor(filter, ch=ch, allkernels=False)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dd968-3f32-480b-9ff6-6671ce149968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "h5Tv2km0K77I",
   "metadata": {
    "id": "h5Tv2km0K77I"
   },
   "source": [
    "# 𝔽𝕦𝕟𝕔𝕥𝕚𝕠𝕟 𝕔𝕒𝕝𝕝𝕤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca581f7-22aa-4923-a1b9-22c23033aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = Configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750b8b5-bf7e-47e2-b215-39b5f4d46df9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3ZIQeL3VK-BI",
    "outputId": "61172eba-eea9-4ed1-95f0-9d02836c332c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if configs.run_decentblocks:\n",
    "    decentblock_routine(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6vh627W0zPLo",
   "metadata": {
    "id": "6vh627W0zPLo"
   },
   "outputs": [],
   "source": [
    "if configs.run_decentnet:\n",
    "    decentnet_routine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pRGZLABtzQdE",
   "metadata": {
    "id": "pRGZLABtzQdE"
   },
   "outputs": [],
   "source": [
    "if configs.run_baseline:\n",
    "    baseline_routine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O-MGutwczQ7L",
   "metadata": {
    "id": "O-MGutwczQ7L"
   },
   "outputs": [],
   "source": [
    "if configs.run_visualisation:\n",
    "    visualisation_routine()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nPKap00_wfgL"
   ],
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
