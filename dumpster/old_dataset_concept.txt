class EyeDataset(Dataset):
    # =============================================================================
    #
    # Parent Dataset
    # create objects based on child class
    #
    # =============================================================================

    def __init__(self, mode, image_size=500, ci_concept=0):
        super(EyeDataset, self).__init__()
        self.mode = mode
        self.image_size = image_size
        
        self.ci_concept = ci_concept

        self.transforms = transforms.Compose(self._get_transforms())
            
        self.set_dataset()
         
    def __len__(self):
        return len(self.csv_data)

    def get_class_labels(self):
        return list(self.csv_data["label"])
    
    def __getitem__(self, index):
        # =============================================================================
        # parameters:
        #   index of single image from dataloader
        # returns:
        #   dictionary "item" with:
        #       image (transformed)
        #       label
        # notes:
        # =============================================================================
        
        if torch.is_tensor(index):
            index=index.tolist()

        path = self.csv_data.iloc[index]['image_path']       
        image = Image.open(path)
            
        if self.transforms:
            # apply transforms to both images
            tct = TwoCropTransform(self.transforms)
            image = tct(image)
            
        
        # print(image)
            
        label = self.csv_data.iloc[index]['label']
        
        # To change: you can add labels here
        item = {
            'image' : image,
            'label' : label
        } 
        
        return item
    
    def _get_transforms(self):
        # =============================================================================
        # notes:
        #   overwritten for training set
        #   when overwriting a transform, use own function ToTensor instead of transforms.ToTensor
        #   dream_c{label}_{patch_id}.jpg
        # =============================================================================
        
        transform_list = []
        transform_list.append(ResizeCrop(self.image_size))
        transform_list.append(RandomAugmentations())
        transform_list.append(ToTensor())
        transform_list.append(Normalise())
        return transform_list
    
    def set_dataset(self):
        
        image_path = []
        label = []
        
        # iterate over files in concepts path directory
        # won't work since in other dirs now
        for ci_dir in os.listdir(concepts_path):
            this_concept_path = os.path.join(concepts_path, ci_dir)
            for filename in os.listdir(this_concept_path):
                # cluster_i is 1, rest is 0
                if filename.split("_")[1] == self.ci_concept:
                    label.append(1) # positive class
                    image_path.append(os.path.join(this_concept_path, filename))
                else:
                    label.append(0) # negative class
                    image_path.append(os.path.join(this_concept_path, filename))
        
        dict = {"image_path" : image_path, "label" : label}
        self.csv_data = pd.DataFrame(dict)
        
        if False:
            self.csv_data = self.csv_data.sample(frac=1, random_state=19).reset_index(drop=True)

            percent95 = int(len(self.csv_data)/100*95)
            
            if self.mode == "train":
                # 95% of data
                self.csv_data = self.csv_data[0:percent95]
                print("trainset length", len(self.csv_data))
                print("value count:", self.csv_data['label'].value_counts())
            
            else:
                # 5% of data
                self.csv_data = self.csv_data[percent95:-1]
                print("valset length",len(self.csv_data))
                print("value count:", self.csv_data['label'].value_counts())
