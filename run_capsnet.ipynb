{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd75e23-5b69-4480-a980-78b4a088f8ba",
   "metadata": {},
   "source": [
    "# CapsNet\n",
    "\n",
    "Source: https://github.com/jindongwang/Pytorch-CapsuleNet/blob/master/test_capsnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f462ec-3df5-48d2-b172-ab138222cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.insert(0, \"helper\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# datasceyence\n",
    "# =============================================================================\n",
    "from helper.visualisation.feature_map import *\n",
    "from helper.model.capsnet import CapsNet\n",
    "\n",
    "from helper.data.mnist import DataMNIST\n",
    "from helper.data.retinamnist import DataRetinaMNIST\n",
    "from helper.data.octmnist import DataOCTMNIST\n",
    "\n",
    "#train_kwargs[\"device\"] = True if torch.cuda.is_available() else False\n",
    "#train_kwargs[\"batch_size\"] = 5\n",
    "# train_kwargs[\"epochs\"] = 30\n",
    "#LEARNING_RATE = 0.01\n",
    "#MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad47ea8-0626-42aa-bd36-0d4ac28b4aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "torch 2.0.0 == False -> 1.13.1\n"
     ]
    }
   ],
   "source": [
    "seed = 1997 # was 19 before\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "debug_model = False\n",
    "\n",
    "print('torch 2.0.0 ==', torch.__version__=='2.0.0' , '->', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990acab7-0253-4a9c-b389-21e13cf3c639",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0744652e-8f2c-4a02-972c-94d107a86f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kwargs {'result_path': 'examples/example_results', 'exp_name': 'debug_oct_no_fc', 'load_ckpt_file': 'version_18/checkpoints/epoch=4-unpruned=192-val_f1=0.12.ckpt', 'epochs': 5, 'img_size': 28, 'batch_size': 2, 'log_every_n_steps': 4, 'device': 'cuda', 'num_workers': 0, 'train_size': 20, 'val_size': 20, 'test_size': 10}\n",
      "model kwargs {'in_channels': 1, 'n_classes': None, 'criterion': CrossEntropyLoss(), 'optimizer': 'sgd', 'base_lr': 0.001, 'min_lr': 1e-05, 'momentum': 0.9, 'lr_update': 100, 'cnn_in_channels': 1, 'cnn_out_channels': 256, 'cnn_kernel_size': 9, 'pc_num_capsules': 8, 'pc_in_channels': 256, 'pc_out_channels': 32, 'pc_kernel_size': 9, 'pc_num_routes': 1152, 'dc_num_capsules': 10, 'dc_num_routes': 1152, 'dc_in_channels': 8, 'dc_out_channels': 16, 'input_width': 28, 'input_height': 28}\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = { # for 1 Channel\n",
    "    'in_channels' : 1,\n",
    "    'n_classes': None, # filled in the dataset\n",
    "    'criterion': torch.nn.CrossEntropyLoss(),# torch.nn.BCEWithLogitsLoss(),\n",
    "    'optimizer': \"sgd\", # sgd adamw\n",
    "    'base_lr': 0.001,\n",
    "    'min_lr' : 0.00001,\n",
    "    'momentum' : 0.9,\n",
    "    'lr_update' : 100,\n",
    "    \n",
    "    # CNN (cnn)\n",
    "    'cnn_in_channels' : 1, # duplicate ...\n",
    "    'cnn_out_channels' : 256,\n",
    "    'cnn_kernel_size' : 9,\n",
    "\n",
    "    # Primary Capsule (pc)\n",
    "    'pc_num_capsules' : 8,\n",
    "    'pc_in_channels' : 256,\n",
    "    'pc_out_channels' : 32,\n",
    "    'pc_kernel_size' : 9,\n",
    "    'pc_num_routes' : 32 * 6 * 6,\n",
    "\n",
    "    # Digit Capsule (dc)\n",
    "    'dc_num_capsules' : 10,\n",
    "    'dc_num_routes' : 32 * 6 * 6,\n",
    "    'dc_in_channels' : 8,\n",
    "    'dc_out_channels' : 16,\n",
    "\n",
    "    # Decoder\n",
    "    'input_width' : 28,\n",
    "    'input_height' : 28,\n",
    "}\n",
    "\n",
    "\n",
    "train_kwargs = {\n",
    "    'result_path': \"examples/example_results\", # \"example_results/lightning_logs\", # not in use??\n",
    "    'exp_name': \"debug_oct_no_fc\", # must include oct or retina\n",
    "    'load_ckpt_file' : 'version_18/checkpoints/epoch=4-unpruned=192-val_f1=0.12.ckpt', # \"version_0/checkpoints/epoch=94-unpruned=1600-val_f1=0.67.ckpt\", # 'version_94/checkpoints/epoch=26-step=1080.ckpt', # change this for loading a file and using \"test\", if you want training, keep None\n",
    "    'epochs': 5, # including the pretrain epochs - no adding up\n",
    "    'img_size' : 28, #168, # keep mnist at original size, training didn't work when i increased the size ... # MNIST/MedMNIST 28 × 28 Pixel\n",
    "    'batch_size': 2, # 128, # the higher the batch_size the faster the training - every iteration adds A LOT OF comp cost\n",
    "    'log_every_n_steps' : 4, # lightning default: 50 # needs to be bigger than the amount of steps in an epoch (based on trainset size and batchsize)\n",
    "    'device': \"cuda\",\n",
    "    'num_workers' : 0, # 18, # 18 for computer, 0 for laptop\n",
    "    'train_size' : (2 * 10), # total or percentage\n",
    "    'val_size' : (2 * 10), # total or percentage\n",
    "    'test_size' : 10, # total or percentage - 0 for all\n",
    "}\n",
    "\n",
    "print(\"train kwargs\", train_kwargs)\n",
    "print(\"model kwargs\", model_kwargs)\n",
    "\n",
    "kwargs = {'train_kwargs':train_kwargs, 'model_kwargs':model_kwargs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4fc53-bb9f-4aca-bd75-2735382f81fa",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905a9a83-47d6-49cd-93b7-6ae79ae110c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\Prinzessin\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Prinzessin\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Prinzessin\\.medmnist\\octmnist.npz\n",
      "python_class : OCTMNIST\n",
      "description : The OCTMNIST is based on a prior dataset of 109,309 valid optical coherence tomography (OCT) images for retinal diseases. The dataset is comprised of 4 diagnosis categories, leading to a multi-class classification task. We split the source training set with a ratio of 9:1 into training and validation set, and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−1,536)×(277−512). We center-crop the images and resize them into 1×28×28.\n",
      "url : https://zenodo.org/record/6496656/files/octmnist.npz?download=1\n",
      "MD5 : c68d92d5b585d8d81f7112f81e2d0842\n",
      "task : multi-class\n",
      "label : {'0': 'choroidal neovascularization', '1': 'diabetic macular edema', '2': 'drusen', '3': 'normal'}\n",
      "n_channels : 1\n",
      "n_samples : {'train': 97477, 'val': 10832, 'test': 1000}\n",
      "license : CC BY 4.0\n"
     ]
    }
   ],
   "source": [
    "data = DataOCTMNIST(train_kwargs, model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac1f14-6a5c-4f04-b2c7-25f056f0ade2",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c2bdf-1780-477b-8219-f89a18cd7317",
   "metadata": {},
   "source": [
    "## Lightning - should become lightning later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae14845-2ea3-4bbb-ad11-3637277e2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, epoch):\n",
    "    capsule_net = model\n",
    "    capsule_net.train()\n",
    "    n_batch = len(list(enumerate(train_loader)))\n",
    "    total_loss = 0\n",
    "    for batch_id, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        # one hot\n",
    "        try:\n",
    "            # print(target)\n",
    "            # tensor([6, 5])\n",
    "            target = torch.sparse.torch.eye(10).index_select(dim=0, index=target)\n",
    "        except: \n",
    "            # print(target.squeeze(1))\n",
    "            # tensor([6, 5])\n",
    "            target = torch.sparse.torch.eye(10).index_select(dim=0, index=target.squeeze(1))\n",
    "        \n",
    "        # print(target)\n",
    "        # tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        # [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct = sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
    "        train_loss = loss.item()\n",
    "        total_loss += train_loss\n",
    "        if batch_id % 100 == 0:\n",
    "            tqdm.write(\"Epoch: [{}/{}], Batch: [{}/{}], train accuracy: {:.6f}, loss: {:.6f}\".format(\n",
    "                epoch,\n",
    "                train_kwargs[\"epochs\"],\n",
    "                batch_id + 1,\n",
    "                n_batch,\n",
    "                correct / float(train_kwargs[\"batch_size\"]),\n",
    "                train_loss / float(train_kwargs[\"batch_size\"])\n",
    "                ))\n",
    "    tqdm.write('Epoch: [{}/{}], train loss: {:.6f}'.format(epoch,train_kwargs[\"epochs\"],total_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def val(capsule_net, val_dataloader, epoch):\n",
    "    capsule_net.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    for batch_id, (data, target) in enumerate(val_dataloader):\n",
    "    \n",
    "        # one hot\n",
    "        try:\n",
    "            # print(target)\n",
    "            # tensor([6, 5])\n",
    "            target = torch.sparse.torch.eye(10).index_select(dim=0, index=target)\n",
    "        except: \n",
    "            # print(target.squeeze(1))\n",
    "            # tensor([6, 5])\n",
    "            target = torch.sparse.torch.eye(10).index_select(dim=0, index=target.squeeze(1))\n",
    "        \n",
    "        # print(target)\n",
    "        # tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        # [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        correct += sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
    "                       np.argmax(target.data.cpu().numpy(), 1))\n",
    "\n",
    "    tqdm.write(\n",
    "        \"Epoch: [{}/{}], val accuracy: {:.6f}, loss: {:.6f}\".format(epoch, train_kwargs[\"epochs\"], correct / len(val_dataloader.dataset),\n",
    "                                                                  val_loss / len(val_dataloader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151e4aa-106b-403d-888e-a832754268fc",
   "metadata": {},
   "source": [
    "## run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a15297-ab76-4195-a6f3-bd1aad143765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:09<01:25,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Batch: [1/10], train accuracy: 0.000000, loss: 0.450048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], train loss: 0.442028\n",
      "Epoch: [1/5], val accuracy: 0.350000, loss: 0.811564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:00<00:03,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/5], Batch: [1/10], train accuracy: 0.500000, loss: 0.403726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/5], train loss: 0.391593\n",
      "Epoch: [2/5], val accuracy: 0.350000, loss: 0.777948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:00<00:03,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/5], Batch: [1/10], train accuracy: 1.000000, loss: 0.369839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/5], train loss: 0.346521\n",
      "Epoch: [3/5], val accuracy: 0.350000, loss: 0.771700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:00<00:03,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/5], Batch: [1/10], train accuracy: 1.000000, loss: 0.207192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/5], train loss: 0.294726\n",
      "Epoch: [4/5], val accuracy: 0.350000, loss: 0.733908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:00<00:03,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5], Batch: [1/10], train accuracy: 0.500000, loss: 0.206109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/5], train loss: 0.224895\n",
      "Epoch: [5/5], val accuracy: 0.350000, loss: 0.723684\n"
     ]
    }
   ],
   "source": [
    "capsule_net = CapsNet(model_kwargs)\n",
    "capsule_net = torch.nn.DataParallel(capsule_net)\n",
    "\n",
    "capsule_net = capsule_net.cuda()\n",
    "capsule_net = capsule_net.module\n",
    "\n",
    "optimizer = torch.optim.Adam(capsule_net.parameters())\n",
    "\n",
    "for e in range(1, train_kwargs[\"epochs\"] + 1):\n",
    "    train(capsule_net, optimizer, data.train_dataloader, e)\n",
    "    val(capsule_net, data.val_dataloader, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839efe65-be4e-4277-9bb5-3ddd4aacade0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14b84e-4bd3-418f-a27e-30d282b2859b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362f6a1-3c48-4c32-86d8-cedbc2501fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
