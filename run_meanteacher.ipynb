{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75832305-6091-4f3c-980a-53004f01a000",
   "metadata": {},
   "source": [
    "# ð•Šð•–ð•žð•š-ð•Šð•¦ð•¡ð•–ð•£ð•§ð•šð•¤ð•–ð•• ð•ð•–ð•’ð•£ð•Ÿð•šð•Ÿð•˜ ð•¦ð•¤ð•šð•Ÿð•˜ ð•„ð•–ð•’ð•Ÿ ð•‹ð•–ð•’ð•”ð•™ð•–ð•£\n",
    "\n",
    "Implementation of pixel-wise Mean Teacher (MT)\n",
    "    \n",
    "This method is proposed in the paper: \n",
    "    'Mean Teachers are Better Role Models:\n",
    "        Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results'\n",
    "This implementation only supports Gaussian noise as input perturbation, and the two-heads\n",
    "outputs trick is not available.\n",
    "\n",
    "Source:\n",
    "https://github.com/ZHKKKe/PixelSSL/blob/master/pixelssl/ssl_algorithm/ssl_mt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6f142-82ee-4f0a-87f8-e2e9eeeb89b6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f3932a-744a-49ca-a076-f12749cf3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "from helper.dataset.mean_teacher import *\n",
    "# from helper.model.mean_teacher import * \n",
    "from helper.sampler.mixed_batch import *\n",
    "from helper.model.block.noise_block import GaussianNoiseBlock\n",
    "from helper.compute.compute_bin_seg import BCE_BinSeg_CU\n",
    "from helper.compute.loss.shape import ShapeLoss\n",
    "from helper.compute.loss.dice import DiceLoss\n",
    "\n",
    "#from pixelssl.utils import REGRESSION, CLASSIFICATION\n",
    "#from pixelssl.utils import logger, cmd, tool\n",
    "#from pixelssl.nn import func\n",
    "#from pixelssl.nn.module import patch_replication_callback, GaussianNoiseLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a707779-ab4d-46a4-ab5b-e123f91b827a",
   "metadata": {},
   "source": [
    "# Experiment Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d1aa89-5640-4263-8051-96580d7d0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # =============================================================================\n",
    "        # \n",
    "        # =============================================================================\n",
    "        \n",
    "        self.prefix = \"tmp\"\n",
    "        self.reduced_data = False\n",
    "        \n",
    "        # smp unet ++ parameters\n",
    "        self.encoder_name = \"efficientnet-b7\"\n",
    "        self.encoder_weights = \"imagenet\"\n",
    "        self.in_channels =  1\n",
    "        self.classes = 1\n",
    "        \n",
    "        self.epochs = 100\n",
    "        \n",
    "        self.gaussian_noise = 0.1 # None\n",
    "        \n",
    "        self.ema_decay = 0.999 # default value\n",
    "        \n",
    "        # Sizes of tensors must match except in dimension 1\n",
    "        # I solved the issue by resizing all the images size divisible to 32.\n",
    "        self.image_size = 128 # 512\n",
    "        \n",
    "        self.num_workers = 0\n",
    "        self.iterations = 50\n",
    "        \n",
    "        # batch size = n_samples_per_class_per_batch * classes\n",
    "        # for mixed batch sampling\n",
    "        self.n_samples_per_class_per_batch = 1\n",
    "        \n",
    "        self.lbs = 3 #  self.args.labeled_batch_size # .... remove this eventually and replace\n",
    "\n",
    "        # optimisation\n",
    "        self.optimiser = \"sgd\"\n",
    "        self.learning_rate = 0.01\n",
    "        self.min_learning_rate = 0.0001\n",
    "        self.weight_decay = 1e-4\n",
    "        self.momentum = 0.9\n",
    "        \n",
    "        # self.is_epoch_lrer = True # epoch or batch based learning rate updater\n",
    "        \n",
    "        self.dropout = None\n",
    "        \n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Paths\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.base_path = r\"C:/Users/Prinzessin/projects/decentnet\"\n",
    "        if not os.path.exists(self.base_path):\n",
    "            os.makedirs(self.base_path)\n",
    "        os.chdir(self.base_path) # this is now the main directory !!!!!!!!!!!!!!!!!!!!\n",
    "        \n",
    "        self.csv_filenames = glob.glob(r\"datasceyence/data_prep/mt_*.csv\")\n",
    "        \n",
    "        print(self.csv_filenames)\n",
    "        \n",
    "        # input\n",
    "        self.load_checkpoint_file = None\n",
    "        \n",
    "        # all csv files used for run_mean_teacher.ipybn\n",
    "        #self.csv_data_paths = [\n",
    "        #    {\"path\" : r\"data/data_ichallenge_amd.csv\"}, \n",
    "        #    {\"path\" : r\"data/data_ichallenge_non_amd.csv\"}\n",
    "        #]\n",
    "        \n",
    "        # output\n",
    "        self.logger_path = f\"results/{self.prefix}\"\n",
    "        if not os.path.exists(self.logger_path):\n",
    "            os.makedirs(self.logger_path)\n",
    "            \n",
    "        self.save_checkpoint_path = f\"results/{self.prefix}/ckpts\"\n",
    "        if not os.path.exists(self.save_checkpoint_path):\n",
    "            os.makedirs(self.save_checkpoint_path)\n",
    "            \n",
    "        \n",
    "    def log(self):\n",
    "        # =============================================================================\n",
    "        # save all class variables to file \"configs.txt\"\n",
    "        # =============================================================================\n",
    "        c = pd.DataFrame.from_dict({'key': self.__dict__.keys(), 'value': self.__dict__.values()})\n",
    "        c.to_csv(os.path.join(self.logger_path, \"configs.txt\"), sep=':', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c64cbd-0bd5-4220-9f34-b7ff564d21ae",
   "metadata": {},
   "source": [
    "# Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7605a7f6-d147-4551-b403-928659086b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutineMT:\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(RoutineMT, self).__init__()\n",
    "        \n",
    "        self.configs = configs\n",
    "        \n",
    "        self.prefix = configs.prefix\n",
    "        self.ema_decay = configs.ema_decay\n",
    "        \n",
    "        self.load_ckpt = torch.load(configs.load_checkpoint_file) if configs.load_checkpoint_file is not None else None\n",
    "        \n",
    "        self.step_counter = 0\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Models\n",
    "        # =============================================================================\n",
    "        s_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.classes,                  # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        \n",
    "        t_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.classes,                  # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        # detach the teacher model\n",
    "        for param in t_model.parameters():\n",
    "            param.detach_()\n",
    "            \n",
    "        self.models = {'s': s_model, \n",
    "                       't': t_model}\n",
    "        \n",
    "        # add gaussian noise\n",
    "        # currently not in use\n",
    "        self.gaussian_noiser = GaussianNoiseBlock(self.configs.gaussian_noise).cuda()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Computing Units\n",
    "        # =============================================================================\n",
    "        self.computing_unit = {\n",
    "            \"s\" : BCE_BinSeg_CU(),\n",
    "            \"t\" : BCE_BinSeg_CU()\n",
    "        }\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Optimisers\n",
    "        # =============================================================================\n",
    "        self.optims = {'s': torch.optim.SGD(self.models[\"s\"].parameters(), lr=self.configs.learning_rate, momentum=self.configs.momentum) # optimizer_funcs[0](self.models[\"s\"].module.param_groups)\n",
    "                          }\n",
    "\n",
    "        # =============================================================================\n",
    "        # Learning rate schedulers\n",
    "        # =============================================================================\n",
    "        self.lrsers = {'s': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optims[\"s\"], \n",
    "                                                                              T_0 = 32, # number of iterations for the first restart.\n",
    "                                                                              eta_min = self.configs.min_learning_rate\n",
    "                                                                               )\n",
    "                      \n",
    "                     } # lrer_funcs[0](self.optimizers['s_optimizer'])\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Loss functions\n",
    "        # =============================================================================\n",
    "        # TODO: support more types of the consistency criterion\n",
    "        # something with head and each head has a loss function attached??\n",
    "        self.criterions = {'s_shape': ShapeLoss(), # criterion_funcs[0](self.args),\n",
    "                           's_pixel': DiceLoss(mode=\"BINARY_MODE\"), \n",
    "                           # TODO\n",
    "                           # BINARY_MODE MULTICLASS_MODE - the loss wants a different encoding ...\n",
    "                           # ground_truth = torch.nn.functional.one_hot(ground_truth, num_classes)  # N,H*W -> N,H*W, C\n",
    "                           # ground_truth = ground_truth.permute(0, 2, 1)  # N, C, H*W\n",
    "                           # RuntimeError: one_hot is only applicable to index tensor.\n",
    "                           'cons': torch.nn.MSELoss()\n",
    "                          }\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Datasets: train, val, test\n",
    "        # =============================================================================\n",
    "                \n",
    "        train_set = MeanTeacherDataset(mode=\"train\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames)\n",
    "        train_mbs = MixedBatchSampler(train_set.get_mbs_labels(), n_samples_per_class_per_batch=self.configs.n_samples_per_class_per_batch)\n",
    "        \n",
    "        val_set = MeanTeacherDataset(mode=\"val\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames)\n",
    "                \n",
    "        self.dataloader = {\"train\" : DataLoader(train_set, batch_sampler=train_mbs),\n",
    "                           \"val\" :   DataLoader(val_set)\n",
    "                          }\n",
    "          \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Resume training\n",
    "        # =============================================================================\n",
    "        if self.load_ckpt:\n",
    "            self.models[\"s\"].load_state_dict(self.load_ckpt['s_model'])\n",
    "            self.models[\"t\"].load_state_dict(self.load_ckpt['t_model'])\n",
    "            self.optims[\"s\"].load_state_dict(self.load_ckpt['s_optimizer'])\n",
    "            self.lrsers[\"s\"].load_state_dict(self.load_ckpt['s_lrer'])\n",
    "\n",
    "\n",
    "    \n",
    "    def run_training(self, epoch):\n",
    "        \n",
    "        mode=\"train\"\n",
    "        \n",
    "        self.models[\"s\"].train()\n",
    "        self.models[\"t\"].train()\n",
    "        \n",
    "        for idx, item in enumerate(self.dataloader[mode]):\n",
    "            # =============================================================================\n",
    "            # Process Batch\n",
    "            # =============================================================================\n",
    "                        \n",
    "            # reset student optimiser\n",
    "            self.optims[\"s\"].zero_grad()\n",
    "            \n",
    "            s_model_output = self.models[\"s\"](item[\"img\"]) # img_t\n",
    "            \n",
    "            s_model_output = torch.nn.functional.softmax(s_model_output)\n",
    "            \n",
    "            print(\"s model\")\n",
    "            print(s_model_output)\n",
    "            print(item[\"msk\"])\n",
    "            print(s_model_output.shape)\n",
    "            print(item[\"msk\"].shape)\n",
    "            print(\"next\")\n",
    "            \n",
    "            # run student batch\n",
    "            s_epoch_collector = self.computing_unit[\"s\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output, ground_truth=item[\"msk\"], mode=mode)\n",
    "\n",
    "            print(\"sigmoid\")\n",
    "            \n",
    "            def sigmoid_rampup(current, rampup_length):\n",
    "                \"\"\" Exponential rampup from https://arxiv.org/abs/1610.02242 . \n",
    "                \"\"\"\n",
    "                if rampup_length == 0:\n",
    "                    return 1.0\n",
    "                else:\n",
    "                    current = np.clip(current, 0.0, rampup_length)\n",
    "                    phase = 1.0 - current / rampup_length\n",
    "                    return float(np.exp(-5.0 * phase * phase))\n",
    "            \n",
    "            # calculate the ramp-up coefficient of the consistency constraint\n",
    "            # use mean squared error as the consistency cost and ramp up its weight from 0 to its final value during the first 80 epochs. \n",
    "            self.step_counter += 1\n",
    "            total_steps = 5 # len(self.dataloader[\"train\"]) * 100 # self.args.cons_rampup_epochs # ????\n",
    "            cons_rampup_scale = sigmoid_rampup(self.step_counter, total_steps)\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Teacher Model\n",
    "            # =============================================================================\n",
    "            \n",
    "            # forward the teacher model\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                t_model_output = self.models[\"t\"](item[\"img\"]) # img_t\n",
    "                                \n",
    "                self.computing_unit[\"t\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=t_model_output, ground_truth=item[\"msk\"], mode=mode)\n",
    "                \n",
    "                \"\"\"\n",
    "                t_resulter, t_debugger = self.t_model.forward(t_inp)\n",
    "                if not 'pred' in t_resulter.keys():\n",
    "                    self._pred_err()\n",
    "                t_pred = tool.dict_value(t_resulter, 'pred')\n",
    "                t_activated_pred = tool.dict_value(t_resulter, 'activated_pred')\n",
    "            \n",
    "                # calculate 't_task_loss' for recording\n",
    "                l_t_pred = func.split_tensor_tuple(t_pred, 0, lbs)\n",
    "                l_t_inp = func.split_tensor_tuple(t_inp, 0, lbs)\n",
    "                t_task_loss = self.s_criterion.forward(l_t_pred, l_gt, l_t_inp)\n",
    "                t_task_loss = torch.mean(t_task_loss)\n",
    "                self.meters.update('t_task_loss', t_task_loss.data)\n",
    "                \"\"\"\n",
    "            # =============================================================================\n",
    "            # Consistency Loss\n",
    "            # =============================================================================\n",
    "            # calculate the consistency constraint from the teacher model to the student model\n",
    "            t_pseudo_gt = Variable(t_model_output[0].detach().data, requires_grad=False)\n",
    "\n",
    "            if True: # self.args.cons_for_labeled:\n",
    "                cons_loss = self.criterions[\"cons\"](s_model_output[0], t_pseudo_gt)\n",
    "            elif False: # self.args.unlabeled_batch_size > 0:\n",
    "                cons_loss = self.criterions[\"cons\"](s_model_output[0][lbs:, ...], t_pseudo_gt[lbs:, ...])\n",
    "            else:\n",
    "                cons_loss = self.zero_tensor\n",
    "            cons_loss = cons_rampup_scale * torch.mean(cons_loss) # self.args.cons_scale * \n",
    "\n",
    "            # =============================================================================\n",
    "            # Backprop for student model\n",
    "            # =============================================================================\n",
    "            loss = s_epoch_collector[\"loss\"] + cons_loss\n",
    "            loss.backward()\n",
    "            \n",
    "            print(\"loss\")\n",
    "            print(loss)\n",
    "            \n",
    "            \n",
    "            self.optims[\"s\"].step()\n",
    "            \n",
    "            \n",
    "\n",
    "            # =============================================================================\n",
    "            # EMA for teacher model\n",
    "            # =============================================================================\n",
    "            # self._update_ema_variables(self.s_model, self.t_model, self.args.ema_decay, cur_step)\n",
    "            self.ema_decay = min(1 - 1 / (self.step_counter + 1), self.ema_decay)\n",
    "            for t_param, s_param in zip(self.models[\"t\"].parameters(), self.models[\"s\"].parameters()):\n",
    "                t_param.data.mul_(self.ema_decay).add_(1 - self.ema_decay, s_param.data)\n",
    "            \n",
    "            # =============================================================================\n",
    "            # LR Scheduler (Batch)\n",
    "            # =============================================================================\n",
    "            # if not self.configs.is_epoch_lrer:\n",
    "            self.lrsers[\"s\"].step()\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Process Epoch\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.computing_unit[\"s\"].run_epoch()\n",
    "        self.computing_unit[\"t\"].run_epoch()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # LR Scheduler (Epoch)\n",
    "        # =============================================================================\n",
    "        #if self.configs.is_epoch_lrer:\n",
    "        #    self.lrsers[\"s\"].step()\n",
    "\n",
    "    def run_validation(self, data_loader, epoch):\n",
    "        self.s_model.eval()\n",
    "        self.t_model.eval()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # for each batch\n",
    "        # =============================================================================\n",
    "\n",
    "        for idx, item in enumerate(self.dataloader[\"val\"]):\n",
    "            \n",
    "            timer = time.time()\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Student\n",
    "            # =============================================================================\n",
    "\n",
    "            s_resulter, s_debugger = self.s_model.forward(s_inp)\n",
    "            if not 'pred' in s_resulter.keys() or not 'activated_pred' in s_resulter.keys():\n",
    "                self._pred_err()\n",
    "            s_pred = tool.dict_value(s_resulter, 'pred')\n",
    "            s_activated_pred = tool.dict_value(s_resulter, 'activated_pred')\n",
    "\n",
    "            s_task_loss = self.s_criterion.forward(s_pred, gt, s_inp)\n",
    "            s_task_loss = torch.mean(s_task_loss)\n",
    "            self.meters.update('s_task_loss', s_task_loss.data)\n",
    "\n",
    "            # =============================================================================\n",
    "            # Teacher\n",
    "            # =============================================================================\n",
    "            \n",
    "            t_resulter, t_debugger = self.t_model.forward(t_inp)\n",
    "            if not 'pred' in t_resulter.keys() or not 'activated_pred' in t_resulter.keys():\n",
    "                self._pred_err()\n",
    "            t_pred = tool.dict_value(t_resulter, 'pred')\n",
    "            t_activated_pred = tool.dict_value(t_resulter, 'activated_pred')\n",
    "\n",
    "            t_task_loss = self.s_criterion.forward(t_pred, gt, t_inp)\n",
    "            t_task_loss = torch.mean(t_task_loss)\n",
    "            self.meters.update('t_task_loss', t_task_loss.data)\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Pseudo ???\n",
    "            # =============================================================================\n",
    "\n",
    "            t_pseudo_gt = Variable(t_pred[0].detach().data, requires_grad=False)\n",
    "            cons_loss = self.cons_criterion(s_pred[0], t_pseudo_gt)\n",
    "            cons_loss = self.args.cons_scale * torch.mean(cons_loss)\n",
    "            self.meters.update('cons_loss', cons_loss.data)\n",
    "\n",
    "            #self.task_func.metrics(s_activated_pred, gt, s_inp, self.meters, id_str='student')\n",
    "            #self.task_func.metrics(t_activated_pred, gt, t_inp, self.meters, id_str='teacher')\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Logger\n",
    "            # =============================================================================\n",
    "            \n",
    "            self.meters.update('batch_time', time.time() - timer)\n",
    "            if idx % self.args.log_freq == 0:\n",
    "                logger.log_info('step: [{0}][{1}/{2}]\\tbatch-time: {meters[batch_time]:.3f}\\n'\n",
    "                                '  student-{3}\\t=>\\t'\n",
    "                                's-task-loss: {meters[s_task_loss]:.6f}\\t'\n",
    "                                's-cons-loss: {meters[cons_loss]:.6f}\\n'\n",
    "                                '  teacher-{3}\\t=>\\t'\n",
    "                                't-task-loss: {meters[t_task_loss]:.6f}\\n'\n",
    "                                .format(epoch + 1, idx, len(data_loader), self.args.task, meters=self.meters))\n",
    "\n",
    "            if self.args.visualize and idx % self.args.visual_freq == 0:\n",
    "                self._visualize(epoch, idx, False, \n",
    "                                func.split_tensor_tuple(s_inp, 0, 1, reduce_dim=True),\n",
    "                                func.split_tensor_tuple(s_activated_pred, 0, 1, reduce_dim=True),\n",
    "                                func.split_tensor_tuple(t_inp, 0, 1, reduce_dim=True),\n",
    "                                func.split_tensor_tuple(t_activated_pred, 0, 1, reduce_dim=True),\n",
    "                                func.split_tensor_tuple(gt, 0, 1, reduce_dim=True))\n",
    "    \n",
    "        # =============================================================================\n",
    "        # Metrics\n",
    "        # =============================================================================\n",
    "        # metrics\n",
    "        metrics_info = {'student': '', 'teacher': ''}\n",
    "        for key in sorted(list(self.meters.keys())):\n",
    "            #if self.task_func.METRIC_STR in key:\n",
    "            if True:\n",
    "                for id_str in metrics_info.keys():\n",
    "                    if key.startswith(id_str):\n",
    "                        metrics_info[id_str] += '{0}: {1:.6}\\t'.format(key, self.meters[key])\n",
    "\n",
    "        logger.log_info('Validation metrics:\\n  student-metrics\\t=>\\t{0}\\n  teacher-metrics\\t=>\\t{1}\\n'\n",
    "            .format(metrics_info['student'].replace('_', '-'), metrics_info['teacher'].replace('_', '-')))\n",
    "\n",
    "    def run_cleanup(self, epoch):\n",
    "        # =============================================================================\n",
    "        # Logger\n",
    "        # =============================================================================\n",
    "        \n",
    "        # if save_model is True:\n",
    "        \n",
    "        if epoch > 5 and self.computing_unit[\"s\"].epoch_collector[\"fscore\"] > self.computing_unit[\"s\"].best[\"fscore\"]:\n",
    "            state = {\n",
    "                'name': self.prefix,\n",
    "                'epoch': epoch, \n",
    "                's_model': self.models[\"s\"].state_dict(),\n",
    "                't_model': self.models[\"t\"].state_dict(),\n",
    "                's_optim': self.optims[\"s\"].state_dict(),\n",
    "                's_lrer': self.lrsers[\"s\"].state_dict()\n",
    "            }\n",
    "\n",
    "            checkpoint = os.path.join(self.configs.save_checkpoint_path, 'checkpoint_{0}.ckpt'.format(epoch))\n",
    "            torch.save(state, checkpoint)\n",
    "            \n",
    "            self.computing_unit[\"s\"].best[\"fscore\"] = self.computing_unit[\"s\"].epoch_collector[\"fscore\"]\n",
    "            \n",
    "        self.computing_unit[\"s\"].reset_epoch()\n",
    "        self.computing_unit[\"t\"].reset_epoch()\n",
    "        \n",
    "        \n",
    "    def log(self, epoch):\n",
    "        # =============================================================================\n",
    "        # Logger\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.meters.update('batch_time', time.time() - timer)\n",
    "        if idx % self.args.log_freq == 0:\n",
    "            logger.log_info('step: [{0}][{1}/{2}]\\tbatch-time: {meters[batch_time]:.3f}\\n'\n",
    "                            '  student-{3}\\t=>\\t'\n",
    "                            's-task-loss: {meters[s_task_loss]:.6f}\\t'\n",
    "                            's-cons-loss: {meters[cons_loss]:.6f}\\n'\n",
    "                            '  teacher-{3}\\t=>\\t'\n",
    "                            't-task-loss: {meters[t_task_loss]:.6f}\\n'\n",
    "                            .format(epoch + 1, idx, len(data_loader), self.args.task, meters=self.meters))\n",
    "\n",
    "        # visualization\n",
    "        if self.args.visualize and idx % self.args.visual_freq == 0:\n",
    "            self._visualize(epoch, idx, True, \n",
    "                            func.split_tensor_tuple(s_inp, 0, 1, reduce_dim=True),\n",
    "                            func.split_tensor_tuple(s_activated_pred, 0, 1, reduce_dim=True),\n",
    "                            func.split_tensor_tuple(t_inp, 0, 1, reduce_dim=True),\n",
    "                            func.split_tensor_tuple(t_activated_pred, 0, 1, reduce_dim=True),\n",
    "                            func.split_tensor_tuple(gt, 0, 1, reduce_dim=True))\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    # Tool Functions for SSL_MT\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "\n",
    "    def _visualize(self, epoch, idx, is_train, \n",
    "                   s_inp, s_pred, t_inp, t_pred, gt):\n",
    "\n",
    "        visualize_path = self.args.visual_train_path if is_train else self.args.visual_val_path\n",
    "        out_path = os.path.join(visualize_path, '{0}_{1}'.format(epoch, idx))\n",
    "\n",
    "        #self.task_func.visualize(out_path, id_str='student', inp=s_inp, pred=s_pred, gt=gt)\n",
    "        #self.task_func.visualize(out_path, id_str='teacher', inp=t_inp, pred=t_pred, gt=gt)\n",
    "\n",
    "    def _batch_prehandle(self, inp, gt, is_train):\n",
    "        # add extra data augmentation process here if necessary\n",
    "\n",
    "        # 'self.gaussian_noiser' will add the noise to the first input element\n",
    "        s_inp_var, t_inp_var = [], []\n",
    "        for idx, i in enumerate(inp):\n",
    "            if is_train and idx == 0:\n",
    "                s_inp_var.append(self.gaussian_noiser.forward(Variable(i).cuda())) \n",
    "                t_inp_var.append(self.gaussian_noiser.forward(Variable(i).cuda())) \n",
    "            else:\n",
    "                s_inp_var.append(Variable(i).cuda()) \n",
    "                t_inp_var.append(Variable(i).cuda())\n",
    "        s_inp = tuple(s_inp_var)\n",
    "        t_inp = tuple(t_inp_var)\n",
    "        \n",
    "        gt_var = []\n",
    "        for g in gt:\n",
    "            gt_var.append(Variable(g).cuda())\n",
    "        gt = tuple(gt_var)\n",
    "\n",
    "        return s_inp, t_inp, gt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0440659-d578-4ae9-a2d5-88331279c1cc",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de02c93-618e-464e-afc8-8da004a671e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasceyence/data\\\\mt_data_ichallenge_amd.csv', 'datasceyence/data\\\\mt_data_ichallenge_glaucoma.csv', 'datasceyence/data\\\\mt_data_ichallenge_non_amd.csv', 'datasceyence/data\\\\mt_data_ichallenge_unlabelled.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\AppData\\Local\\Temp\\ipykernel_15424\\1214844690.py:123: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  s_model_output = torch.nn.functional.softmax(s_model_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s model\n",
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "torch.Size([4, 1, 128, 128])\n",
      "torch.Size([4, 1, 128, 128])\n",
      "next\n",
      "sigmoid\n",
      "loss\n",
      "tensor(0.9681, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\AppData\\Local\\Temp\\ipykernel_15424\\1214844690.py:212: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  t_param.data.mul_(self.ema_decay).add_(1 - self.ema_decay, s_param.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s model\n",
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "torch.Size([4, 1, 128, 128])\n",
      "torch.Size([4, 1, 128, 128])\n",
      "next\n",
      "sigmoid\n",
      "loss\n",
      "tensor(1.0389, grad_fn=<AddBackward0>)\n",
      "s model\n",
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "torch.Size([4, 1, 128, 128])\n",
      "torch.Size([4, 1, 128, 128])\n",
      "next\n",
      "sigmoid\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15424\\3253320090.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#run.run_validation(epoch=epoch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#run.run_cleanup(epoch=epoch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15424\\1214844690.py\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;31m# =============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_epoch_collector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcons_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;31m# _forward_cls is defined by derived class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "configs = Configs()\n",
    "configs.log()\n",
    "\n",
    "# Run\n",
    "run = RoutineMT(configs)\n",
    "\n",
    "for epoch in range(configs.epochs):\n",
    "\n",
    "    run.run_training(epoch=epoch)\n",
    "    #run.run_validation(epoch=epoch)\n",
    "    #run.run_cleanup(epoch=epoch)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    routine.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1781785-eb28-4327-b98f-bc1b0c926181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
