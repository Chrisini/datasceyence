{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75832305-6091-4f3c-980a-53004f01a000",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ð•Šð•–ð•žð•š-ð•Šð•¦ð•¡ð•–ð•£ð•§ð•šð•¤ð•–ð•• ð•ð•–ð•’ð•£ð•Ÿð•šð•Ÿð•˜ ð•¦ð•¤ð•šð•Ÿð•˜ ð•„ð•–ð•’ð•Ÿ ð•‹ð•–ð•’ð•”ð•™ð•–ð•£\n",
    "\n",
    "Implementation of pixel-wise Mean Teacher (MT)\n",
    "    \n",
    "This method is proposed in the paper: \n",
    "    'Mean Teachers are Better Role Models:\n",
    "        Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results'\n",
    "This implementation only supports Gaussian noise as input perturbation, and the two-heads\n",
    "outputs trick is not available.\n",
    "\n",
    "Source:\n",
    "https://github.com/ZHKKKe/PixelSSL/blob/master/pixelssl/ssl_algorithm/ssl_mt.py\n",
    "\n",
    "\n",
    "Todo:\n",
    "* [] get everything on cuda, cpu -> to configs.device\n",
    "* [] metrics for segmentation + unittests\n",
    "* [] track the combined loss - what's the weight, ...\n",
    "\n",
    "\n",
    "Things that we have to set to the device (gpu):\n",
    "* the model\n",
    "* the image that gets fed into the model\n",
    "* the ground truth that gets fed into the criterion\n",
    "* the ground truth that gets fed into the metrics - due to activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6f142-82ee-4f0a-87f8-e2e9eeeb89b6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f3932a-744a-49ca-a076-f12749cf3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import logging\n",
    "import shutil # to remove dirs\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "from helper.dataset.meanteacher import *\n",
    "# from helper.model.mean_teacher import * \n",
    "from helper.sampler.mixed_batch import *\n",
    "# from helper.model.block.noise_block import GaussianNoiseBlock\n",
    "from helper.compute.bin_seg import BCE_BinSeg_CU\n",
    "from helper.compute.loss.shape import ShapeLoss\n",
    "from helper.compute.loss.dice import DiceLoss\n",
    "from helper.compute.metric.uncertainty import *\n",
    "from helper.compute.metric.segmentation import *\n",
    "\n",
    "\n",
    "#from pixelssl.utils import REGRESSION, CLASSIFICATION\n",
    "#from pixelssl.utils import logger, cmd, tool\n",
    "#from pixelssl.nn import func\n",
    "#from pixelssl.nn.module import patch_replication_callback, GaussianNoiseLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a707779-ab4d-46a4-ab5b-e123f91b827a",
   "metadata": {},
   "source": [
    "# Experiment Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d1aa89-5640-4263-8051-96580d7d0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # CHECK THESE\n",
    "        # =============================================================================\n",
    "        self.prefix = \"exp1_mt\"\n",
    "        self.reduced_data = True\n",
    "        # =============================================================================\n",
    "        # CHECK THESE\n",
    "        # =============================================================================\n",
    "        \n",
    "        # smp unet ++ parameters\n",
    "        self.encoder_name = \"efficientnet-b7\"\n",
    "        self.encoder_weights = \"imagenet\"\n",
    "        self.in_channels =  1\n",
    "        self.n_output_neurons = 2\n",
    "        \n",
    "        self.eps = 1e-6\n",
    "        \n",
    "        self.num_workers = 0\n",
    "        self.epochs = 100\n",
    "        self.rampup_length = 50\n",
    "        \n",
    "        self.gaussian_noise = 0.1 # None\n",
    "        \n",
    "        self.ema_decay = 0.999 # default value\n",
    "        \n",
    "        # Sizes of tensors must match except in dimension 1\n",
    "        # I solved the issue by resizing all the images size divisible to 32.\n",
    "        self.image_size = 128 # 512\n",
    "        \n",
    "        \n",
    "        \n",
    "        # batch size = n_samples_per_class_per_batch * classes\n",
    "        # for mixed batch sampling\n",
    "        self.n_samples_per_class_per_batch = 1\n",
    "        \n",
    "        # self.lbs = 3 #  self.args.labeled_batch_size # .... remove this eventually and replace\n",
    "\n",
    "        # optimisation\n",
    "        self.optimiser = \"sgd\"\n",
    "        self.base_lr = 0.01\n",
    "        self.min_lr = 0.0001\n",
    "        self.weight_decay = 1e-4\n",
    "        self.momentum = 0.9\n",
    "        \n",
    "        # self.is_epoch_lrer = True # epoch or batch based learning rate updater\n",
    "        \n",
    "        self.dropout = None\n",
    "        \n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Paths\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.base_path = r\"C:/Users/Prinzessin/projects/decentnet\"\n",
    "        if not os.path.exists(self.base_path):\n",
    "            os.makedirs(self.base_path)\n",
    "        os.chdir(self.base_path) # this is now the main directory !!!!!!!!!!!!!!!!!!!!\n",
    "        \n",
    "        self.csv_filenames = glob.glob(r\"datasceyence/data_prep/mt_*.csv\")\n",
    "        \n",
    "        print(self.csv_filenames)\n",
    "        \n",
    "        # input\n",
    "        self.load_checkpoint_file = None\n",
    "        \n",
    "        # all csv files used for run_mean_teacher.ipybn\n",
    "        #self.csv_data_paths = [\n",
    "        #    {\"path\" : r\"data/data_ichallenge_amd.csv\"}, \n",
    "        #    {\"path\" : r\"data/data_ichallenge_non_amd.csv\"}\n",
    "        #]\n",
    "        \n",
    "        \n",
    "        # output\n",
    "        self.logger_path = f\"results/{self.prefix}/logs\"\n",
    "        # if path exists: delete, create path\n",
    "        if os.path.exists(self.logger_path):\n",
    "            shutil.rmtree(self.logger_path)\n",
    "        os.makedirs(self.logger_path)\n",
    "            \n",
    "        self.result_path = os.path.join(self.logger_path, f\"metrics_{self.prefix}.csv\" )\n",
    "            \n",
    "        self.save_checkpoint_path = f\"results/{self.prefix}/ckpts\"\n",
    "         # if path exists: delete, create path\n",
    "        if os.path.exists(self.save_checkpoint_path):\n",
    "            shutil.rmtree(self.save_checkpoint_path)\n",
    "        os.makedirs(self.save_checkpoint_path)\n",
    "\n",
    "\n",
    "    def log(self):\n",
    "        # =============================================================================\n",
    "        # save all class variables to file \"configs.txt\"\n",
    "        # =============================================================================\n",
    "        c = pd.DataFrame.from_dict({'key': self.__dict__.keys(), 'value': self.__dict__.values()})\n",
    "        c.to_csv(os.path.join(self.logger_path, \"configs.txt\"), sep=':', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c64cbd-0bd5-4220-9f34-b7ff564d21ae",
   "metadata": {},
   "source": [
    "# Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7605a7f6-d147-4551-b403-928659086b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutineMT:\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(RoutineMT, self).__init__()\n",
    "        \n",
    "        self.configs = configs\n",
    "                \n",
    "        self.load_ckpt = torch.load(configs.load_checkpoint_file) if configs.load_checkpoint_file is not None else None\n",
    "        \n",
    "        self.i_item_total = 0\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Logger\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.writer =  SummaryWriter(log_dir=self.configs.logger_path)\n",
    "        logging.basicConfig(filename=os.path.join(self.configs.logger_path, 'logger.log'), encoding='utf-8', level=logging.DEBUG)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Models\n",
    "        # =============================================================================\n",
    "        s_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        \n",
    "        t_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        # detach the teacher model\n",
    "        for param in t_model.parameters():\n",
    "            param.detach_()\n",
    "            \n",
    "        self.models = {'s': s_model.to(self.configs.device), \n",
    "                       't': t_model.to(self.configs.device)}\n",
    "        \n",
    "        # add gaussian noise\n",
    "        # currently not in use\n",
    "        # self.gaussian_noiser = GaussianNoiseBlock(self.configs.gaussian_noise).cuda()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Computing Units\n",
    "        # =============================================================================\n",
    "        self.computing_unit = {\n",
    "            \"s_train\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"train\", model=\"s\", device=self.configs.device),\n",
    "            \"s_val\"   : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"val\", model=\"s\", device=self.configs.device),\n",
    "            \"t_train\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"train\", model=\"t\", device=self.configs.device),\n",
    "        }\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Optimisers\n",
    "        # =============================================================================\n",
    "        self.optims = {'s': torch.optim.SGD(self.models[\"s\"].parameters(), lr=self.configs.base_lr, momentum=self.configs.momentum) # optimizer_funcs[0](self.models[\"s\"].module.param_groups)\n",
    "                          }\n",
    "\n",
    "        # =============================================================================\n",
    "        # Learning rate schedulers\n",
    "        # =============================================================================\n",
    "        self.lrsers = {'s': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optims[\"s\"], \n",
    "                                                                              T_0 = 1, # number of iterations for the first restart.\n",
    "                                                                              eta_min = self.configs.min_lr\n",
    "                                                                               )\n",
    "                      \n",
    "                     } # lrer_funcs[0](self.optimizers['s_optimizer'])\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Loss functions\n",
    "        # =============================================================================\n",
    "        # TODO: support more types of the consistency criterion\n",
    "        # something with head and each head has a loss function attached??\n",
    "        self.criterions = {'shape': ShapeLoss(device=self.configs.device), # criterion_funcs[0](self.args),\n",
    "                           'pixel': DiceLoss(n_output_neurons=self.configs.n_output_neurons),\n",
    "                           # TODO\n",
    "                           # BINARY_MODE MULTICLASS_MODE - the loss wants a different encoding ...\n",
    "                           # ground_truth = torch.nn.functional.one_hot(ground_truth, num_classes)  # N,H*W -> N,H*W, C\n",
    "                           # ground_truth = ground_truth.permute(0, 2, 1)  # N, C, H*W\n",
    "                           # RuntimeError: one_hot is only applicable to index tensor.\n",
    "                           'cons': torch.nn.MSELoss() # softmax missing? there is a softmax mse loss ?? todo\n",
    "                          }\n",
    "        \n",
    "        self.um = UncertaintyMetric(n_noise=4, n_repeat=2, n_output_neurons=self.configs.n_output_neurons)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Datasets: train, val, test\n",
    "        # =============================================================================\n",
    "                \n",
    "        train_set = MeanTeacherTrainDataset(mode=\"train\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames, reduced_data=self.configs.reduced_data)\n",
    "        train_mbs = MixedBatchSampler(train_set.get_mbs_labels(), n_samples_per_class_per_batch=self.configs.n_samples_per_class_per_batch)\n",
    "        \n",
    "        val_set = MeanTeacherValDataset(mode=\"val\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames, reduced_data=self.configs.reduced_data)\n",
    "                \n",
    "        self.dataloader = {\"train\" : DataLoader(train_set, batch_sampler=train_mbs),\n",
    "                           \"val\" :   DataLoader(val_set)\n",
    "                          }\n",
    "          \n",
    "        # =============================================================================\n",
    "        # Resume training\n",
    "        # =============================================================================\n",
    "        if self.load_ckpt:\n",
    "            self.models[\"s\"].load_state_dict(self.load_ckpt['s_model'])\n",
    "            self.models[\"t\"].load_state_dict(self.load_ckpt['t_model'])\n",
    "            self.optims[\"s\"].load_state_dict(self.load_ckpt['s_optimizer'])\n",
    "            self.lrsers[\"s\"].load_state_dict(self.load_ckpt['s_lrer'])\n",
    "\n",
    "\n",
    "    \n",
    "    def run_training(self, i_epoch):\n",
    "        # =============================================================================\n",
    "        # Training\n",
    "        # =============================================================================\n",
    "        \n",
    "        mode=\"train\"\n",
    "        \n",
    "        self.models[\"s\"].train()\n",
    "        self.models[\"t\"].train()\n",
    "        \n",
    "        for i_item, item in enumerate(self.dataloader[mode]):\n",
    "            # =============================================================================\n",
    "            # Process Batch\n",
    "            # =============================================================================\n",
    "            \n",
    "            # unlabelled for consistency loss\n",
    "            unlabelled_batch_ids = np.where(item[\"has_mask\"] == False) \n",
    "            # labelled for task loss\n",
    "            labelled_batch_ids = np.where(item[\"has_mask\"] == True) \n",
    "            \n",
    "            # get predictions of student model for all images\n",
    "            s_model_output = self.models[\"s\"](item[\"img\"].to(self.configs.device)) # we want all images (task loss and consistency loss)\n",
    "            \n",
    "            # run batch for student model\n",
    "            self.computing_unit[\"s_train\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output[labelled_batch_ids], ground_truth=item[\"msk\"][labelled_batch_ids])\n",
    "            \n",
    "            if False:\n",
    "                print(labelled_batch_ids)\n",
    "                print(unlabelled_batch_ids)\n",
    "                print(\"item\"*40)\n",
    "                print(item)\n",
    "                print(\"item\"*40)\n",
    "                print(\"s model\")\n",
    "                print(s_model_output)\n",
    "                print(item[\"msk\"])\n",
    "                print(s_model_output.shape)\n",
    "                print(item[\"msk\"].shape)\n",
    "                print(\"next\")\n",
    "\n",
    "            # =============================================================================\n",
    "            # Teacher Model\n",
    "            # =============================================================================\n",
    "            \n",
    "            # forward the teacher model\n",
    "            with torch.no_grad():\n",
    "                # get predictions of teacher model for all images\n",
    "                t_model_output = self.models[\"t\"](item[\"img\"].to(self.configs.device))                \n",
    "                self.computing_unit[\"t_train\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=t_model_output[labelled_batch_ids], ground_truth=item[\"msk\"][labelled_batch_ids])\n",
    "            \n",
    "            uncertainy_mask = self.um.run(self.models[\"t\"], item[\"img\"].to(self.configs.device))\n",
    "        \n",
    "            # =============================================================================\n",
    "            # Consistency Loss\n",
    "            # =============================================================================\n",
    "            \n",
    "            def sigmoid_rampup(current, rampup_length):\n",
    "                # calculate the ramp-up coefficient of the consistency constraint\n",
    "                # returns vavlue between 0 and 1\n",
    "                # https://github.com/HiLab-git/SSL4MIS/blob/master/code/utils/ramps.py\n",
    "                # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "                if rampup_length == 0:\n",
    "                    return 1.0\n",
    "                else:\n",
    "                    current = np.clip(current, 0.0, rampup_length)\n",
    "                    phase = 1.0 - current / rampup_length\n",
    "                    return float(np.exp(-5.0 * phase * phase))\n",
    "            \n",
    "                        \n",
    "            cons_weight = sigmoid_rampup(i_epoch, self.configs.rampup_length)\n",
    "            \n",
    "            # calculate the consistency constraint from the teacher model to the student model\n",
    "            t_pseudo_gt = t_model_output # Variable(t_model_output.detach().data, requires_grad=False)\n",
    "            \n",
    "            if unlabelled_batch_ids:\n",
    "                cons_loss = self.criterions[\"cons\"](s_model_output[unlabelled_batch_ids], t_pseudo_gt[unlabelled_batch_ids])\n",
    "            else:\n",
    "                cons_loss = self.zero_tensor\n",
    "            \n",
    "            # this is a float\n",
    "            threshold = torch.tensor( ( 0.75 + (0.25*sigmoid_rampup(i_epoch, self.configs.rampup_length)) * np.log(2) ) ).to(self.configs.device)\n",
    "            \n",
    "            print(uncertainy_mask)\n",
    "            print(threshold)\n",
    "            \n",
    "            # this is not on the gpu ...\n",
    "            bin_uncertainy_mask = (uncertainy_mask.to(self.configs.device) < threshold) # .float()\n",
    "            \n",
    "            cons_loss_masked = torch.sum(bin_uncertainy_mask * cons_loss) / (2*torch.sum(bin_uncertainy_mask)+self.configs.eps)\n",
    "\n",
    "            # =============================================================================\n",
    "            # Backprop for student model\n",
    "            # =============================================================================\n",
    "            \n",
    "            # combined loss\n",
    "            \n",
    "            # supervised loss + consistency loss * consistency weight\n",
    "            loss = self.computing_unit[\"s_train\"].task_loss + cons_loss_masked * cons_weight\n",
    "            \n",
    "            self.optims[\"s\"].zero_grad()\n",
    "            loss.backward()\n",
    "            self.optims[\"s\"].step()\n",
    "            \n",
    "            # =============================================================================\n",
    "            # EMA for teacher model\n",
    "            # https://github.com/HiLab-git/SSL4MIS/blob/master/code/train_uncertainty_aware_mean_teacher_2D.py\n",
    "            # https://github.com/ZHKKKe/PixelSSL/blob/master/pixelssl/ssl_algorithm/ssl_mt.py\n",
    "            # =============================================================================\n",
    "            local_ema_decay = min(1 - 1 / (self.i_item_total + 1), self.configs.ema_decay)\n",
    "            for t_param, s_param in zip(self.models[\"t\"].parameters(), self.models[\"s\"].parameters()):\n",
    "                # model_weights = decay * model_weights + (1 - decay) * new_model_weights\n",
    "                t_param.data = t_param.data * local_ema_decay +  s_param.data * (1 - local_ema_decay)\n",
    "        \n",
    "            self.i_item_total += 1\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch Process (basically logging)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_train\"].run_epoch(i_epoch=i_epoch)\n",
    "        self.computing_unit[\"t_train\"].run_epoch(i_epoch=i_epoch)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch LR Scheduler\n",
    "        # =============================================================================\n",
    "        self.lrsers[\"s\"].step()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch log and reset (training)\n",
    "        # =============================================================================\n",
    "        \n",
    "        print(\"training task loss\")\n",
    "        print(self.computing_unit[\"s_train\"].epoch_collector[\"loss\"])\n",
    "        \n",
    "        print(\"training fscore\")\n",
    "        print(self.computing_unit[\"s_train\"].epoch_collector[\"fscore\"])\n",
    "        \n",
    "        self.computing_unit[\"s_train\"].log(csv_file_path = self.configs.result_path)\n",
    "        self.computing_unit[\"t_train\"].log(csv_file_path = self.configs.result_path)\n",
    "        self.computing_unit[\"s_train\"].reset_epoch()\n",
    "        self.computing_unit[\"t_train\"].reset_epoch()\n",
    "        \n",
    "        logging.info(\"Traning of epoch %d done\" % i_epoch)\n",
    "\n",
    "    def run_validation(self, i_epoch):\n",
    "        self.models[\"s\"].eval()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # for each batch\n",
    "        # =============================================================================\n",
    "\n",
    "        for i_item, item in enumerate(self.dataloader[\"val\"]):\n",
    "            \n",
    "            # timer = time.time()\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Student\n",
    "            # =============================================================================\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # get predictions of student model for all images\n",
    "                s_model_output = self.models[\"s\"](item[\"img\"].to(self.configs.device)) # we want all images (task loss and consistency loss)\n",
    "                \n",
    "                # should be based on loss function!!!!! - can we do all of them in the loss function? this is annoying\n",
    "                # s_model_output = torch.nn.functional.softmax(s_model_output, dim=1) # I DON'T KNOOOOW\n",
    "\n",
    "                # run batch for student model\n",
    "                self.computing_unit[\"s_val\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output, ground_truth=item[\"msk\"])\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch Process (basically logging)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_val\"].run_epoch(i_epoch=i_epoch)\n",
    "\n",
    "        # =============================================================================\n",
    "        # Epoch log and reset (validation)\n",
    "        # =============================================================================\n",
    "        \n",
    "        print(\"validation task loss\")\n",
    "        print(self.computing_unit[\"s_val\"].epoch_collector[\"loss\"])\n",
    "        \n",
    "        print(\"validation fscore\")\n",
    "        print(self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"])\n",
    "        \n",
    "        self.computing_unit[\"s_val\"].log(csv_file_path = self.configs.result_path)\n",
    "        self.computing_unit[\"s_val\"].reset_epoch()\n",
    "        \n",
    "        logging.info(\"Validation of epoch %d done\" % i_epoch)\n",
    "        \n",
    "\n",
    "    def log(self, i_epoch):\n",
    "        # =============================================================================\n",
    "        # Save checkpoint\n",
    "        # =============================================================================\n",
    "                \n",
    "        # this cannot woooooooooooooork\n",
    "        # we save the best already in the epoch .... ?\n",
    "            \n",
    "        if i_epoch > 5 and self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"] > self.computing_unit[\"s_val\"].top[\"highest_fscore\"]:\n",
    "            state = {\n",
    "                'name': self.configs.prefix,\n",
    "                'epoch': i_epoch, \n",
    "                's_model': self.models[\"s\"].state_dict(),\n",
    "                't_model': self.models[\"t\"].state_dict(),\n",
    "                's_optim': self.optims[\"s\"].state_dict(),\n",
    "                's_lrer': self.lrsers[\"s\"].state_dict()\n",
    "            }\n",
    "\n",
    "            checkpoint = os.path.join(self.configs.save_checkpoint_path, 'checkpoint_{0}.ckpt'.format(i_epoch))\n",
    "            torch.save(state, checkpoint)\n",
    "            \n",
    "            self.computing_unit[\"s_val\"].top[\"fscore\"] = self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"]\n",
    "            \n",
    "            logging.info(\"Saved model at epoch %d\" % i_epoch)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0440659-d578-4ae9-a2d5-88331279c1cc",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de02c93-618e-464e-afc8-8da004a671e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasceyence/data_prep\\\\mt_data_ichallenge_amd.csv', 'datasceyence/data_prep\\\\mt_data_ichallenge_glaucoma.csv', 'datasceyence/data_prep\\\\mt_data_ichallenge_non_amd.csv', 'datasceyence/data_prep\\\\mt_data_ichallenge_unlabelled.csv']\n",
      "tensor([[[[0.6931, 0.6689, 0.6568,  ..., 0.6929, 0.6841, 0.6561],\n",
      "          [0.4669, 0.4975, 0.5339,  ..., 0.6673, 0.6923, 0.5819],\n",
      "          [0.6427, 0.4619, 0.6176,  ..., 0.6238, 0.5864, 0.4914],\n",
      "          ...,\n",
      "          [0.6814, 0.6884, 0.6784,  ..., 0.6925, 0.6930, 0.6592],\n",
      "          [0.6621, 0.6775, 0.6793,  ..., 0.6123, 0.5902, 0.6921],\n",
      "          [0.6783, 0.6795, 0.5934,  ..., 0.6800, 0.6931, 0.6614]]]])\n",
      "tensor(0.7512, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 1.05 GiB already allocated; 0 bytes free; 1.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4008\\3879141501.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_epoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#run.log(i_epoch=i_epoch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4008\\239633456.py\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m(self, i_epoch)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_param\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"s\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;31m# model_weights = decay * model_weights + (1 - decay) * new_model_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0mt_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlocal_ema_decay\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0ms_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlocal_ema_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi_item_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 1.05 GiB already allocated; 0 bytes free; 1.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "configs = Configs()\n",
    "configs.log()\n",
    "\n",
    "# Run\n",
    "run = RoutineMT(configs)\n",
    "\n",
    "for i_epoch in range(configs.epochs):\n",
    "    \n",
    "    run.run_training(i_epoch=i_epoch)\n",
    "    run.run_validation(i_epoch=i_epoch)\n",
    "    #run.log(i_epoch=i_epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1781785-eb28-4327-b98f-bc1b0c926181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f74619-f77d-4796-af9c-a2e19ac6fa52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
