{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75832305-6091-4f3c-980a-53004f01a000",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ð•Šð•–ð•žð•š-ð•Šð•¦ð•¡ð•–ð•£ð•§ð•šð•¤ð•–ð•• ð•ð•–ð•’ð•£ð•Ÿð•šð•Ÿð•˜ ð•¦ð•¤ð•šð•Ÿð•˜ ð•„ð•–ð•’ð•Ÿ ð•‹ð•–ð•’ð•”ð•™ð•–ð•£\n",
    "\n",
    "Implementation of pixel-wise Mean Teacher (MT)\n",
    "    \n",
    "This method is proposed in the paper: \n",
    "    'Mean Teachers are Better Role Models:\n",
    "        Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results'\n",
    "This implementation only supports Gaussian noise as input perturbation, and the two-heads\n",
    "outputs trick is not available.\n",
    "\n",
    "Source:\n",
    "https://github.com/ZHKKKe/PixelSSL/blob/master/pixelssl/ssl_algorithm/ssl_mt.py\n",
    "\n",
    "\n",
    "Todo:\n",
    "* [] get everything on cuda, cpu -> to configs.device\n",
    "* [] metrics for segmentation + unittests\n",
    "* [] track the combined loss - what's the weight, ...\n",
    "\n",
    "\n",
    "Things that we have to set to the device (gpu):\n",
    "* the model\n",
    "* the image that gets fed into the model\n",
    "* the ground truth that gets fed into the criterion\n",
    "* the ground truth that gets fed into the metrics - due to activation functions\n",
    "\n",
    "\n",
    "recall high: most of the roi has been segmented\n",
    "in combination with low precision: general oversegmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde2fc8-5e60-4c2e-ad54-aa8aa6206ed5",
   "metadata": {},
   "source": [
    "Using Learning Rate Scheduler:\n",
    "\n",
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/5\n",
    "\n",
    "```\n",
    "steps = 10\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for idx in range(steps):\n",
    "        scheduler.step()\n",
    "        print(scheduler.get_lr())\n",
    "\n",
    "    print('Reset scheduler')\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)\n",
    "```            \n",
    "\n",
    "\n",
    "* TODO\n",
    "* BINARY_MODE MULTICLASS_MODE - the loss wants a different encoding ...\n",
    "* ground_truth = torch.nn.functional.one_hot(ground_truth, num_classes)  # N,H*W -> N,H*W, C\n",
    "* ground_truth = ground_truth.permute(0, 2, 1)  # N, C, H*W\n",
    "* RuntimeError: one_hot is only applicable to index tensor.\n",
    "\n",
    "           \n",
    "C:\\Users\\Christina\\Documents\\datasceyence\\helper\\dataset\\template.py:38: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n",
    "  self.csv_data = pd.concat(csv_list, axis=0, ignore_index=False)\n",
    "C:\\Users\\Christina\\Documents\\datasceyence\\helper\\dataset\\template.py:38: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n",
    "  self.csv_data = pd.concat(csv_list, axis=0, ignore_index=False)\n",
    "  \n",
    "  OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\shapedescr.cpp:355: error: (-215:Assertion failed) n >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::fitEllipseNoDirect'\n",
    "  \n",
    "  C:\\Users\\Christina\\Documents\\datasceyence\\helper\\compute\\loss\\shape.py:235: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "  return torch.tensor(loss)\n",
    "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
    "  warnings.warn('PyTorch is not compiled with NCCL support')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6f142-82ee-4f0a-87f8-e2e9eeeb89b6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3932a-744a-49ca-a076-f12749cf3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import logging\n",
    "import shutil # to remove dirs\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "from helper.dataset.meanteacher import *\n",
    "# from helper.model.mean_teacher import * \n",
    "from helper.sampler.mixed_batch import *\n",
    "# from helper.model.block.noise_block import GaussianNoiseBlock\n",
    "from helper.compute.bin_seg import BCE_BinSeg_CU\n",
    "from helper.compute.loss.shape import SignedDistanceLoss, HausdorffDTLoss\n",
    "from helper.compute.loss.dice import DiceLoss\n",
    "from helper.compute.metric.uncertainty import *\n",
    "from helper.compute.metric.segmentation import *\n",
    "\n",
    "\n",
    "#from pixelssl.utils import REGRESSION, CLASSIFICATION\n",
    "#from pixelssl.utils import logger, cmd, tool\n",
    "#from pixelssl.nn import func\n",
    "#from pixelssl.nn.module import patch_replication_callback, GaussianNoiseLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a707779-ab4d-46a4-ab5b-e123f91b827a",
   "metadata": {},
   "source": [
    "# Experiment Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82d1aa89-5640-4263-8051-96580d7d0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs():\n",
    "    \n",
    "    def __init__(self, reset=False):\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # CHECK THESE\n",
    "        # =============================================================================\n",
    "        reset_2 = True # double control, otherwise all results for this prefix will be deleted\n",
    "        if reset and reset_2:\n",
    "            reset=True\n",
    "        else:\n",
    "            reset=False\n",
    "        self.prefix = \"tmp_local\" # put local if christina's computer\n",
    "        self.reduced_data = True\n",
    "        # \"cuda\" - use all the available GPUs\n",
    "        # \"cuda:1,3\" - use specific GPUs            \n",
    "        self.print_todos = False\n",
    "        self.min_save_fscore = 0.5 # 0.7\n",
    "        self.description = \"with b0 model, currently trying the consistency with max area - no ellipse, and dice loss instead of mse\"\n",
    "        # =============================================================================\n",
    "        # CHECK THESE\n",
    "        # =============================================================================\n",
    "        \n",
    "        if \"local\" in self.prefix:\n",
    "            self.device = \"cpu\" # \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.base_path = r\"C:/Users/Prinzessin/projects/decentnet\"\n",
    "            self.logger_path = f\"C:/Users/Prinzessin/projects/decentnet/datasceyence/results/{self.prefix}/logs\"\n",
    "            self.save_checkpoint_path = f\"C:/Users/Prinzessin/projects/decentnet/datasceyence/results/{self.prefix}/ckpts\"\n",
    "        else:\n",
    "            self.device = \"cuda\" # \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.base_path = r\"C:/Users/Christina/Documents\"\n",
    "            self.logger_path = f\"E:/Christina/datasceyence/results/{self.prefix}/logs\"\n",
    "            self.save_checkpoint_path = f\"E:/Christina/datasceyence/results/{self.prefix}/ckpts\"\n",
    "        \n",
    "        # smp unet ++ parameters\n",
    "        self.encoder_name = \"timm-efficientnet-b0\" # \"efficientnet-b7\"\n",
    "        self.encoder_weights = \"imagenet\"\n",
    "        self.in_channels =  1\n",
    "        self.n_output_neurons = 2\n",
    "        \n",
    "        self.eps = 1e-6\n",
    "        \n",
    "        self.num_workers = 4\n",
    "        self.epochs = 100 # need more for final training ... more than 1000\n",
    "        self.rampup_length = 50 # 600 for 1000\n",
    "        \n",
    "        # self.gaussian_noise = None # not in use\n",
    "        \n",
    "        self.ema_decay = 0.999 # default value\n",
    "        \n",
    "        # Sizes of tensors must match except in dimension 1\n",
    "        # I solved the issue by resizing all the images size divisible to 32.\n",
    "        self.image_size = 128 # 512\n",
    "        \n",
    "        # batch size = n_samples_per_class_per_batch * classes\n",
    "        # for mixed batch sampling\n",
    "        self.n_samples_per_class_per_batch = 8\n",
    "        \n",
    "        # self.lbs = 3 #  self.args.labeled_batch_size # .... remove this eventually and replace\n",
    "\n",
    "        # optimisation\n",
    "        # self.optimiser = \"sgd\"\n",
    "        self.base_lr = 0.001 # 0.0001\n",
    "        self.min_lr = 0.00001\n",
    "        self.weight_decay = 1e-4 # not in use\n",
    "        self.momentum = 0.9\n",
    "        \n",
    "        # self.is_epoch_lrer = True # epoch or batch based learning rate updater\n",
    "        \n",
    "        # self.dropout = None\n",
    "        \n",
    "        \n",
    "         \n",
    "        # =============================================================================\n",
    "        # Paths\n",
    "        # =============================================================================\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(self.base_path):\n",
    "            os.makedirs(self.base_path)\n",
    "        os.chdir(self.base_path) # this is now the main directory !!!!!!!!!!!!!!!!!!!!\n",
    "        \n",
    "        self.csv_filenames = glob.glob(r\"datasceyence/data_prep/mt_*.csv\")\n",
    "        self.csv_test_filenames = [\"datasceyence/data_prep/mt_data_cirrus.csv\"]\n",
    "        \n",
    "        print(self.csv_filenames)\n",
    "        \n",
    "        # input # should be none for actual experiments\n",
    "        self.load_checkpoint_file = None # \"E:/Christina/datasceyence/results/exp3_dice_cons_all_data_b7/ckpts/checkpoint_0.799_134.ckpt\" \n",
    "        \n",
    "        # all csv files used for run_mean_teacher.ipybn\n",
    "        #self.csv_data_paths = [\n",
    "        #    {\"path\" : r\"data/data_ichallenge_amd.csv\"}, \n",
    "        #    {\"path\" : r\"data/data_ichallenge_non_amd.csv\"}\n",
    "        #]\n",
    "        \n",
    "        \n",
    "        # output\n",
    "        \n",
    "        # if path exists: delete, create path\n",
    "        if reset:\n",
    "            if os.path.exists(self.logger_path):\n",
    "                shutil.rmtree(self.logger_path)\n",
    "            os.makedirs(self.logger_path)\n",
    "            \n",
    "        self.result_path = os.path.join(self.logger_path, f\"metrics_{self.prefix}.csv\" )\n",
    "            \n",
    "        \n",
    "         # if path exists: delete, create path\n",
    "        if reset:\n",
    "            if os.path.exists(self.save_checkpoint_path):\n",
    "                shutil.rmtree(self.save_checkpoint_path)\n",
    "            os.makedirs(self.save_checkpoint_path)\n",
    "\n",
    "\n",
    "    def log(self):\n",
    "        # =============================================================================\n",
    "        # save all class variables to file \"configs.txt\"\n",
    "        # =============================================================================\n",
    "        c = pd.DataFrame.from_dict({'key': self.__dict__.keys(), 'value': self.__dict__.values()})\n",
    "        c.to_csv(os.path.join(self.logger_path, \"configs.txt\"), sep=':', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c64cbd-0bd5-4220-9f34-b7ff564d21ae",
   "metadata": {},
   "source": [
    "# Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7605a7f6-d147-4551-b403-928659086b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutineMT:\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(RoutineMT, self).__init__()\n",
    "        \n",
    "        self.configs = configs\n",
    "                \n",
    "        self.load_ckpt = torch.load(configs.load_checkpoint_file) if configs.load_checkpoint_file is not None else None\n",
    "        \n",
    "        self.i_item_total = 0\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Logger\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.writer =  SummaryWriter(log_dir=self.configs.logger_path)\n",
    "        logging.basicConfig(filename=os.path.join(self.configs.logger_path, 'logger.log'), encoding='utf-8', level=logging.INFO) # everything more important or INFO\n",
    "        # https://docs.python.org/3/library/logging.html\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Models\n",
    "        # =============================================================================\n",
    "        s_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        \n",
    "        t_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        \n",
    "        # detach the teacher model\n",
    "        for param in t_model.parameters():\n",
    "            param.detach_()\n",
    "            \n",
    "        # model= nn.DataParallel(model)\n",
    "        # if only one gpu ??\n",
    "        if \"cpu\" in self.configs.device:\n",
    "            self.models = {'s': s_model, \n",
    "                           't': t_model}\n",
    "        else: \n",
    "            self.models = {'s': torch.nn.DataParallel(s_model).to(self.configs.device), \n",
    "                           't': torch.nn.DataParallel(t_model).to(self.configs.device)}\n",
    "        \n",
    "        # add gaussian noise\n",
    "        # currently not in use\n",
    "        # self.gaussian_noiser = GaussianNoiseBlock(self.configs.gaussian_noise).cuda()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Computing Units\n",
    "        # =============================================================================\n",
    "        self.computing_unit = {\n",
    "            \"s_train\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"train\", model=\"s\", device=self.configs.device, writer=self.writer),\n",
    "            \"s_val\"   : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"val\", model=\"s\", device=self.configs.device, writer=self.writer),\n",
    "            \"t_train\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"train\", model=\"t\", device=self.configs.device, writer=self.writer),\n",
    "            \"s_test\"  : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"val\", model=\"s\", device=self.configs.device, writer=None),\n",
    "        }\n",
    "        \n",
    "        self.top_val = { #'lowest_loss' : np.inf,  # low good\n",
    "                         'highest_fscore' : self.configs.min_save_fscore, # high good\n",
    "                         #'highest_jac' : 0, # high good\n",
    "                         #'highest_symhd' : np.inf # low good\n",
    "                     }\n",
    "        \n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Loss functions\n",
    "        # =============================================================================\n",
    "        # TODO: support more types of the consistency criterion\n",
    "        # something with head and each head has a loss function attached??\n",
    "        self.criterions = {'shape': HausdorffDTLoss(), # (device=self.configs.device, n_output_neurons=self.configs.n_output_neurons), # criterion_funcs[0](self.args),\n",
    "                           'pixel': DiceLoss(n_output_neurons=self.configs.n_output_neurons, softmax=True), # added softmax on 29-may-2023 4pm\n",
    "                           'cons': DiceLoss(n_output_neurons=self.configs.n_output_neurons, softmax=True) # ,torch.nn.MSELoss() # softmax missing? there is a softmax mse loss ?? todo\n",
    "                          }\n",
    "        \n",
    "        self.um = UncertaintyMetric(n_noise=4, n_repeat=2, n_output_neurons=self.configs.n_output_neurons)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Datasets: train, val, test\n",
    "        # =============================================================================\n",
    "                \n",
    "        train_set = MeanTeacherTrainDataset(mode=\"train\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames, reduced_data=self.configs.reduced_data)\n",
    "        train_mbs = MixedBatchSampler(train_set.get_mbs_labels(), n_samples_per_class_per_batch=self.configs.n_samples_per_class_per_batch)\n",
    "        \n",
    "        print(\"*\"*50)\n",
    "        print(\"all labels\", train_set.get_mbs_labels())\n",
    "        \n",
    "        x = train_set.get_mbs_labels()\n",
    "        leastFrequent = min(x, key=x.count)\n",
    "        amount = x.count(leastFrequent)\n",
    "        print(\"this needs some error catching\")\n",
    "        self.steps = int(amount/self.configs.n_samples_per_class_per_batch)\n",
    "        print(\"steps\", self.steps)\n",
    "                \n",
    "        val_set = MeanTeacherValDataset(mode=\"val\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames, reduced_data=self.configs.reduced_data)\n",
    "        \n",
    "        cir_set = MeanTeacherCirDataset(channels=self.configs.in_channels, csv_filenames=self.configs.csv_test_filenames, image_size=self.configs.image_size)\n",
    "              \n",
    "        self.dataloader = {\"train\" : DataLoader(train_set, batch_sampler=train_mbs),\n",
    "                           \"val\"   : DataLoader(val_set),\n",
    "                           \"cir\"   : DataLoader(cir_set, shuffle=False)\n",
    "                          }\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Optimisers\n",
    "        # =============================================================================\n",
    "        self.optims = {'s': torch.optim.SGD(self.models[\"s\"].parameters(), lr=self.configs.base_lr, momentum=self.configs.momentum) # optimizer_funcs[0](self.models[\"s\"].module.param_groups)\n",
    "                          }\n",
    "\n",
    "        # =============================================================================\n",
    "        # Learning rate schedulers\n",
    "        # =============================================================================\n",
    "        self.lrsers = {'s': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optims[\"s\"], \n",
    "                                                                              T_0 = 100, # number of iterations for the first restart.\n",
    "                                                                              eta_min = self.configs.min_lr\n",
    "                                                                               )\n",
    "                     }\n",
    "                  \n",
    "        # =============================================================================\n",
    "        # Resume training\n",
    "        # =============================================================================\n",
    "        if self.load_ckpt:\n",
    "            self.models[\"s\"].load_state_dict(self.load_ckpt['s_model'])\n",
    "            self.models[\"t\"].load_state_dict(self.load_ckpt['t_model'])\n",
    "            self.optims[\"s\"].load_state_dict(self.load_ckpt['s_optim'])\n",
    "            self.lrsers[\"s\"].load_state_dict(self.load_ckpt['s_lrer'])\n",
    "            try: \n",
    "                self.start_epoch = self.load_ckpt['epoch']\n",
    "            except:\n",
    "                self.start_epoch = self.load_ckpt['i_epoch']\n",
    "        else:\n",
    "            self.start_epoch = 0\n",
    "            \n",
    "\n",
    "    \n",
    "    def run_training(self, i_epoch):\n",
    "        # =============================================================================\n",
    "        # Training\n",
    "        # =============================================================================\n",
    "        \n",
    "        mode=\"train\"\n",
    "        \n",
    "        self.models[\"s\"].train()\n",
    "        self.models[\"t\"].eval() # train or eval ... ???\n",
    "        \n",
    "        for i_item, item in enumerate(self.dataloader[mode]):\n",
    "            # =============================================================================\n",
    "            # Process Batch\n",
    "            # =============================================================================\n",
    "            \n",
    "            # unlabelled for consistency loss\n",
    "            unlabelled_batch_ids = np.where(item[\"has_mask\"] == False) \n",
    "            # labelled for task loss\n",
    "            labelled_batch_ids = np.where(item[\"has_mask\"] == True) \n",
    "            \n",
    "            # get predictions of student model for all images\n",
    "            s_model_output = self.models[\"s\"](item[\"img\"].to(self.configs.device)) # we want all images (task loss and consistency loss)\n",
    "            \n",
    "            # run batch for student model\n",
    "            self.computing_unit[\"s_train\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output[labelled_batch_ids], ground_truth=item[\"msk\"][labelled_batch_ids])\n",
    "            \n",
    "            if False:\n",
    "                print(labelled_batch_ids)\n",
    "                print(unlabelled_batch_ids)\n",
    "                print(\"item\"*40)\n",
    "                print(item)\n",
    "                print(\"item\"*40)\n",
    "                print(\"s model\")\n",
    "                print(s_model_output)\n",
    "                print(item[\"msk\"])\n",
    "                print(s_model_output.shape)\n",
    "                print(item[\"msk\"].shape)\n",
    "                print(\"next\")\n",
    "\n",
    "            # =============================================================================\n",
    "            # Teacher Model\n",
    "            # =============================================================================\n",
    "            \n",
    "            no_grad_img = Variable(item[\"img\"], requires_grad=False)\n",
    "            \n",
    "            # forward the teacher model\n",
    "            with torch.no_grad():\n",
    "                # get predictions of teacher model for all images\n",
    "                t_model_output = self.models[\"t\"](no_grad_img.to(self.configs.device)) # we want all images (task loss and consistency loss)               \n",
    "                self.computing_unit[\"t_train\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=t_model_output[labelled_batch_ids], ground_truth=item[\"msk\"][labelled_batch_ids])\n",
    "                            \n",
    "            if self.configs.print_todos: \n",
    "                print(\"run_meanteacher todo: the uncertainty mask is not good - for consistency loss\")    \n",
    "            # uncertainy_mask = self.um.run(self.models[\"t\"], item[\"img\"].to(self.configs.device))\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Consistency Loss\n",
    "            # =============================================================================\n",
    "            \n",
    "            def sigmoid_rampup(current, rampup_length):\n",
    "                # calculate the ramp-up coefficient of the consistency constraint\n",
    "                # returns vavlue between 0 and 1\n",
    "                # https://github.com/HiLab-git/SSL4MIS/blob/master/code/utils/ramps.py\n",
    "                # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "                if rampup_length == 0:\n",
    "                    return 1.0\n",
    "                else:\n",
    "                    current = np.clip(current, 0.0, rampup_length)\n",
    "                    phase = 1.0 - current / rampup_length\n",
    "                    return float(np.exp(-5.0 * phase * phase))\n",
    "                        \n",
    "            cons_weight = sigmoid_rampup(i_epoch, self.configs.rampup_length)\n",
    "            \n",
    "            \n",
    "            if self.writer:\n",
    "                self.writer.add_scalars(\"info/weight\", {\"cons_ramp\" : cons_weight}, self.i_item_total)\n",
    "            \n",
    "            # calculate the consistency constraint from the teacher model to the student model\n",
    "            if self.configs.print_todos: \n",
    "                print(\"run_meanteacher todo: here inside we have to do some beautifying of the mask - for consistency loss\")\n",
    "            # https://discuss.pytorch.org/t/how-does-applying-a-mask-to-the-output-affect-the-gradients/126520\n",
    "            \n",
    "            def create_circle(model_output):\n",
    "                \n",
    "                \n",
    "                # 3 dims (batch, widht, height)\n",
    "                _, highest_class = torch.max(model_output, 1)  \n",
    "                \n",
    "                # 3 dims (batch, widht, height)\n",
    "                final_masks = torch.zeros_like(highest_class)\n",
    "                \n",
    "                #print(highest_class.shape)\n",
    "                \n",
    "                for i, output in enumerate(highest_class):\n",
    "                    \n",
    "                    output = output.detach().cpu().numpy()\n",
    "                    \n",
    "                    #plt.figure()\n",
    "                    #plt.imshow(output)\n",
    "                    \n",
    "                    max_area = 0\n",
    "                    circle = np.zeros(output.shape, dtype = np.uint8)\n",
    "                    \n",
    "                    num_labels, labels_im = cv2.findContours(output, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "                    if len(num_labels) > 0:\n",
    "                        max_area = max(num_labels, key = cv2.contourArea)\n",
    "                    \n",
    "                        try:\n",
    "                            #ellipse = cv2.fitEllipse(max_area)\n",
    "\n",
    "                            #cv2.ellipse(circle, ellipse, (1), thickness=-1)\n",
    "\n",
    "                            cv2.drawContours(circle, [max_area], -1, color=(1), thickness=-1)\n",
    "\n",
    "                            final_masks[i] = torch.tensor(circle)\n",
    "\n",
    "                            #plt.figure()\n",
    "                            #plt.imshow(circle)\n",
    "                        except Exception as e:\n",
    "                            # logging.info(\"fitting the ellipse didn't work\")\n",
    "                            logging.info(\"max area %d\", cv2.contourArea(max_area))\n",
    "                            logging.info(e)\n",
    "                            print(\"probably empty mask\", cv2.contourArea(max_area))\n",
    "                            #final_masks[i, 0] = model_output[i, 0]\n",
    "                            final_masks[i] = highest_class[i]\n",
    "                    else:\n",
    "                        \n",
    "                        print(final_masks.shape)\n",
    "                        print(highest_class.shape)\n",
    "                        print(final_masks[i].shape)\n",
    "                        print(highest_class[i].shape)\n",
    "                        \n",
    "                        # 2 dims + 1 = 3 dims\n",
    "                        final_masks[i] = highest_class[i]\n",
    "                \n",
    "                if self.configs.print_todos: \n",
    "                    print(final_masks.shape)\n",
    "                \n",
    "                # 3 dims (batch, 1, widht, height)\n",
    "                final_masks = final_masks.unsqueeze(1)\n",
    "                \n",
    "                if self.configs.print_todos: \n",
    "                    print(final_masks.shape)\n",
    "                \n",
    "                return final_masks # Variable(final_masks, requires_grad=False) # circle\n",
    "            \n",
    "            circle = create_circle(t_model_output[unlabelled_batch_ids])\n",
    "\n",
    "            t_pseudo_gt = circle.to(self.configs.device) # t_model_output * circle # Variable(t_model_output.detach().data, requires_grad=False) # t_model_output\n",
    "            \n",
    "            if self.configs.print_todos: \n",
    "                print(\"modeeeeeeeeeeeeeel output of teeeacheeer\")\n",
    "                print(t_pseudo_gt)\n",
    "                print(t_pseudo_gt.shape)\n",
    "                \n",
    "                \n",
    "                print(\" hier ist ein subplot\")\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3)\n",
    "                _, highest_class = torch.max(s_model_output[unlabelled_batch_ids], 1)  \n",
    "                highest_class = highest_class[0].detach().cpu().numpy()\n",
    "                axs[0].imshow(highest_class, cmap=\"cool\")\n",
    "                axs[0].axis('off')\n",
    "                axs[1].imshow(t_pseudo_gt[0,0].detach().cpu().numpy(), cmap=\"cool\")\n",
    "                axs[1].axis('off')\n",
    "\n",
    "\n",
    "                _, highest_class2 = torch.max(t_model_output[unlabelled_batch_ids], 1)  \n",
    "                highest_class2 = highest_class2[0].detach().cpu().numpy()\n",
    "                axs[2].imshow(highest_class2, cmap=\"cool\")\n",
    "                axs[2].axis('off')\n",
    "                fig.show()\n",
    "                \n",
    "            \n",
    "\n",
    "            \n",
    "            if unlabelled_batch_ids:\n",
    "                cons_loss = self.criterions[\"cons\"](s_model_output[unlabelled_batch_ids], t_pseudo_gt)\n",
    "            else:\n",
    "                cons_loss = self.zero_tensor\n",
    "                            \n",
    "            # this is a float\n",
    "            threshold = torch.tensor( ( 0.75 + (0.25*sigmoid_rampup(i_epoch, self.configs.rampup_length)) * np.log(2) ) ).to(self.configs.device)\n",
    "            \n",
    "            \n",
    "            if self.writer:\n",
    "                self.writer.add_scalars(\"info/weight\", {\"thresh_ramp\" : threshold.detach().cpu().numpy()}, self.i_item_total)\n",
    "            \n",
    "            #print(uncertainy_mask)\n",
    "            #print(threshold)\n",
    "            \n",
    "            # this is not on the gpu ... now it is ...\n",
    "            #bin_uncertainy_mask = (uncertainy_mask.to(self.configs.device) < threshold) # .float()\n",
    "            \n",
    "            #cons_loss_masked = torch.sum(bin_uncertainy_mask * cons_loss) / (2*torch.sum(bin_uncertainy_mask)+self.configs.eps)\n",
    "\n",
    "            # =============================================================================\n",
    "            # Backprop for student model\n",
    "            # =============================================================================\n",
    "            \n",
    "            # combined loss\n",
    "            # supervised loss + consistency loss * consistency weight\n",
    "            loss = self.computing_unit[\"s_train\"].task_loss + cons_loss * cons_weight #  + cons_loss_masked * cons_weight\n",
    "            \n",
    "            self.writer.add_scalars(\"info/loss\", {\"backprop\" : loss,\n",
    "                                                  \"cons\"  : cons_loss,\n",
    "                                                  \"cons_weighted\"  : cons_loss * cons_weight,\n",
    "                                                  \"shape\" : self.computing_unit[\"s_train\"].shape_loss,\n",
    "                                                  \"pixel\" : self.computing_unit[\"s_train\"].pixel_loss}, self.i_item_total)\n",
    "            \n",
    "            self.optims[\"s\"].zero_grad()\n",
    "            loss.backward()\n",
    "            self.optims[\"s\"].step()      \n",
    "            \n",
    "            # =============================================================================\n",
    "            # LR Scheduler = every batch a step\n",
    "            # =============================================================================\n",
    "            self.lrsers[\"s\"].step()\n",
    "            if self.writer:\n",
    "                self.writer.add_scalars(\"info/lr\", {\"s_train\" : self.lrsers[\"s\"].get_last_lr()[0]}, self.i_item_total)\n",
    "            \n",
    "            # =============================================================================\n",
    "            # EMA for teacher model\n",
    "            # https://github.com/HiLab-git/SSL4MIS/blob/master/code/train_uncertainty_aware_mean_teacher_2D.py\n",
    "            # https://github.com/ZHKKKe/PixelSSL/blob/master/pixelssl/ssl_algorithm/ssl_mt.py\n",
    "            # =============================================================================\n",
    "            self.models[\"t\"].train() # this should be train for ema\n",
    "            \n",
    "            local_ema_decay = min(1 - 1 / (self.i_item_total + 1), self.configs.ema_decay)\n",
    "            for t_param, s_param in zip(self.models[\"t\"].parameters(), self.models[\"s\"].parameters()):\n",
    "                # model_weights = decay * model_weights + (1 - decay) * new_model_weights\n",
    "                t_param.data = t_param.data * local_ema_decay +  s_param.data * (1 - local_ema_decay)\n",
    "        \n",
    "            self.i_item_total += 1\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch Process (basically logging)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_train\"].run_epoch(i_epoch=i_epoch)\n",
    "        self.computing_unit[\"t_train\"].run_epoch(i_epoch=i_epoch)\n",
    "        \n",
    "        \n",
    "\n",
    "        if self.configs.print_todos: \n",
    "            print(\"lr\")\n",
    "            print(self.lrsers[\"s\"].get_last_lr())\n",
    "            print(self.lrsers[\"s\"].get_last_lr()[0])\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch log and reset (training)\n",
    "        # =============================================================================\n",
    "        \n",
    "        if self.configs.print_todos: \n",
    "            print(\"training task loss\")\n",
    "            print(self.computing_unit[\"s_train\"].epoch_collector[\"taskloss\"])\n",
    "\n",
    "            print(\"training fscore\")\n",
    "            print(self.computing_unit[\"s_train\"].epoch_collector[\"fscore\"])\n",
    "        \n",
    "        self.computing_unit[\"s_train\"].log(csv_file_path = self.configs.result_path)\n",
    "        self.computing_unit[\"t_train\"].log(csv_file_path = self.configs.result_path)\n",
    "        self.computing_unit[\"s_train\"].reset_epoch()\n",
    "        self.computing_unit[\"t_train\"].reset_epoch()\n",
    "        \n",
    "    def run_validation(self, i_epoch):\n",
    "        self.models[\"s\"].eval()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # for each batch\n",
    "        # =============================================================================\n",
    "\n",
    "        for i_item, item in enumerate(self.dataloader[\"val\"]):\n",
    "            # =============================================================================\n",
    "            # Student\n",
    "            # =============================================================================\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # get predictions of student model for all images\n",
    "                s_model_output = self.models[\"s\"](item[\"img\"].to(self.configs.device)) # we want all images (task loss and consistency loss)\n",
    "                \n",
    "                # should be based on loss function!!!!! - can we do all of them in the loss function? this is annoying\n",
    "                # s_model_output = torch.nn.functional.softmax(s_model_output, dim=1) # I DON'T KNOOOOW\n",
    "\n",
    "                # run batch for student model\n",
    "                self.computing_unit[\"s_val\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output, ground_truth=item[\"msk\"])\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch Process (basically logging)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_val\"].run_epoch(i_epoch=i_epoch)\n",
    "\n",
    "        # =============================================================================\n",
    "        # Epoch log and reset (validation)\n",
    "        # =============================================================================\n",
    "        \n",
    "        if self.configs.print_todos: \n",
    "            print(\"validation task loss\")\n",
    "            print(self.computing_unit[\"s_val\"].epoch_collector[\"taskloss\"])\n",
    "\n",
    "            print(\"validation fscore\")\n",
    "            print(self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"])\n",
    "        \n",
    "        self.computing_unit[\"s_val\"].log(csv_file_path = self.configs.result_path)\n",
    "        self.computing_unit[\"s_val\"].reset_epoch()\n",
    "        \n",
    "        logging.info(\"Validation of epoch %d done\" % i_epoch)\n",
    "        \n",
    "    def run_final_evaluation(self, i_epoch):\n",
    "                \n",
    "        model = self.models[\"s\"]\n",
    "        \n",
    "        paths = glob.glob(os.path.join(self.configs.save_checkpoint_path, f'checkpoint_*_{i_epoch}.ckpt'))\n",
    "        \n",
    "        model.load_state_dict(torch.load(paths[0])['s_model'])\n",
    "        model.eval()\n",
    "\n",
    "        for i_item, item in enumerate(self.dataloader[\"cir\"]):\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # get predictions of student model for all images\n",
    "                s_model_output = self.models[\"s\"](item[\"img\"].to(self.configs.device)) # we want all images (task loss and consistency loss)\n",
    "                \n",
    "                # should be based on loss function!!!!! - can we do all of them in the loss function? this is annoying\n",
    "                # s_model_output = torch.nn.functional.softmax(s_model_output, dim=1) # I DON'T KNOOOOW\n",
    "\n",
    "                # run batch for student model\n",
    "                self.computing_unit[\"s_test\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output, ground_truth=item[\"msk\"])\n",
    "                \n",
    "                print(s_model_output.shape)\n",
    "                \n",
    "                fig, axs = plt.subplots(1, 4)\n",
    "                axs[0].imshow(item[\"img\"][0].permute(1, 2, 0))\n",
    "                _, highest_class = torch.max(s_model_output, 1)  \n",
    "                print(highest_class.shape)\n",
    "                highest_class = highest_class[0].detach().cpu().numpy()\n",
    "                print(highest_class.shape)\n",
    "                axs[1].imshow(highest_class, cmap=\"cool\")\n",
    "                axs[1].axis('off')\n",
    "                from skimage import measure\n",
    "                contours = measure.find_contours(highest_class, 0.5)\n",
    "                axs[2].imshow(item[\"img\"][0].permute(1, 2, 0), cmap=\"gray\")\n",
    "                for contour in contours:\n",
    "                    axs[2].plot(contour[:, 1], contour[:, 0], linewidth=2, color = 'mediumvioletred')\n",
    "                axs[2].axis('off')\n",
    "                axs[3].imshow(item[\"msk\"][0].squeeze())\n",
    "                axs[3].axis('off')\n",
    "                fig.savefig(\"artefact.jpg\", dpi=1000)\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            if i_item == 10:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch Process (basically logging)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_test\"].run_epoch(i_epoch=i_epoch)\n",
    "\n",
    "        # =============================================================================\n",
    "        # Epoch log and reset (validation)\n",
    "        # =============================================================================\n",
    "        \n",
    "        print(\"Test task loss\")\n",
    "        print(self.computing_unit[\"s_test\"].epoch_collector[\"taskloss\"])\n",
    "        \n",
    "        print(\"Test fscore\")\n",
    "        print(self.computing_unit[\"s_test\"].epoch_collector[\"fscore\"])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def log(self, i_epoch):\n",
    "        # =============================================================================\n",
    "        # Save checkpoint\n",
    "        # =============================================================================\n",
    "                \n",
    "        # this cannot woooooooooooooork\n",
    "        # we save the best already in the epoch .... ?\n",
    "        \n",
    "        #print(\"black magic \" * 10)\n",
    "        #print(self.top_val['highest_fscore'])\n",
    "        #print(self.computing_unit[\"s_val\"].top_collector[\"highest_fscore\"] )\n",
    "        \n",
    "        if i_epoch > 2: #  and self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"] > self.computing_unit[\"s_val\"].top[\"highest_fscore\"]:\n",
    "            \n",
    "\n",
    "            \n",
    "            if self.top_val['highest_fscore'] < self.computing_unit[\"s_val\"].top_collector[\"highest_fscore\"]:\n",
    "                \n",
    "                self.top_val['highest_fscore'] = self.computing_unit[\"s_val\"].top_collector[\"highest_fscore\"] \n",
    "                \n",
    "                #print(self.top_val['highest_fscore'])\n",
    "            \n",
    "                checkpoint = {\n",
    "                    'name': self.configs.prefix,\n",
    "                    'i_epoch': i_epoch, \n",
    "                    's_model': self.models[\"s\"].state_dict(),\n",
    "                    't_model': self.models[\"t\"].state_dict(),\n",
    "                    's_optim': self.optims[\"s\"].state_dict(),\n",
    "                    's_lrer': self.lrsers[\"s\"].state_dict()\n",
    "                }\n",
    "                \n",
    "                # self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"]\n",
    "\n",
    "                tmp = self.top_val['highest_fscore']\n",
    "                checkpoint_path = os.path.join(self.configs.save_checkpoint_path, f'checkpoint_{tmp}_{i_epoch}.ckpt')\n",
    "                torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "                # self.computing_unit[\"s_val\"].top[\"fscore\"] = self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"]\n",
    "\n",
    "                logging.info(\"Saved model at epoch \" + str(i_epoch) + \" with fscore \" + str(self.top_val['highest_fscore']))\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0440659-d578-4ae9-a2d5-88331279c1cc",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348ce92-a870-4e22-a192-35b36b883274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configs\n",
    "configs = Configs(reset=True)\n",
    "configs.log()\n",
    "\n",
    "# Run\n",
    "run = RoutineMT(configs)\n",
    "\n",
    "for i_epoch in range(run.start_epoch+1, configs.epochs):\n",
    "\n",
    "    run.run_training(i_epoch=i_epoch)\n",
    "    run.run_validation(i_epoch=i_epoch)\n",
    "    run.log(i_epoch=i_epoch)\n",
    "\n",
    "    if i_epoch > 1 and configs.reduced_data:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64c44c-7478-41e6-987a-7527edd5f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "configs = Configs(reset=False)\n",
    "configs.log()\n",
    "\n",
    "# Run\n",
    "run = RoutineMT(configs)\n",
    "\n",
    "i_epoch = 98\n",
    "\n",
    "run.run_final_evaluation(i_epoch=i_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5635ce9-15d2-43e0-96ff-283f4d581e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "configs = Configs(reset=False)\n",
    "configs.log()\n",
    "\n",
    "# Run\n",
    "run = RoutineMT(configs)\n",
    "\n",
    "i_epoch = 71\n",
    "\n",
    "run.run_final_evaluation(i_epoch=i_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b60f4-b035-43d2-9b52-ae6f72d379a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir projects\\decentnet\\results\\exp1_mt\\logs port=6005   \n",
    "# http://localhost:6005/?runColorGroup=regex%3A(_s_train|_s_val|_t_)#timeseries\n",
    "\n",
    "# regex: (_s_train|_s_val|_t_)\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir E:/Christina/datasceyence/results/exp4_max_mask_b0/logs --port 6039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e4f5d-b8f3-42d8-9fc5-c7ccd9065b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c65a2-7421-4941-87f9-15c57e332fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
