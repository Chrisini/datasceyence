{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75832305-6091-4f3c-980a-53004f01a000",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 𝕊𝕖𝕞𝕚-𝕊𝕦𝕡𝕖𝕣𝕧𝕚𝕤𝕖𝕕 𝕝𝕖𝕒𝕣𝕟𝕚𝕟𝕘 𝕦𝕤𝕚𝕟𝕘 𝕄𝕖𝕒𝕟 𝕋𝕖𝕒𝕔𝕙𝕖𝕣\n",
    "\n",
    "Implementation of pixel-wise Mean Teacher (MT)\n",
    "    \n",
    "This method is proposed in the paper: \n",
    "    'Mean Teachers are Better Role Models:\n",
    "        Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results'\n",
    "This implementation only supports Gaussian noise as input perturbation, and the two-heads\n",
    "outputs trick is not available.\n",
    "\n",
    "Source:\n",
    "https://github.com/ZHKKKe/PixelSSL/blob/master/pixelssl/ssl_algorithm/ssl_mt.py\n",
    "\n",
    "\n",
    "Todo:\n",
    "* [] get everything on cuda, cpu\n",
    "* [] metrics for segmentation + unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b6f142-82ee-4f0a-87f8-e2e9eeeb89b6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a6f3932a-744a-49ca-a076-f12749cf3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "from helper.dataset.meanteacher import *\n",
    "# from helper.model.mean_teacher import * \n",
    "from helper.sampler.mixed_batch import *\n",
    "from helper.model.block.noise_block import GaussianNoiseBlock\n",
    "from helper.compute.bin_seg import BCE_BinSeg_CU\n",
    "from helper.compute.loss.shape import ShapeLoss\n",
    "from helper.compute.loss.dice import DiceLoss\n",
    "from helper.compute.metric.uncertainty import *\n",
    "\n",
    "#from pixelssl.utils import REGRESSION, CLASSIFICATION\n",
    "#from pixelssl.utils import logger, cmd, tool\n",
    "#from pixelssl.nn import func\n",
    "#from pixelssl.nn.module import patch_replication_callback, GaussianNoiseLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a707779-ab4d-46a4-ab5b-e123f91b827a",
   "metadata": {},
   "source": [
    "# Experiment Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "82d1aa89-5640-4263-8051-96580d7d0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # =============================================================================\n",
    "        # \n",
    "        # =============================================================================\n",
    "        \n",
    "        self.prefix = \"mt_tmp\"\n",
    "        self.reduced_data = False\n",
    "        \n",
    "        # smp unet ++ parameters\n",
    "        self.encoder_name = \"efficientnet-b7\"\n",
    "        self.encoder_weights = \"imagenet\"\n",
    "        self.in_channels =  1\n",
    "        self.n_output_neurons = 2\n",
    "        \n",
    "        self.eps = 1e-6\n",
    "        \n",
    "        self.epochs = 100\n",
    "        self.rampup_length = 50\n",
    "        \n",
    "        self.gaussian_noise = 0.1 # None\n",
    "        \n",
    "        self.ema_decay = 0.999 # default value\n",
    "        \n",
    "        # Sizes of tensors must match except in dimension 1\n",
    "        # I solved the issue by resizing all the images size divisible to 32.\n",
    "        self.image_size = 128 # 512\n",
    "        \n",
    "        self.num_workers = 0\n",
    "        self.iterations = 50\n",
    "        \n",
    "        # batch size = n_samples_per_class_per_batch * classes\n",
    "        # for mixed batch sampling\n",
    "        self.n_samples_per_class_per_batch = 1\n",
    "        \n",
    "        self.lbs = 3 #  self.args.labeled_batch_size # .... remove this eventually and replace\n",
    "\n",
    "        # optimisation\n",
    "        self.optimiser = \"sgd\"\n",
    "        self.base_lr = 0.01\n",
    "        self.min_lr = 0.0001\n",
    "        self.weight_decay = 1e-4\n",
    "        self.momentum = 0.9\n",
    "        \n",
    "        # self.is_epoch_lrer = True # epoch or batch based learning rate updater\n",
    "        \n",
    "        self.dropout = None\n",
    "        \n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Paths\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.base_path = r\"C:/Users/Prinzessin/projects/decentnet\"\n",
    "        if not os.path.exists(self.base_path):\n",
    "            os.makedirs(self.base_path)\n",
    "        os.chdir(self.base_path) # this is now the main directory !!!!!!!!!!!!!!!!!!!!\n",
    "        \n",
    "        self.csv_filenames = glob.glob(r\"datasceyence/data_prep/mt_*.csv\")\n",
    "        \n",
    "        print(self.csv_filenames)\n",
    "        \n",
    "        # input\n",
    "        self.load_checkpoint_file = None\n",
    "        \n",
    "        # all csv files used for run_mean_teacher.ipybn\n",
    "        #self.csv_data_paths = [\n",
    "        #    {\"path\" : r\"data/data_ichallenge_amd.csv\"}, \n",
    "        #    {\"path\" : r\"data/data_ichallenge_non_amd.csv\"}\n",
    "        #]\n",
    "        \n",
    "        # output\n",
    "        self.logger_path = f\"results/{self.prefix}/logs\"\n",
    "        if not os.path.exists(self.logger_path):\n",
    "            os.makedirs(self.logger_path)\n",
    "            \n",
    "        self.save_checkpoint_path = f\"results/{self.prefix}/ckpts\"\n",
    "        if not os.path.exists(self.save_checkpoint_path):\n",
    "            os.makedirs(self.save_checkpoint_path)\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    def log(self):\n",
    "        # =============================================================================\n",
    "        # save all class variables to file \"configs.txt\"\n",
    "        # =============================================================================\n",
    "        c = pd.DataFrame.from_dict({'key': self.__dict__.keys(), 'value': self.__dict__.values()})\n",
    "        c.to_csv(os.path.join(self.logger_path, \"configs.txt\"), sep=':', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c64cbd-0bd5-4220-9f34-b7ff564d21ae",
   "metadata": {},
   "source": [
    "# Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7605a7f6-d147-4551-b403-928659086b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutineMT:\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(RoutineMT, self).__init__()\n",
    "        \n",
    "        self.configs = configs\n",
    "        \n",
    "        self.prefix = configs.prefix\n",
    "        self.ema_decay = configs.ema_decay\n",
    "        \n",
    "        self.load_ckpt = torch.load(configs.load_checkpoint_file) if configs.load_checkpoint_file is not None else None\n",
    "        \n",
    "        self.step_counter = 0\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Logger\n",
    "        # =============================================================================\n",
    "        \n",
    "        self.writer =  SummaryWriter(log_dir=self.configs.logger_path)\n",
    "        logging.basicConfig(filename=os.path.join(self.configs.logger_path, 'logger.log'), encoding='utf-8', level=logging.DEBUG)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Models\n",
    "        # =============================================================================\n",
    "        s_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        \n",
    "        t_model = smp.UnetPlusPlus(\n",
    "                        encoder_name=self.configs.encoder_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights=self.configs.encoder_weights,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                        in_channels=self.configs.in_channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                        classes=self.configs.n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "        # detach the teacher model\n",
    "        for param in t_model.parameters():\n",
    "            param.detach_()\n",
    "            \n",
    "        self.models = {'s': s_model, \n",
    "                       't': t_model}\n",
    "        \n",
    "        # add gaussian noise\n",
    "        # currently not in use\n",
    "        self.gaussian_noiser = GaussianNoiseBlock(self.configs.gaussian_noise).cuda()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Computing Units\n",
    "        # =============================================================================\n",
    "        self.computing_unit = {\n",
    "            \"s_train\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"train\"),\n",
    "            \"s_val\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"val\"),\n",
    "            \"t_train\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"train\"),\n",
    "            \"t_val\" : BCE_BinSeg_CU(n_output_neurons=self.configs.n_output_neurons, mode=\"val\")\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Optimisers\n",
    "        # =============================================================================\n",
    "        self.optims = {'s': torch.optim.SGD(self.models[\"s\"].parameters(), lr=self.configs.base_lr, momentum=self.configs.momentum) # optimizer_funcs[0](self.models[\"s\"].module.param_groups)\n",
    "                          }\n",
    "\n",
    "        # =============================================================================\n",
    "        # Learning rate schedulers\n",
    "        # =============================================================================\n",
    "        self.lrsers = {'s': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optims[\"s\"], \n",
    "                                                                              T_0 = 1, # number of iterations for the first restart.\n",
    "                                                                              eta_min = self.configs.min_lr\n",
    "                                                                               )\n",
    "                      \n",
    "                     } # lrer_funcs[0](self.optimizers['s_optimizer'])\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Loss functions\n",
    "        # =============================================================================\n",
    "        # TODO: support more types of the consistency criterion\n",
    "        # something with head and each head has a loss function attached??\n",
    "        self.criterions = {'shape': ShapeLoss(), # criterion_funcs[0](self.args),\n",
    "                           'pixel': DiceLoss(n_output_neurons=self.configs.n_output_neurons),\n",
    "                           # TODO\n",
    "                           # BINARY_MODE MULTICLASS_MODE - the loss wants a different encoding ...\n",
    "                           # ground_truth = torch.nn.functional.one_hot(ground_truth, num_classes)  # N,H*W -> N,H*W, C\n",
    "                           # ground_truth = ground_truth.permute(0, 2, 1)  # N, C, H*W\n",
    "                           # RuntimeError: one_hot is only applicable to index tensor.\n",
    "                           'cons': torch.nn.MSELoss() # softmax missing? there is a softmax mse loss ?? todo\n",
    "                          }\n",
    "        \n",
    "        self.um = UncertaintyMetric(n_noise=4, n_repeat=2, n_output_neurons=self.configs.n_output_neurons)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Datasets: train, val, test\n",
    "        # =============================================================================\n",
    "                \n",
    "        train_set = MeanTeacherTrainDataset(mode=\"train\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames)\n",
    "        train_mbs = MixedBatchSampler(train_set.get_mbs_labels(), n_samples_per_class_per_batch=self.configs.n_samples_per_class_per_batch)\n",
    "        \n",
    "        val_set = MeanTeacherValDataset(mode=\"val\", channels=self.configs.in_channels, image_size=self.configs.image_size, csv_filenames=self.configs.csv_filenames)\n",
    "                \n",
    "        self.dataloader = {\"train\" : DataLoader(train_set, batch_sampler=train_mbs),\n",
    "                           \"val\" :   DataLoader(val_set)\n",
    "                          }\n",
    "          \n",
    "        # =============================================================================\n",
    "        # Resume training\n",
    "        # =============================================================================\n",
    "        if self.load_ckpt:\n",
    "            self.models[\"s\"].load_state_dict(self.load_ckpt['s_model'])\n",
    "            self.models[\"t\"].load_state_dict(self.load_ckpt['t_model'])\n",
    "            self.optims[\"s\"].load_state_dict(self.load_ckpt['s_optimizer'])\n",
    "            self.lrsers[\"s\"].load_state_dict(self.load_ckpt['s_lrer'])\n",
    "\n",
    "\n",
    "    \n",
    "    def run_training(self, i_epoch):\n",
    "        # =============================================================================\n",
    "        # Training\n",
    "        # =============================================================================\n",
    "        \n",
    "        mode=\"train\"\n",
    "        \n",
    "        self.models[\"s\"].train()\n",
    "        self.models[\"t\"].train()\n",
    "        \n",
    "        for i_item, item in enumerate(self.dataloader[mode]):\n",
    "            # =============================================================================\n",
    "            # Process Batch\n",
    "            # =============================================================================\n",
    "            \n",
    "            # unlabelled for consistency loss\n",
    "            unlabelled_batch_ids = np.where(item[\"has_mask\"] == False) \n",
    "            # labelled for task loss\n",
    "            labelled_batch_ids = np.where(item[\"has_mask\"] == True) \n",
    "            \n",
    "            # get predictions of student model for all images\n",
    "            s_model_output = self.models[\"s\"](item[\"img\"]) # we want all images (task loss and consistency loss)\n",
    "            \n",
    "            # run batch for student model\n",
    "            self.computing_unit[\"s_train\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output[labelled_batch_ids], ground_truth=item[\"msk\"][labelled_batch_ids])\n",
    "            \n",
    "            if False:\n",
    "                print(labelled_batch_ids)\n",
    "                print(unlabelled_batch_ids)\n",
    "                print(\"item\"*40)\n",
    "                print(item)\n",
    "                print(\"item\"*40)\n",
    "                print(\"s model\")\n",
    "                print(s_model_output)\n",
    "                print(item[\"msk\"])\n",
    "                print(s_model_output.shape)\n",
    "                print(item[\"msk\"].shape)\n",
    "                print(\"next\")\n",
    "\n",
    "            # =============================================================================\n",
    "            # Teacher Model\n",
    "            # =============================================================================\n",
    "            \n",
    "            # forward the teacher model\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                # get predictions of teacher model for all images\n",
    "                t_model_output = self.models[\"t\"](item[\"img\"])                \n",
    "                self.computing_unit[\"t_train\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=t_model_output[labelled_batch_ids], ground_truth=item[\"msk\"][labelled_batch_ids])\n",
    "                \n",
    "                \n",
    "            \n",
    "            uncertainy_mask = self.um.run(self.models[\"t\"], item[\"img\"])\n",
    "        \n",
    "            # =============================================================================\n",
    "            # Consistency Loss\n",
    "            # =============================================================================\n",
    "            \n",
    "            def sigmoid_rampup(current, rampup_length):\n",
    "                # calculate the ramp-up coefficient of the consistency constraint\n",
    "                # returns vavlue between 0 and 1\n",
    "                # https://github.com/HiLab-git/SSL4MIS/blob/master/code/utils/ramps.py\n",
    "                # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "                if rampup_length == 0:\n",
    "                    return 1.0\n",
    "                else:\n",
    "                    current = np.clip(current, 0.0, rampup_length)\n",
    "                    phase = 1.0 - current / rampup_length\n",
    "                    return float(np.exp(-5.0 * phase * phase))\n",
    "            \n",
    "                        \n",
    "            cons_weight = sigmoid_rampup(i_epoch, self.configs.rampup_length)\n",
    "            \n",
    "            # calculate the consistency constraint from the teacher model to the student model\n",
    "            t_pseudo_gt = Variable(t_model_output.detach().data, requires_grad=False)\n",
    "            \n",
    "            \n",
    "            if unlabelled_batch_ids:\n",
    "                cons_loss = self.criterions[\"cons\"](s_model_output[unlabelled_batch_ids], t_pseudo_gt[unlabelled_batch_ids])\n",
    "            else:\n",
    "                cons_loss = self.zero_tensor\n",
    "            \n",
    "            threshold = ( 0.75 + (0.25*sigmoid_rampup(i_epoch, self.configs.rampup_length)) * np.log(2) )\n",
    "            \n",
    "            bin_uncertainy_mask = (uncertainy_mask < threshold).float()\n",
    "            \n",
    "            cons_loss_masked = torch.sum(bin_uncertainy_mask * cons_loss) / (2*torch.sum(bin_uncertainy_mask)+self.configs.eps)\n",
    "\n",
    "            # =============================================================================\n",
    "            # Backprop for student model\n",
    "            # =============================================================================\n",
    "            \n",
    "            # combined loss\n",
    "            \n",
    "            # supervised loss + consistency loss * consistency weight\n",
    "            loss = self.computing_unit[\"s_train\"].task_loss + cons_loss_masked * cons_weight\n",
    "            \n",
    "            if False: # todo xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx x x x x x x x x x x\n",
    "                # x sajldn asffas y y y y x x x x x x x x  x x x x x x x x x x x x x \n",
    "                # reset student optimiser\n",
    "                # why is this wrong again?? ...\n",
    "                self.optims[\"s\"].zero_grad()\n",
    "                loss.backward()\n",
    "                self.optims[\"s\"].step()\n",
    "            \n",
    "            print(\"training loss\")\n",
    "            print(loss)\n",
    "            \n",
    "            # =============================================================================\n",
    "            # EMA for teacher model\n",
    "            # https://github.com/HiLab-git/SSL4MIS/blob/master/code/train_uncertainty_aware_mean_teacher_2D.py\n",
    "            # https://github.com/ZHKKKe/PixelSSL/blob/master/pixelssl/ssl_algorithm/ssl_mt.py\n",
    "            # =============================================================================\n",
    "            self.ema_decay = min(1 - 1 / (self.step_counter + 1), self.ema_decay)\n",
    "            for t_param, s_param in zip(self.models[\"t\"].parameters(), self.models[\"s\"].parameters()):\n",
    "                t_param.data.mul_(self.ema_decay).add_(1 - self.ema_decay, s_param.data)\n",
    "        \n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch Process (basically logging)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_train\"].run_epoch()\n",
    "        self.computing_unit[\"t_train\"].run_epoch()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch LR Scheduler\n",
    "        # =============================================================================\n",
    "        self.lrsers[\"s\"].step()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Epoch log and reset (training)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_train\"].log()\n",
    "        self.computing_unit[\"t_train\"].log()\n",
    "        self.computing_unit[\"s_train\"].reset_epoch()\n",
    "        self.computing_unit[\"t_train\"].reset_epoch()\n",
    "        \n",
    "        logger.info(\"Traning of epoch %d done\" % i_epoch)\n",
    "\n",
    "    def run_validation(self, data_loader, i_epoch):\n",
    "        self.s_model.eval()\n",
    "        self.t_model.eval()\n",
    "        \n",
    "        # =============================================================================\n",
    "        # for each batch\n",
    "        # =============================================================================\n",
    "\n",
    "        for i_item, item in enumerate(self.dataloader[\"val\"]):\n",
    "            \n",
    "            timer = time.time()\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Student\n",
    "            # =============================================================================\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # get predictions of student model for all images\n",
    "                s_model_output = self.models[\"s\"](item[\"img\"]) # we want all images (task loss and consistency loss)\n",
    "                s_model_output = torch.nn.functional.softmax(s_model_output, dim=0) # I DON'T KNOOOOW\n",
    "\n",
    "                # run batch for student model\n",
    "                self.computing_unit[\"s_val\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=s_model_output, ground_truth=item[\"msk\"])\n",
    "            \n",
    "            # =============================================================================\n",
    "            # Teacher\n",
    "            # =============================================================================\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # get predictions of teacher model for all images\n",
    "                t_model_output = self.models[\"t\"](item[\"img\"])                \n",
    "            \n",
    "                self.computing_unit[\"t_val\"].run_batch(configs=self.configs, criterions=self.criterions, model_output=t_model_output[labelled_batch_ids], ground_truth=item[\"msk\"][labelled_batch_ids])\n",
    "                \n",
    "            # =============================================================================\n",
    "            # Consistency loss\n",
    "            # =============================================================================\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # calculate the consistency constraint from the teacher model to the student model\n",
    "                t_pseudo_gt = Variable(t_model_output.detach().data, requires_grad=False)\n",
    "                cons_loss = self.criterions[\"cons\"](s_model_output, t_pseudo_gt)    \n",
    "                cons_loss = torch.mean(cons_loss) # * self.args.cons_scale\n",
    "\n",
    "            \n",
    "        # =============================================================================\n",
    "        # Epoch log and reset (validation)\n",
    "        # =============================================================================\n",
    "        self.computing_unit[\"s_val\"].log()\n",
    "        self.computing_unit[\"t_val\"].log()\n",
    "        self.computing_unit[\"s_val\"].reset_epoch()\n",
    "        self.computing_unit[\"t_val\"].reset_epoch()\n",
    "        \n",
    "        logger.info(\"Validation of epoch %d done\" % i_epoch)\n",
    "        \n",
    "\n",
    "    def log(self, i_epoch):\n",
    "        # =============================================================================\n",
    "        # Save checkpoint\n",
    "        # =============================================================================\n",
    "                \n",
    "        if i_epoch > 5 and self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"] > self.computing_unit[\"s_val\"].best[\"fscore\"]:\n",
    "            state = {\n",
    "                'name': self.prefix,\n",
    "                'epoch': i_epoch, \n",
    "                's_model': self.models[\"s\"].state_dict(),\n",
    "                't_model': self.models[\"t\"].state_dict(),\n",
    "                's_optim': self.optims[\"s\"].state_dict(),\n",
    "                's_lrer': self.lrsers[\"s\"].state_dict()\n",
    "            }\n",
    "\n",
    "            checkpoint = os.path.join(self.configs.save_checkpoint_path, 'checkpoint_{0}.ckpt'.format(i_epoch))\n",
    "            torch.save(state, checkpoint)\n",
    "            \n",
    "            self.computing_unit[\"s_val\"].best[\"fscore\"] = self.computing_unit[\"s_val\"].epoch_collector[\"fscore\"]\n",
    "            \n",
    "            logger.info(\"Saved model at epoch %d\" % i_epoch)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0440659-d578-4ae9-a2d5-88331279c1cc",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9de02c93-618e-464e-afc8-8da004a671e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasceyence/data_prep\\\\mt_data_ichallenge_amd.csv', 'datasceyence/data_prep\\\\mt_data_ichallenge_glaucoma.csv', 'datasceyence/data_prep\\\\mt_data_ichallenge_non_amd.csv', 'datasceyence/data_prep\\\\mt_data_ichallenge_unlabelled.csv']\n",
      "training loss\n",
      "tensor(0.8615, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\AppData\\Local\\Temp\\ipykernel_31104\\590022837.py:234: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  t_param.data.mul_(self.ema_decay).add_(1 - self.ema_decay, s_param.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss\n",
      "tensor(0.8302, grad_fn=<AddBackward0>)\n",
      "training loss\n",
      "tensor(0.8330, grad_fn=<AddBackward0>)\n",
      "training loss\n",
      "tensor(0.8615, grad_fn=<AddBackward0>)\n",
      "training loss\n",
      "tensor(0.8605, grad_fn=<AddBackward0>)\n",
      "training loss\n",
      "tensor(0.7902, grad_fn=<AddBackward0>)\n",
      "training loss\n",
      "tensor(0.8624, grad_fn=<AddBackward0>)\n",
      "training loss\n",
      "tensor(0.8656, grad_fn=<AddBackward0>)\n",
      "training loss\n",
      "tensor(0.8759, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31104\\3403682603.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_epoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#run.run_validation(i_epoch=i_epoch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#run.log(i_epoch=i_epoch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31104\\590022837.py\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m(self, i_epoch)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0muncertainy_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"img\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;31m# =============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\decentnet\\datasceyence\\helper\\compute\\metric\\uncertainty.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, model, img_batch)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mema_preds\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_repeat\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_repeat\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mema_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mema_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mema_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\segmentation_models_pytorch\\base\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;34m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\segmentation_models_pytorch\\encoders\\efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0mdrop_connect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mblock_number\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[0mblock_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_connect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\efficientnet_pytorch\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_block_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_ratio\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expand_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\efficientnet_pytorch\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "configs = Configs()\n",
    "configs.log()\n",
    "\n",
    "# Run\n",
    "run = RoutineMT(configs)\n",
    "\n",
    "for i_epoch in range(configs.epochs):\n",
    "    \n",
    "    run.run_training(i_epoch=i_epoch)\n",
    "    #run.run_validation(i_epoch=i_epoch)\n",
    "    #run.log(i_epoch=i_epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1781785-eb28-4327-b98f-bc1b0c926181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1756\n"
     ]
    }
   ],
   "source": [
    "import torch.nn\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "input = torch.randn(1, 2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f74619-f77d-4796-af9c-a2e19ac6fa52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
