{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c6274-2e43-4dd4-828f-82b305e6d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "import unittest\n",
    "\n",
    "# model and transform\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "# \"helper\" needs to be part of sys path\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "sys.path.insert(0, \"/helper\")\n",
    "sys.path.insert(0, \"./helper\")\n",
    "sys.path.insert(0, \"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "device=\"cpu\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own module\n",
    "from visualisation.deepdream import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080e42f-3d09-46e6-8bca-485aeec64dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "\"\"\"\n",
    "img=Image.effect_noise((500, 500), 25).convert('RGB') \n",
    "\"\"\"\n",
    "# tensor preparation\n",
    "resize = transforms.Resize(128)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img = resize(img)\n",
    "fig = plt.figure(figsize = (5 , 5))\n",
    "plt.imshow(img)\n",
    "img = to_tensor(img).to(device)\n",
    "\n",
    "# model preparation\n",
    "#model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "from model.decent_block import *\n",
    "#model = DecentBlock(None, None, 2, device)\n",
    "model = DecentBlock(\"example_ckpt\", \"exp_1_mlp_c0_ep46_1.5189.ckpt\", 2, device)\n",
    "\n",
    "# layer to focus on\n",
    "print(\"*\"*50)\n",
    "print(\"example graph nodes:\", get_graph_node_names(model)[0][10:20])\n",
    "print(\"*\"*50)\n",
    "layer = model.decent_block.decent_block_116[2][3].branch2[0]\n",
    "# model.decent_block.decent_block_reduction[0] # model.stage4[0].branch1[2] # model.fusion_layer # conv\n",
    "\n",
    "# run deep dream\n",
    "dd = DeepDream(model=model, layer=layer, device=device, iterations=1000, lr=0.1)\n",
    "dd.run(img)\n",
    "dd.plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46fa62d-44c1-45d1-8016-18dba5ba8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "img=Image.effect_noise((500, 500), 25).convert('RGB') \n",
    "\n",
    "# tensor preparation\n",
    "resize = transforms.Resize(128)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img = resize(img)\n",
    "fig = plt.figure(figsize = (5 , 5))\n",
    "plt.imshow(img)\n",
    "img = to_tensor(img).to(device)\n",
    "\n",
    "# model preparation\n",
    "#model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "from model.decent_block import *\n",
    "model = DecentBlock(\"example_ckpt\", \"exp_1_mlp_c3_ep43_1.2093.ckpt\", 2, device)\n",
    "\n",
    "# layer to focus on\n",
    "print(\"*\"*50)\n",
    "print(\"example graph nodes:\", get_graph_node_names(model)[0][10:20])\n",
    "print(\"*\"*50)\n",
    "layer = model.decent_block.decent_block_116[2][3].branch2[0]\n",
    "# model.decent_block.decent_block_reduction[0] # model.stage4[0].branch1[2] # model.fusion_layer # conv\n",
    "\n",
    "# run deep dream\n",
    "dd = DeepDream(model=model, layer=layer, device=device, iterations=1000, lr=0.1)\n",
    "dd.run(img)\n",
    "dd.plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ef020-2ed8-476a-8d7b-ea34016b0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "img=Image.effect_noise((500, 500), 25).convert('RGB') \n",
    "\n",
    "# tensor preparation\n",
    "resize = transforms.Resize(128)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img = resize(img)\n",
    "fig = plt.figure(figsize = (5 , 5))\n",
    "plt.imshow(img)\n",
    "img = to_tensor(img).to(device)\n",
    "\n",
    "# model preparation\n",
    "#model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "from model.decent_block import *\n",
    "model = DecentBlock(\"example_ckpt\", \"exp_1_mlp_c5_ep36_1.1963.ckpt\", 2, device)\n",
    "\n",
    "# layer to focus on\n",
    "print(\"*\"*50)\n",
    "print(\"example graph nodes:\", get_graph_node_names(model)[0][10:20])\n",
    "print(\"*\"*50)\n",
    "layer = model.decent_block.decent_block_116[2][3].branch2[0]\n",
    "# model.decent_block.decent_block_reduction[0] # model.stage4[0].branch1[2] # model.fusion_layer # conv model.stage4[0].branch1[2] # \n",
    "\n",
    "# run deep dream\n",
    "dd = DeepDream(model=model, layer=layer, device=device, iterations=5000, lr=0.01)\n",
    "dd.run(img)\n",
    "dd.plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33ad56-d235-43f1-a799-01de3e802314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
