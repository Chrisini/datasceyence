{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8ea6b-7e2f-4257-9875-25f651882f81",
   "metadata": {},
   "source": [
    "# some links\n",
    "\n",
    "* https://github.com/MSKCC-Computational-Pathology/MIL-nature-medicine-2019/blob/master/MIL_train.py\n",
    "\n",
    "* https://github.com/binli123/dsmil-wsi/blob/master/attention_map.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38836e4-6905-4e0c-b344-bcc3b8094388",
   "metadata": {},
   "source": [
    "# original conv2d layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b972ff66-723c-43a1-a9d9-80c43b450efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.utils import _single, _pair, _triple, _reverse_repeat_tuple\n",
    "from torch._torch_docs import reproducibility_notes\n",
    "\n",
    "from torch.nn.common_types import _size_1_t, _size_2_t, _size_3_t\n",
    "from typing import Optional, List, Tuple, Union\n",
    "\n",
    "__all__ = ['Conv1d', 'Conv2d', 'Conv3d', 'ConvTranspose1d', 'ConvTranspose2d', 'ConvTranspose3d',\n",
    "           'LazyConv1d', 'LazyConv2d', 'LazyConv3d', 'LazyConvTranspose1d', 'LazyConvTranspose2d',\n",
    "           'LazyConvTranspose3d']\n",
    "\n",
    "convolution_notes = \\\n",
    "    {\"groups_note\": r\"\"\"* :attr:`groups` controls the connections between inputs and outputs.\n",
    "      :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
    "      :attr:`groups`. For example,\n",
    "\n",
    "        * At groups=1, all inputs are convolved to all outputs.\n",
    "        * At groups=2, the operation becomes equivalent to having two conv\n",
    "          layers side by side, each seeing half the input channels\n",
    "          and producing half the output channels, and both subsequently\n",
    "          concatenated.\n",
    "        * At groups= :attr:`in_channels`, each input channel is convolved with\n",
    "          its own set of filters (of size\n",
    "          :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\"\"\",\n",
    "\n",
    "        \"depthwise_separable_note\": r\"\"\"When `groups == in_channels` and `out_channels == K * in_channels`,\n",
    "        where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
    "\n",
    "        In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
    "        a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
    "        :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\"\"\"}  # noqa: B950\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class _ConvNd(Module):\n",
    "\n",
    "    __constants__ = ['stride', 'padding', 'dilation', 'groups',\n",
    "                     'padding_mode', 'output_padding', 'in_channels',\n",
    "                     'out_channels', 'kernel_size']\n",
    "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]) -> Tensor:\n",
    "        ...\n",
    "\n",
    "    in_channels: int\n",
    "    _reversed_padding_repeated_twice: List[int]\n",
    "    out_channels: int\n",
    "    kernel_size: Tuple[int, ...]\n",
    "    stride: Tuple[int, ...]\n",
    "    padding: Union[str, Tuple[int, ...]]\n",
    "    dilation: Tuple[int, ...]\n",
    "    transposed: bool\n",
    "    output_padding: Tuple[int, ...]\n",
    "    groups: int\n",
    "    padding_mode: str\n",
    "    weight: Tensor\n",
    "    bias: Optional[Tensor]\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Tuple[int, ...],\n",
    "                 stride: Tuple[int, ...],\n",
    "                 padding: Tuple[int, ...],\n",
    "                 dilation: Tuple[int, ...],\n",
    "                 transposed: bool,\n",
    "                 output_padding: Tuple[int, ...],\n",
    "                 groups: int,\n",
    "                 bias: bool,\n",
    "                 padding_mode: str,\n",
    "                 device=None,\n",
    "                 dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        if groups <= 0:\n",
    "            raise ValueError('groups must be a positive integer')\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        valid_padding_strings = {'same', 'valid'}\n",
    "        if isinstance(padding, str):\n",
    "            if padding not in valid_padding_strings:\n",
    "                raise ValueError(\n",
    "                    \"Invalid padding string {!r}, should be one of {}\".format(\n",
    "                        padding, valid_padding_strings))\n",
    "            if padding == 'same' and any(s != 1 for s in stride):\n",
    "                raise ValueError(\"padding='same' is not supported for strided convolutions\")\n",
    "\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        # `_reversed_padding_repeated_twice` is the padding to be passed to\n",
    "        # `F.pad` if needed (e.g., for non-zero padding types that are\n",
    "        # implemented as two ops: padding + conv). `F.pad` accepts paddings in\n",
    "        # reverse order than the dimension.\n",
    "        if isinstance(self.padding, str):\n",
    "            self._reversed_padding_repeated_twice = [0, 0] * len(kernel_size)\n",
    "            if padding == 'same':\n",
    "                for d, k, i in zip(dilation, kernel_size,\n",
    "                                   range(len(kernel_size) - 1, -1, -1)):\n",
    "                    total_padding = d * (k - 1)\n",
    "                    left_pad = total_padding // 2\n",
    "                    self._reversed_padding_repeated_twice[2 * i] = left_pad\n",
    "                    self._reversed_padding_repeated_twice[2 * i + 1] = (\n",
    "                        total_padding - left_pad)\n",
    "        else:\n",
    "            self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2)\n",
    "\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (in_channels, out_channels // groups, *kernel_size), **factory_kwargs))\n",
    "        else:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (out_channels, in_channels // groups, *kernel_size), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            if fan_in != 0:\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'\n",
    "\n",
    "\n",
    "class Conv2d(_ConvNd):\n",
    "    __doc__ = r\"\"\"Applies a 2D convolution over an input signal composed of several input\n",
    "    planes.\n",
    "\n",
    "    In the simplest case, the output value of the layer with input size\n",
    "    :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
    "    can be precisely described as:\n",
    "\n",
    "    .. math::\n",
    "        \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
    "        \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
    "\n",
    "\n",
    "    where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
    "    :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
    "    :math:`H` is a height of input planes in pixels, and :math:`W` is\n",
    "    width in pixels.\n",
    "    \"\"\" + r\"\"\"\n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
    "\n",
    "    * :attr:`stride` controls the stride for the cross-correlation, a single\n",
    "      number or a tuple.\n",
    "\n",
    "    * :attr:`padding` controls the amount of padding applied to the input. It\n",
    "      can be either a string {{'valid', 'same'}} or an int / a tuple of ints giving the\n",
    "      amount of implicit padding applied on both sides.\n",
    "\n",
    "    * :attr:`dilation` controls the spacing between the kernel points; also\n",
    "      known as the à trous algorithm. It is harder to describe, but this `link`_\n",
    "      has a nice visualization of what :attr:`dilation` does.\n",
    "\n",
    "    {groups_note}\n",
    "\n",
    "    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
    "\n",
    "        - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
    "        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
    "          and the second `int` for the width dimension\n",
    "\n",
    "    Note:\n",
    "        {depthwise_separable_note}\n",
    "\n",
    "    Note:\n",
    "        {cudnn_reproducibility_note}\n",
    "\n",
    "    Note:\n",
    "        ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
    "        the input so the output has the shape as the input. However, this mode\n",
    "        doesn't support any stride values other than 1.\n",
    "\n",
    "    Note:\n",
    "        This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int, tuple or str, optional): Padding added to all four sides of\n",
    "            the input. Default: 0\n",
    "        padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
    "            ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        groups (int, optional): Number of blocked connections from input\n",
    "            channels to output channels. Default: 1\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the\n",
    "            output. Default: ``True``\n",
    "    \"\"\".format(**reproducibility_notes, **convolution_notes) + r\"\"\"\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
    "        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
    "                        \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
    "                        \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
    "\n",
    "    Attributes:\n",
    "        weight (Tensor): the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
    "            :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
    "            The values of these weights are sampled from\n",
    "            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
    "        bias (Tensor):   the learnable bias of the module of shape\n",
    "            (out_channels). If :attr:`bias` is ``True``,\n",
    "            then the values of these weights are\n",
    "            sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> # With square kernels and equal stride\n",
    "        >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "        >>> # non-square kernels and unequal stride and with padding\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "        >>> # non-square kernels and unequal stride and with padding and dilation\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "        >>> input = torch.randn(20, 16, 50, 100)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    .. _cross-correlation:\n",
    "        https://en.wikipedia.org/wiki/Cross-correlation\n",
    "\n",
    "    .. _link:\n",
    "        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: _size_2_t,\n",
    "        stride: _size_2_t = 1,\n",
    "        padding: Union[str, _size_2_t] = 0,\n",
    "        dilation: _size_2_t = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        padding_mode: str = 'zeros',  # TODO: refine this type\n",
    "        device=None,\n",
    "        dtype=None\n",
    "    ) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        kernel_size_ = _pair(kernel_size)\n",
    "        stride_ = _pair(stride)\n",
    "        padding_ = padding if isinstance(padding, str) else _pair(padding)\n",
    "        dilation_ = _pair(dilation)\n",
    "        super().__init__(\n",
    "            in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n",
    "            False, _pair(0), groups, bias, padding_mode, **factory_kwargs)\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "        if self.padding_mode != 'zeros':\n",
    "            return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            weight, bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        return F.conv2d(input, weight, bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self._conv_forward(input, self.weight, self.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f2a10-1d10-4dcc-9991-043d79dc535c",
   "metadata": {},
   "source": [
    "# freeze 2d layer\n",
    "* https://github.com/galidor/PyTorchPartialLayerFreezing/blob/main/partial_freezing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9677422-d9f4-48f4-9fca-3eb85b4b6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_conv2d_params(layer, weight_indices, bias_indices=None, weight_hook_handle=None, bias_hook_handle=None):\n",
    "    if weight_hook_handle is not None:\n",
    "        weight_hook_handle.remove()\n",
    "    if bias_hook_handle is not None:\n",
    "        bias_hook_handle.remove()\n",
    "\n",
    "    if (weight_indices == [] or weight_indices is None) and (bias_indices == [] or bias_indices is None):\n",
    "        return\n",
    "\n",
    "    if bias_indices is None:\n",
    "        bias_indices = weight_indices\n",
    "\n",
    "    if not (isinstance(layer, Conv2d) or isinstance(layer, nn.Conv2d)):\n",
    "        raise ValueError(\"layer must be a valid Conv2d layer\")\n",
    "\n",
    "    if max(weight_indices) >= layer.weight.shape[0]:\n",
    "        raise IndexError(\"weight_indices must be less than the number output channels\")\n",
    "\n",
    "    if layer.bias is not None:\n",
    "        if max(bias_indices) >= layer.bias.shape[0]:\n",
    "            raise IndexError(\"bias_indices must be less than the number output channels\")\n",
    "\n",
    "    def freezing_hook_weight_full(grad, weight_multiplier):\n",
    "        return grad * weight_multiplier\n",
    "\n",
    "    def freezing_hook_bias_full(grad, bias_multiplier):\n",
    "        return grad * bias_multiplier\n",
    "\n",
    "    weight_multiplier = torch.ones(layer.weight.shape[0]).to(layer.weight.device)\n",
    "    weight_multiplier[weight_indices] = 0\n",
    "    weight_multiplier = weight_multiplier.view(-1, 1, 1, 1)\n",
    "    freezing_hook_weight = lambda grad: freezing_hook_weight_full(grad, weight_multiplier)\n",
    "    weight_hook_handle = layer.weight.register_hook(freezing_hook_weight)\n",
    "\n",
    "    if layer.bias is not None:\n",
    "        bias_multiplier = torch.ones(layer.weight.shape[0]).to(layer.bias.device)\n",
    "        bias_multiplier[bias_indices] = 0\n",
    "        freezing_hook_bias = lambda grad: freezing_hook_bias_full(grad, bias_multiplier)\n",
    "        bias_hook_handle = layer.bias.register_hook(freezing_hook_bias)\n",
    "    else:\n",
    "        bias_hook_handle = None\n",
    "\n",
    "    return weight_hook_handle, bias_hook_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369256cb-1ea4-4ff2-8ce5-a820511e0779",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2823e218-5eb3-44d9-a277-2cf17b772c84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../helper', './helper', '/helper', 'helper', '../helper', './helper', '/helper', 'helper', '../helper', './helper', '/helper', 'helper', 'C:\\\\Users\\\\Christina\\\\Documents\\\\datasceyence\\\\examples', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\python39.zip', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\DLLs', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy', '', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\pixelssl-0.1.4-py3.9.egg', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\Pythonwin']\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.727132\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 239\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_model \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    235\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_results/mnist_cnn_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 229\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m#scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 229\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m     test(args, model, device, test_loader, epoch)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 114\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(args, model, device, train_loader, optimizer, epoch):\n\u001b[0;32m    113\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m    118\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# .to(device)\u001b[39;00m\n\u001b[0;32m    119\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "sys.path.insert(0, \"/helper\")\n",
    "sys.path.insert(0, \"./helper\")\n",
    "sys.path.insert(0, \"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "# own module\n",
    "from visualisation.feature_map import *\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.K = 100 \n",
    "        self.L = 10 # last one\n",
    "        self.num_of_bases = 1 # 3rd dim\n",
    "        \n",
    "        self.conv1 = Conv2d(1, 32, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv2 = Conv2d(32, 64, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv3 = Conv2d(64, 128, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv1x1 = Conv2d(128, 10, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        #self.dropout1 = nn.Dropout(0.25)\n",
    "        #self.dropout2 = nn.Dropout(0.5)\n",
    "        # 4x16384\n",
    "        # self.fc1 = nn.Linear(10*10*10, 10)\n",
    "        #self.fc2 = nn.Linear(10, 10)\n",
    "        \n",
    "        #self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc3 = nn.Linear(10, 10)\n",
    "        \n",
    "        self.mish1 = torch.nn.Mish()\n",
    "        self.mish2 = torch.nn.Mish()\n",
    "        self.mish3 = torch.nn.Mish()\n",
    "        self.mish1x1 = torch.nn.Mish()\n",
    "        \n",
    "        #self.sub_concept_pooling = nn.modules.MaxPool2d((self.K, 1), stride=(1,1))\n",
    "        #self.instance_pooling = nn.modules.MaxPool2d((opt.num_of_bases, 1), stride=(1,1))\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.mish1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.mish2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.mish3(x)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        x = self.mish1x1(x)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        \n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        #x = self.dropout1(x)\n",
    "        \n",
    "        #print(x.size())\n",
    "        #print(x.size()[2:])\n",
    "        \n",
    "        x = F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        \n",
    "        #x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        #x = x.view(-1, self.L, self.K, 10)\n",
    "        \n",
    "        # input, kernel_size, stride, padding, dilation, ceil_mode\n",
    "        #x = self.sub_concept_pooling(x).view(-1, self.L, self.num_of_bases).permute(0,2,1).unsqueeze(1)\n",
    "        \n",
    "        # output = F.sigmoid(x)\n",
    "        # x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        #x = torch.flatten(x, 1)\n",
    "        # x = self.fc1(x)\n",
    "        #x = F.relu(x)\n",
    "        \n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.fc2(x)\n",
    "        #output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76fa05-b47e-4264-85cf-766d8ca060d3",
   "metadata": {},
   "source": [
    "# normal run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0819306e-ff93-4f38-898b-4c1cd2221b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.723641\n",
      "\n",
      "Test set: Average loss: 0.3251, Accuracy: 2186/10000 (22%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.325065\n",
      "\n",
      "Test set: Average loss: 0.3172, Accuracy: 2060/10000 (21%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.318317\n",
      "\n",
      "Test set: Average loss: 0.2708, Accuracy: 3668/10000 (37%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.277439\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 128\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_model \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    124\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_results/mnist_cnn_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 119\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    118\u001b[0m     train(args, model, device, train_loader, optimizer, epoch)\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_model \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[43], line 55\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(args, model, device, test_loader, epoch)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\u001b[39;00m\n\u001b[0;32m     54\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# get the index of the max log-probability\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# if False: # i == 0:\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "        \n",
    "        if batch_idx == -1:\n",
    "            print(data.shape) # torch.Size([4, 1, 28, 28])\n",
    "            print(target)\n",
    "            \"\"\"\n",
    "            tensor([[8],\n",
    "            [7],\n",
    "            [2],\n",
    "            [7]])\n",
    "            \"\"\"\n",
    "            print(target_multi_hot)\n",
    "            \"\"\"\n",
    "            tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "            [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
    "            \"\"\"\n",
    "        \n",
    "        loss = F.binary_cross_entropy(output, target_multi_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % (args.log_interval*1000) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "            test_loss += F.binary_cross_entropy(output, target_multi_hot, reduction='mean').item()\n",
    "        \n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "            \n",
    "            if i == 0 and epoch % args.log_interval == 0:\n",
    "            # if False: # i == 0:\n",
    "                print(data.shape)\n",
    "                layer = model.conv1x1 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "                # run feature map\n",
    "                dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "                dd.run(data)\n",
    "                dd.plot(path=f\"example_results/feature_map_{epoch}.png\")\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class Parser():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.test_batch_size = 1\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.1\n",
    "        self.gamma = 0.7\n",
    "        self.log_interval = 5\n",
    "        self.save_model = True\n",
    "        \n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('example_data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader, epoch)\n",
    "        #scheduler.step()\n",
    "        \n",
    "        \n",
    "        if args.save_model and epoch % args.log_interval == 0:\n",
    "            torch.save(model.state_dict(), f\"example_results/mnist_cnn_{epoch}.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7fda0-4191-4cbe-a761-cce43ea31ed4",
   "metadata": {},
   "source": [
    "# freeze run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4609fee-aee9-4536-9c6a-09402447a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is instance Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
      "is instance Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
      "is instance Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
      "is instance Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "Conv2d grads passed\n",
      "Conv2d frozen weights and biases passed\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "    \n",
    "device = 'cuda:0' if next(net.parameters()).is_cuda else 'cpu'\n",
    "\n",
    "indices = [2, 3, 4, 5]\n",
    "for module in net.modules():\n",
    "    if isinstance(module, Conv2d):\n",
    "        print(\"is instance\", module)\n",
    "        freeze_conv2d_params(module, indices)\n",
    "\n",
    "init_weights = net.conv1x1.weight.clone()\n",
    "init_biases = net.conv1x1.bias.clone()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "random_input2d = torch.randn((1, 1, 32, 32)).to(device)\n",
    "\n",
    "net.train()\n",
    "optimizer.zero_grad()\n",
    "output = net(random_input2d)\n",
    "loss = F.cross_entropy(output, torch.tensor([5]).to(device))\n",
    "loss.backward(create_graph=True)\n",
    "if (net.conv1x1.bias.grad[indices] == torch.zeros_like(net.conv1x1.bias.grad[indices])).all() and \\\n",
    "   (net.conv1x1.weight.grad[indices, :, :, :] == torch.zeros_like(net.conv1x1.weight.grad[indices, :, :, :])).all():\n",
    "    print(\"Conv2d grads passed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n",
    "else:\n",
    "    print(\"Conv2d grads failed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n",
    "optimizer.step()\n",
    "\n",
    "if (net.conv1x1.bias == init_biases)[indices].all() and (net.conv1x1.weight == init_weights)[indices].all():\n",
    "    print(\"Conv2d frozen weights and biases passed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n",
    "else:\n",
    "    print(\"Conv2d frozen weights and biases failed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1118d82-8e48-4607-ab22-58b42d94962d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0688]],\n",
       "\n",
       "         [[ 0.0582]],\n",
       "\n",
       "         [[-0.0335]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0647]],\n",
       "\n",
       "         [[-0.0054]],\n",
       "\n",
       "         [[ 0.0016]]],\n",
       "\n",
       "\n",
       "        [[[-0.0622]],\n",
       "\n",
       "         [[ 0.0738]],\n",
       "\n",
       "         [[ 0.0194]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0730]],\n",
       "\n",
       "         [[ 0.0285]],\n",
       "\n",
       "         [[-0.0233]]],\n",
       "\n",
       "\n",
       "        [[[-0.0251]],\n",
       "\n",
       "         [[-0.0236]],\n",
       "\n",
       "         [[-0.0163]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0656]],\n",
       "\n",
       "         [[-0.0551]],\n",
       "\n",
       "         [[-0.0740]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0794]],\n",
       "\n",
       "         [[ 0.0027]],\n",
       "\n",
       "         [[-0.0104]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0561]],\n",
       "\n",
       "         [[ 0.0790]],\n",
       "\n",
       "         [[ 0.0860]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0561]],\n",
       "\n",
       "         [[ 0.0270]],\n",
       "\n",
       "         [[ 0.0822]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0773]],\n",
       "\n",
       "         [[-0.0473]],\n",
       "\n",
       "         [[ 0.0526]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0076]],\n",
       "\n",
       "         [[-0.0839]],\n",
       "\n",
       "         [[ 0.0333]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0095]],\n",
       "\n",
       "         [[ 0.0596]],\n",
       "\n",
       "         [[-0.0723]]]], requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1x1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96675744-26ea-45b8-8259-91fdff0c1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in net.modules():\n",
    "    print(i.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee7610-4b8e-43b6-b184-1d84fca420eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in net.named_modules():\n",
    "    # print(module)\n",
    "    if isinstance(module, Conv2d):\n",
    "        print(name, module.weight.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe53715-1dca-4246-b119-7ffba67ac337",
   "metadata": {},
   "source": [
    "# something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db2c241c-4006-4d52-bfa0-c820bb5a8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the layers Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d grads passed\n",
      "Conv2d frozen weights and biases passed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class vgg16_bn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vgg16_bn, self).__init__()\n",
    "        self.features = models.vgg16_bn(pretrained=False).features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def test_conv2d_freezing(net):\n",
    "    device = 'cuda:0' if next(model.parameters()).is_cuda else 'cpu'\n",
    "\n",
    "    indices = [2, 3, 4, 5]\n",
    "    for module in net.features:\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            freeze_conv2d_params(module, indices)\n",
    "\n",
    "    init_weights = net.features[3].weight.clone()\n",
    "    \n",
    "    print(\"one of the layers\", net.features[3])\n",
    "    \n",
    "    init_biases = net.features[3].bias.clone()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "    random_input2d = torch.randn((1, 3, 32, 32)).to(device)\n",
    "\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = net(random_input2d)\n",
    "    loss = F.cross_entropy(output, torch.tensor([5]).to(device))\n",
    "    loss.backward(create_graph=True)\n",
    "    if (net.features[3].bias.grad[indices] == torch.zeros_like(net.features[3].bias.grad[indices])).all() and \\\n",
    "       (net.features[3].weight.grad[indices, :, :, :] == torch.zeros_like(net.features[3].weight.grad[indices, :, :, :])).all():\n",
    "        print(\"Conv2d grads passed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n",
    "    else:\n",
    "        print(\"Conv2d grads failed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n",
    "    optimizer.step()\n",
    "\n",
    "    if (net.features[3].bias == init_biases)[indices].all() and (net.features[3].weight == init_weights)[indices].all():\n",
    "        print(\"Conv2d frozen weights and biases passed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n",
    "    else:\n",
    "        print(\"Conv2d frozen weights and biases failed{:}\".format(' on CUDA' if device == 'cuda:0' else ''))\n",
    "    \n",
    "    \n",
    "model = vgg16_bn()\n",
    "test_conv2d_freezing(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92da6083-0fe4-4c47-8171-7f010c18b234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8799, 0.3235, 0.5193, 0.7517, 0.6015, 0.5361, 0.2711, 0.5005, 0.3705,\n",
      "         0.8194],\n",
      "        [0.2918, 0.7412, 0.8018, 0.4085, 0.6336, 0.5268, 0.0360, 0.0849, 0.8739,\n",
      "         0.6862],\n",
      "        [0.5561, 0.3134, 0.1298, 0.6572, 0.6069, 0.2491, 0.3297, 0.1984, 0.4230,\n",
      "         0.6347]])\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
      "tensor(0.7924)\n",
      "tensor(0.7924)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 3\n",
    "num_classes = 10\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "outputs_before_sigmoid = torch.randn(batch_size, num_classes)\n",
    "sigmoid_outputs = torch.sigmoid(outputs_before_sigmoid)\n",
    "\n",
    "# classes = [[2, 4, 7], [3, 6, 9]]\n",
    "labels = torch.tensor([[1], [9], [4]])\n",
    "# labels = labels.unsqueeze(0)\n",
    "target_classes = torch.zeros(labels.size(0), 10).scatter_(1, labels, 1.)\n",
    "\n",
    "\n",
    "# target_classes = torch.randint(0, 2, (batch_size, num_classes)).to(torch.float32)  # randints in [0, 2).\n",
    "\n",
    "loss = loss_fn(sigmoid_outputs, target_classes)\n",
    "\n",
    "# alternatively, use BCE with logits, on outputs before sigmoid.\n",
    "loss_fn_2 = torch.nn.BCEWithLogitsLoss()\n",
    "loss2 = loss_fn_2(outputs_before_sigmoid, target_classes)\n",
    "\n",
    "print(sigmoid_outputs)\n",
    "\n",
    "print(target_classes)\n",
    "\n",
    "print(loss)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d27aa-4fc3-4b43-920d-071d3cc464d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([1, 0, 5, 2])\n",
    "labels = labels.unsqueeze(0)\n",
    "\n",
    "target = torch.zeros(labels.size(0), 10).scatter_(1, labels, 1.)\n",
    "print(target)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784a059-0ada-423c-a4c1-112548c099de",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.empty(3, 4, 5)\n",
    "t.size()\n",
    "\n",
    "t.size(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae197ae-7a60-4445-9c11-91614ed75c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c674872-1f7b-4772-9bff-cf6b896c45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "64*16*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2736a566-a08f-4fa1-b1b0-b29884bc9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "12800/128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b52d2-f69b-4699-8bbf-165a70fc1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b00b39-433d-4ad6-9cf9-c61d805b5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MultiLabelMarginLoss()\n",
    "x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])\n",
    "# for target y, only consider labels 3 and 0, not after label -1\n",
    "y = torch.LongTensor([[3, 0, -1, 1]])\n",
    "# 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n",
    "loss(x, y)\n",
    "#tensor(0.85...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eafd75-37c3-44c7-a432-c96e98b3d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.label = self.Tensor(opt.batchSize, opt.L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591608c7-afbb-48fc-9a02-9da08a3e8fd1",
   "metadata": {},
   "source": [
    "# Multilabel\n",
    "https://github.com/rhgao/Deep-MIML-Network/blob/master/models/MIML.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d95199-2872-42d5-bdbc-23b11bdecc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from .base_model import BaseModel\n",
    "from . import networks\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "class MIMLModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'MIMLModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseModel.initialize(self, opt)\n",
    "        self.isTrain = opt.isTrain\n",
    "\n",
    "        if opt.using_multi_labels:\n",
    "            self.label = self.Tensor(opt.batchSize, opt.L)\n",
    "        else:\n",
    "            self.label = self.Tensor(opt.batchSize)\n",
    "        self.bases = self.Tensor(opt.batchSize, opt.F, opt.num_of_bases)\n",
    "\n",
    "        self.BasesNet = networks.BasesNet(opt)\n",
    "        self.sub_concept_pooling = nn.modules.MaxPool2d((opt.K, 1), stride=(1,1))\n",
    "        self.instance_pooling = nn.modules.MaxPool2d((opt.num_of_bases,1), stride=(1,1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if opt.using_multi_labels:\n",
    "            self.loss = nn.MultiLabelMarginLoss()\n",
    "        else:\n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        if(len(opt.gpu_ids)>0):\n",
    "            self.BasesNet.cuda(opt.gpu_ids[0])\n",
    "            self.sub_concept_pooling.cuda(opt.gpu_ids[0])\n",
    "            self.instance_pooling.cuda(opt.gpu_ids[0])\n",
    "            self.softmax.cuda(opt.gpu_ids[0])\n",
    "            self.sigmoid.cuda(opt.gpu_ids[0])\n",
    "            self.loss.cuda(opt.gpu_ids[0])\n",
    "\n",
    "        networks.init_weights(self.BasesNet, self.opt.init_type)\n",
    "\n",
    "        if(self.isTrain):\n",
    "            if opt.using_multi_labels:\n",
    "                self.optimizer = optim.Adam(list(self.BasesNet.parameters()), lr=opt.learning_rate, weight_decay=0.00001)\n",
    "            else:\n",
    "                self.optimizer = optim.Adam(list(self.BasesNet.parameters()), lr=opt.learning_rate, weight_decay=0.00001)\n",
    "        else:\n",
    "            self.BasesNet.eval()\n",
    "\n",
    "        self.batch_loss = []\n",
    "        self.batch_accuracy = []\n",
    "        self.batch_ap = []\n",
    "\n",
    "    def forward(self, input, volatile=False):\n",
    "        bases = input['bases'].unsqueeze(3) #add another dimension for 2D convolution, a trick to replace fc with 1x1conv\n",
    "        label = input['label']\n",
    "        self.bases.resize_(bases.size()).copy_(bases)\n",
    "        self.label.resize_(label.size()).copy_(label)\n",
    "\n",
    "        #print(self.bases.size())\n",
    "        # shape: (batchSize, L*K, num_of_bases)\n",
    "        basesnet_output = self.BasesNet(Variable(self.bases, requires_grad=False, volatile=volatile)).view(-1, self.opt.L, self.opt.K, self.opt.num_of_bases)\n",
    "        #print(\"sub_concept_layer_output:\",basesnet_output.size())\n",
    "        # shape: (batchSize, L, K, num_of_bases)\n",
    "        sub_concept_pooling_output = self.sub_concept_pooling(basesnet_output).view(-1, self.opt.L, self.opt.num_of_bases).permute(0,2,1).unsqueeze(1)\n",
    "        #print(\"sub_concept_pooling_output:\",sub_concept_pooling_output.size())\n",
    "        #softmax\n",
    "        if self.opt.with_softmax:\n",
    "            softmax_normalization_output = self.softmax(sub_concept_pooling_output)\n",
    "            self.output = self.instance_pooling(softmax_normalization_output).view(-1, self.opt.L)\n",
    "        else:\n",
    "            self.output = self.instance_pooling(sub_concept_pooling_output).view(-1, self.opt.L)\n",
    "\n",
    "    def getInstanceLabelRelation(self, input, volatile=True):\n",
    "        bases = input['bases'].unsqueeze(3) #add another dimension for 2D convolution, a trick to replace fc with 1x1conv\n",
    "        label = input['label']\n",
    "        self.bases.resize_(bases.size()).copy_(bases)\n",
    "        self.label.resize_(label.size()).copy_(label)\n",
    "\n",
    "        basesnet_output = self.BasesNet(Variable(self.bases, requires_grad=False, volatile=volatile)).view(-1, self.opt.L, self.opt.K, self.opt.num_of_bases)\n",
    "        instanceLabelRelation = self.sub_concept_pooling(basesnet_output).view(-1, self.opt.L, self.opt.num_of_bases).permute(0,2,1)\n",
    "        if self.opt.using_multi_labels:\n",
    "            self.output = self.instance_pooling(instanceLabelRelation.unsqueeze(1)).view(-1, self.opt.L)\n",
    "            prediction = np.zeros(self.output.size())\n",
    "            gt_label = np.zeros(self.output.size())\n",
    "            max_label = self.output.max(dim=1)[1].data\n",
    "            for i in range(gt_label.shape[0]):\n",
    "                prediction[i,max_label[i]] = 1\n",
    "            prediction[self.softmax(self.output).data.cpu().numpy() >= 0.3] = 1\n",
    "            for index, x in np.ndenumerate(self.label.cpu().numpy()):\n",
    "                if x == -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    gt_label[index[0],int(x)] = 1\n",
    "            return self.softmax(instanceLabelRelation).data.cpu().numpy(), gt_label, prediction\n",
    "        else:\n",
    "            if self.opt.with_softmax:\n",
    "                self.output = self.instance_pooling(self.softmax(instanceLabelRelation).unsqueeze(1)).view(-1, self.opt.L)\n",
    "            else:\n",
    "                self.output = self.instance_pooling(instanceLabelRelation.unsqueeze(1)).view(-1, self.opt.L)\n",
    "            prediction = self.output.max(dim=1)[1].data.float()\n",
    "            return self.softmax(instanceLabelRelation).data.cpu().numpy(), label, prediction\n",
    "\n",
    "    def decrease_learning_rate(self, times, factor):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.opt.learning_rate * pow(factor, times)\n",
    "        print(\"current learning rate:\",self.opt.learning_rate * pow(factor, times))\n",
    "\n",
    "    def backward(self):\n",
    "        if self.opt.using_multi_labels:\n",
    "            label = Variable(self.label, requires_grad=False).long()\n",
    "            prediction = np.zeros(self.output.size())\n",
    "            #construt ground-truth label to compute mAP\n",
    "            gt_label = np.zeros(self.output.size())\n",
    "            max_label = self.output.max(dim=1)[1].data\n",
    "            for i in range(gt_label.shape[0]):\n",
    "                prediction[i,max_label[i]] = 1\n",
    "            prediction[self.softmax(self.output).data.cpu().numpy() >= 0.3] = 1\n",
    "            for index, x in np.ndenumerate(self.label.cpu().numpy()):\n",
    "                if x == -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    gt_label[index[0],int(x)] = 1\n",
    "            ap = average_precision_score(gt_label.T, prediction.T)\n",
    "            self.batch_ap.append(ap)\n",
    "        else:\n",
    "            label = Variable(self.label, requires_grad=False).long()\n",
    "            prediction = self.output.max(dim=1)[1].data.float()\n",
    "            correct = (self.label.eq(prediction)).sum()\n",
    "            accuracy = correct*1.0/self.label.size()[0]\n",
    "            self.batch_accuracy.append(accuracy)\n",
    "        loss = self.loss(self.output, label)\n",
    "        self.batch_loss.append(loss.data[0]) \n",
    "        loss.backward()\n",
    "\n",
    "    def display_train(self, writer, index):\n",
    "        loss = sum(self.batch_loss)/len(self.batch_loss)\n",
    "        writer.add_scalar('data/loss', loss, index)\n",
    "        print('loss: ' + str(loss))\n",
    "        self.batch_loss = []\n",
    "        if self.opt.using_multi_labels:\n",
    "            ap = sum(self.batch_ap)/len(self.batch_ap)\n",
    "            writer.add_scalar('data/mAP', ap, index)\n",
    "            print('mAP: ' + str(ap))\n",
    "            self.batch_ap = []\n",
    "        else:\n",
    "            accuracy = sum(self.batch_accuracy)/len(self.batch_accuracy)\n",
    "            writer.add_scalar('data/accuracy', accuracy, index)\n",
    "            print('accuracy: ' + str(accuracy))\n",
    "            self.batch_accuracy = []\n",
    "\n",
    "    def display_val(self, writer, index, dataset_val):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        aps = []\n",
    "        for i, val_data in enumerate(dataset_val):\n",
    "            if i >= self.opt.validation_batches:\n",
    "                break\n",
    "            if self.opt.using_multi_labels:\n",
    "                ap, loss = self.test_multi_label(val_data)\n",
    "                aps.append(ap)\n",
    "            else:\n",
    "                accuracy,loss = self.test(val_data)\n",
    "                accuracies.append(accuracy)\n",
    "            losses.append(loss)\n",
    "        if self.opt.using_multi_labels:\n",
    "            ap = sum(aps) / len(aps)\n",
    "            writer.add_scalar('data/val_mAP', ap, index)\n",
    "            print('validation mAP is: ' + str(ap))\n",
    "        else:\n",
    "            accuracy = sum(accuracies)/len(accuracies)\n",
    "            writer.add_scalar('data/val_accuracy', accuracy, index)\n",
    "            print('validation accuracy is: ' + str(accuracy))\n",
    "        loss = sum(losses)/len(losses)\n",
    "        writer.add_scalar('data/val_loss', loss, index)\n",
    "        print('validation loss is: ' + str(loss))\n",
    "\n",
    "    def test(self, input):\n",
    "        self.forward(input, volatile=True)\n",
    "        prediction = self.output.max(dim=1)[1].data.float()\n",
    "        correct = (self.label.eq(prediction)).sum()\n",
    "        accuracy = correct*1.0/self.label.size()[0]\n",
    "        label = Variable(self.label.long(), requires_grad=False)\n",
    "        loss = self.loss(self.output, label).data.cpu().numpy()[0]\n",
    "        return accuracy, loss\n",
    "\n",
    "    def test_multi_label(self, input):\n",
    "        self.forward(input, volatile=True)\n",
    "        prediction = np.zeros(self.output.size())\n",
    "        gt_label = np.zeros(self.output.size())\n",
    "        max_label = self.output.max(dim=1)[1].data\n",
    "        for i in range(gt_label.shape[0]):\n",
    "            prediction[i,max_label[i]] = 1\n",
    "        prediction[self.softmax(self.output).data.cpu().numpy() >= 0.3] = 1\n",
    "        for index, x in np.ndenumerate(self.label.cpu().numpy()):\n",
    "            if x == -1:\n",
    "                continue\n",
    "            else:\n",
    "                gt_label[index[0],int(x)] = 1\n",
    "        ap = average_precision_score(gt_label.T, prediction.T)\n",
    "        label = Variable(self.label, requires_grad=False).long()\n",
    "        loss = self.loss(self.output, label).data.cpu().numpy()[0]\n",
    "        return ap, loss\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        self.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5fe838-8aec-4dc3-ae37-e474c5457dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
