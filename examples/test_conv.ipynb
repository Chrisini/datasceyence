{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8ea6b-7e2f-4257-9875-25f651882f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DecentNet from conv layer\n",
    "\n",
    "    # additionally needed\n",
    "    \"\"\"\n",
    "    \n",
    "    position\n",
    "    activated channels\n",
    "    connection between channels\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "        \n",
    "        # this layer id\n",
    "        layer_id = 0\n",
    "        \n",
    "        # within this layer, a whole filter can be deactivated\n",
    "        # within a filter, single channels can be deactivated\n",
    "        # within this layer, filters can be swapped\n",
    "     \n",
    "* pruning actually doesn\"t work: https://discuss.pytorch.org/t/pruning-doesnt-affect-speed-nor-memory-for-resnet-101/75814   \n",
    "* fine tune a pruned model: https://stackoverflow.com/questions/73103144/how-to-fine-tune-the-pruned-model-in-pytorch\n",
    "* an actual pruning mechanism: https://arxiv.org/pdf/2002.08258.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46441962-88b7-4cd6-bd4a-a71a6fbbd427",
   "metadata": {},
   "source": [
    "pip install:\n",
    "    pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd77a1f-a306-47cc-9905-993793aee5be",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f2bf02-f53b-4688-bf18-5b8075397e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../helper', './helper', '/helper', 'helper', 'C:\\\\Users\\\\Prinzessin\\\\projects\\\\decentnet\\\\datasceyence\\\\examples', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\python39.zip', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\DLLs', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta', '', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Prinzessin\\\\.ipython']\n",
      "\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "# from torch.nn import init\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.utils import _single, _pair, _triple, _reverse_repeat_tuple\n",
    "from torch._torch_docs import reproducibility_notes\n",
    "\n",
    "from torch.nn.common_types import _size_1_t, _size_2_t, _size_3_t\n",
    "from typing import Optional, List, Tuple, Union\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "sys.path.insert(0, \"/helper\")\n",
    "sys.path.insert(0, \"./helper\")\n",
    "sys.path.insert(0, \"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "# own module\n",
    "from visualisation.feature_map import *\n",
    "\n",
    "import random\n",
    "\n",
    "print()\n",
    "print(\"cuda available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7f1ab-1129-436d-aed0-5643651c84a0",
   "metadata": {},
   "source": [
    "# Conv experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38836e4-6905-4e0c-b344-bcc3b8094388",
   "metadata": {},
   "source": [
    "## conv2d layer (slightly adapted original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b972ff66-723c-43a1-a9d9-80c43b450efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ConvNd(torch.nn.Module):\n",
    "\n",
    "    __constants__ = ['stride', 'padding', 'dilation', 'groups',\n",
    "                     'padding_mode', 'output_padding', 'in_channels',\n",
    "                     'out_channels', 'kernel_size']\n",
    "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]) -> Tensor:\n",
    "        ...\n",
    "\n",
    "    in_channels: int\n",
    "    _reversed_padding_repeated_twice: List[int]\n",
    "    out_channels: int\n",
    "    kernel_size: Tuple[int, ...]\n",
    "    stride: Tuple[int, ...]\n",
    "    padding: Union[str, Tuple[int, ...]]\n",
    "    dilation: Tuple[int, ...]\n",
    "    transposed: bool\n",
    "    output_padding: Tuple[int, ...]\n",
    "    groups: int\n",
    "    padding_mode: str\n",
    "    weight: Tensor\n",
    "    bias: Optional[Tensor]\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Tuple[int, ...],\n",
    "                 stride: Tuple[int, ...],\n",
    "                 padding: Tuple[int, ...],\n",
    "                 dilation: Tuple[int, ...],\n",
    "                 transposed: bool,\n",
    "                 output_padding: Tuple[int, ...],\n",
    "                 groups: int,\n",
    "                 bias: bool,\n",
    "                 padding_mode: str,\n",
    "                 device=None,\n",
    "                 dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        print(factory_kwargs)\n",
    "        super().__init__()\n",
    "        if groups <= 0:\n",
    "            raise ValueError('groups must be a positive integer')\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        valid_padding_strings = {'same', 'valid'}\n",
    "        if isinstance(padding, str):\n",
    "            if padding not in valid_padding_strings:\n",
    "                raise ValueError(\n",
    "                    \"Invalid padding string {!r}, should be one of {}\".format(\n",
    "                        padding, valid_padding_strings))\n",
    "            if padding == 'same' and any(s != 1 for s in stride):\n",
    "                raise ValueError(\"padding='same' is not supported for strided convolutions\")\n",
    "\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        # `_reversed_padding_repeated_twice` is the padding to be passed to\n",
    "        # `F.pad` if needed (e.g., for non-zero padding types that are\n",
    "        # implemented as two ops: padding + conv). `F.pad` accepts paddings in\n",
    "        # reverse order than the dimension.\n",
    "        if isinstance(self.padding, str):\n",
    "            self._reversed_padding_repeated_twice = [0, 0] * len(kernel_size)\n",
    "            if padding == 'same':\n",
    "                for d, k, i in zip(dilation, kernel_size,\n",
    "                                   range(len(kernel_size) - 1, -1, -1)):\n",
    "                    total_padding = d * (k - 1)\n",
    "                    left_pad = total_padding // 2\n",
    "                    self._reversed_padding_repeated_twice[2 * i] = left_pad\n",
    "                    self._reversed_padding_repeated_twice[2 * i + 1] = (\n",
    "                        total_padding - left_pad)\n",
    "        else:\n",
    "            self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2)\n",
    "\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (in_channels, out_channels // groups, *kernel_size), **factory_kwargs))\n",
    "            #self.importance = Parameter(torch.empty(\n",
    "            #    (in_channels, out_channels // groups), **factory_kwargs))\n",
    "            \n",
    "        else:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (out_channels, in_channels // groups, *kernel_size), **factory_kwargs))\n",
    "            #self.importance = Parameter(torch.empty(\n",
    "            #    (out_channels, in_channels // groups), **factory_kwargs))\n",
    "            \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "class CustomConv2d(_ConvNd):\n",
    "    \n",
    "    # additionally needed\n",
    "    \"\"\"\n",
    "    \n",
    "    position\n",
    "    activated channels\n",
    "    connection between channels\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: _size_2_t,\n",
    "        stride: _size_2_t = 1,\n",
    "        padding: Union[str, _size_2_t] = 0,\n",
    "        dilation: _size_2_t = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        padding_mode: str = 'zeros',  # TODO: refine this type\n",
    "        device=None,\n",
    "        dtype=None\n",
    "    ) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        kernel_size_ = _pair(kernel_size)\n",
    "        stride_ = stride #_pair(stride)\n",
    "        padding_ = padding if isinstance(padding, str) else _pair(padding)\n",
    "        dilation_ = _pair(dilation)\n",
    "        super().__init__(\n",
    "            in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n",
    "            False, _pair(0), groups, bias, padding_mode, **factory_kwargs)\n",
    "        \n",
    "        # this layer id\n",
    "        layer_id = 0\n",
    "        \n",
    "        # within this layer, a whole filter can be deactivated\n",
    "        # within a filter, single channels can be deactivated\n",
    "        # within this layer, filters can be swapped\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            if fan_in != 0:\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "        if self.padding_mode != 'zeros':\n",
    "            return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            weight, bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        \n",
    "        # this is written in c++ - try not to change ...\n",
    "        print(self.stride)\n",
    "        return F.conv2d(input, weight, bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self._conv_forward(input, self.weight, self.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369256cb-1ea4-4ff2-8ce5-a820511e0779",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2823e218-5eb3-44d9-a277-2cf17b772c84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = CustomConv2d(1, 32, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv2 = CustomConv2d(32, 64, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv3 = CustomConv2d(64, 128, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv1x1 = CustomConv2d(128, 10, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        \n",
    "        self.K = 100 \n",
    "        self.L = 10 # last one\n",
    "        self.num_of_bases = 1 # 3rd dim\n",
    "        \n",
    "        if False:\n",
    "            self.conv1 = Conv2d(1, 32, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "            self.conv2 = Conv2d(32, 64, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "            self.conv3 = Conv2d(64, 128, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "            self.conv1x1 = Conv2d(128, 10, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        #self.dropout1 = nn.Dropout(0.25)\n",
    "        #self.dropout2 = nn.Dropout(0.5)\n",
    "        # 4x16384\n",
    "        # self.fc1 = nn.Linear(10*10*10, 10)\n",
    "        #self.fc2 = nn.Linear(10, 10)\n",
    "        \n",
    "        #self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc3 = nn.Linear(10, 10)\n",
    "        \n",
    "        self.mish1 = torch.nn.Mish()\n",
    "        self.mish2 = torch.nn.Mish()\n",
    "        self.mish3 = torch.nn.Mish()\n",
    "        self.mish1x1 = torch.nn.Mish()\n",
    "        \n",
    "        #self.sub_concept_pooling = nn.modules.MaxPool2d((self.K, 1), stride=(1,1))\n",
    "        #self.instance_pooling = nn.modules.MaxPool2d((opt.num_of_bases, 1), stride=(1,1))\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.mish1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.mish2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.mish3(x)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        x = self.mish1x1(x)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        \n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        #x = self.dropout1(x)\n",
    "        \n",
    "        #print(x.size())\n",
    "        #print(x.size()[2:])\n",
    "        \n",
    "        x = F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        \n",
    "        #x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        #x = x.view(-1, self.L, self.K, 10)\n",
    "        \n",
    "        # input, kernel_size, stride, padding, dilation, ceil_mode\n",
    "        #x = self.sub_concept_pooling(x).view(-1, self.L, self.num_of_bases).permute(0,2,1).unsqueeze(1)\n",
    "        \n",
    "        # output = F.sigmoid(x)\n",
    "        # x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        #x = torch.flatten(x, 1)\n",
    "        # x = self.fc1(x)\n",
    "        #x = F.relu(x)\n",
    "        \n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.fc2(x)\n",
    "        #output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76fa05-b47e-4264-85cf-766d8ca060d3",
   "metadata": {},
   "source": [
    "## normal run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0819306e-ff93-4f38-898b-4c1cd2221b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for i_batch, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "        \n",
    "        if i_batch == -1:\n",
    "            print(data.shape) # torch.Size([4, 1, 28, 28])\n",
    "            print(target)\n",
    "            \"\"\"\n",
    "            tensor([[8],\n",
    "            [7],\n",
    "            [2],\n",
    "            [7]])\n",
    "            \"\"\"\n",
    "            print(target_multi_hot)\n",
    "            \"\"\"\n",
    "            tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "            [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
    "            \"\"\"\n",
    "        \n",
    "        loss = F.binary_cross_entropy(output, target_multi_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % (args.log_interval*1000) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i_batch * len(data), len(train_loader.dataset),\n",
    "                100. * i_batch / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "            test_loss += F.binary_cross_entropy(output, target_multi_hot, reduction='mean').item()\n",
    "        \n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "            \n",
    "            \"\"\"\n",
    "            if i == 0 and epoch % args.log_interval == 0:\n",
    "            # if False: # i == 0:\n",
    "                print(data.shape)\n",
    "                layer = model.conv1x1 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "                # run feature map\n",
    "                dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "                dd.run(data)\n",
    "                dd.plot(path=f\"example_results/feature_map_{epoch}.png\")\n",
    "                \"\"\"\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.test_batch_size = 1\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.1\n",
    "        self.gamma = 0.7\n",
    "        self.log_interval = 5\n",
    "        self.save_model = True\n",
    "        \n",
    "\n",
    "def main_train():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('example_data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader, epoch)\n",
    "        #scheduler.step()\n",
    "        \n",
    "        \n",
    "        if args.save_model and epoch % args.log_interval == 0:\n",
    "            torch.save(model.state_dict(), f\"example_results/mnist_cnn_{epoch}.ckpt\")\n",
    "\n",
    "\n",
    "def main_test():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "\n",
    "    if True:\n",
    "        model.load_state_dict(torch.load(\"example_results/mnist_cnn_5.ckpt\"))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(\"example_results/pruned_model.ckpt\"))\n",
    "    \n",
    "\n",
    "    # model = torch.load(model.state_dict(), \"example_results/mnist_cnn_30.ckpt\")\n",
    "    if False:\n",
    "        test(args, model, device, test_loader, 0)\n",
    "    \n",
    "    return model\n",
    "        \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38eb5e24-3f20-4788-8344-66a98d6791bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1242e1a-c691-4cb6-a279-9904cedcd806",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_to_prune= main_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270319e6-3827-47cd-a579-476c89217968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(model_to_prune.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f898ba-2323-4628-a0e3-70ee44ce0b0d",
   "metadata": {},
   "source": [
    "# DecentNet trial and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db53f551-b504-444f-b318-762eb857195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor([[1, 0, 5, 2]])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor([1, 0, 5, 2])\n",
    "labels = labels.unsqueeze(0)\n",
    "\n",
    "target = torch.zeros(labels.size(0), 10).scatter_(1, labels, 1.)\n",
    "print(target)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a387d2d9-2247-4330-9fb7-c44aa0a2322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common pair at indices [1, 0]: (2, 2), (4, 4)\n",
      "Common pair at indices [2, 5]: (4, 4), (8, 8)\n",
      "[1 2]\n",
      "[0 5]\n"
     ]
    }
   ],
   "source": [
    "# Two lists of data\n",
    "ms_in = [1, 2, 4]\n",
    "ns_in = [2, 4, 8]\n",
    "\n",
    "ms_x = [2, 2, 2, 5, 9, 4]\n",
    "ns = [4, 2, 2, 3, 6, 8]\n",
    "\n",
    "# Find the indices (IDs) of pairs that exist in both lists\n",
    "common_pairs = [[f, x] for f, (item1, item2) in enumerate(zip(ms_in, ns_in)) for x, (item3, item4) in enumerate(zip(ms_x, ns)) if (item1==item3 and item2==item4)]\n",
    "\n",
    "# Print the common pairs\n",
    "for pair in common_pairs:\n",
    "    print(f\"Common pair at indices {pair}: {ms_in[pair[0]], ms_x[pair[1]]}, {ns_in[pair[0]], ns[pair[1]]}\")\n",
    "    \n",
    "a = np.array(common_pairs)\n",
    "f_ids = a[:,0]\n",
    "x_ids = a[:,1]\n",
    "\n",
    "print(f_ids)\n",
    "print(x_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd6da2-32d7-4727-af6d-cee380d01b5f",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607d8fb-4ac1-4fad-848c-11d189a62637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bd40000-1da6-4f92-b9e4-ace7a184a19a",
   "metadata": {},
   "source": [
    "## X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8a8868-9d8f-47cf-a42b-5ab72f44b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class X:\n",
    "    def __init__(self, data, ms_x, ns_x):\n",
    "        \n",
    "        self.ms_x = ms_x # list of integers\n",
    "        self.ns_x = ns_x # list of integers\n",
    "        self.data = data # list of tensors\n",
    "                \n",
    "    def set(self, data, ms_x, ns_x):\n",
    "        self.ms_x = ms_x\n",
    "        self.ns_x = ns_x\n",
    "        self.data = data\n",
    "    \n",
    "    def get(self):\n",
    "        return self.data, self.m, self.n\n",
    "    \n",
    "    def __str__(self):\n",
    "        # amout of channels need to have same length as m and n lists\n",
    "        return 'X(data: ' + str(self.data.shape) +' at positions: ms_x= ' + ', '.join(str(m.item()) for m in self.ms_x) + ', ns_x= ' + ', '.join(str(n.item()) for n in self.ns_x) + ')'\n",
    "    \n",
    "    \n",
    "    __repr__ = __str__\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff8f8ab-976a-4199-974f-9b1cb93c1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 5 == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfa123-54e1-4053-94c3-52b45ec0859c",
   "metadata": {},
   "source": [
    "## DecentFilter\n",
    "* conv2d problem: https://stackoverflow.com/questions/61269421/expected-stride-to-be-a-single-integer-value-or-a-list-of-1-values-to-match-the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bc1f3c-5f40-445c-b5f1-4ca6387eb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentFilter(torch.nn.Module):\n",
    "    # convolution happens in here\n",
    "    \n",
    "    def __init__(self, ms_in, ns_in, m_this, n_this,\n",
    "                 kernel_size=3, \n",
    "                 stride=1, \n",
    "                 padding=0, \n",
    "                 padding_mode=\"zeros\",\n",
    "                 dilation=3, \n",
    "                 # transposed=None, \n",
    "                 device=None, \n",
    "                 dtype=None):\n",
    "        \n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        \n",
    "        # padding\n",
    "        padding = padding if isinstance(padding, str) else _pair(padding)\n",
    "        valid_padding_strings = {'same', 'valid'}\n",
    "        if isinstance(padding, str):\n",
    "            if padding not in valid_padding_strings:\n",
    "                raise ValueError(\n",
    "                    \"Invalid padding string {!r}, should be one of {}\".format(\n",
    "                        padding, valid_padding_strings))\n",
    "            if padding == 'same' and any(s != 1 for s in stride):\n",
    "                raise ValueError(\"padding='same' is not supported for strided convolutions\")\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "        \n",
    "         \n",
    "        # convolution\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = stride\n",
    "        self.padding_mode = padding_mode\n",
    "        self.padding = padding\n",
    "        self.dilation = _pair(dilation)\n",
    "        #self.transposed = transposed\n",
    "        \n",
    "        \n",
    "        # weights\n",
    "        assert len(ms_in) == len(ns_in), \"ms_in and ns_in are not of same length\"\n",
    "        self.n_weights = len(ms_in)\n",
    "        \n",
    "        # position\n",
    "        # self.non_trainable_param = nn.Parameter(torch.Tensor([1.0]), requires_grad=False)\n",
    "        # todo\n",
    "        self.ms_in = nn.Parameter(torch.Tensor(ms_in), requires_grad=False) # ms_in # list\n",
    "        self.ns_in = nn.Parameter(torch.Tensor(ns_in), requires_grad=False) # ns_in # list\n",
    "        self.m_this = nn.Parameter(torch.Tensor([m_this]), requires_grad=False) # m_this # single integer\n",
    "        self.n_this = nn.Parameter(torch.Tensor([n_this]), requires_grad=False) # n_this # single integer\n",
    "        \n",
    "        # weight\n",
    "        # filters x channels x kernel x kernel\n",
    "        # self.weights = torch.autograd.Variable(torch.randn(1,n_weights,*self.kernel_size)).to(\"cuda\")\n",
    "        # self.weights = torch.nn.Parameter(torch.randn(1,n_weights,*self.kernel_size))\n",
    "        self.weights = torch.nn.Parameter(torch.empty((1, self.n_weights, *self.kernel_size), **factory_kwargs))\n",
    "        \n",
    "        print(\"weight shape init\")\n",
    "        print(self.weights.shape)\n",
    "            \n",
    "        # bias    \n",
    "        if False: \n",
    "            # bias:\n",
    "            # where should the bias be???\n",
    "            self.bias = Parameter(torch.empty(1, **factory_kwargs))\n",
    "        else:\n",
    "            #self.bias = False\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # reset weights and bias in filter\n",
    "        self.reset_parameters()\n",
    "            \n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*self.kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        torch.nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))        \n",
    "        \n",
    "    def forward(self, x:X) -> Tensor:\n",
    "        \n",
    "        # weights = 1 filter x channels x kernel x kernel\n",
    "        # x = batch x channels x width x height\n",
    "\n",
    "        # Find the indices (IDs) of pairs that exist in both lists\n",
    "        common_pairs = [[i_in, i_x] for i_in, (m_in, n_in) in enumerate(zip(self.ms_in, self.ns_in)) for i_x, (m_x, n_x) in enumerate(zip(x.ms_x, x.ns_x)) if (m_in==m_x and n_in==n_x)]\n",
    "        \n",
    "        if False:\n",
    "            print(common_pairs)\n",
    "            print(len(self.ms_in))\n",
    "            print(len(self.ns_in))\n",
    "            print(len(x.ms_x))\n",
    "            print(len(x.ns_x))\n",
    "\n",
    "            for pair in common_pairs:\n",
    "                print(f\"Common pair at indices {pair}: {self.ms_in[pair[0]], tmp_ms[pair[1]]}, {self.ns_in[pair[0]], tmp_ns[pair[1]]}\")\n",
    "        \n",
    "        common_pairs_a = np.array(common_pairs)\n",
    "        try:\n",
    "            f_ids = common_pairs_a[:,0]\n",
    "            x_ids = common_pairs_a[:,1]\n",
    "        except Exception as e:\n",
    "            print(common_pairs_a)\n",
    "            print(common_pairs_a.shape)\n",
    "            print(len(self.ms_in))\n",
    "            print(len(self.ns_in))\n",
    "            print(len(x.ms_x))\n",
    "            print(len(x.ns_x))\n",
    "            print(e)\n",
    "        \n",
    "        # filter data and weights based on common pairs of data and weights\n",
    "        tmp_x = x.data[:, x_ids, :, :]\n",
    "        tmp_w = self.weights[:, f_ids, :, :]\n",
    "        \n",
    "        if self.padding_mode != 'zeros':\n",
    "            # this is written in c++\n",
    "            x_data = torch.nn.functional.conv2d(F.pad(tmp_x, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            tmp_w, self.bias, self.stride,\n",
    "                            _pair(0), self.dilation, groups=1)\n",
    "        else:\n",
    "            # this is written in c++\n",
    "            x_data = torch.nn.functional.conv2d(tmp_x, tmp_w, self.bias, self.stride, self.padding, self.dilation, groups=1)\n",
    "        \n",
    "        # print(x_data.shape, \"- batch x filters x width x height\")        \n",
    "        return x_data\n",
    "    \n",
    "    \"\"\"\n",
    "    def set_position_and_value(self, value, m_this, n_this):\n",
    "        self.weights = value # weights in this filter\n",
    "        self.m_this = m_this # single integer\n",
    "        self.n_this = n_this # single integer\n",
    "    \n",
    "    def get_position_and_value(self):\n",
    "        return self.weights, self.m_this, self.n_this\n",
    "    \"\"\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'DecentFilter(weights: ' + str(self.weights.shape) + ' at position: m_this=' + str(self.m_this) + ', n_this=' + str(self.n_this) + ')' + \\\n",
    "    '\\n with inputs: ms_in= ' + ', '.join(str(int(m.item())) for m in self.ms_in) + ', ns_in= ' + ', '.join(str(int(n.item())) for n in self.ns_in) + ')'\n",
    "    __repr__ = __str__\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ffdab4-e0b0-4523-882f-dad3ebf06090",
   "metadata": {},
   "source": [
    "## DecentLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fddb74c7-5940-424d-aab8-2c75efd914bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentLayer(torch.nn.Module):\n",
    "    __constants__ = ['stride', 'padding', 'dilation', # 'groups',\n",
    "                     'padding_mode', # 'n_channels', #  'output_padding', # 'n_filters',\n",
    "                     'kernel_size']\n",
    "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
    "                \n",
    "    def __init__(self, ms_in:list, ns_in:list, n_filters:int,\n",
    "                 kernel_size: _size_2_t,  \n",
    "                 stride: _size_2_t = 1,  \n",
    "                 padding: Union[str, _size_2_t] = 0,  \n",
    "                 dilation: _size_2_t = 1,\n",
    "                 prune_keep:float = 0.9,\n",
    "                 prune_keep_total:float = 0.5,\n",
    "                 #transposed: bool = False, \n",
    "                 grid_size:int=81,\n",
    "                 #output_padding: Tuple[int, ...] = _pair(0),\n",
    "                 #groups: int = 1,\n",
    "                 bias: bool = True,  # not in use\n",
    "                 padding_mode: str = \"zeros\",  # not in use\n",
    "                 device=None,  # not in use\n",
    "                 dtype=None) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # from prev layer\n",
    "        self.ms_in = ms_in\n",
    "        self.ns_in = ns_in\n",
    "        \n",
    "        self.original_size = len(self.ms_in)\n",
    "        \n",
    "        # prune numbers\n",
    "        self.prune_keep = prune_keep # in each update [0.0:1.0]\n",
    "        self.prune_keep_total = prune_keep_total # total [0.0:1.0]\n",
    "        \n",
    "        self.grid_sqrt = math.sqrt(grid_size)\n",
    "        assert self.grid_sqrt == int(self.grid_sqrt), f\"square root ({self.grid_sqrt}) from grid size {grid_size} not possible; possible exampes: 81 (9*9), 144 (12*12)\"\n",
    "        self.grid_sqrt = int(self.grid_sqrt)\n",
    "        \n",
    "        # use techniques from coo matrix\n",
    "        self.geometry_array = np.full(grid_size, np.nan)\n",
    "        # plus 1 here cause of to_sparse array\n",
    "        self.geometry_array[0:n_filters] = range(1,n_filters+1)\n",
    "        np.random.shuffle(self.geometry_array)\n",
    "        self.geometry_array = self.geometry_array.reshape((self.grid_sqrt,self.grid_sqrt), order='C')\n",
    "        self.geometry_array = torch.tensor(self.geometry_array)\n",
    "        self.geometry_array = self.geometry_array.to_sparse(sparse_dim=2).to(\"cuda\")\n",
    "\n",
    "        #print(self.geometry_array)\n",
    "        #print(self.geometry_array.values())\n",
    "\n",
    "        self.filter_list = torch.nn.ModuleList([])\n",
    "        for i_filter in range(n_filters):\n",
    "            # minus 1 here cause of to_sparse array\n",
    "            index = (self.geometry_array.values()-1 == i_filter).nonzero(as_tuple=True)[0]\n",
    "            m_this = self.geometry_array.indices()[0][index]\n",
    "            n_this = self.geometry_array.indices()[1][index]\n",
    "            f = DecentFilter(ms_in, ns_in, m_this, n_this, \n",
    "                             kernel_size=kernel_size, \n",
    "                             stride=stride, padding=padding, dilation=dilation)\n",
    "            self.filter_list.append(f)\n",
    "            # self.register_parameter(f\"filter {i_filter}\", f.weights)\n",
    "            \n",
    "            #torch.nn.Parameter(torch.empty((1, n_channels, *kernel_size), **factory_kwargs))\n",
    "    \n",
    "    def compute_layer_connection_cost(self) -> Tensor:\n",
    "        # compute connection cost for a layer\n",
    "        # based on previous layer (cause I only have input ms_in, n_in information)\n",
    "        # mean( sum( of connection cost between this filter and all incoming filters\n",
    "        # need it for loss - aka all layers, all filters together\n",
    "        # need it for swapping - this layer, all filters\n",
    "        # only the active ones (we need to use the indices for that)\n",
    "        # for swapping i need ??\n",
    "        # adapted from BIMT: https://github.com/KindXiaoming/BIMT/blob/main/mnist_3.5.ipynb\n",
    "        # def get_cc(self, weight_factor=2.0, bias_penalize=True, no_penalize_last=False):\n",
    "        # https://stackoverflow.com/questions/74086766/how-to-find-total-cost-of-each-path-in-graph-using-dictionary-in-python\n",
    "        \"\"\"\n",
    "        num_linear = len(self.linears)\n",
    "        for i in range(num_linear):\n",
    "            if i == num_linear - 1 and no_penalize_last:\n",
    "                weight_factor = 0.\n",
    "            biolinear = self.linears[i]\n",
    "            dist = torch.sum(torch.abs(biolinear.out_coordinates.unsqueeze(dim=1) - biolinear.in_coordinates.unsqueeze(dim=0)),dim=2)\n",
    "            cc += torch.mean(torch.abs(biolinear.linear.weight)*(weight_factor*dist+self.l0))\n",
    "            if bias_penalize == True:\n",
    "                cc += torch.mean(torch.abs(biolinear.linear.bias)*(self.l0))\n",
    "        if self.token_embedding:\n",
    "            cc += torch.mean(torch.abs(self.embedding)*(self.l0))\n",
    "            #pass\n",
    "        \"\"\"\n",
    "            \n",
    "        cc = []\n",
    "        for f in self.filter_list:\n",
    "\n",
    "            #mn = torch.cat([torch.tensor(f.m_this), torch.tensor(f.n_this)])\n",
    "            #print(mn.shape)\n",
    "            #msns = torch.cat([torch.tensor(f.ms_in), torch.tensor(f.ns_in)]) # .transpose(1,0)\n",
    "            #print(msns.shape)\n",
    "            #cc.append(torch.cdist(mn.unsqueeze(dim=0), msns.transpose(1,0), 'euclidean') / 8) # number comes from 9*9 = 81 [0-8]\n",
    "            \n",
    "            mn = torch.cat([f.m_this.unsqueeze(0), f.n_this.unsqueeze(0)]).transpose(1,0)\n",
    "            #print(mn)\n",
    "            msns = torch.cat([f.ms_in.unsqueeze(0), f.ns_in.unsqueeze(0)]).transpose(1,0)\n",
    "            #print(msns)\n",
    "            # mean ( l2 norm as distance metric / normalisation term for l2 norm)\n",
    "            # mean of distances\n",
    "            # normalise with max=grid square root, min=0\n",
    "            cc.append(torch.mean( torch.cdist(mn.float(), msns.float()) / self.grid_sqrt )) \n",
    "        \n",
    "        # mean connection cost of a layer\n",
    "        return torch.mean(torch.tensor(cc))\n",
    "    \n",
    "    def compute_channel_importance(self, i_f:int) -> list:\n",
    "        # channel importance metric for pruning\n",
    "        # based on l2 norm = magnitude = euclidean distance\n",
    "        \n",
    "        ci = []\n",
    "        \n",
    "        #print(self.filter_list[i_f].weights.shape)\n",
    "        \n",
    "        for i_w in range(self.filter_list[i_f].weights.shape[1]):\n",
    "            # importance of a kernel in a layer\n",
    "            #print(self.filter_list[i_f].weights[:,i_w].shape)\n",
    "            # maybe the kernel trigger todo\n",
    "            ci.append(self.filter_list[i_f].weights[:,i_w].norm(2).detach().cpu().numpy()) # .detach().cpu().numpy()\n",
    "            \n",
    "        return ci # channel importance list of a filter\n",
    "    \n",
    "    def swap_filter(self):\n",
    "        # we swap filters within the layer\n",
    "        # based on connection cost\n",
    "        # filter can move a maximum of two positions per swap\n",
    "    \n",
    "        # change positions\n",
    "        # change\n",
    "        \n",
    "        print(\"swap here\")\n",
    "        \n",
    "        self.m_this = self.m_this # single integer\n",
    "        self.n_this = self.n_this # single integer\n",
    "    \n",
    "    def grow_filter(self) -> None:\n",
    "        # introduce new filters in a layer\n",
    "        # based on \n",
    "        # algorithmic growth process \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def grow_channel(self) -> None:\n",
    "        # introduce new channel in a layer\n",
    "        # based on connection cost??\n",
    "        # algorithmic growth process \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def prune_filter(self) -> None:\n",
    "        # delete filter in a layer\n",
    "        pass\n",
    "    \n",
    "    def prune_channel(self, i_f:int, keep_ids:list) -> None:\n",
    "        # delete channels in a filter\n",
    "        # based on importance score\n",
    "        \n",
    "        #print(\"prune here\")\n",
    "        \n",
    "        #for f in self.filter_list:\n",
    "            # f.update()\n",
    "            \n",
    "        # only keep \"the best\" weights\n",
    "        \n",
    "        if False:\n",
    "            for i in keep_ids:\n",
    "                print(i)\n",
    "                print(self.filter_list[i_f].ms_in[i])\n",
    "                print( torch.nn.Parameter(self.filter_list[i_f].ms_in[keep_ids]) )\n",
    "        \n",
    "        print(\"the problem seems to be the parameter\")\n",
    "        print(torch.nn.Parameter(self.filter_list[i_f].weights[:, keep_ids, :, :]).shape)\n",
    "        print(self.filter_list[i_f].weights[:, keep_ids, :, :].shape)\n",
    "        \n",
    "        self.filter_list[i_f].weights = torch.nn.Parameter(self.filter_list[i_f].weights[:, keep_ids, :, :])\n",
    "        self.filter_list[i_f].ms_in = torch.nn.Parameter(self.filter_list[i_f].ms_in[keep_ids])\n",
    "        #[self.filter_list[i_f].ms_in[i] for i in keep_ids] # self.ms_in[remove_ids]\n",
    "        self.filter_list[i_f].ns_in = torch.nn.Parameter(self.filter_list[i_f].ns_in[keep_ids])\n",
    "        # [self.filter_list[i_f].ns_in[i] for i in keep_ids] # self.ns_in[remove_ids]\n",
    "\n",
    "        \n",
    "        # pruning based on a metric\n",
    "        \n",
    "        # delete layer with id\n",
    "        # delete channels in each layer with id\n",
    "        \n",
    "        # channel deactivation\n",
    "        # require_grad = False/True for each channel\n",
    "        #deactivate_ids = [1, 2, 6]\n",
    "        #self.active[deactivate_ids] = False\n",
    "        #print(\"weight\")\n",
    "        #print(self.weight.shape)\n",
    "        #print(self.weight[:,self.active,:,:].shape)\n",
    "        # this is totally wrong - iterative will break after first iteration\n",
    "        #print()\n",
    "        # Good to hear it’s working, although I would think you’ll get an error at some point in your code, as the cuda() call creates a non-leaf tensor.\n",
    "        #self.weight = torch.nn.Parameter(  self.weight[:,self.active,:,:] ) # .detach().cpu().numpy()\n",
    "        #self.weight = self.weight.cuda()\n",
    "        #print(self.weight.shape)\n",
    "        #print(self.active)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def reset_parameters(self) -> None:\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def extra_repr(self):\n",
    "        \n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        # return s.format(**self.__dict__)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'\n",
    "    \"\"\"       \n",
    "\n",
    "        \n",
    "    def forward(self, x: X) -> Tensor:\n",
    "        \n",
    "        # calculate output for each filter\n",
    "        output_list = []\n",
    "        m_list = []\n",
    "        n_list = []\n",
    "        for f in self.filter_list:\n",
    "            # output = filter(input)\n",
    "            output_list.append(f(x))\n",
    "            m_list.append(f.m_this)\n",
    "            n_list.append(f.n_this)\n",
    "        x.ms_x = m_list\n",
    "        x.ns_x = n_list\n",
    "        x.data = torch.cat(output_list, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def update(self):\n",
    "        # 1: deactivate channels based on importance metric\n",
    "        '''\n",
    "        n = 256\n",
    "        n_tmp = n * 0.5\n",
    "\n",
    "        for i in range (100):\n",
    "\n",
    "            n = n*0.97\n",
    "            if n <= n_tmp:\n",
    "                break\n",
    "            print(int(n))\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        amout_remove = 1\n",
    "        \n",
    "        all_ci = []\n",
    "        all_len = 0\n",
    "        for i_f in range(len(self.filter_list)):\n",
    "            all_len += len(self.filter_list[i_f].ms_in)\n",
    "            # list of lists\n",
    "            all_ci.append(self.compute_channel_importance(i_f))\n",
    "            #tmp_ids = sorted(range(len(all_ci)), key=lambda sub: all_ci[sub])\n",
    "          \n",
    "        if all_len < int(self.original_size * self.prune_keep_total):\n",
    "            # if n percent have been pruned, stop this layer\n",
    "            print(\"pruning done for this layer\")\n",
    "        else:\n",
    "            n = int(all_len*self.prune_keep)\n",
    "            all_ci_flatten = [item for row in all_ci for item in row] # don't have equal lengths, so no numpy possible\n",
    "            index = sorted(range(all_len), key=lambda sub: all_ci_flatten[sub])[-n]\n",
    "            threshold_value = all_ci_flatten[index]\n",
    "\n",
    "            for i_f in range(len(self.filter_list)):\n",
    "\n",
    "                # channel importance list for this filter\n",
    "                ci = all_ci[i_f] # self.compute_channel_importance(i_f)\n",
    "\n",
    "                print(ci)\n",
    "                print(threshold_value)\n",
    "                # torch.where()\n",
    "                try:\n",
    "                    \n",
    "                    indices = np.where((ci >= threshold_value))\n",
    "                except:\n",
    "                    print(\"a\")\n",
    "                    indices = torch.where((torch.tensor(ci) >= threshold_value))\n",
    "\n",
    "                # indices should be list/np/detached\n",
    "                self.prune_channel(i_f, indices)\n",
    "                \n",
    "                print(\"pruuuuuuuuuuuneeeeeeeeeeeeeeeee\")\n",
    "\n",
    "                # ci = ci[indices] # probably not useful\n",
    "            \n",
    "            \n",
    "            # print(\"channel importance ci\", ci)\n",
    "            # keep_ids = random.sample(range(0, 8), 5)\n",
    "            #keep_ids = sorted(range(len(ci)), key=lambda sub: ci[sub])[amout_remove:]\n",
    "            #print(keep_ids)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "                print()\n",
    "                print(\"update\")\n",
    "                print()\n",
    "                n = len(test_list)\n",
    "                n = int(n*0.97)\n",
    "\n",
    "                print(\"keep\", n)\n",
    "\n",
    "                index = sorted(range(len(test_list)), key=lambda sub: test_list[sub])[-n]\n",
    "                threshold_value = test_list[index]\n",
    "                print(\"t\", threshold_value)\n",
    "\n",
    "                # get indices from array where condition\n",
    "                indices = np.where((test_list >= threshold_value))\n",
    "\n",
    "                print(\"v\", test_list)\n",
    "                print(\"s\", sorted(test_list))\n",
    "\n",
    "                test_list = np.array(test_list)[indices]\n",
    "\n",
    "                print(\"v\", test_list) # i want this to not be ordered\n",
    "                print(\"si\", index)\n",
    "\n",
    "\n",
    "                #test_list = random.sample(range(100, 200), len(test_list))\n",
    "\n",
    "                if n <= n_tmp:\n",
    "                    break\n",
    "\n",
    "\n",
    "                pass\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_filter_positions(self):\n",
    "        # in use for next layer input\n",
    "        \n",
    "        ms_this = []\n",
    "        ns_this = []\n",
    "        for f in self.filter_list:\n",
    "            ms_this.append(f.m_this)\n",
    "            ns_this.append(f.n_this)\n",
    "        \n",
    "        return ms_this, ns_this\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01ff28b-033a-4b00-a301-94d5cf842e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 5, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[2,3],[4,5,5,3]]\n",
    "[item for row in a for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d986320e-2189-4edf-a7c8-1de1af933a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import torchvision\n",
    "    tmp = torchvision.models.squeezenet1_0(weights=torchvision.models.SqueezeNet1_0_Weights.IMAGENET1K_V1)\n",
    "    tmp.classifier[1] = torch.nn.Conv2d(512, 10, (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c186cf1-c7db-45da-b779-f7ab88f3896f",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## DecentNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd6a2811-6313-41cc-82a0-78cdb812c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentNet(nn.Module):\n",
    "    def __init__(self, out_dim:list=[1, 16, 32, 64], n_classes:int=10, grid_size:int=81, prune_keep:float=0.9, prune_keep_total:float= 0.5) -> None:\n",
    "        super(DecentNet, self).__init__()\n",
    "        \n",
    "        out_dim.append(n_classes)\n",
    "        #out_dim = [1, 32, 48, 64, 10]       \n",
    "        assert not any(i > grid_size for i in out_dim), f\"filters need to be less than {grid_size}\"\n",
    "        \n",
    "        # backbone\n",
    "        \n",
    "        ms_in_1 = [torch.tensor(0)]\n",
    "        ns_in_1 = [torch.tensor(0)]\n",
    "        assert out_dim[0] == len(ms_in_1), f\"x data (out_dim[0]={out_dim[0]}) needs to match (ms_in_1={len(ms_in_1)})\"\n",
    "        assert out_dim[0] == len(ns_in_1), f\"x data (out_dim[0]={out_dim[0]}) needs to match (ns_in_1={len(ns_in_1)})\"\n",
    "        self.decent1 = DecentLayer(ms_in=ms_in_1, ns_in=ns_in_1, n_filters=out_dim[1], kernel_size=3, stride=1, padding=0, dilation=3, grid_size=grid_size, prune_keep=prune_keep, prune_keep_total=prune_keep_total)\n",
    "        \n",
    "        ms_in_2,ns_in_2 = self.decent1.get_filter_positions()\n",
    "        assert out_dim[1] == len(ms_in_2), f\"x data (out_dim[1]={out_dim[1]}) needs to match (ms_in_2={len(ms_in_2)})\"\n",
    "        assert out_dim[1] == len(ns_in_2), f\"x data (out_dim[1]={out_dim[1]}) needs to match (ns_in_2={len(ns_in_2)})\"\n",
    "        self.decent2 = DecentLayer(ms_in=ms_in_2, ns_in=ns_in_2, n_filters=out_dim[2], kernel_size=3, stride=1, padding=0, dilation=3, grid_size=grid_size, prune_keep=prune_keep, prune_keep_total=prune_keep_total)\n",
    "        \n",
    "        ms_in_3,ns_in_3 = self.decent2.get_filter_positions()\n",
    "        assert out_dim[2] == len(ms_in_3), f\"x data (out_dim[2]={out_dim[2]}) needs to match (ms_in_3={len(ms_in_3)})\"\n",
    "        assert out_dim[2] == len(ns_in_3), f\"x data (out_dim[2]={out_dim[2]}) needs to match (ns_in_3={len(ns_in_3)})\"\n",
    "        self.decent3 = DecentLayer(ms_in=ms_in_3, ns_in=ns_in_3, n_filters=out_dim[3], kernel_size=3, stride=1, padding=0, dilation=3, grid_size=grid_size, prune_keep=prune_keep, prune_keep_total=prune_keep_total)\n",
    "        \n",
    "        ms_in_1x1,ns_in_1x1 = self.decent3.get_filter_positions()\n",
    "        assert out_dim[3] == len(ms_in_1x1), f\"x data (out_dim[3]={out_dim[3]}) needs to match (ms_in_1x1={len(ms_in_1x1)})\"\n",
    "        assert out_dim[3] == len(ns_in_1x1), f\"x data (out_dim[3]={out_dim[3]}) needs to match (ns_in_1x1={len(ns_in_1x1)})\"\n",
    "        self.decent1x1 = DecentLayer(ms_in=ms_in_1x1, ns_in=ns_in_1x1, n_filters=out_dim[-1], kernel_size=1, stride=1, padding=0, dilation=3, grid_size=grid_size, prune_keep=prune_keep, prune_keep_total=prune_keep_total)\n",
    "        \n",
    "        #self.tmp = torchvision.models.squeezenet1_0(torchvision.models.SqueezeNet1_0_Weights.IMAGENET1K_V1)\n",
    "        #self.tmp.classifier[1] = torch.nn.Conv2d(512, 10, kernel_size=(3,3))\n",
    "        \n",
    "        # head\n",
    "        self.fc = torch.nn.Linear(out_dim[-1], out_dim[-1])\n",
    "    \n",
    "        # activation\n",
    "        self.mish1 = torch.nn.Mish()\n",
    "        self.mish2 = torch.nn.Mish()\n",
    "        self.mish3 = torch.nn.Mish()\n",
    "        self.mish1x1 = torch.nn.Mish()\n",
    "        \n",
    "        # bias\n",
    "        self.bias1 = torch.nn.InstanceNorm2d(out_dim[1])\n",
    "        self.bias2 = torch.nn.InstanceNorm2d(out_dim[2])\n",
    "        self.bias3 = torch.nn.InstanceNorm2d(out_dim[3])\n",
    "        self.bias1x1 = torch.nn.InstanceNorm2d(out_dim[-1])\n",
    "        \n",
    "        # activation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # init cc\n",
    "        self.cc = []\n",
    "        self.compute_connection_cost()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        \n",
    "        x = self.decent1(x)\n",
    "        x.data = self.mish1(x.data)\n",
    "        x.data = self.bias1(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        x = self.decent2(x)\n",
    "        x.data = self.mish2(x.data)\n",
    "        x.data = self.bias2(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        x = self.decent3(x)\n",
    "        x.data = self.mish3(x.data)\n",
    "        x.data = self.bias3(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        x = self.decent1x1(x)\n",
    "        x.data = self.mish1x1(x.data)\n",
    "        x.data = self.bias1x1(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        # global max pooling for MIL\n",
    "        x.data = F.max_pool2d(x.data, kernel_size=x.data.size()[2:])\n",
    "        \n",
    "        x.data = x.data.reshape(x.data.size(0), -1)\n",
    "        x.data = self.fc(x.data) \n",
    "        \n",
    "        # x.data = self.sigmoid(x.data)\n",
    "        \n",
    "        # x.data = self.tmp(x.data)\n",
    "        \n",
    "        return x.data\n",
    "    \n",
    "    def compute_connection_cost(self):\n",
    "        self.cc = []\n",
    "        # self.cc.append(self.decent1.compute_layer_connection_cost()) # maybe not even needed ...\n",
    "        self.cc.append(self.decent2.compute_layer_connection_cost())\n",
    "        self.cc.append(self.decent3.compute_layer_connection_cost())\n",
    "        self.cc.append(self.decent1x1.compute_layer_connection_cost())\n",
    "        self.cc = torch.mean(torch.tensor(self.cc))\n",
    "        \n",
    "    \n",
    "    def update(self):\n",
    "        \n",
    "        # adapted from BIMT: https://github.com/KindXiaoming/BIMT/blob/main/mnist_3.5.ipynb\n",
    "        #self.decent1.update()\n",
    "        self.decent2.update()\n",
    "        self.decent3.update()\n",
    "        #self.decent1x1.update()\n",
    "        \n",
    "        # measurement for updating\n",
    "        \n",
    "        # update layer by layer\n",
    "        \n",
    "        \n",
    "        # connection cost has to be calculated after pruning\n",
    "        self.compute_connection_cost()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f2c55a-0f86-423d-97fb-aa1502f4fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecentNet(n_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60bdf0-147c-4bfe-83c0-4a330c7f9bfc",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3988da38-6bbe-4665-b6a1-dd682020435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  7,  3, 12], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.autograd.Variable(torch.randn(5, 2, 30, 30)) # batch x channel x width x height\n",
    "# dense_input.shape\n",
    "\n",
    "# todo: ms need to have same size as channel\n",
    "\n",
    "X(tmp, [torch.tensor(5), torch.tensor(7)], [torch.tensor(3), torch.tensor(12)])\n",
    "\n",
    "torch.stack( [torch.tensor(5, device=\"cuda\"), torch.tensor(7, device=\"cuda\"), torch.tensor(3, device=\"cuda\"), torch.tensor(12, device=\"cuda\")] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90dfcd-c00f-4f9d-8c24-bbac8c6af17b",
   "metadata": {},
   "source": [
    "### Lightning version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92509f06-c9fb-4084-843e-b80b3552c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "import os\n",
    "import torchmetrics\n",
    "\n",
    "class DecentLightning(pl.LightningModule):\n",
    "    def __init__(self, kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # print(\"the kwargs: \", kwargs)\n",
    "        \n",
    "        model_kwargs = kwargs['model_kwargs']\n",
    "        \n",
    "        self.n_classes = model_kwargs[\"n_classes\"]\n",
    "        self.grid_size = model_kwargs[\"grid_size\"]\n",
    "        self.out_dim = model_kwargs[\"out_dim\"]\n",
    "        self.prune_keep = model_kwargs[\"prune_keep\"]\n",
    "        self.prune_keep_total = model_kwargs[\"prune_keep_total\"]\n",
    "        \n",
    "        self.model = DecentNet(n_classes=self.n_classes, grid_size=self.grid_size, out_dim=self.out_dim, prune_keep=self.prune_keep, prune_keep_total=self.prune_keep_total).to(\"cuda\")\n",
    "        \n",
    "        self.criterion = model_kwargs[\"criterion\"]\n",
    "        self.optimizer = model_kwargs[\"optimizer\"]\n",
    "        self.base_lr = model_kwargs[\"base_lr\"]\n",
    "        self.min_lr = model_kwargs[\"min_lr\"]\n",
    "        self.lr_update = model_kwargs[\"lr_update\"]\n",
    "        self.momentum = model_kwargs[\"momentum\"]\n",
    "        self.cc_weight = model_kwargs[\"cc_weight\"]\n",
    "        self.update_every_nth_epoch = model_kwargs[\"update_every_nth_epoch\"]\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        if False:\n",
    "            self.metric = { \"train_acc\" : torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes),\n",
    "                     \"train_f1\" : torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes),\n",
    "                     \"val_acc\" : torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes),\n",
    "                     \"val_f1\" : torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes)\n",
    "                   }\n",
    "        else:\n",
    "            self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.train_prec =  torchmetrics.Precision(task=\"multiclass\", average='macro', num_classes=self.n_classes)\n",
    "            self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.val_prec =  torchmetrics.Precision(task=\"multiclass\", average='macro', num_classes=self.n_classes)\n",
    "\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        print(\"configure_optimizers\")\n",
    "        \n",
    "        if self.optimizer == \"adamw\":\n",
    "            optimiser = optim.AdamW(self.parameters(), lr=self.base_lr)\n",
    "            lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimiser, milestones=[100,150], gamma=0.1)\n",
    "            return [optimiser], [lr_scheduler]\n",
    "        else:\n",
    "            optimiser = optim.SGD(self.parameters(), lr=self.base_lr, momentum=self.momentum)\n",
    "            lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimiser, \n",
    "                                                                              T_0 = self.lr_update, # number of iterations for the first restart.\n",
    "                                                                              eta_min = self.min_lr\n",
    "                                                                               )\n",
    "            return [optimiser], [lr_scheduler]\n",
    "        \n",
    "    def on_train_epoch_start(self):\n",
    "        \n",
    "        print(\"* EPOCH START * \" * 50)\n",
    "        \n",
    "        if (self.current_epoch % self.update_every_nth_epoch) == 0 and self.current_epoch != 0:\n",
    "            \n",
    "            print(self.model)\n",
    "            self.model.update()\n",
    "\n",
    "            print(\"*\"*50)\n",
    "            print(\"*\"*50)\n",
    "            print(\"*\"*50)\n",
    "            print(\"model is updated now\")\n",
    "            print(\"*\"*50)\n",
    "            print(\"*\"*50)\n",
    "            print(\"*\"*50)\n",
    "        \n",
    "            print(self.model)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # 1       \n",
    "        loss = self._loss_n_metrics(batch, mode=\"train\")\n",
    "        if batch_idx < 5:\n",
    "            print(\"training_step\", batch_idx)\n",
    "        #loss = torch.tensor(1)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # 2\n",
    "        self._loss_n_metrics(batch, mode=\"val\")\n",
    "        if batch_idx < 3:\n",
    "            print(\"validation_step\", batch_idx)\n",
    "        #self._loss_n_metrics(batch, mode=\"val\")\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        print(\"on_validation_epoch_end\")\n",
    "        # 3\n",
    "        \n",
    "        \"\"\"\n",
    "        for parameter in self.parameters():\n",
    "            print(\"parameter\")\n",
    "            print(parameter)\n",
    "        \"\"\" \n",
    "        #return\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        print(\"on_train_epoch_end\")\n",
    "        # 4\n",
    "        pass\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._loss_n_metrics(batch, mode=\"test\")\n",
    "        if batch_idx < 3:\n",
    "            print(\"test_step\", batch_idx)\n",
    "            \n",
    "    def on_test_epoch_end(self):\n",
    "        print(\"on_test_epoch_end\")\n",
    "        # 3\n",
    "        \n",
    "        \"\"\"\n",
    "        for parameter in self.parameters():\n",
    "            print(\"parameter\")\n",
    "            print(parameter)\n",
    "        \"\"\" \n",
    "        #return\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _loss_n_metrics(self, batch, mode=\"train\"):\n",
    "        \n",
    "        img, ground_truth = batch\n",
    "        # make it an X object\n",
    "        \n",
    "        #print(img.shape)\n",
    "        \n",
    "        # init with position 0/0 as input for first layer\n",
    "        img = X(img.to(\"cuda\"), [torch.tensor(0)], [torch.tensor(0)])\n",
    "        \n",
    "        model_output = self(img) # cause of the forward function\n",
    "        \n",
    "        # ground_truth = ground_truth\n",
    "        \n",
    "        ground_truth_multi_hot = torch.zeros(ground_truth.unsqueeze(1).size(0), self.n_classes).scatter_(1, ground_truth.unsqueeze(1).to(\"cpu\"), 1.).to(\"cuda\")\n",
    "        \n",
    "        # this needs fixing\n",
    "        # ground_truth_multi_hot = torch.zeros(ground_truth.size(0), 10).to(\"cuda\").scatter_(torch.tensor(1).to(\"cuda\"), ground_truth.to(\"cuda\"), torch.tensor(1.).to(\"cuda\")).to(\"cuda\")\n",
    "        \n",
    "        loss = self.criterion(model_output, ground_truth) # ground_truth_multi_hot)\n",
    "        cc = torch.mean(self.model.cc) * self.cc_weight\n",
    "        \n",
    "        # print(cc)\n",
    "        # from BIMT\n",
    "        # loss_train = loss_fn(mlp(x.to(device)), one_hots[label])\n",
    "        # cc = mlp.get_cc(weight_factor=2.0, no_penalize_last=True)\n",
    "        # total_loss = loss_train + lamb*cc\n",
    "        \n",
    "        pred_value, pred_i  = torch.max(model_output, 1)\n",
    "        \n",
    "        #print(model_output)\n",
    "        #print(pred_i)\n",
    "        #print(ground_truth)\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            self.train_acc(preds=pred_i, target=ground_truth) # (model_output.argmax(dim=-1) == ground_truth).float().mean()\n",
    "            self.train_f1(preds=pred_i, target=ground_truth) \n",
    "            self.train_prec(preds=pred_i, target=ground_truth) \n",
    "            \n",
    "            self.log(f'{mode}_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_f1', self.train_f1, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_prec', self.train_prec, on_step=False, on_epoch=True)\n",
    "            \n",
    "            if random.randint(1, 50) == 5:\n",
    "                print()\n",
    "                print(\"p\", pred_i)\n",
    "                print(\"g\", ground_truth)\n",
    "                print(\"a\", self.train_acc)\n",
    "                print(\"f\", self.train_f1)\n",
    "                print(\"p\", self.train_prec)\n",
    "                print(\"l\", loss)\n",
    "                \n",
    "        else:\n",
    "            self.val_acc(preds=pred_i, target=ground_truth) # (model_output.argmax(dim=-1) == ground_truth).float().mean()\n",
    "            self.val_f1(preds=pred_i, target=ground_truth) \n",
    "            self.val_prec(preds=pred_i, target=ground_truth) \n",
    "            \n",
    "            self.log(f'{mode}_acc', self.val_acc, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_f1', self.val_f1, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_prec', self.val_prec, on_step=False, on_epoch=True)\n",
    "            \n",
    "        self.log(f'{mode}_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'{mode}_cc', cc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        \n",
    "        # loss + connection cost term\n",
    "        return loss + cc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8cae21-08fe-4e44-a1ea-a7ae8d12ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset = datasets.MNIST('example_data', train=True, download=True, transform=transform)\n",
    "val_set = datasets.MNIST('example_data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(len(val_set))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d36c8d-87e6-4f01-8e52-cdcea768df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dev_routine(**kwargs):\n",
    "    \n",
    "    print(\"train kwargs\", kwargs['train_kwargs'])\n",
    "    print(\"model kwargs\", kwargs['model_kwargs'])\n",
    "    \n",
    "    train_kwargs = kwargs['train_kwargs']\n",
    "    \n",
    "    transform=transforms.Compose([\n",
    "        #transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(size=train_kwargs[\"img_size\"]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        #transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST('example_data', train=False, download=True, transform=transform)\n",
    "    # val_set = datasets.MNIST('example_data', train=False, transform=transform)\n",
    "    \n",
    "    print(len(dataset))\n",
    "    \n",
    "    # Split the indices in a stratified way\n",
    "    indices = np.arange(len(dataset))\n",
    "    # train_indices, val_indices = train_test_split(indices, train_size=0.8, test_size=0.2, stratify=dataset.targets)\n",
    "    train_indices, val_indices = train_test_split(indices, train_size=50, test_size=50, stratify=dataset.targets)\n",
    "    train_subset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_subset, shuffle=True, batch_size=train_kwargs[\"batch_size\"], num_workers=train_kwargs[\"num_workers\"])\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_subset, shuffle=False, batch_size=train_kwargs[\"batch_size\"], num_workers=train_kwargs[\"num_workers\"])\n",
    "    \n",
    "    logger = CSVLogger(\"example_results/lightning_logs\", name=\"tmp_exp\")\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(train_kwargs[\"ckpt_path\"], \"example_results\"),\n",
    "                         accelerator=\"gpu\" if str(train_kwargs[\"device\"]).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         log_every_n_steps=train_kwargs[\"log_every_n_steps\"],\n",
    "                         logger=logger,\n",
    "                         check_val_every_n_epoch=1,\n",
    "                         max_epochs=train_kwargs[\"epochs\"],\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_f1\"),\n",
    "                                    LearningRateMonitor(\"epoch\")])\n",
    "    \n",
    "    \n",
    "    \n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(train_kwargs[\"ckpt_path\"], \"DecentNet.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = DecentLightning.load_from_checkpoint(pretrained_filename, kwargs=kwargs) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(19) # To be reproducable\n",
    "                \n",
    "        # Initialize the LightningModule and LightningDataModule\n",
    "        model = DecentLightning(kwargs)\n",
    "        \n",
    "\n",
    "        # Train the model using a Trainer\n",
    "        trainer.fit(model, train_dataloader, val_dataloader)\n",
    "        \n",
    "        # we don't save the positions here ...\n",
    "        # model = DecentLightning.load_from_checkpoint(trainer.checkpoint_callback.best_model_path, kwargs=kwargs) # Load best checkpoint after training\n",
    "\n",
    "        \n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, val_dataloader, verbose=False)\n",
    "    # test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    try:\n",
    "        result = {\"test accuracy on valset\": val_result[0][\"test_acc\"]}\n",
    "    except:\n",
    "        result = 0\n",
    "        \n",
    "    print(result)\n",
    "\n",
    "    return model, result, val_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c1dfe-a818-43a0-848c-d6b5c0efe719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a3f1c73-2b3b-4c4c-91b2-b0eb2f6e88e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18*18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ad8b29-48de-4f62-88da-381f60d698f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kwargs {'epochs': 100, 'img_size': 96, 'batch_size': 16, 'log_every_n_steps': 4, 'ckpt_path': '', 'device': 'cuda', 'num_workers': 0}\n",
      "model kwargs {'n_classes': 10, 'out_dim': [1, 8, 16, 32], 'grid_size': 324, 'criterion': CrossEntropyLoss(), 'optimizer': 'sgd', 'base_lr': 0.001, 'min_lr': 1e-05, 'momentum': 0.9, 'lr_update': 100, 'cc_weight': 0.2, 'update_every_nth_epoch': 1, 'prune_keep': 0.97, 'prune_keep_total': 0.5}\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 19\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 1, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 8, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 16, 3, 3])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n",
      "weight shape init\n",
      "torch.Size([1, 32, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | model      | DecentNet           | 8.3 K \n",
      "1 | criterion  | CrossEntropyLoss    | 0     \n",
      "2 | train_acc  | MulticlassAccuracy  | 0     \n",
      "3 | train_f1   | MulticlassF1Score   | 0     \n",
      "4 | train_prec | MulticlassPrecision | 0     \n",
      "5 | val_acc    | MulticlassAccuracy  | 0     \n",
      "6 | val_f1     | MulticlassF1Score   | 0     \n",
      "7 | val_prec   | MulticlassPrecision | 0     \n",
      "---------------------------------------------------\n",
      "6.3 K     Trainable params\n",
      "2.1 K     Non-trainable params\n",
      "8.3 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure_optimizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_step 0\n",
      "validation_step 1\n",
      "on_validation_epoch_end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aa6b5032aa49f28db1fa90b1d7a786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * \n",
      "training_step 0\n",
      "training_step 1\n",
      "training_step 2\n",
      "training_step 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_step 0\n",
      "validation_step 1\n",
      "validation_step 2\n",
      "on_validation_epoch_end\n",
      "on_train_epoch_end\n",
      "* EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * * EPOCH START * \n",
      "DecentNet(\n",
      "  (decent1): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "    )\n",
      "  )\n",
      "  (decent2): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (8): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (9): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (10): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (11): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (12): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (13): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (14): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (15): DecentFilter(weights: torch.Size([1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "    )\n",
      "  )\n",
      "  (decent3): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([17.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (8): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (9): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (10): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (11): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (12): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (13): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (14): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (15): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (16): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (17): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (18): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (19): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (20): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (21): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (22): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (23): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([4.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (24): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (25): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (26): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (27): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (28): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (29): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (30): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (31): DecentFilter(weights: torch.Size([1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([4.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "    )\n",
      "  )\n",
      "  (decent1x1): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (8): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (9): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (mish1): Mish()\n",
      "  (mish2): Mish()\n",
      "  (mish3): Mish()\n",
      "  (mish1x1): Mish()\n",
      "  (bias1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (bias2): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (bias3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (bias1x1): InstanceNorm2d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "[array(0.17352554, dtype=float32), array(0.17338999, dtype=float32), array(0.20314437, dtype=float32), array(0.17594022, dtype=float32), array(0.21397404, dtype=float32), array(0.20261154, dtype=float32), array(0.18687856, dtype=float32), array(0.15321007, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.18377228, dtype=float32), array(0.2516736, dtype=float32), array(0.19644395, dtype=float32), array(0.19046032, dtype=float32), array(0.19869909, dtype=float32), array(0.1907045, dtype=float32), array(0.27029005, dtype=float32), array(0.19401377, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.25293428, dtype=float32), array(0.12479828, dtype=float32), array(0.16996406, dtype=float32), array(0.22502069, dtype=float32), array(0.18074867, dtype=float32), array(0.18892668, dtype=float32), array(0.20140569, dtype=float32), array(0.26794976, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.17519818, dtype=float32), array(0.1965606, dtype=float32), array(0.19992493, dtype=float32), array(0.20765536, dtype=float32), array(0.27082276, dtype=float32), array(0.18628788, dtype=float32), array(0.20513356, dtype=float32), array(0.23553443, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.21489841, dtype=float32), array(0.216446, dtype=float32), array(0.24792267, dtype=float32), array(0.25107667, dtype=float32), array(0.16108882, dtype=float32), array(0.22229192, dtype=float32), array(0.20741573, dtype=float32), array(0.2013146, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.21301241, dtype=float32), array(0.25491548, dtype=float32), array(0.17684844, dtype=float32), array(0.23884289, dtype=float32), array(0.21027762, dtype=float32), array(0.20489113, dtype=float32), array(0.26987785, dtype=float32), array(0.21057725, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.14472337, dtype=float32), array(0.15140194, dtype=float32), array(0.19693704, dtype=float32), array(0.22358479, dtype=float32), array(0.24372636, dtype=float32), array(0.1712037, dtype=float32), array(0.1934046, dtype=float32), array(0.17456006, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.2566357, dtype=float32), array(0.23305373, dtype=float32), array(0.24412583, dtype=float32), array(0.22988711, dtype=float32), array(0.2593979, dtype=float32), array(0.19761223, dtype=float32), array(0.21076396, dtype=float32), array(0.25203103, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.22109373, dtype=float32), array(0.18686175, dtype=float32), array(0.20631193, dtype=float32), array(0.19655246, dtype=float32), array(0.23937334, dtype=float32), array(0.2088852, dtype=float32), array(0.22614361, dtype=float32), array(0.23194587, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16813271, dtype=float32), array(0.24391003, dtype=float32), array(0.21193802, dtype=float32), array(0.21826214, dtype=float32), array(0.26838735, dtype=float32), array(0.1737253, dtype=float32), array(0.22182094, dtype=float32), array(0.20847036, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.15532896, dtype=float32), array(0.25306118, dtype=float32), array(0.18772393, dtype=float32), array(0.2409446, dtype=float32), array(0.23074628, dtype=float32), array(0.19117029, dtype=float32), array(0.17579176, dtype=float32), array(0.23240004, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.17457683, dtype=float32), array(0.19891484, dtype=float32), array(0.1583366, dtype=float32), array(0.2246401, dtype=float32), array(0.20130649, dtype=float32), array(0.18325494, dtype=float32), array(0.19468099, dtype=float32), array(0.19596598, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16598131, dtype=float32), array(0.1989025, dtype=float32), array(0.21238562, dtype=float32), array(0.2144397, dtype=float32), array(0.18846974, dtype=float32), array(0.21529098, dtype=float32), array(0.23339559, dtype=float32), array(0.20621395, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.19311476, dtype=float32), array(0.13665208, dtype=float32), array(0.18251903, dtype=float32), array(0.2411152, dtype=float32), array(0.22228253, dtype=float32), array(0.15382104, dtype=float32), array(0.22943503, dtype=float32), array(0.2428215, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.24666232, dtype=float32), array(0.20996362, dtype=float32), array(0.16027626, dtype=float32), array(0.19557093, dtype=float32), array(0.19811797, dtype=float32), array(0.17468882, dtype=float32), array(0.16890371, dtype=float32), array(0.17921852, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "torch.Size([1, 1, 8, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.23923671, dtype=float32), array(0.21716394, dtype=float32), array(0.19018161, dtype=float32), array(0.14673726, dtype=float32), array(0.1931621, dtype=float32), array(0.21737558, dtype=float32), array(0.2753865, dtype=float32), array(0.17994213, dtype=float32)]\n",
      "0.15140194\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "torch.Size([1, 1, 7, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\AppData\\Local\\Temp\\ipykernel_8412\\647691469.py:177: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  print(torch.nn.Parameter(self.filter_list[i_f].weights[:, keep_ids, :, :]).shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.16027169, dtype=float32), array(0.16084145, dtype=float32), array(0.13920099, dtype=float32), array(0.14842203, dtype=float32), array(0.17946994, dtype=float32), array(0.15751214, dtype=float32), array(0.12189554, dtype=float32), array(0.13077503, dtype=float32), array(0.11215594, dtype=float32), array(0.14782932, dtype=float32), array(0.13600668, dtype=float32), array(0.10582612, dtype=float32), array(0.12050866, dtype=float32), array(0.175343, dtype=float32), array(0.18829899, dtype=float32), array(0.14667265, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.12996277, dtype=float32), array(0.12805972, dtype=float32), array(0.10973226, dtype=float32), array(0.15954168, dtype=float32), array(0.08251081, dtype=float32), array(0.159863, dtype=float32), array(0.15416835, dtype=float32), array(0.12388362, dtype=float32), array(0.14128761, dtype=float32), array(0.16807707, dtype=float32), array(0.14141557, dtype=float32), array(0.10538501, dtype=float32), array(0.15404832, dtype=float32), array(0.16017331, dtype=float32), array(0.14960553, dtype=float32), array(0.12605947, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.14401355, dtype=float32), array(0.1393565, dtype=float32), array(0.18224862, dtype=float32), array(0.16567563, dtype=float32), array(0.15558818, dtype=float32), array(0.14130105, dtype=float32), array(0.13411553, dtype=float32), array(0.15680552, dtype=float32), array(0.12609889, dtype=float32), array(0.10538264, dtype=float32), array(0.13201086, dtype=float32), array(0.17502977, dtype=float32), array(0.138267, dtype=float32), array(0.16626228, dtype=float32), array(0.15884899, dtype=float32), array(0.13209948, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.14196785, dtype=float32), array(0.11328894, dtype=float32), array(0.1538242, dtype=float32), array(0.12951796, dtype=float32), array(0.13643722, dtype=float32), array(0.14989871, dtype=float32), array(0.15313813, dtype=float32), array(0.17322688, dtype=float32), array(0.15949196, dtype=float32), array(0.10293054, dtype=float32), array(0.11850735, dtype=float32), array(0.11711065, dtype=float32), array(0.15791693, dtype=float32), array(0.1263217, dtype=float32), array(0.15409291, dtype=float32), array(0.1436522, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.19019619, dtype=float32), array(0.12800781, dtype=float32), array(0.15766051, dtype=float32), array(0.16504017, dtype=float32), array(0.17169397, dtype=float32), array(0.12183706, dtype=float32), array(0.12216938, dtype=float32), array(0.13712218, dtype=float32), array(0.13855909, dtype=float32), array(0.15929541, dtype=float32), array(0.15357198, dtype=float32), array(0.12086753, dtype=float32), array(0.1562147, dtype=float32), array(0.17223711, dtype=float32), array(0.17023869, dtype=float32), array(0.1552539, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.14800884, dtype=float32), array(0.14569479, dtype=float32), array(0.15792115, dtype=float32), array(0.1693194, dtype=float32), array(0.15385152, dtype=float32), array(0.10649469, dtype=float32), array(0.15886892, dtype=float32), array(0.16615026, dtype=float32), array(0.14443135, dtype=float32), array(0.14084172, dtype=float32), array(0.148136, dtype=float32), array(0.1770411, dtype=float32), array(0.16954507, dtype=float32), array(0.13658334, dtype=float32), array(0.13384335, dtype=float32), array(0.17367344, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.14450976, dtype=float32), array(0.16421182, dtype=float32), array(0.1635051, dtype=float32), array(0.1210556, dtype=float32), array(0.1558023, dtype=float32), array(0.15058257, dtype=float32), array(0.12451106, dtype=float32), array(0.14083041, dtype=float32), array(0.13212538, dtype=float32), array(0.1291483, dtype=float32), array(0.16580817, dtype=float32), array(0.13652079, dtype=float32), array(0.13368544, dtype=float32), array(0.11488032, dtype=float32), array(0.13700251, dtype=float32), array(0.12541153, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16688862, dtype=float32), array(0.13916627, dtype=float32), array(0.15534927, dtype=float32), array(0.15107483, dtype=float32), array(0.14942048, dtype=float32), array(0.1499577, dtype=float32), array(0.17661357, dtype=float32), array(0.16998579, dtype=float32), array(0.1542216, dtype=float32), array(0.1362289, dtype=float32), array(0.09894942, dtype=float32), array(0.10178788, dtype=float32), array(0.16305213, dtype=float32), array(0.09253778, dtype=float32), array(0.15477698, dtype=float32), array(0.15224354, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.15899345, dtype=float32), array(0.1560872, dtype=float32), array(0.17240553, dtype=float32), array(0.14996171, dtype=float32), array(0.13915852, dtype=float32), array(0.17680244, dtype=float32), array(0.1415169, dtype=float32), array(0.10434233, dtype=float32), array(0.14943616, dtype=float32), array(0.14013658, dtype=float32), array(0.12808798, dtype=float32), array(0.15598899, dtype=float32), array(0.15305403, dtype=float32), array(0.14256342, dtype=float32), array(0.16718419, dtype=float32), array(0.1566542, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16458116, dtype=float32), array(0.1549529, dtype=float32), array(0.09917761, dtype=float32), array(0.13972156, dtype=float32), array(0.15903503, dtype=float32), array(0.11117739, dtype=float32), array(0.13083936, dtype=float32), array(0.11882523, dtype=float32), array(0.12865728, dtype=float32), array(0.1165228, dtype=float32), array(0.13694939, dtype=float32), array(0.14133237, dtype=float32), array(0.15669926, dtype=float32), array(0.0936541, dtype=float32), array(0.09743612, dtype=float32), array(0.12861383, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 14, 3, 3])\n",
      "torch.Size([1, 1, 14, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.13596243, dtype=float32), array(0.17146134, dtype=float32), array(0.14277604, dtype=float32), array(0.16583113, dtype=float32), array(0.09597993, dtype=float32), array(0.15899317, dtype=float32), array(0.11406511, dtype=float32), array(0.10908048, dtype=float32), array(0.13827558, dtype=float32), array(0.13955517, dtype=float32), array(0.13800816, dtype=float32), array(0.12621327, dtype=float32), array(0.1489234, dtype=float32), array(0.14687398, dtype=float32), array(0.14497808, dtype=float32), array(0.11348746, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.09966676, dtype=float32), array(0.12314609, dtype=float32), array(0.14080127, dtype=float32), array(0.15226808, dtype=float32), array(0.14687005, dtype=float32), array(0.17007676, dtype=float32), array(0.11588841, dtype=float32), array(0.18755868, dtype=float32), array(0.14126265, dtype=float32), array(0.1655795, dtype=float32), array(0.11055136, dtype=float32), array(0.16571066, dtype=float32), array(0.13623236, dtype=float32), array(0.1484097, dtype=float32), array(0.16784568, dtype=float32), array(0.1382531, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.15494646, dtype=float32), array(0.13796704, dtype=float32), array(0.1592317, dtype=float32), array(0.13110153, dtype=float32), array(0.16833948, dtype=float32), array(0.14631207, dtype=float32), array(0.14440782, dtype=float32), array(0.15192965, dtype=float32), array(0.17758372, dtype=float32), array(0.14053789, dtype=float32), array(0.11169372, dtype=float32), array(0.12976025, dtype=float32), array(0.11132538, dtype=float32), array(0.15993191, dtype=float32), array(0.15193431, dtype=float32), array(0.16602509, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.15466028, dtype=float32), array(0.13489069, dtype=float32), array(0.12658578, dtype=float32), array(0.11614776, dtype=float32), array(0.14290294, dtype=float32), array(0.13731328, dtype=float32), array(0.15067515, dtype=float32), array(0.11123072, dtype=float32), array(0.16864887, dtype=float32), array(0.1317545, dtype=float32), array(0.13035128, dtype=float32), array(0.15910402, dtype=float32), array(0.13096002, dtype=float32), array(0.12986036, dtype=float32), array(0.12474886, dtype=float32), array(0.12546894, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16264898, dtype=float32), array(0.15553221, dtype=float32), array(0.16836749, dtype=float32), array(0.13593628, dtype=float32), array(0.1359302, dtype=float32), array(0.10145576, dtype=float32), array(0.14087865, dtype=float32), array(0.15528513, dtype=float32), array(0.1514233, dtype=float32), array(0.18542998, dtype=float32), array(0.16917026, dtype=float32), array(0.17297941, dtype=float32), array(0.10047963, dtype=float32), array(0.14227779, dtype=float32), array(0.12675121, dtype=float32), array(0.10101187, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16816618, dtype=float32), array(0.13249357, dtype=float32), array(0.10995188, dtype=float32), array(0.13643645, dtype=float32), array(0.18127944, dtype=float32), array(0.14008936, dtype=float32), array(0.14878066, dtype=float32), array(0.12428248, dtype=float32), array(0.13927096, dtype=float32), array(0.13294308, dtype=float32), array(0.08998347, dtype=float32), array(0.14648181, dtype=float32), array(0.16349521, dtype=float32), array(0.15846397, dtype=float32), array(0.13238642, dtype=float32), array(0.1378268, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.17796081, dtype=float32), array(0.17356145, dtype=float32), array(0.17280413, dtype=float32), array(0.10503303, dtype=float32), array(0.1538543, dtype=float32), array(0.14025095, dtype=float32), array(0.17174412, dtype=float32), array(0.16200574, dtype=float32), array(0.11040572, dtype=float32), array(0.16989309, dtype=float32), array(0.12402996, dtype=float32), array(0.09121738, dtype=float32), array(0.14913388, dtype=float32), array(0.13852447, dtype=float32), array(0.09977695, dtype=float32), array(0.18378216, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.15965325, dtype=float32), array(0.16823164, dtype=float32), array(0.17127988, dtype=float32), array(0.1477328, dtype=float32), array(0.15775561, dtype=float32), array(0.1284645, dtype=float32), array(0.1403109, dtype=float32), array(0.10794767, dtype=float32), array(0.12851135, dtype=float32), array(0.16280879, dtype=float32), array(0.09324736, dtype=float32), array(0.14900659, dtype=float32), array(0.13279198, dtype=float32), array(0.14587188, dtype=float32), array(0.12669611, dtype=float32), array(0.15266758, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.13593237, dtype=float32), array(0.17737928, dtype=float32), array(0.12042584, dtype=float32), array(0.13537185, dtype=float32), array(0.13668895, dtype=float32), array(0.11035205, dtype=float32), array(0.14476871, dtype=float32), array(0.12374384, dtype=float32), array(0.20019047, dtype=float32), array(0.14419462, dtype=float32), array(0.14721297, dtype=float32), array(0.1482597, dtype=float32), array(0.14983308, dtype=float32), array(0.07937923, dtype=float32), array(0.13165371, dtype=float32), array(0.13782793, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.12438472, dtype=float32), array(0.1527523, dtype=float32), array(0.14304298, dtype=float32), array(0.13148859, dtype=float32), array(0.11563127, dtype=float32), array(0.138352, dtype=float32), array(0.15474732, dtype=float32), array(0.16725822, dtype=float32), array(0.10479099, dtype=float32), array(0.1579692, dtype=float32), array(0.09859768, dtype=float32), array(0.13771021, dtype=float32), array(0.11693011, dtype=float32), array(0.14337194, dtype=float32), array(0.15536033, dtype=float32), array(0.13979952, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.15904102, dtype=float32), array(0.16176869, dtype=float32), array(0.17726392, dtype=float32), array(0.11291445, dtype=float32), array(0.11996084, dtype=float32), array(0.14939313, dtype=float32), array(0.13860804, dtype=float32), array(0.1508054, dtype=float32), array(0.13891411, dtype=float32), array(0.16796799, dtype=float32), array(0.15669164, dtype=float32), array(0.17420518, dtype=float32), array(0.15842931, dtype=float32), array(0.17445755, dtype=float32), array(0.12493372, dtype=float32), array(0.15448515, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.11765051, dtype=float32), array(0.1426041, dtype=float32), array(0.1539019, dtype=float32), array(0.10630243, dtype=float32), array(0.15344796, dtype=float32), array(0.12094087, dtype=float32), array(0.13960724, dtype=float32), array(0.12987445, dtype=float32), array(0.17776443, dtype=float32), array(0.15325692, dtype=float32), array(0.1601092, dtype=float32), array(0.10571974, dtype=float32), array(0.15728572, dtype=float32), array(0.1319984, dtype=float32), array(0.17348444, dtype=float32), array(0.10141397, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.18182303, dtype=float32), array(0.16183944, dtype=float32), array(0.14163207, dtype=float32), array(0.16993985, dtype=float32), array(0.12871963, dtype=float32), array(0.12565872, dtype=float32), array(0.11604416, dtype=float32), array(0.1630219, dtype=float32), array(0.12638052, dtype=float32), array(0.15409742, dtype=float32), array(0.13987528, dtype=float32), array(0.15132622, dtype=float32), array(0.11381444, dtype=float32), array(0.1531727, dtype=float32), array(0.1810669, dtype=float32), array(0.09807973, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16176762, dtype=float32), array(0.14037447, dtype=float32), array(0.1159717, dtype=float32), array(0.11390746, dtype=float32), array(0.12720345, dtype=float32), array(0.14696978, dtype=float32), array(0.13766326, dtype=float32), array(0.134845, dtype=float32), array(0.17212947, dtype=float32), array(0.13767262, dtype=float32), array(0.15251164, dtype=float32), array(0.15575124, dtype=float32), array(0.15196669, dtype=float32), array(0.14748287, dtype=float32), array(0.11843894, dtype=float32), array(0.12834992, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.11613525, dtype=float32), array(0.1473751, dtype=float32), array(0.16272046, dtype=float32), array(0.14658956, dtype=float32), array(0.11189067, dtype=float32), array(0.11715379, dtype=float32), array(0.14034675, dtype=float32), array(0.17848432, dtype=float32), array(0.16811098, dtype=float32), array(0.15500101, dtype=float32), array(0.18054275, dtype=float32), array(0.13234955, dtype=float32), array(0.10850924, dtype=float32), array(0.12786394, dtype=float32), array(0.15424034, dtype=float32), array(0.16672944, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.13652231, dtype=float32), array(0.13796984, dtype=float32), array(0.14618823, dtype=float32), array(0.15126546, dtype=float32), array(0.1368572, dtype=float32), array(0.12278128, dtype=float32), array(0.10236934, dtype=float32), array(0.11352172, dtype=float32), array(0.120301, dtype=float32), array(0.13027643, dtype=float32), array(0.12513654, dtype=float32), array(0.14369723, dtype=float32), array(0.12621228, dtype=float32), array(0.19620442, dtype=float32), array(0.13962066, dtype=float32), array(0.12062539, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.12330149, dtype=float32), array(0.10229938, dtype=float32), array(0.12529567, dtype=float32), array(0.16542357, dtype=float32), array(0.12483133, dtype=float32), array(0.17791328, dtype=float32), array(0.13231818, dtype=float32), array(0.1681851, dtype=float32), array(0.1355157, dtype=float32), array(0.12898391, dtype=float32), array(0.14810242, dtype=float32), array(0.12720133, dtype=float32), array(0.15584688, dtype=float32), array(0.14079344, dtype=float32), array(0.12126529, dtype=float32), array(0.18536, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.13777347, dtype=float32), array(0.18161371, dtype=float32), array(0.14928447, dtype=float32), array(0.14336471, dtype=float32), array(0.09689372, dtype=float32), array(0.12893511, dtype=float32), array(0.12505229, dtype=float32), array(0.0886602, dtype=float32), array(0.15484579, dtype=float32), array(0.17092018, dtype=float32), array(0.13743392, dtype=float32), array(0.1465573, dtype=float32), array(0.1530925, dtype=float32), array(0.11256512, dtype=float32), array(0.16668138, dtype=float32), array(0.15835297, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 14, 3, 3])\n",
      "torch.Size([1, 1, 14, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.13523507, dtype=float32), array(0.16098057, dtype=float32), array(0.08844098, dtype=float32), array(0.15467574, dtype=float32), array(0.16739997, dtype=float32), array(0.15060808, dtype=float32), array(0.14134233, dtype=float32), array(0.14882445, dtype=float32), array(0.12814477, dtype=float32), array(0.13763565, dtype=float32), array(0.13407005, dtype=float32), array(0.14906597, dtype=float32), array(0.09451181, dtype=float32), array(0.16152719, dtype=float32), array(0.16115804, dtype=float32), array(0.16336408, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 14, 3, 3])\n",
      "torch.Size([1, 1, 14, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.13727148, dtype=float32), array(0.13961995, dtype=float32), array(0.14472373, dtype=float32), array(0.10298949, dtype=float32), array(0.12131093, dtype=float32), array(0.1395828, dtype=float32), array(0.16616863, dtype=float32), array(0.10248002, dtype=float32), array(0.13587376, dtype=float32), array(0.1113072, dtype=float32), array(0.11416533, dtype=float32), array(0.12785326, dtype=float32), array(0.11351071, dtype=float32), array(0.15502976, dtype=float32), array(0.13291954, dtype=float32), array(0.1428388, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.13169369, dtype=float32), array(0.16733909, dtype=float32), array(0.1374613, dtype=float32), array(0.14661877, dtype=float32), array(0.12816773, dtype=float32), array(0.15952937, dtype=float32), array(0.11278506, dtype=float32), array(0.18364133, dtype=float32), array(0.19115745, dtype=float32), array(0.14237992, dtype=float32), array(0.11412358, dtype=float32), array(0.10783748, dtype=float32), array(0.17967726, dtype=float32), array(0.17058973, dtype=float32), array(0.17822322, dtype=float32), array(0.12823406, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "torch.Size([1, 1, 16, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "[array(0.16997138, dtype=float32), array(0.10060984, dtype=float32), array(0.1421296, dtype=float32), array(0.09869871, dtype=float32), array(0.1292326, dtype=float32), array(0.12830645, dtype=float32), array(0.1607338, dtype=float32), array(0.14731333, dtype=float32), array(0.18323937, dtype=float32), array(0.1370438, dtype=float32), array(0.17365986, dtype=float32), array(0.13036117, dtype=float32), array(0.16705915, dtype=float32), array(0.09158545, dtype=float32), array(0.13580677, dtype=float32), array(0.11798692, dtype=float32)]\n",
      "0.098698705\n",
      "the problem seems to be the parameter\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "torch.Size([1, 1, 15, 3, 3])\n",
      "pruuuuuuuuuuuneeeeeeeeeeeeeeeee\n",
      "**************************************************\n",
      "**************************************************\n",
      "**************************************************\n",
      "model is updated now\n",
      "**************************************************\n",
      "**************************************************\n",
      "**************************************************\n",
      "DecentNet(\n",
      "  (decent1): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 1, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'))\n",
      "       with inputs: ms_in= 0, ns_in= 0)\n",
      "    )\n",
      "  )\n",
      "  (decent2): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 1, 7, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 2, 13, 14, 12, 2, 8, ns_in= 10, 1, 11, 1, 2, 3, 15)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 1, 7, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 1, 2, 13, 14, 12, 2, 8, ns_in= 6, 1, 11, 1, 2, 3, 15)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (8): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (9): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (10): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (11): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (12): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (13): DecentFilter(weights: torch.Size([1, 1, 7, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 2, 13, 14, 12, 2, 8, ns_in= 10, 1, 11, 1, 2, 3, 15)\n",
      "      (14): DecentFilter(weights: torch.Size([1, 1, 8, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 13, 14, 12, 2, 8, ns_in= 10, 6, 1, 11, 1, 2, 3, 15)\n",
      "      (15): DecentFilter(weights: torch.Size([1, 1, 7, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 1, 2, 14, 12, 2, 8, ns_in= 10, 6, 1, 1, 2, 3, 15)\n",
      "    )\n",
      "  )\n",
      "  (decent3): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([17.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 8, 10)\n",
      "      (8): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (9): DecentFilter(weights: torch.Size([1, 1, 14, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 10)\n",
      "      (10): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (11): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (12): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (13): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([12.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (14): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (15): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 13, 10, 14, 8, 10)\n",
      "      (16): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 10, 14, 8, 10)\n",
      "      (17): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 13, 10, 14, 8, 10)\n",
      "      (18): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 8, 10)\n",
      "      (19): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 13, 10, 14, 8, 10)\n",
      "      (20): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (21): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (22): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8)\n",
      "      (23): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([4.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (24): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (25): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (26): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([15.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (27): DecentFilter(weights: torch.Size([1, 1, 14, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([11.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 12, 14, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 6, 16, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (28): DecentFilter(weights: torch.Size([1, 1, 14, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 16, 6, 11, ns_in= 5, 0, 7, 16, 6, 16, 8, 3, 3, 7, 13, 14, 8, 10)\n",
      "      (29): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([0.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (30): DecentFilter(weights: torch.Size([1, 1, 16, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 16, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 14, 8, 10)\n",
      "      (31): DecentFilter(weights: torch.Size([1, 1, 15, 3, 3]) at position: m_this=Parameter containing:\n",
      "      tensor([4.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 10, 13, 13, 9, 0, 12, 14, 7, 16, 3, 7, 9, 9, 6, 11, ns_in= 5, 0, 6, 7, 16, 6, 16, 8, 3, 3, 7, 13, 10, 8, 10)\n",
      "    )\n",
      "  )\n",
      "  (decent1x1): DecentLayer(\n",
      "    (filter_list): ModuleList(\n",
      "      (0): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (1): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([9.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (2): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([8.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (3): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([7.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (4): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (5): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([16.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([13.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (6): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([5.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([6.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (7): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([2.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([1.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (8): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([3.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "      (9): DecentFilter(weights: torch.Size([1, 32, 1, 1]) at position: m_this=Parameter containing:\n",
      "      tensor([10.], device='cuda:0'), n_this=Parameter containing:\n",
      "      tensor([14.], device='cuda:0'))\n",
      "       with inputs: ms_in= 7, 17, 5, 0, 12, 5, 12, 14, 15, 14, 1, 11, 0, 12, 6, 0, 6, 7, 11, 14, 5, 16, 13, 4, 13, 1, 2, 11, 9, 1, 2, 4, ns_in= 3, 14, 8, 7, 12, 14, 14, 13, 8, 7, 11, 16, 13, 0, 2, 2, 9, 14, 13, 10, 13, 15, 8, 1, 3, 2, 15, 10, 9, 0, 7, 9)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (mish1): Mish()\n",
      "  (mish2): Mish()\n",
      "  (mish3): Mish()\n",
      "  (mish1x1): Mish()\n",
      "  (bias1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (bias2): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (bias3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (bias1x1): InstanceNorm2d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    567\u001b[0m         )\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;31m# ----------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"run_training_epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    217\u001b[0m                     \u001b[1;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                     \u001b[0mbatch_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch_idx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# model hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         call._call_lightning_module_hook(\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\core\\module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \"\"\"\n\u001b[1;32m-> 1256\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mstep_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mclosure_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mstep_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py\u001b[0m in \u001b[0;36m_training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;31m# manually capture logged metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtraining_step_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"training_step\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainingStep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\2255027306.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_n_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\2255027306.py\u001b[0m in \u001b[0;36m_loss_n_metrics\u001b[1;34m(self, batch, mode)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mmodel_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# cause of the forward function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\2255027306.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\2495994724.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecent2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmish2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\647691469.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;31m# output = filter(input)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0moutput_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m             \u001b[0mm_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm_this\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\1575289750.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;31m# this is written in c++\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected stride to be a single integer value or a list of 3 values to match the convolution dimensions, but got stride=[1, 1]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\2567970143.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model, results = dev_routine(model_kwargs={\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[1;34m'n_classes'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 \u001b[1;34m'out_dim'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#  [1, 32, 64, 128], # [1, 8, 16, 32], #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[1;34m'grid_size'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[1;34m'criterion'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m# torch.nn.BCEWithLogitsLoss(),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8412\\292500310.py\u001b[0m in \u001b[0;36mdev_routine\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# Train the model using a Trainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# we don't save the positions here ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[0;32m    530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"failed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    994\u001b[0m         \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\n\u001b[0;32m    995\u001b[0m         Callback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\n\u001b[1;32m--> 996\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m         \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[1;31m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\u001b[0m in \u001b[0;36mteardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[0mIt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mright\u001b[0m \u001b[0mplace\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrelease\u001b[0m \u001b[0mmemory\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfree\u001b[0m \u001b[0mother\u001b[0m \u001b[0mresources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m--> 472\u001b[1;33m         \u001b[0m_optimizers_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_fabric\\utilities\\optimizer.py\u001b[0m in \u001b[0;36m_optimizers_to_device\u001b[1;34m(optimizers, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;34m\"\"\"Moves optimizer states for a sequence of optimizers to the device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0m_optimizer_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_fabric\\utilities\\optimizer.py\u001b[0m in \u001b[0;36m_optimizer_to_device\u001b[1;34m(optimizer, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;34m\"\"\"Moves the state of a single optimizer to the device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove_data_to_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_frozen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             v = apply_to_collection(\n\u001b[0m\u001b[0;32m     60\u001b[0m                 \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Breaking condition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_fabric\\utilities\\apply_func.py\u001b[0m in \u001b[0;36mmove_data_to_device\u001b[1;34m(batch, device)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_TransferableDataType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Breaking condition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_fabric\\utilities\\apply_func.py\u001b[0m in \u001b[0;36mbatch_to\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_BLOCKING_DEVICE_TYPES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"non_blocking\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mdata_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model, results = dev_routine(model_kwargs={\n",
    "                                'n_classes': 10,\n",
    "                                'out_dim' : [1, 8, 16, 32], #  [1, 32, 64, 128], # [1, 8, 16, 32], #\n",
    "                                'grid_size' : 18*18,\n",
    "                                'criterion': torch.nn.CrossEntropyLoss(),# torch.nn.BCEWithLogitsLoss(),\n",
    "                                'optimizer': \"sgd\",\n",
    "                                'base_lr': 0.001,\n",
    "                                'min_lr' : 0.00001,\n",
    "                                'momentum' : 0.9,\n",
    "                                'lr_update' : 100,\n",
    "                                'cc_weight': 0.2,\n",
    "                                'update_every_nth_epoch' : 1,\n",
    "                                'prune_keep' : 0.97, # in each epoch\n",
    "                                'prune_keep_total' : 0.5, # \n",
    "                            },\n",
    "                            train_kwargs={\n",
    "                                'epochs': 100,\n",
    "                                'img_size' : 96,\n",
    "                                'batch_size': 16,\n",
    "                                'log_every_n_steps' : 4,\n",
    "                                # 'test_batch_size': 1,\n",
    "                                'ckpt_path': \"\", # not in use??\n",
    "                                'device': \"cuda\",\n",
    "                                'num_workers' : 0, # 18 for computer\n",
    "                            }\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f4513-419a-433b-97ff-6f54c5a6d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b09e4-644a-4cca-9da3-a47986de1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256\n",
    "n_tmp = n * 0.5\n",
    "\n",
    "for i in range (100):\n",
    "    \n",
    "    n = n*0.97\n",
    "    if n <= n_tmp:\n",
    "        break\n",
    "    print(int(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfeca4-659f-46e6-bd25-270aa25ae08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca471c2c-819f-44aa-a8f9-e318aacf3f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfa186-0125-4a4b-adc6-c748cb2587c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e68578-ec3f-417e-8144-1e8ff14b20ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a04f0-8c5d-44f1-b0b9-616c64341cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79954f6-112e-4036-aa78-1930828cf4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19929df-c8e1-4548-95e4-cd7c807f1b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f4c7f-d650-41fb-b1ef-953fba2e3e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97faa8-afbb-4869-b630-ec3c18936e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd46dc-dcde-48c4-bc34-f9bf5bcad6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb9d4c30-9266-4c29-862b-fffef138cebe",
   "metadata": {},
   "source": [
    "### normal train without lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d89cfe-7561-438c-a0b4-bb3c0c951716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for i_batch, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        \n",
    "        target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "        \n",
    "        if i_batch == 5:\n",
    "            \n",
    "            \n",
    "            #model.update()\n",
    "            \n",
    "            #print(data.shape) # torch.Size([4, 1, 28, 28])\n",
    "            #print(target)\n",
    "            \"\"\"\n",
    "            tensor([[8],\n",
    "            [7],\n",
    "            [2],\n",
    "            [7]])\n",
    "            \"\"\"\n",
    "            #print(target_multi_hot)\n",
    "            \"\"\"\n",
    "            tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "            [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
    "            \"\"\"\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        loss = F.binary_cross_entropy(output, target_multi_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % (args.log_interval*1000) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i_batch * len(data), len(train_loader.dataset),\n",
    "                100. * i_batch / len(train_loader), loss.item()))\n",
    "            \n",
    "            # model.update()\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "            test_loss += F.binary_cross_entropy(output, target_multi_hot, reduction='mean').item()\n",
    "        \n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "            \n",
    "            if False: # i == 0:\n",
    "                print(data.shape)\n",
    "                layer = model.conv1x1 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "                # run feature map\n",
    "                dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "                dd.run(data)\n",
    "                dd.plot()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.test_batch_size = 1\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.001\n",
    "        self.gamma = 0.7\n",
    "        self.log_interval = 1\n",
    "        self.save_model = False\n",
    "        \n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('example_data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = DecentNet().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        model.update() \n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.ckpt\")\n",
    "\n",
    "    return model\n",
    "\n",
    "if False:\n",
    "    model = main()\n",
    "\n",
    "    for i in model.parameters():\n",
    "        print(i.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95870660-6418-4b85-a673-13e266a53960",
   "metadata": {},
   "source": [
    "# conv filter test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7bceb-331c-4f16-be5f-3c5c5d91ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16303538-75ae-4064-ae26-848926552bb7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# this is one filter\n",
    "\n",
    "w_groups = 1 # groups of the channels\n",
    "w_channels = 1024 # input channels\n",
    "w_filters = 10\n",
    "\n",
    "assert w_filters % w_groups == 0\n",
    "assert w_channels % w_groups == 0\n",
    "\n",
    "# batch size x channels (= w_groups*w_channels) x width x height\n",
    "inputs = torch.autograd.Variable(torch.randn(27,w_groups*w_channels,100,100))\n",
    "\n",
    "# w_filters x w_channels x kernel x kernel\n",
    "weights = torch.autograd.Variable(torch.randn(w_filters,w_channels,3,3))\n",
    "\n",
    "# batch size x w_filters x width x height\n",
    "out = F.conv2d(inputs, weights, padding=1, groups=w_groups)\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "print(inputs.shape, \"- batch x groups*channels x width x height\")\n",
    "print(weights.shape, \"- filters x channels x kernel x kernel\")\n",
    "print(out.shape, \"- batch x filters x width x height\")\n",
    "print()\n",
    "\n",
    "print(\"*\"*50)\n",
    "\n",
    "# batch size x channels (= w_groups*w_channels) x width x height\n",
    "inputs = torch.autograd.Variable(torch.randn(27,w_groups*w_channels,100,100))\n",
    "\n",
    "output_list = []\n",
    "\n",
    "# for each filter, we need different true false vales for our channels\n",
    "active = list(np.random.choice([True, False], size=w_channels, replace=True, p=None))\n",
    "\n",
    "# w_filters x w_channels x kernel x kernel\n",
    "weights = torch.autograd.Variable(torch.randn(1,w_channels,3,3))\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "output_list = []\n",
    "start = time.time()\n",
    "for i in range (10):\n",
    "    for _ in range(w_filters):\n",
    "        \n",
    "        pass\n",
    "\n",
    "        #print()\n",
    "        #print(active)\n",
    "        #print()\n",
    "        #print(inputs.shape, \"- batch x groups*channels x width x height\")\n",
    "        #print(weights.shape, \"- filters x channels x kernel x kernel\")\n",
    "\n",
    "\n",
    "        # need to remove weight and input channels according to active list for each filter\n",
    "        #print(inputs.shape)\n",
    "        #print(inputs[:,active,:,:].shape)\n",
    "\n",
    "        #print(weights.shape)\n",
    "        #print(weights[:,active,:,:].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # batch size x w_filters x width x height\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #output_list.append(this_output)\n",
    "        #print(this_output.shape, \"- batch x 1 filter x width x height\")\n",
    "\n",
    "    #out = torch.cat(output_list, dim=1)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "weights = torch.autograd.Variable(torch.randn(w_filters,w_channels,3,3))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range (10):\n",
    "    i_tmp = inputs[:,active,:,:]\n",
    "    w_tmp = weights[:,active,:,:]\n",
    "    this_output = F.conv2d(i_tmp, w_tmp, padding=1, groups=w_groups)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights = torch.autograd.Variable(torch.randn(w_filters,w_channels,3,3))\n",
    "\n",
    "start = time.time()\n",
    "for i in range (10):\n",
    "    this_output = F.conv2d(inputs, weights, padding=1, groups=w_groups)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(out.shape, \"- batch x filters x width x height\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# take the mean of all - we can remove all sorts of information from the out tensor\n",
    "mean = torch.mean(out, 1, keepdim=True)\n",
    "print(mean.shape, \"- mean accross the filters (no sense here ...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e3c4e-80a1-448f-9b3c-4ae14cd7bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "#b = torch.empty(w_filters, w_channels, dtype=torch.bool)\n",
    "b = torch.ByteTensor(500, w_channels)\n",
    "print(sys.getsizeof(b.storage())) # 1310776 (bytes)\n",
    "\n",
    "#a = torch.empty(w_filters, w_channels, dtype=torch.uint8)\n",
    "a = torch.ByteTensor(500, w_channels)\n",
    "print(sys.getsizeof(a.storage())) # 1310776 (bytes)\n",
    "\n",
    "active = list(np.random.choice([True, False], size=w_channels, replace=True, p=None))\n",
    "print(sys.getsizeof(active)*500) # 1310776 (bytes)\n",
    "\n",
    "weights = torch.FloatTensor(torch.randn(500,w_channels,3,3))\n",
    "print(sys.getsizeof(weights.storage())) # 1310776 (bytes) 36912\n",
    "print(36912*500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2b255-ccc3-4809-948c-cd4dc5efe661",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dadee83-7300-4844-8284-8d0ef29aaee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(2, size=10)\n",
    "\n",
    "list(np.random.choice([True, False], size=10, replace=True, p=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c72946-baf5-4c90-b84e-14f14c8d949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(1, 82, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2754cb-b071-4267-b53c-5f2190a7baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "9*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95feb489-36f2-4d83-81e3-5e21a530f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(a=4, size=2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5d97e-7408-4c52-8891-864827810c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# this is one filter\n",
    "\n",
    "w_groups = 27 # groups of the channels\n",
    "w_channels = 7 # input channels\n",
    "w_filters = 200\n",
    "batch_size = 27\n",
    "\n",
    "# batch size x channels (= w_groups*w_channels) x width x height\n",
    "inputs = torch.autograd.Variable(torch.randn(batch_size, w_channels*w_groups, 100,100))\n",
    "#inputs = torch.autograd.Variable(torch.randn(w_channels*w_groups, 100,100))\n",
    "\n",
    "# w_groups x w_channels x kernel x kernel\n",
    "weights = torch.autograd.Variable(torch.randn(1, w_channels,3,3))\n",
    "#weights = torch.autograd.Variable(torch.randn(w_groups*w_channels,3,3))\n",
    "\n",
    "print(inputs.shape, \"- batch x groups*channels x width x height\")\n",
    "print(weights.shape, \"- filter 1 x channels x kernel x kernel\")\n",
    "\n",
    "try:\n",
    "    o_list = []\n",
    "    for _ in range(w_filters):\n",
    "        # batch size x groups x width x height\n",
    "        out = F.conv2d(inputs, weights, groups=w_groups)\n",
    "        o_list.append(out)\n",
    "        # take the mean of all - we can remove all sorts of information from the out tensor\n",
    "        #mean = torch.mean(out, 1, keepdim=True)\n",
    "    \n",
    "    print(torch.cat(o_list, dim=1).shape, \"- batch x filters x width x height\")\n",
    "    #print(mean.shape, \"- mean accross the groups\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3d443-372f-4548-804e-11efbebe6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = torch.randn(8, 4, 3, 3)\n",
    "inputs = torch.randn(1, 4, 5, 5)\n",
    "F.conv2d(inputs, filters, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bf7b8-35d2-4f68-b045-0ba93bd4c5fc",
   "metadata": {},
   "source": [
    "# Visualise filters and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536067b-6098-4844-9ef4-7a5db5a23156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net() # .to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320d57b-3e22-404f-ad6c-b04515fe2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "\n",
    "def visChannels(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    \n",
    "    plt.figure(figsize=(nrow,rows) )\n",
    "    plt.title(f\"Channels with index {ch}\")\n",
    "    plt.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "\n",
    "def visFilters(tensor, filt=0, allkernels=False, nrow=8, padding=1): \n",
    "    f,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(f*c, -1, w, h)\n",
    "    elif f != 3: tensor = tensor[filt,:,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.title(f\"Filter {filt}\")\n",
    "    plt.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "def visFilters_subplot(subplot, tensor, filt=0, allkernels=False, nrow=8, padding=1): \n",
    "    f,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(f*c, -1, w, h)\n",
    "    elif f != 3: tensor = tensor[filt,:,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    # plt.figure( figsize=(nrow,rows) )\n",
    "    subplot.set_title(f\"Filter {filt+1} with {c} channels\")\n",
    "    subplot.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "    subplot.axis('off')\n",
    "    \n",
    "layer = 1\n",
    "filter = model.conv2.weight.data.clone()\n",
    "\n",
    "print(model.conv2.weight.shape)\n",
    "\n",
    "# need to match the network parameters!!!!\n",
    "in_channels = 5\n",
    "out_filters = 3 # 64\n",
    "\n",
    "\n",
    "fig, subplot = plt.subplots(out_filters, figsize=(10, 10))\n",
    "fig.suptitle(f'Layer with shape {list(model.conv2.weight.shape)} [out, in, kernel, kernel]')\n",
    "\n",
    "for filt in range(0, out_filters):\n",
    "    \n",
    "    visFilters_subplot(subplot[filt], filter, filt=filt, allkernels=False)\n",
    "\n",
    "    #plt.axis('off')\n",
    "    #plt.ioff()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"example_results/filter_with_weights.png\")\n",
    "plt.show()\n",
    "    \n",
    "if False:    \n",
    "    for filt in range(0, out_filters):\n",
    "\n",
    "        visFilters(filter, filt=filt, allkernels=False)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(f\"examples/example_results/filter_with_weights.png\")\n",
    "        plt.show()\n",
    "\n",
    "    for ch in range(0, in_channels):\n",
    "\n",
    "        visChannels(filter, ch=ch, allkernels=False)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791fa94-5bb8-4d3a-ad97-72cc5a59025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "res = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655d64a-7fc0-42c7-880e-69e7be6acedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.layer1[0].conv1.bias == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3322395-f2a0-40e1-a0e8-86c090586f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.layer1[0].conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d52543-cd67-4d00-963a-5d1effbfc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.extra_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77091394-6e75-4aa3-84c3-a9ebc7ce932e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
