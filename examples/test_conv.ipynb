{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8ea6b-7e2f-4257-9875-25f651882f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DecentNet from conv layer\n",
    "\n",
    "    # additionally needed\n",
    "    \"\"\"\n",
    "    \n",
    "    position\n",
    "    activated channels\n",
    "    connection between channels\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "        \n",
    "        # this layer id\n",
    "        layer_id = 0\n",
    "        \n",
    "        # within this layer, a whole filter can be deactivated\n",
    "        # within a filter, single channels can be deactivated\n",
    "        # within this layer, filters can be swapped\n",
    "     \n",
    "* pruning actually doesn\"t work: https://discuss.pytorch.org/t/pruning-doesnt-affect-speed-nor-memory-for-resnet-101/75814   \n",
    "* fine tune a pruned model: https://stackoverflow.com/questions/73103144/how-to-fine-tune-the-pruned-model-in-pytorch\n",
    "* an actual pruning mechanism: https://arxiv.org/pdf/2002.08258.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46441962-88b7-4cd6-bd4a-a71a6fbbd427",
   "metadata": {},
   "source": [
    "pip install:\n",
    "    pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f2bf02-f53b-4688-bf18-5b8075397e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../helper', './helper', '/helper', 'helper', 'C:\\\\Users\\\\Prinzessin\\\\projects\\\\decentnet\\\\datasceyence\\\\examples', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\python39.zip', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\DLLs', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta', '', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Prinzessin\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.utils import _single, _pair, _triple, _reverse_repeat_tuple\n",
    "from torch._torch_docs import reproducibility_notes\n",
    "\n",
    "from torch.nn.common_types import _size_1_t, _size_2_t, _size_3_t\n",
    "from typing import Optional, List, Tuple, Union\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "sys.path.insert(0, \"/helper\")\n",
    "sys.path.insert(0, \"./helper\")\n",
    "sys.path.insert(0, \"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "# own module\n",
    "from visualisation.feature_map import *\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38836e4-6905-4e0c-b344-bcc3b8094388",
   "metadata": {},
   "source": [
    "# conv2d layer (slightly adapted original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b972ff66-723c-43a1-a9d9-80c43b450efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ConvNd(torch.nn.Module):\n",
    "\n",
    "    __constants__ = ['stride', 'padding', 'dilation', 'groups',\n",
    "                     'padding_mode', 'output_padding', 'in_channels',\n",
    "                     'out_channels', 'kernel_size']\n",
    "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]) -> Tensor:\n",
    "        ...\n",
    "\n",
    "    in_channels: int\n",
    "    _reversed_padding_repeated_twice: List[int]\n",
    "    out_channels: int\n",
    "    kernel_size: Tuple[int, ...]\n",
    "    stride: Tuple[int, ...]\n",
    "    padding: Union[str, Tuple[int, ...]]\n",
    "    dilation: Tuple[int, ...]\n",
    "    transposed: bool\n",
    "    output_padding: Tuple[int, ...]\n",
    "    groups: int\n",
    "    padding_mode: str\n",
    "    weight: Tensor\n",
    "    bias: Optional[Tensor]\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Tuple[int, ...],\n",
    "                 stride: Tuple[int, ...],\n",
    "                 padding: Tuple[int, ...],\n",
    "                 dilation: Tuple[int, ...],\n",
    "                 transposed: bool,\n",
    "                 output_padding: Tuple[int, ...],\n",
    "                 groups: int,\n",
    "                 bias: bool,\n",
    "                 padding_mode: str,\n",
    "                 device=None,\n",
    "                 dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        print(factory_kwargs)\n",
    "        super().__init__()\n",
    "        if groups <= 0:\n",
    "            raise ValueError('groups must be a positive integer')\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        valid_padding_strings = {'same', 'valid'}\n",
    "        if isinstance(padding, str):\n",
    "            if padding not in valid_padding_strings:\n",
    "                raise ValueError(\n",
    "                    \"Invalid padding string {!r}, should be one of {}\".format(\n",
    "                        padding, valid_padding_strings))\n",
    "            if padding == 'same' and any(s != 1 for s in stride):\n",
    "                raise ValueError(\"padding='same' is not supported for strided convolutions\")\n",
    "\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        # `_reversed_padding_repeated_twice` is the padding to be passed to\n",
    "        # `F.pad` if needed (e.g., for non-zero padding types that are\n",
    "        # implemented as two ops: padding + conv). `F.pad` accepts paddings in\n",
    "        # reverse order than the dimension.\n",
    "        if isinstance(self.padding, str):\n",
    "            self._reversed_padding_repeated_twice = [0, 0] * len(kernel_size)\n",
    "            if padding == 'same':\n",
    "                for d, k, i in zip(dilation, kernel_size,\n",
    "                                   range(len(kernel_size) - 1, -1, -1)):\n",
    "                    total_padding = d * (k - 1)\n",
    "                    left_pad = total_padding // 2\n",
    "                    self._reversed_padding_repeated_twice[2 * i] = left_pad\n",
    "                    self._reversed_padding_repeated_twice[2 * i + 1] = (\n",
    "                        total_padding - left_pad)\n",
    "        else:\n",
    "            self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2)\n",
    "\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (in_channels, out_channels // groups, *kernel_size), **factory_kwargs))\n",
    "            #self.importance = Parameter(torch.empty(\n",
    "            #    (in_channels, out_channels // groups), **factory_kwargs))\n",
    "            \n",
    "        else:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (out_channels, in_channels // groups, *kernel_size), **factory_kwargs))\n",
    "            #self.importance = Parameter(torch.empty(\n",
    "            #    (out_channels, in_channels // groups), **factory_kwargs))\n",
    "            \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "class CustomConv2d(_ConvNd):\n",
    "    \n",
    "    # additionally needed\n",
    "    \"\"\"\n",
    "    \n",
    "    position\n",
    "    activated channels\n",
    "    connection between channels\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: _size_2_t,\n",
    "        stride: _size_2_t = 1,\n",
    "        padding: Union[str, _size_2_t] = 0,\n",
    "        dilation: _size_2_t = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        padding_mode: str = 'zeros',  # TODO: refine this type\n",
    "        device=None,\n",
    "        dtype=None\n",
    "    ) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        kernel_size_ = _pair(kernel_size)\n",
    "        stride_ = stride #_pair(stride)\n",
    "        padding_ = padding if isinstance(padding, str) else _pair(padding)\n",
    "        dilation_ = _pair(dilation)\n",
    "        super().__init__(\n",
    "            in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n",
    "            False, _pair(0), groups, bias, padding_mode, **factory_kwargs)\n",
    "        \n",
    "        # this layer id\n",
    "        layer_id = 0\n",
    "        \n",
    "        # within this layer, a whole filter can be deactivated\n",
    "        # within a filter, single channels can be deactivated\n",
    "        # within this layer, filters can be swapped\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            if fan_in != 0:\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "        if self.padding_mode != 'zeros':\n",
    "            return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            weight, bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        \n",
    "        # this is written in c++ - try not to change ...\n",
    "        print(self.stride)\n",
    "        return F.conv2d(input, weight, bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self._conv_forward(input, self.weight, self.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369256cb-1ea4-4ff2-8ce5-a820511e0779",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2823e218-5eb3-44d9-a277-2cf17b772c84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = CustomConv2d(1, 32, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv2 = CustomConv2d(32, 64, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv3 = CustomConv2d(64, 128, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv1x1 = CustomConv2d(128, 10, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        \n",
    "        self.K = 100 \n",
    "        self.L = 10 # last one\n",
    "        self.num_of_bases = 1 # 3rd dim\n",
    "        \n",
    "        if False:\n",
    "            self.conv1 = Conv2d(1, 32, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "            self.conv2 = Conv2d(32, 64, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "            self.conv3 = Conv2d(64, 128, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "            self.conv1x1 = Conv2d(128, 10, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        #self.dropout1 = nn.Dropout(0.25)\n",
    "        #self.dropout2 = nn.Dropout(0.5)\n",
    "        # 4x16384\n",
    "        # self.fc1 = nn.Linear(10*10*10, 10)\n",
    "        #self.fc2 = nn.Linear(10, 10)\n",
    "        \n",
    "        #self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc3 = nn.Linear(10, 10)\n",
    "        \n",
    "        self.mish1 = torch.nn.Mish()\n",
    "        self.mish2 = torch.nn.Mish()\n",
    "        self.mish3 = torch.nn.Mish()\n",
    "        self.mish1x1 = torch.nn.Mish()\n",
    "        \n",
    "        #self.sub_concept_pooling = nn.modules.MaxPool2d((self.K, 1), stride=(1,1))\n",
    "        #self.instance_pooling = nn.modules.MaxPool2d((opt.num_of_bases, 1), stride=(1,1))\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.mish1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.mish2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.mish3(x)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        x = self.mish1x1(x)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        \n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        #x = self.dropout1(x)\n",
    "        \n",
    "        #print(x.size())\n",
    "        #print(x.size()[2:])\n",
    "        \n",
    "        x = F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        \n",
    "        #x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        #x = x.view(-1, self.L, self.K, 10)\n",
    "        \n",
    "        # input, kernel_size, stride, padding, dilation, ceil_mode\n",
    "        #x = self.sub_concept_pooling(x).view(-1, self.L, self.num_of_bases).permute(0,2,1).unsqueeze(1)\n",
    "        \n",
    "        # output = F.sigmoid(x)\n",
    "        # x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        #x = torch.flatten(x, 1)\n",
    "        # x = self.fc1(x)\n",
    "        #x = F.relu(x)\n",
    "        \n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.fc2(x)\n",
    "        #output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76fa05-b47e-4264-85cf-766d8ca060d3",
   "metadata": {},
   "source": [
    "# normal run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0819306e-ff93-4f38-898b-4c1cd2221b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for i_batch, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "        \n",
    "        if i_batch == -1:\n",
    "            print(data.shape) # torch.Size([4, 1, 28, 28])\n",
    "            print(target)\n",
    "            \"\"\"\n",
    "            tensor([[8],\n",
    "            [7],\n",
    "            [2],\n",
    "            [7]])\n",
    "            \"\"\"\n",
    "            print(target_multi_hot)\n",
    "            \"\"\"\n",
    "            tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "            [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
    "            \"\"\"\n",
    "        \n",
    "        loss = F.binary_cross_entropy(output, target_multi_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % (args.log_interval*1000) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i_batch * len(data), len(train_loader.dataset),\n",
    "                100. * i_batch / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "            test_loss += F.binary_cross_entropy(output, target_multi_hot, reduction='mean').item()\n",
    "        \n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "            \n",
    "            \"\"\"\n",
    "            if i == 0 and epoch % args.log_interval == 0:\n",
    "            # if False: # i == 0:\n",
    "                print(data.shape)\n",
    "                layer = model.conv1x1 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "                # run feature map\n",
    "                dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "                dd.run(data)\n",
    "                dd.plot(path=f\"example_results/feature_map_{epoch}.png\")\n",
    "                \"\"\"\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.test_batch_size = 1\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.1\n",
    "        self.gamma = 0.7\n",
    "        self.log_interval = 5\n",
    "        self.save_model = True\n",
    "        \n",
    "\n",
    "def main_train():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('example_data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader, epoch)\n",
    "        #scheduler.step()\n",
    "        \n",
    "        \n",
    "        if args.save_model and epoch % args.log_interval == 0:\n",
    "            torch.save(model.state_dict(), f\"example_results/mnist_cnn_{epoch}.ckpt\")\n",
    "\n",
    "\n",
    "def main_test():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "\n",
    "    if True:\n",
    "        model.load_state_dict(torch.load(\"example_results/mnist_cnn_5.ckpt\"))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(\"example_results/pruned_model.ckpt\"))\n",
    "    \n",
    "\n",
    "    # model = torch.load(model.state_dict(), \"example_results/mnist_cnn_30.ckpt\")\n",
    "    if False:\n",
    "        test(args, model, device, test_loader, 0)\n",
    "    \n",
    "    return model\n",
    "        \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38eb5e24-3f20-4788-8344-66a98d6791bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1242e1a-c691-4cb6-a279-9904cedcd806",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device': None, 'dtype': None}\n",
      "{'device': None, 'dtype': None}\n",
      "{'device': None, 'dtype': None}\n",
      "{'device': None, 'dtype': None}\n"
     ]
    }
   ],
   "source": [
    "# model_to_prune= main_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270319e6-3827-47cd-a579-476c89217968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print(list(model_to_prune.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f898ba-2323-4628-a0e3-70ee44ce0b0d",
   "metadata": {},
   "source": [
    "# DecentNet trial and error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfa123-54e1-4053-94c3-52b45ec0859c",
   "metadata": {},
   "source": [
    "## DecentFilter\n",
    "* conv2d problem: https://stackoverflow.com/questions/61269421/expected-stride-to-be-a-single-integer-value-or-a-list-of-1-values-to-match-the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bc1f3c-5f40-445c-b5f1-4ca6387eb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentFilter(torch.nn.Module):\n",
    "    # convolution happens in here\n",
    "    \n",
    "    def __init__(self, \n",
    "                 i_channels=32, \n",
    "                 i_filter=[],\n",
    "                 kernel_size=3, \n",
    "                 stride=1, \n",
    "                 padding=0, \n",
    "                 padding_mode=\"zeros\",\n",
    "                 dilation=3, \n",
    "                 transposed=None, \n",
    "                 device=None, \n",
    "                 dtype=None):\n",
    "        \n",
    "        #print(\"device\", device)\n",
    "        \n",
    "        \n",
    "        # out_channels = 1\n",
    "        # groups = 1\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = stride # _pair(stride)\n",
    "        padding = padding if isinstance(padding, str) else _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        \n",
    "        \n",
    "        valid_padding_strings = {'same', 'valid'}\n",
    "        if isinstance(padding, str):\n",
    "            if padding not in valid_padding_strings:\n",
    "                raise ValueError(\n",
    "                    \"Invalid padding string {!r}, should be one of {}\".format(\n",
    "                        padding, valid_padding_strings))\n",
    "            if padding == 'same' and any(s != 1 for s in stride):\n",
    "                raise ValueError(\"padding='same' is not supported for strided convolutions\")\n",
    "\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "            \n",
    "        self.i_channels = i_channels\n",
    "        self.i_filter = i_filter # index of this filter\n",
    "        # self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        #self.output_padding = output_padding\n",
    "        # self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        # print(factory_kwargs)\n",
    "        \n",
    "        super().__init__()\n",
    "    \n",
    "        # filters x channels x kernel x kernel\n",
    "        self.weight = Parameter(torch.empty((1, i_channels, *kernel_size), **factory_kwargs)) # .to(device)\n",
    "        \n",
    "        \n",
    "        # set each channel true\n",
    "        self.active = np.array([True] * self.i_channels)\n",
    "        \n",
    "        self.init_position()\n",
    "        \n",
    "        # for each filter, we need different true false vales for our channels\n",
    "        #active = list(np.random.choice([True, False], size=w_channels, replace=True, p=None))\n",
    "\n",
    "        # w_filters x w_channels x kernel x kernel\n",
    "        #weights = torch.autograd.Variable(torch.randn(1,w_channels,3,3))\n",
    "\n",
    "        \n",
    "        \n",
    "        #self.importance = Parameter(torch.empty(\n",
    "        #    (in_channels), **factory_kwargs))\n",
    "            \n",
    "        if False: \n",
    "            # bias:\n",
    "            # where should the bias be???\n",
    "            self.bias = Parameter(torch.empty(1, **factory_kwargs))\n",
    "        else:\n",
    "            #self.bias = False\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        \n",
    "        # reset weights and bias - in filter or in layer?\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def init_position(self):\n",
    "        # numbers fro 0 to 81\n",
    "        # 0/0 to \n",
    "        self.position = list(np.random.randint(81, size=self.i_channels))\n",
    "    \n",
    "    def reset_parameters(self) -> None:\n",
    "        # randomly initialise the positional array\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        \n",
    "        # todo - weight has to be the one in the filter\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "    \n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.padding_mode != 'zeros':\n",
    "            return F.conv2d(F.pad(input[:,self.active,:,:], self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            weight, bias, self.stride,\n",
    "                            _pair(0), self.dilation, groups=1)\n",
    "        else:\n",
    "            # this is written in c++\n",
    "            # todo: cuda is ... not a variable ...\n",
    "            out = F.conv2d(input[:,self.active,:,:], weight, bias, self.stride, self.padding, self.dilation, groups=1)\n",
    "        \n",
    "            # print(out.shape, \"- batch x filters x width x height\")        \n",
    "\n",
    "            return out\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    def update(self):\n",
    "        # channel deactivation\n",
    "        # require_grad = False/True for each channel\n",
    "        \n",
    "        deactivate_ids = [1, 2, 6]\n",
    "        \n",
    "        self.active[deactivate_ids] = False\n",
    "        \n",
    "        \n",
    "        print(\"weight\")\n",
    "        print(self.weight.shape)\n",
    "        \n",
    "        print(self.weight[:,self.active,:,:].shape)\n",
    "        \n",
    "        # this is totally wrong - iterative will break after first iteration\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Good to hear it’s working, although I would think you’ll get an error at some point in your code, as the cuda() call creates a non-leaf tensor.\n",
    "        self.weight = torch.nn.Parameter(  self.weight[:,self.active,:,:] ) # .detach().cpu().numpy()\n",
    "        self.weight = self.weight.cuda()\n",
    "        \n",
    "        \n",
    "        print(self.weight.shape)\n",
    "        #print(self.active)\n",
    "        \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self._conv_forward(input, self.weight, self.bias)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "99cba028-66b0-4781-8334-855d22186e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([True] * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2c4e7-d451-4246-8253-9d4591875a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "5cf5bf8e-bc64-4f06-b95d-e7cc16ea42d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 3, 0])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.tensor([1, 6, 9, 40, 5, 3, 4]) # np.arange(50)\n",
    "# l = l[[1, 6, 2, 4, 3]]\n",
    "\n",
    "l[[1, 6, 2, 4, 3]] = False\n",
    "\n",
    "l \n",
    "#np.where(l == 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ffdab4-e0b0-4523-882f-dad3ebf06090",
   "metadata": {},
   "source": [
    "## DecentLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fddb74c7-5940-424d-aab8-2c75efd914bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentLayer(torch.nn.Module):\n",
    "    __constants__ = ['stride', 'padding', 'dilation', 'groups',\n",
    "                     'padding_mode', 'in_channels', #  'output_padding',\n",
    "                     'out_channels', 'kernel_size']\n",
    "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
    "        \n",
    "        \n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: _size_2_t,\n",
    "                 stride: _size_2_t = 1,\n",
    "                 padding: Union[str, _size_2_t] = 0,\n",
    "                 dilation: _size_2_t = 1,\n",
    "                 transposed: bool = False,\n",
    "                 #output_padding: Tuple[int, ...] = _pair(0),\n",
    "                 #groups: int = 1,\n",
    "                 bias: bool = True,\n",
    "                 padding_mode: str = \"zeros\",\n",
    "                 device=None,\n",
    "                 dtype=None) -> None:\n",
    "        \n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = stride # _pair(stride)\n",
    "        padding = padding if isinstance(padding, str) else _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # torch.nn.ModuleList\n",
    "        \n",
    "        self.geometry_array = np.full(81, np.nan)\n",
    "        self.module_list = nn.ModuleList([])\n",
    "        for i_filter in range(out_channels):\n",
    "            self.module_list.append(DecentFilter(i_channels=in_channels, i_filter=i_filter))\n",
    "            self.geometry_array[i_filter]=i_filter # id of the filter\n",
    "        \n",
    "        \n",
    "        np.random.shuffle(self.geometry_array)\n",
    "        self.geometry_array = self.geometry_array.reshape((9,9), order='C')\n",
    "        \n",
    "        # a = np.full(81, np.nan)\n",
    "        # geometry_array = a.reshape((9,9))\n",
    "        \n",
    "        print()\n",
    "        print(self.geometry_array)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        # reset in initialisation\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        \n",
    "    def sparcify(self) -> None:\n",
    "        # pruning based on a metric\n",
    "        \n",
    "        # delete layer with id\n",
    "        # delete channels in each layer with id\n",
    "        \n",
    "        # change positions\n",
    "        # change\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def reset_parameters(self) -> None:\n",
    "        pass\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        \n",
    "        # todo - weight has to be the one in the filter\n",
    "        # init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        \"\"\"\n",
    "        not needed due to instance norm layer\n",
    "        https://github.com/pytorch/vision/issues/4914\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            if fan_in != 0:\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                init.uniform_(self.bias, -bound, bound)\"\"\"\n",
    "\n",
    "    def extra_repr(self):\n",
    "        \"\"\"\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'\n",
    "            \n",
    "    def update(self):\n",
    "        for module in self.module_list:\n",
    "            module.update()\n",
    "        \n",
    "            \n",
    "            \n",
    "    def forward(self, input: Tensor, pos=None) -> Tensor:\n",
    "        \n",
    "        output_list = []\n",
    "        for module in self.module_list:\n",
    "            output_list.append(module(input))\n",
    "         \n",
    "        out = torch.cat(output_list, dim=1)\n",
    "        # mean = torch.mean(out, 0, keepdim=True)\n",
    "        \n",
    "        return out, pos\n",
    "        # return self._conv_forward(input, self.weight, self.bias)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c186cf1-c7db-45da-b779-f7ab88f3896f",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## DecentNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd6a2811-6313-41cc-82a0-78cdb812c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecentNet, self).__init__()\n",
    "        \n",
    "        dim = [1, 32, 48, 64, 10]\n",
    "        dim = [1, 8, 16, 24, 10]\n",
    "        assert not any(i > 81 for i in dim), \"filters need to be less than 81\"\n",
    "        \n",
    "        self.decent1 = DecentLayer(dim[0], dim[1], kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.decent2 = DecentLayer(dim[1], dim[2], kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.decent3 = DecentLayer(dim[2], dim[3], kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.decent1x1 = DecentLayer(dim[3], dim[-1], kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "\n",
    "        self.fc3 = nn.Linear(dim[-1], dim[-1])\n",
    "        \n",
    "        self.mish1 = torch.nn.Mish()\n",
    "        self.mish2 = torch.nn.Mish()\n",
    "        self.mish3 = torch.nn.Mish()\n",
    "        self.mish1x1 = torch.nn.Mish()\n",
    "        \n",
    "        self.bias1 = torch.nn.InstanceNorm2d(dim[1])\n",
    "        self.bias2 = torch.nn.InstanceNorm2d(dim[2])\n",
    "        self.bias3 = torch.nn.InstanceNorm2d(dim[3])\n",
    "        self.bias1x1 = torch.nn.InstanceNorm2d(dim[-1])\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x, pos = self.decent1(x)\n",
    "        x = self.mish1(x)\n",
    "        x = self.bias1(x)\n",
    "        \n",
    "        x, pos = self.decent2(x, pos)\n",
    "        x = self.mish2(x)\n",
    "        x = self.bias2(x)\n",
    "        \n",
    "        x, pos = self.decent3(x, pos)\n",
    "        x = self.mish3(x)\n",
    "        x = self.bias3(x)\n",
    "        \n",
    "        x, pos = self.decent1x1(x, pos)\n",
    "        x = self.mish1x1(x)\n",
    "        x = self.bias1x1(x)\n",
    "        \n",
    "        # global max pooling for MIL\n",
    "        x = F.max_pool2d(x, kernel_size=x.size()[2:])\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc3(x) \n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def update(self):\n",
    "        #self.decent1.update()\n",
    "        self.decent2.update()\n",
    "        self.decent3.update()\n",
    "        self.decent1x1.update()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf5f6e6-248a-4442-8b9b-1d48a4c598f6",
   "metadata": {},
   "source": [
    "## standard routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b080f-09fd-496a-90dd-d120144c463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for i_batch, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        \n",
    "        target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "        \n",
    "        if i_batch == 5:\n",
    "            \n",
    "            \n",
    "            #model.update()\n",
    "            \n",
    "            #print(data.shape) # torch.Size([4, 1, 28, 28])\n",
    "            #print(target)\n",
    "            \"\"\"\n",
    "            tensor([[8],\n",
    "            [7],\n",
    "            [2],\n",
    "            [7]])\n",
    "            \"\"\"\n",
    "            #print(target_multi_hot)\n",
    "            \"\"\"\n",
    "            tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "            [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
    "            \"\"\"\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        loss = F.binary_cross_entropy(output, target_multi_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % (args.log_interval*1000) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i_batch * len(data), len(train_loader.dataset),\n",
    "                100. * i_batch / len(train_loader), loss.item()))\n",
    "            \n",
    "            # model.update()\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "            test_loss += F.binary_cross_entropy(output, target_multi_hot, reduction='mean').item()\n",
    "        \n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "            \n",
    "            if False: # i == 0:\n",
    "                print(data.shape)\n",
    "                layer = model.conv1x1 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "                # run feature map\n",
    "                dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "                dd.run(data)\n",
    "                dd.plot()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.test_batch_size = 1\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.001\n",
    "        self.gamma = 0.7\n",
    "        self.log_interval = 1\n",
    "        self.save_model = False\n",
    "        \n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('example_data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = DecentNet().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        model.update()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdb954-7eba-4e84-86d9-a9684ededaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty((1,81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7906f9-52a5-4af9-92f5-e3ca3060b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full(81, np.nan)\n",
    "geometry_array = a.reshape((9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d002d4-9e52-46c4-ab0a-e5552a978463",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe389e-2713-4a65-81d2-6bea9d7bbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.parameters():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d27aa-4fc3-4b43-920d-071d3cc464d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([1, 0, 5, 2])\n",
    "labels = labels.unsqueeze(0)\n",
    "\n",
    "target = torch.zeros(labels.size(0), 10).scatter_(1, labels, 1.)\n",
    "print(target)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb570b41-9eec-4d5c-9a5c-f74fabb03cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "16*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784a059-0ada-423c-a4c1-112548c099de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.conv2.importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558d1bb-7c6b-4ad1-a04b-e845e812c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.conv2.importance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3c4a0-af85-4589-9fe9-f997d39a0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.conv2.weight.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36655bcd-1600-47a5-a9b9-90ed015ac4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb60bdf0-147c-4bfe-83c0-4a330c7f9bfc",
   "metadata": {},
   "source": [
    "# Lightning version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92509f06-c9fb-4084-843e-b80b3552c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "class DecentLightning(pl.LightningModule):\n",
    "    def __init__(self, model_kwargs):\n",
    "        super().__init__()\n",
    "        self.model = DecentNet().to(\"cuda\")\n",
    "        self.criterion = model_kwargs[\"criterion\"]\n",
    "        self.optimizer = model_kwargs[\"optimizer\"]\n",
    "        self.lr = model_kwargs[\"lr\"]\n",
    "        self.cc_weight = model_kwargs[\"cc_weight\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # 1       \n",
    "        loss = self._loss_n_metrics(batch, mode=\"train\")\n",
    "        print(\"training_step\")\n",
    "        #loss = torch.tensor(1)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self):\n",
    "        # 2\n",
    "        print(\"validation_step\")\n",
    "        #self._loss_n_metrics(batch, mode=\"val\")\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        print(\"on_validation_epoch_end\")\n",
    "        # 3\n",
    "        pass\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        print(\"on_validation_epoch_end\")\n",
    "        # 4\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print(\"configure_optimizers\")\n",
    "        \n",
    "        if self.optimizer == \"adamw\":\n",
    "            optimizer = optim.AdamW(self.parameters(), lr=self.lr)\n",
    "            lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,150], gamma=0.1)\n",
    "            return [optimizer], [lr_scheduler]\n",
    "        else:\n",
    "            return optim.SGD(self.parameters(), lr=self.lr)\n",
    "        \n",
    "    def get_cc(self):\n",
    "        # compute connection cost\n",
    "        # adapted from BIMT: https://github.com/KindXiaoming/BIMT/blob/main/mnist_3.5.ipynb\n",
    "        # def get_cc(self, weight_factor=2.0, bias_penalize=True, no_penalize_last=False):\n",
    "        # https://stackoverflow.com/questions/74086766/how-to-find-total-cost-of-each-path-in-graph-using-dictionary-in-python\n",
    "        cc = 0\n",
    "        \"\"\"\n",
    "        num_linear = len(self.linears)\n",
    "        for i in range(num_linear):\n",
    "            if i == num_linear - 1 and no_penalize_last:\n",
    "                weight_factor = 0.\n",
    "            biolinear = self.linears[i]\n",
    "            dist = torch.sum(torch.abs(biolinear.out_coordinates.unsqueeze(dim=1) - biolinear.in_coordinates.unsqueeze(dim=0)),dim=2)\n",
    "            cc += torch.mean(torch.abs(biolinear.linear.weight)*(weight_factor*dist+self.l0))\n",
    "            if bias_penalize == True:\n",
    "                cc += torch.mean(torch.abs(biolinear.linear.bias)*(self.l0))\n",
    "        if self.token_embedding:\n",
    "            cc += torch.mean(torch.abs(self.embedding)*(self.l0))\n",
    "            #pass\n",
    "        \"\"\"\n",
    "        return cc\n",
    "    \n",
    "    def _loss_n_metrics(self, batch, mode=\"train\"):\n",
    "        \n",
    "        img, ground_truth = batch\n",
    "        model_output = self(img.to(\"cuda\")) # cause of the forward function\n",
    "        \n",
    "        ground_truth = ground_truth.unsqueeze(1)\n",
    "        \n",
    "        ground_truth_multi_hot = torch.zeros(ground_truth.size(0), 10).scatter_(1, ground_truth.to(\"cpu\"), 1.)\n",
    "        \n",
    "        # this needs fixing\n",
    "        # ground_truth_multi_hot = torch.zeros(ground_truth.size(0), 10).to(\"cuda\").scatter_(torch.tensor(1).to(\"cuda\"), ground_truth.to(\"cuda\"), torch.tensor(1.).to(\"cuda\")).to(\"cuda\")\n",
    "        \n",
    "        loss = self.criterion(model_output, ground_truth_multi_hot.to(\"cuda\"))\n",
    "        cc = self.get_cc() * self.cc_weight\n",
    "        # from BIMT\n",
    "        # loss_train = loss_fn(mlp(x.to(device)), one_hots[label])\n",
    "        # cc = mlp.get_cc(weight_factor=2.0, no_penalize_last=True)\n",
    "        # total_loss = loss_train + lamb*cc\n",
    "        \n",
    "        \n",
    "        acc = (model_output.argmax(dim=-1) == ground_truth).float().mean()\n",
    "\n",
    "        self.log(f'{mode}_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'{mode}_cc', cc, on_step=False, on_epoch=True)\n",
    "        self.log(f'{mode}_acc', acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        # loss + connection cost term\n",
    "        return loss + cc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d36c8d-87e6-4f01-8e52-cdcea768df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_routine(**kwargs):\n",
    "    \n",
    "    train_kwargs = kwargs['train_kwargs']\n",
    "    \n",
    "    \n",
    "    transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset1 = datasets.MNIST('example_data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    #dataset2 = datasets.MNIST('example_data', train=False,\n",
    "    #                   transform=transform)\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset1, batch_size=train_kwargs[\"batch_size\"])\n",
    "    #inference_loader = torch.utils.data.DataLoader(dataset2, **train_kwargs)\n",
    "    \n",
    "    print(train_kwargs)\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(train_kwargs[\"ckpt_path\"], \"example_results\"),\n",
    "                         accelerator=\"gpu\" if str(train_kwargs[\"device\"]).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=train_kwargs[\"epochs\"],\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "                                    LearningRateMonitor(\"epoch\")])\n",
    "    \n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(train_kwargs[\"ckpt_path\"], \"DecentNet.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = DecentLightning.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(19) # To be reproducable\n",
    "        \n",
    "        # Initialize the LightningModule and LightningDataModule\n",
    "        model = DecentLightning(kwargs['model_kwargs'])\n",
    "\n",
    "        # Train the model using a Trainer\n",
    "        trainer.fit(model, train_dataloader)\n",
    "        \n",
    "        model = DecentLightning.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39ad8b29-48de-4f62-88da-381f60d698f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 100, 'batch_size': 16, 'ckpt_path': '', 'device': 'cuda'}\n",
      "\n",
      "[[nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan  6.  2. nan nan nan nan]\n",
      " [ 1. nan  7. nan nan nan nan nan  3.]\n",
      " [nan nan nan nan nan nan nan nan  0.]\n",
      " [nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan  4.]\n",
      " [nan nan nan nan nan nan nan  5. nan]]\n",
      "\n",
      "\n",
      "[[ 5. nan nan nan  8. nan 12. nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan 10. nan nan nan]\n",
      " [nan  1. 11.  2. nan nan  6. nan nan]\n",
      " [nan  3. nan nan nan nan nan nan nan]\n",
      " [13. nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan  9. 15.]\n",
      " [nan nan nan nan nan nan nan nan nan]\n",
      " [ 7. nan nan nan  0. 14. nan nan  4.]]\n",
      "\n",
      "\n",
      "[[nan nan nan nan nan 12. nan nan nan]\n",
      " [nan nan nan nan nan  1.  8.  2. nan]\n",
      " [nan nan  0. nan 20. 16. nan nan nan]\n",
      " [nan nan nan nan  5. nan nan nan nan]\n",
      " [nan nan  3. 11. nan 13. 14. 21. nan]\n",
      " [nan nan 15. nan nan nan  6. nan nan]\n",
      " [nan 23. nan nan nan nan nan nan nan]\n",
      " [22. nan 10. nan nan 17.  9. nan nan]\n",
      " [18. 19. nan  7. nan nan nan nan  4.]]\n",
      "\n",
      "\n",
      "[[nan  3. nan nan  4. nan nan nan nan]\n",
      " [nan nan nan nan nan  7. nan nan  0.]\n",
      " [nan nan nan nan nan  1. nan nan nan]\n",
      " [nan nan nan nan nan  2. nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan  8.]\n",
      " [ 6. nan nan nan  9. nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan  5.]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | model     | DecentNet | 7.0 K \n",
      "1 | criterion | BCELoss   | 0     \n",
      "----------------------------------------\n",
      "7.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.0 K     Total params\n",
      "0.028     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configure_optimizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6620217f48f04bd69a2de9e89dfbb38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "on_validation_epoch_end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:359: UserWarning: `ModelCheckpoint(monitor='val_acc')` could not find the monitored key in the returned metrics: ['train_loss', 'train_acc', 'epoch', 'step']. HINT: Did you call `log('val_acc', value)` in the `LightningModule`?\n",
      "  warning_cache.warn(m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n",
      "training_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/Prinzessin/projects/decentnet/datasceyence/examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2728\\3484705329.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model, results = dev_routine(model_kwargs={\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[1;34m'embed_dim'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 \u001b[1;34m'hidden_dim'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[1;34m'num_heads'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[1;34m'num_layers'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2728\\1502809611.py\u001b[0m in \u001b[0;36mdev_routine\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecentLightning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Load best checkpoint after training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# Test best model on validation and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\core\\module.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m         \"\"\"\n\u001b[1;32m-> 1520\u001b[1;33m         loaded = _load_from_checkpoint(\n\u001b[0m\u001b[0;32m   1521\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\pytorch_lightning\\core\\saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m ) -> Union[\"pl.LightningModule\", \"pl.LightningDataModule\"]:\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# convert legacy checkpoints to the new format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(path_or_url, map_location)\u001b[0m\n\u001b[0;32m     48\u001b[0m         )\n\u001b[0;32m     49\u001b[0m     \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\fsspec\\spec.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m             \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"autocommit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m             f = self._open(\n\u001b[0m\u001b[0;32m   1242\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\fsspec\\implementations\\local.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"w\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\fsspec\\implementations\\local.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\feta\\lib\\site-packages\\fsspec\\implementations\\local.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"w\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0mcompress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/Prinzessin/projects/decentnet/datasceyence/examples'"
     ]
    }
   ],
   "source": [
    "model, results = dev_routine(model_kwargs={\n",
    "                                'embed_dim': 256,\n",
    "                                'hidden_dim': 512,\n",
    "                                'num_heads': 8,\n",
    "                                'num_layers': 6,\n",
    "                                'patch_size': 4,\n",
    "                                'num_channels': 3,\n",
    "                                'num_patches': 64,\n",
    "                                'num_classes': 10,\n",
    "                                'criterion': torch.nn.BCELoss(),\n",
    "                                'optimizer': \"adamw\",\n",
    "                                'lr': 0.001,\n",
    "                                'cc_weight': 0.2,\n",
    "                            },\n",
    "                            train_kwargs={\n",
    "                                'epochs': 100,\n",
    "                                'batch_size': 16,\n",
    "                                # 'test_batch_size': 1,\n",
    "                                'ckpt_path': \"\",\n",
    "                                'device': \"cuda\"\n",
    "                            }\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d89cfe-7561-438c-a0b4-bb3c0c951716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95870660-6418-4b85-a673-13e266a53960",
   "metadata": {},
   "source": [
    "# conv filter test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7bceb-331c-4f16-be5f-3c5c5d91ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "16303538-75ae-4064-ae26-848926552bb7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 1024, 100, 100]) - batch x groups*channels x width x height\n",
      "torch.Size([10, 1024, 3, 3]) - filters x channels x kernel x kernel\n",
      "torch.Size([27, 10, 100, 100]) - batch x filters x width x height\n",
      "\n",
      "**************************************************\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christina\\AppData\\Local\\Temp\\ipykernel_12532\\2723409993.py:95: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  i_tmp = inputs[:,active,:,:]\n",
      "C:\\Users\\Christina\\AppData\\Local\\Temp\\ipykernel_12532\\2723409993.py:96: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  w_tmp = weights[:,active,:,:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.23818039894104\n",
      "3.1647353172302246\n",
      "\n",
      "torch.Size([27, 10, 100, 100]) - batch x filters x width x height\n",
      "\n",
      "\n",
      "torch.Size([27, 1, 100, 100]) - mean accross the filters (no sense here ...)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# this is one filter\n",
    "\n",
    "w_groups = 1 # groups of the channels\n",
    "w_channels = 1024 # input channels\n",
    "w_filters = 10\n",
    "\n",
    "assert w_filters % w_groups == 0\n",
    "assert w_channels % w_groups == 0\n",
    "\n",
    "# batch size x channels (= w_groups*w_channels) x width x height\n",
    "inputs = torch.autograd.Variable(torch.randn(27,w_groups*w_channels,100,100))\n",
    "\n",
    "# w_filters x w_channels x kernel x kernel\n",
    "weights = torch.autograd.Variable(torch.randn(w_filters,w_channels,3,3))\n",
    "\n",
    "# batch size x w_filters x width x height\n",
    "out = F.conv2d(inputs, weights, padding=1, groups=w_groups)\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "print(inputs.shape, \"- batch x groups*channels x width x height\")\n",
    "print(weights.shape, \"- filters x channels x kernel x kernel\")\n",
    "print(out.shape, \"- batch x filters x width x height\")\n",
    "print()\n",
    "\n",
    "print(\"*\"*50)\n",
    "\n",
    "# batch size x channels (= w_groups*w_channels) x width x height\n",
    "inputs = torch.autograd.Variable(torch.randn(27,w_groups*w_channels,100,100))\n",
    "\n",
    "output_list = []\n",
    "\n",
    "# for each filter, we need different true false vales for our channels\n",
    "active = list(np.random.choice([True, False], size=w_channels, replace=True, p=None))\n",
    "\n",
    "# w_filters x w_channels x kernel x kernel\n",
    "weights = torch.autograd.Variable(torch.randn(1,w_channels,3,3))\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "output_list = []\n",
    "start = time.time()\n",
    "for i in range (10):\n",
    "    for _ in range(w_filters):\n",
    "        \n",
    "        pass\n",
    "\n",
    "        #print()\n",
    "        #print(active)\n",
    "        #print()\n",
    "        #print(inputs.shape, \"- batch x groups*channels x width x height\")\n",
    "        #print(weights.shape, \"- filters x channels x kernel x kernel\")\n",
    "\n",
    "\n",
    "        # need to remove weight and input channels according to active list for each filter\n",
    "        #print(inputs.shape)\n",
    "        #print(inputs[:,active,:,:].shape)\n",
    "\n",
    "        #print(weights.shape)\n",
    "        #print(weights[:,active,:,:].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # batch size x w_filters x width x height\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #output_list.append(this_output)\n",
    "        #print(this_output.shape, \"- batch x 1 filter x width x height\")\n",
    "\n",
    "    #out = torch.cat(output_list, dim=1)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "weights = torch.autograd.Variable(torch.randn(w_filters,w_channels,3,3))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range (10):\n",
    "    i_tmp = inputs[:,active,:,:]\n",
    "    w_tmp = weights[:,active,:,:]\n",
    "    this_output = F.conv2d(i_tmp, w_tmp, padding=1, groups=w_groups)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights = torch.autograd.Variable(torch.randn(w_filters,w_channels,3,3))\n",
    "\n",
    "start = time.time()\n",
    "for i in range (10):\n",
    "    this_output = F.conv2d(inputs, weights, padding=1, groups=w_groups)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(out.shape, \"- batch x filters x width x height\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# take the mean of all - we can remove all sorts of information from the out tensor\n",
    "mean = torch.mean(out, 1, keepdim=True)\n",
    "print(mean.shape, \"- mean accross the filters (no sense here ...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e3c4e-80a1-448f-9b3c-4ae14cd7bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "#b = torch.empty(w_filters, w_channels, dtype=torch.bool)\n",
    "b = torch.ByteTensor(500, w_channels)\n",
    "print(sys.getsizeof(b.storage())) # 1310776 (bytes)\n",
    "\n",
    "#a = torch.empty(w_filters, w_channels, dtype=torch.uint8)\n",
    "a = torch.ByteTensor(500, w_channels)\n",
    "print(sys.getsizeof(a.storage())) # 1310776 (bytes)\n",
    "\n",
    "active = list(np.random.choice([True, False], size=w_channels, replace=True, p=None))\n",
    "print(sys.getsizeof(active)*500) # 1310776 (bytes)\n",
    "\n",
    "weights = torch.FloatTensor(torch.randn(500,w_channels,3,3))\n",
    "print(sys.getsizeof(weights.storage())) # 1310776 (bytes) 36912\n",
    "print(36912*500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2b255-ccc3-4809-948c-cd4dc5efe661",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dadee83-7300-4844-8284-8d0ef29aaee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(2, size=10)\n",
    "\n",
    "list(np.random.choice([True, False], size=10, replace=True, p=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c72946-baf5-4c90-b84e-14f14c8d949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(1, 82, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2754cb-b071-4267-b53c-5f2190a7baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "9*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95feb489-36f2-4d83-81e3-5e21a530f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(a=4, size=2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5d97e-7408-4c52-8891-864827810c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# this is one filter\n",
    "\n",
    "w_groups = 27 # groups of the channels\n",
    "w_channels = 7 # input channels\n",
    "w_filters = 200\n",
    "batch_size = 27\n",
    "\n",
    "# batch size x channels (= w_groups*w_channels) x width x height\n",
    "inputs = torch.autograd.Variable(torch.randn(batch_size, w_channels*w_groups, 100,100))\n",
    "#inputs = torch.autograd.Variable(torch.randn(w_channels*w_groups, 100,100))\n",
    "\n",
    "# w_groups x w_channels x kernel x kernel\n",
    "weights = torch.autograd.Variable(torch.randn(1, w_channels,3,3))\n",
    "#weights = torch.autograd.Variable(torch.randn(w_groups*w_channels,3,3))\n",
    "\n",
    "print(inputs.shape, \"- batch x groups*channels x width x height\")\n",
    "print(weights.shape, \"- filter 1 x channels x kernel x kernel\")\n",
    "\n",
    "try:\n",
    "    o_list = []\n",
    "    for _ in range(w_filters):\n",
    "        # batch size x groups x width x height\n",
    "        out = F.conv2d(inputs, weights, groups=w_groups)\n",
    "        o_list.append(out)\n",
    "        # take the mean of all - we can remove all sorts of information from the out tensor\n",
    "        #mean = torch.mean(out, 1, keepdim=True)\n",
    "    \n",
    "    print(torch.cat(o_list, dim=1).shape, \"- batch x filters x width x height\")\n",
    "    #print(mean.shape, \"- mean accross the groups\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3d443-372f-4548-804e-11efbebe6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = torch.randn(8, 4, 3, 3)\n",
    "inputs = torch.randn(1, 4, 5, 5)\n",
    "F.conv2d(inputs, filters, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bf7b8-35d2-4f68-b045-0ba93bd4c5fc",
   "metadata": {},
   "source": [
    "# Visualise filters and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536067b-6098-4844-9ef4-7a5db5a23156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net() # .to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320d57b-3e22-404f-ad6c-b04515fe2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import utils\n",
    "\n",
    "def visChannels(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    \n",
    "    plt.figure(figsize=(nrow,rows) )\n",
    "    plt.title(f\"Channels with index {ch}\")\n",
    "    plt.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "\n",
    "def visFilters(tensor, filt=0, allkernels=False, nrow=8, padding=1): \n",
    "    f,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(f*c, -1, w, h)\n",
    "    elif f != 3: tensor = tensor[filt,:,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.title(f\"Filter {filt}\")\n",
    "    plt.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "def visFilters_subplot(subplot, tensor, filt=0, allkernels=False, nrow=8, padding=1): \n",
    "    f,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(f*c, -1, w, h)\n",
    "    elif f != 3: tensor = tensor[filt,:,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    # plt.figure( figsize=(nrow,rows) )\n",
    "    subplot.set_title(f\"Filter {filt+1} with {c} channels\")\n",
    "    subplot.imshow(grid.detach().cpu().numpy().transpose((1, 2, 0)))\n",
    "    subplot.axis('off')\n",
    "    \n",
    "layer = 1\n",
    "filter = model.conv2.weight.data.clone()\n",
    "\n",
    "print(model.conv2.weight.shape)\n",
    "\n",
    "# need to match the network parameters!!!!\n",
    "in_channels = 5\n",
    "out_filters = 3 # 64\n",
    "\n",
    "\n",
    "fig, subplot = plt.subplots(out_filters, figsize=(10, 10))\n",
    "fig.suptitle(f'Layer with shape {list(model.conv2.weight.shape)} [out, in, kernel, kernel]')\n",
    "\n",
    "for filt in range(0, out_filters):\n",
    "    \n",
    "    visFilters_subplot(subplot[filt], filter, filt=filt, allkernels=False)\n",
    "\n",
    "    #plt.axis('off')\n",
    "    #plt.ioff()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"example_results/filter_with_weights.png\")\n",
    "plt.show()\n",
    "    \n",
    "if False:    \n",
    "    for filt in range(0, out_filters):\n",
    "\n",
    "        visFilters(filter, filt=filt, allkernels=False)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig(f\"examples/example_results/filter_with_weights.png\")\n",
    "        plt.show()\n",
    "\n",
    "    for ch in range(0, in_channels):\n",
    "\n",
    "        visChannels(filter, ch=ch, allkernels=False)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791fa94-5bb8-4d3a-ad97-72cc5a59025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "res = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655d64a-7fc0-42c7-880e-69e7be6acedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.layer1[0].conv1.bias == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3322395-f2a0-40e1-a0e8-86c090586f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.layer1[0].conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d52543-cd67-4d00-963a-5d1effbfc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.extra_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77091394-6e75-4aa3-84c3-a9ebc7ce932e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
