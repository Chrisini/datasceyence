{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c4575e-ffe5-4966-aba6-30c569d1e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../helper', './helper', '/helper', 'helper', 'C:\\\\Users\\\\Prinzessin\\\\projects\\\\decentnet\\\\datasceyence\\\\examples', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\python39.zip', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\DLLs', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta', '', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Prinzessin\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "import unittest\n",
    "\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, r\"helper\")\n",
    "sys.path.insert(0, r\"/helper\")\n",
    "sys.path.insert(0, r\"./helper\")\n",
    "sys.path.insert(0, r\"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "# relevant: import the UncertaintyMetric\n",
    "from compute.metric.uncertainty import * \n",
    "\n",
    "from dataset.meanteacher import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11daf72a-09fe-4087-82cf-eeed8a0918d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitTestUncertainty(unittest.TestCase):   \n",
    "\n",
    "        \n",
    "    def test_metric(self):\n",
    "        \n",
    "        # preparation\n",
    "        channels = 1\n",
    "        n_output_neurons=2\n",
    "        model = smp.UnetPlusPlus(\n",
    "                                encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                                encoder_weights=\"imagenet\",  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                                in_channels=channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                                classes=n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                            )\n",
    "        csv_filenames = glob.glob(r\"../data_prep/mt_*.csv\")\n",
    "        # image size has to be dividable by 32!!\n",
    "        dataset = MeanTeacherTrainDataset(mode=\"train\", channels=channels, image_size=512, csv_filenames=csv_filenames)\n",
    "        train_loader = DataLoader(dataset, batch_size=3, shuffle=False)\n",
    "\n",
    "        # relevant: create instance of class\n",
    "        um = UncertaintyMetric(n_noise=4, n_repeat=2, n_output_neurons=n_output_neurons)\n",
    "        uncertainy_mask = None\n",
    "\n",
    "        # load one batch\n",
    "        for idx, item in enumerate(train_loader):\n",
    "\n",
    "            # relevant: get mask\n",
    "            uncertainy_mask = um.run(model, item[\"img\"])\n",
    "            print(uncertainy_mask)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow( uncertainy_mask[0].permute(1, 2, 0), cmap=\"gray\" )\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow( uncertainy_mask[0].permute(1, 2, 0) < 0.68, cmap=\"gray\" )\n",
    "\n",
    "            break\n",
    "\n",
    "    \n",
    "    \n",
    "    def test_dummy(self):\n",
    "        \n",
    "        # same code as in metric class, but with prints\n",
    "        \n",
    "        import torch\n",
    "\n",
    "        #for image in batch:\n",
    "\n",
    "        batch_size = 6\n",
    "        width = 3\n",
    "        height = 3\n",
    "        n_copy = 2\n",
    "        n_noise = 4\n",
    "        output_neurons = 5\n",
    "        input_channels = 1\n",
    "\n",
    "        tmp_img = torch.rand(batch_size, input_channels, width, height) # 1 image, 2 probability outputs, 3x3 wxh\n",
    "        print(\"action: dummy batch\")\n",
    "        print(\"batch shape\", tmp_img.shape, \"### batch size, input_channels, w, h\")\n",
    "        print()\n",
    "\n",
    "        tmp_img_double = tmp_img.repeat(n_copy, 1, 1 ,1) # becomes 6, 2, 3, 3\n",
    "        print(\"action: repeat dummy batch\")\n",
    "        print(\"batch shape double\", tmp_img_double.shape, \"### batch size * 2, input_channels, w, h\")\n",
    "        print()\n",
    "\n",
    "        batch_times_repeat = tmp_img_double.shape[0] # = 6\n",
    "\n",
    "        preds = torch.zeros( (batch_size*n_noise*n_copy), output_neurons, width, height )\n",
    "        print(\"action: tensor for predictions\")\n",
    "        print(\"shape\", preds.shape, \"### n_noise * batch_size * 2 , output_neurons, w, h\")\n",
    "        print()\n",
    "\n",
    "        for i in range (n_noise):\n",
    "\n",
    "            noise = torch.clamp(torch.randn_like(tmp_img_double) * 0.1, min=-0.2, max=0.2)\n",
    "\n",
    "            ema_input = tmp_img_double + noise\n",
    "\n",
    "            with torch.no_grad():\n",
    "                #print(n_copy * batch_size * i)\n",
    "                #print(n_copy * batch_size * (i+1))\n",
    "                preds[n_copy * batch_size * i    :    n_copy * batch_size * (i+1)] = i # model(input)\n",
    "\n",
    "        preds = torch.nn.functional.softmax(preds, dim=1)\n",
    "\n",
    "\n",
    "        preds = preds.reshape(n_copy*n_noise, batch_size, output_neurons, width, height)\n",
    "        print(\"action: reshape\")\n",
    "        print(\"shape\", preds.shape, \" ### noise*2, batch size, output neuronns, w, h\")\n",
    "        print()\n",
    "\n",
    "        preds = torch.mean(preds, dim=0)\n",
    "        print(\"action: mean on dimension 0\")\n",
    "        print(\"shape\", preds.shape, \" ### batch size, output neuronns, w, h\")\n",
    "        print()\n",
    "\n",
    "        uncertainty = -torch.sum(preds * torch.log(preds), dim=1, keepdim=True)\n",
    "        print(\"action: uncertainty on dimension 1\")\n",
    "        print(\"uncertainty shape\", uncertainty.shape, \" ### batch size, 1, w, h\")\n",
    "        print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdde5996-152d-4ce8-8d6a-ceb36213bf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: dummy batch\n",
      "batch shape torch.Size([6, 1, 3, 3]) ### batch size, input_channels, w, h\n",
      "\n",
      "action: repeat dummy batch\n",
      "batch shape double torch.Size([12, 1, 3, 3]) ### batch size * 2, input_channels, w, h\n",
      "\n",
      "action: tensor for predictions\n",
      "shape torch.Size([48, 5, 3, 3]) ### n_noise * batch_size * 2 , output_neurons, w, h\n",
      "\n",
      "action: reshape\n",
      "shape torch.Size([8, 6, 5, 3, 3])  ### noise*2, batch size, output neuronns, w, h\n",
      "\n",
      "action: mean on dimension 0\n",
      "shape torch.Size([6, 5, 3, 3])  ### batch size, output neuronns, w, h\n",
      "\n",
      "action: uncertainty on dimension 1\n",
      "uncertainty shape torch.Size([6, 1, 3, 3])  ### batch size, 1, w, h\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: test_metric (__main__.UnitTestUncertainty)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Prinzessin\\AppData\\Local\\Temp\\ipykernel_18664\\1160094553.py\", line 31, in test_metric\n",
      "    plt.figure()\n",
      "NameError: name 'plt' is not defined\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 123.785s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6539, 0.6871, 0.6093,  ..., 0.6188, 0.6931, 0.6763],\n",
      "          [0.6470, 0.5947, 0.5041,  ..., 0.4452, 0.5036, 0.6048],\n",
      "          [0.6251, 0.6854, 0.5554,  ..., 0.5942, 0.6410, 0.5817],\n",
      "          ...,\n",
      "          [0.6923, 0.6742, 0.6931,  ..., 0.6849, 0.6289, 0.5847],\n",
      "          [0.5452, 0.6760, 0.6906,  ..., 0.5764, 0.4018, 0.3620],\n",
      "          [0.5624, 0.6746, 0.6780,  ..., 0.6094, 0.6683, 0.5042]]],\n",
      "\n",
      "\n",
      "        [[[0.6498, 0.6918, 0.6255,  ..., 0.5922, 0.6930, 0.6882],\n",
      "          [0.6851, 0.6618, 0.6026,  ..., 0.4693, 0.4991, 0.5838],\n",
      "          [0.6745, 0.6906, 0.6815,  ..., 0.5886, 0.6730, 0.5786],\n",
      "          ...,\n",
      "          [0.6911, 0.6521, 0.6816,  ..., 0.6091, 0.5632, 0.5756],\n",
      "          [0.5697, 0.6675, 0.6926,  ..., 0.6106, 0.5296, 0.4049],\n",
      "          [0.6418, 0.6809, 0.6630,  ..., 0.5275, 0.6912, 0.4833]]],\n",
      "\n",
      "\n",
      "        [[[0.6119, 0.6922, 0.6509,  ..., 0.6734, 0.6901, 0.6841],\n",
      "          [0.6548, 0.5971, 0.5724,  ..., 0.5675, 0.4399, 0.6045],\n",
      "          [0.6897, 0.6879, 0.6780,  ..., 0.6706, 0.5988, 0.6424],\n",
      "          ...,\n",
      "          [0.6816, 0.6585, 0.6856,  ..., 0.6903, 0.5117, 0.5063],\n",
      "          [0.5425, 0.6557, 0.6897,  ..., 0.6672, 0.5205, 0.3946],\n",
      "          [0.5684, 0.6931, 0.6890,  ..., 0.4961, 0.6449, 0.5600]]]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5f926-4c79-4ab7-a48b-d67a182c64b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
