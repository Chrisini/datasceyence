{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c113af1-da2a-474d-b281-20d163a23edf",
   "metadata": {},
   "source": [
    "# Activation Functions - dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4adc42-cc62-4c9d-92ed-56e2eadfb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "img = torch.randn(1, 2, 3)\n",
    "model_output = m(img)\n",
    "\n",
    "print(img)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c24c9-7348-412d-8a36-b5cee5ff440c",
   "metadata": {},
   "source": [
    "# Rampup function visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba393e8-9e41-46fc-9d74-0085ba7b898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "currents = range(0, 1000)\n",
    "rampup_length = 600\n",
    "\n",
    "results = []\n",
    "for current in currents:\n",
    "    current = np.clip(current, 0.0, rampup_length)\n",
    "    result = float(np.exp(-5.0 * (1.0 - current / rampup_length) ** 2))\n",
    "    results.append(result)\n",
    "\n",
    "print(results[25])\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(currents, results, color = 'k', label = \"ramp(t, 75)\")\n",
    "plt.xlabel(\"Epoch t\")\n",
    "plt.ylabel(\"Rampup value [0, 1]\")\n",
    "plt.axvline(x = 75, color = 'darkorange', label = 't=75: 1.0', linestyle = '-.')\n",
    "plt.axhline(y = 1, color = 'darkorange', linestyle = '-.')\n",
    "plt.axvline(x = 50, color = 'mediumvioletred', label = 't=50: 0.57', linestyle = '--')\n",
    "plt.axhline(y = 0.57, color = 'mediumvioletred', linestyle = '--')\n",
    "plt.axvline(x = 25, color = 'teal', label = 't=25: 0.11', linestyle = ':')\n",
    "plt.axhline(y = 0.11, color = 'teal', linestyle = ':')\n",
    "plt.legend(loc = 'lower right', facecolor=\"white\", framealpha=1, fontsize=\"large\")\n",
    "plt.savefig(\"example_results/rampup.png\", dpi=1200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44a9fd-2ef1-4a42-b5e2-62f77d4e9a2c",
   "metadata": {},
   "source": [
    "# dict from keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce5390-b0ce-44e1-84ba-8ee4fe9b0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_keys = [  'loss',\n",
    "            'acc', 'fscore', 'fmicro', 'jac', 'prec', 'rec',\n",
    "            'symhd' # task specific: segmentation\n",
    "        ]\n",
    "\n",
    "# everything we want to track\n",
    "batch_collector = { key : [] for key in b_keys }\n",
    "\n",
    "print(batch_collector)\n",
    "\n",
    "for i in range(5):\n",
    "    batch_collector[\"loss\"].append(4)\n",
    "    # batch_collector[\"acc\"] = 1.0\n",
    "\n",
    "print(batch_collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617f66c-9bd3-40a1-b12b-160155700023",
   "metadata": {},
   "outputs": [],
   "source": [
    "Details = {\"Destination\": \"China\", \n",
    "           \"Nationality\": \"Italian\", \"Age\": []}\n",
    "\n",
    "for i in range(5):\n",
    "    Details[\"Age\"].append(2) # [20, \"Twenty\"]\n",
    "    \n",
    "print(Details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f082a-1de8-4451-a5ec-dfa6e2b155d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in batch_collector.keys():\n",
    "    print(key, np.mean(batch_collector[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15ca34-aa93-4e23-bf8f-2f7942c04861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of vowels\n",
    "keys = {'a', 'e', 'i', 'o', 'u' }\n",
    "\n",
    "# assign empty list to value\n",
    "value = []\n",
    "\n",
    "# creates a dictionary with keys and values\n",
    "vowels = { key : [] for key in keys }\n",
    "\n",
    "vowels[\"a\"].append(\"hi\")\n",
    "\n",
    "print(vowels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbcd35-e40b-4d00-96eb-41ed03e06194",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99fb06-f4ed-4b55-a6ab-349c2821133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c953d77-f877-49fe-b2b8-b96019ee9433",
   "metadata": {},
   "source": [
    "# Domain shift dependent on two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d10005-f612-41ce-8e7c-8bd7566e0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "\n",
    "#domain1 = glob.glob('C:/snec_data/Result_Data/cirrus/enface/*_cube_z.tif')\n",
    "#domain2 = glob.glob('C:/snec_data/Result_Data/plex/enface/*_cube_z.tif')\n",
    "#domain3 = glob.glob('C:/Users/Prinzessin/projects/image_data/iChallenge_AMD_OD_Fovea_lesions/images_AMD/*.jpg')\n",
    "# domain2 = glob.glob('C:/Users/Prinzessin/projects/image_data/iChallenge_AMD_OD_Fovea_lesions/images_Non-AMD/*.jpg')\n",
    "\n",
    "domain1 = glob.glob('C:/snec_data/Result_Data/cirrus/enface/*_cube_z.tif')\n",
    "domain2 = glob.glob('C:/snec_data/Result_Data/plex/enface/*_cube_z.tif')\n",
    "domain3 = glob.glob('C:/Users/Prinzessin/projects/image_data/iChallenge_AMD_OD_Fovea_lesions/images_AMD/*.jpg')\n",
    "\n",
    "domain1 = glob.glob(\"E:/Christina/Result_Data/CIRRUS_*/enface/*_cube_z.tif\")[0:10]\n",
    "domain2 = glob.glob(\"E:/Christina/Result_Data/PLEX_*/enface/*/*_cube_z.tif\")[0:10]   \n",
    "domain3 = glob.glob(\"E:/Christina/Result_Data/ADAM_*/fundus/*jpg\")[0:10]\n",
    "\n",
    "x1 = []\n",
    "x2 = []\n",
    "x3 = []\n",
    "\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "# from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "\n",
    "def calc_entropy(img, base=\"contrast\"):\n",
    "    glcm = np.squeeze(graycomatrix(img, distances=[1], \n",
    "                               angles=[0], symmetric=True, \n",
    "                               normed=True))\n",
    "    \n",
    "    if base == \"entropy\":\n",
    "        feature = -np.sum(glcm*np.log2(glcm + (glcm==0)))\n",
    "    \n",
    "    else:\n",
    "        glcm = graycomatrix(img, distances=[1], \n",
    "                               angles=[0], symmetric=True, \n",
    "                               normed=True)\n",
    "        \n",
    "        feature = graycoprops(glcm, base)\n",
    "    \n",
    "\n",
    "    \n",
    "    return feature\n",
    "\n",
    "for path in domain1:\n",
    "    image = skimage.io.imread(path, plugin='pil')\n",
    "    \n",
    "    x1.append(calc_entropy(image, \"contrast\")) # np.mean(image))\n",
    "    y1.append(calc_entropy(image, \"ASM\"))    \n",
    "print(\"done domain 1\")    \n",
    "\n",
    "for path in domain2:\n",
    "    image = skimage.io.imread(path, plugin='pil')\n",
    "    \n",
    "    x2.append(calc_entropy(image, \"contrast\")) # np.mean(image))\n",
    "    y2.append(calc_entropy(image, \"ASM\"))\n",
    "print(\"done domain 2\")    \n",
    "\n",
    "for path in domain3:\n",
    "    image = skimage.io.imread(path, as_gray=True)\n",
    "    image = img_as_ubyte(image)\n",
    "    \n",
    "    x3.append(calc_entropy(image, \"contrast\")) # np.mean(image))\n",
    "    y3.append(calc_entropy(image, \"ASM\"))\n",
    "print(\"done domain 3\")    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(mean2)\n",
    "print(median2)\n",
    "\n",
    "print(mean1)\n",
    "print(median1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468e277-17a0-43e2-9810-f9fe4f8edf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.scatter(x2, y2, label=\"PLEX\", color = 'darkorange', s=50, marker='^')\n",
    "plt.scatter(x1, y1, label=\"CIRRUS\",  color = 'mediumvioletred', s=50, marker='+')\n",
    "#plt.scatter(x3, y3, label=\"iChallenge\", color = 'teal', s=7, marker=',')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"example_results/domainshift.png\", dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb30b56-66e6-407f-b94e-aeef1ec9f217",
   "metadata": {},
   "source": [
    "# Mean and average images\n",
    "* https://towardsdatascience.com/exploratory-data-analysis-ideas-for-image-classification-d3fc6bbfb2d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952af38-03eb-40bc-b826-fabd5811556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain1 = glob.glob('C:/snec_data/Result_Data/cirrus/enface/*_cube_z.tif')\n",
    "domain2 = glob.glob('C:/snec_data/Result_Data/plex/enface/*_cube_z.tif')\n",
    "domain3 = glob.glob('C:/Users/Prinzessin/projects/image_data/iChallenge_AMD_OD_Fovea_lesions/images_AMD/*.jpg')\n",
    "\n",
    "domain1 = glob.glob(\"E:/Christina/Result_Data/CIRRUS_Normal/enface/*_cube_z.tif\")\n",
    "domain2 = glob.glob(\"E:/Christina/Result_Data/PLEX_*/enface/*/*_cube_z.tif\")        \n",
    "domain3 = glob.glob(\"E:/Christina/Result_Data/ADAM_*/fundus/*jpg\")\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "# making n X m matrix\n",
    "def img2np(paths, size = (150, 150)):\n",
    "    # iterating through each file\n",
    "    \n",
    "    images = []\n",
    "    current_image = None\n",
    "    \n",
    "    for i, path in enumerate(paths):\n",
    "                \n",
    "        current_image = skimage.io.imread(path, as_gray=True, plugin='pil')\n",
    "        current_image = resize(current_image, size, anti_aliasing=True)\n",
    "                \n",
    "        images.append(current_image)\n",
    "        \n",
    "        stacked = np.stack(images, axis=-1)  \n",
    "    \n",
    "    return stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8d88e-1b1e-41c3-9890-dc1ea6411783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it on our folders\n",
    "domain1_images = img2np(domain1)\n",
    "print(\"done 1\")\n",
    "domain2_images = img2np(domain2)\n",
    "print(\"done 2\")\n",
    "domain3_images = img2np(domain3)\n",
    "print(\"done 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b7a63-ac8d-4533-b98d-dfea27260649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_img(full_mat, title, f):\n",
    "    # calculate the average\n",
    "    result = np.mean(full_mat, axis = 2)\n",
    "    \n",
    "    f.imshow(result, cmap='gray')\n",
    "    f.set_title(f'Mean {title}')\n",
    "    f.axis('off')\n",
    "    return result\n",
    "\n",
    "def find_std_img(full_mat, title, f):\n",
    "    # calculate the standard deviation\n",
    "    result = np.std(full_mat, axis = 2)\n",
    "\n",
    "    f.imshow(result, cmap='gray')\n",
    "    f.set_title(f'Std {title}')\n",
    "    f.axis('off')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b0b48-bac9-4c50-b536-0e67a03da758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "cirrus_mean = find_mean_img(domain1_images, \"CIRRUS\", axs[0])\n",
    "plex_mean = find_mean_img(domain2_images, \"PLEX\", axs[1])\n",
    "ichallenge_mean = find_mean_img(domain3_images, \"iChallenge\", axs[2])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"example_results/domain_shift_mean.png\", dpi=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9b875-468a-41d0-a161-f59c4e31610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_mean = np.absolute(plex_mean - cirrus_mean)\n",
    "#contrast_mean = cv2.absdiff(plex_mean, cirrus_mean)\n",
    "# contrast_mean = plex_mean * cirrus_mean\n",
    "plt.imshow(contrast_mean, cmap='cool')\n",
    "plt.title(f'Difference of mean PLEX and CIRRUS')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"example_results/domain_shift_diff_mean.png\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f573976-f46d-41da-afb1-a70667e3deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "cirrus_std = find_std_img(domain1_images, \"CIRRUS\", axs[0])\n",
    "plex_std = find_std_img(domain2_images, \"PLEX\", axs[1])\n",
    "ichallenge_std = find_std_img(domain3_images, \"iChallenge\", axs[2])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"example_results/domain_shift_std.png\", dpi=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a6880-3c77-4459-83ea-2a17a73175f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_mean = np.absolute(plex_std - cirrus_std)\n",
    "plt.imshow(contrast_mean, cmap='cool')\n",
    "plt.title(f'Difference of std PLEX and CIRRUS')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"example_results/domain_shift_diff_std.png\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e50ee-2cef-48a4-8740-70b765147a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing contour stuff here - to draw an area, it needs to be in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a1b9e-f3a9-4356-908e-80e5efd4c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('E:/Christina/Result_Data/ADAM_AMD/fundus_mask_bin/A0010.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "ret,thresh = cv2.threshold(img,127,255,0)\n",
    "contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "cnt = contours[0]\n",
    "M = cv.moments(cnt)\n",
    "print( M )\n",
    "\n",
    "area = cv2.contourArea(cnt)\n",
    "print(area)\n",
    "\n",
    "num_labels, labels_im = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "if len(num_labels) > 0:\n",
    "    max_area = max(num_labels, key = cv2.contourArea)\n",
    "    max_area = cv2.contourArea(max_area)\n",
    "    print(max_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e36424-831e-4bd6-a5ba-925293674400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d19a07-896e-40ff-8bea-176a62449381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
