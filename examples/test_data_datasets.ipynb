{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6366f3b-d324-4f8d-8991-df340d1c2073",
   "metadata": {},
   "source": [
    "# Dataset tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7409fb-9bf3-4a9a-8639-0ae2ccf53cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7e803-36b3-43f8-8088-975dd55335d9",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad73a21-152a-4b33-8ed4-e3df27ac8c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset = datasets.MNIST('example_data', train=True, download=True, transform=transform)\n",
    "val_set = datasets.MNIST('example_data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(len(val_set))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a96613-778f-4b6f-b27b-704a110172eb",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9397ab9d-74e2-4561-a903-3bc110055b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "tensor([[1, 0, 5, 2]])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor([1, 0, 5, 2])\n",
    "labels = labels.unsqueeze(0)\n",
    "\n",
    "target = torch.zeros(labels.size(0), 10).scatter_(1, labels, 1.)\n",
    "print(target)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366b99b-3b99-4765-8810-0276b154c04e",
   "metadata": {},
   "source": [
    "# OCT MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19c49948-ad58-45cf-816d-ab55c9a536c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kwargs {'input_data_csv': ['data_prep/data_octa500.csv'], 'result_path': 'examples/example_results', 'exp_name': 'every3_95', 'load_ckpt_file': 'version_16/checkpoints/mu_epoch=8-val_f1_macro=0.64-unpruned=2373.ckpt', 'load_mode': False, 'dataset': 'octmnist', 'epochs': 40, 'img_size': 28, 'p_augment': 0.2, 'batch_size': 1, 'log_every_n_steps': 50, 'device': 'cuda', 'num_workers': 0, 'train_size': -1, 'val_size': -1, 'test_size': -1, 'octa500_id': 199, 'xai_done': False}\n",
      "model kwargs {'in_channels': 1, 'n_classes': None, 'out_dim': [1, 8, 16, 32], 'grid_size': 324, 'criterion': CrossEntropyLoss(), 'new_cc_mode': True, 'reset_optimiser_at_update': True, 'optimizer': 'sgd', 'base_lr': 0.001, 'min_lr': 1e-05, 'momentum': 0.9, 'lr_update': 100, 'cc_weight': 5, 'cc_metric': 'l2_torch', 'ci_metric': 'l2', 'cm_metric': 'not implemented yet', 'update_every_nth_epoch': 3, 'pretrain_epochs': 15, 'prune_keep': 0.95, 'prune_keep_total': 0.4}\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {\n",
    "    'in_channels' : 1, # not in use yet\n",
    "    'n_classes': None, # filled in the dataset\n",
    "    'out_dim' :  [1, 8, 16, 32], # [1, 8, 16, 32], #[1, 16, 24, 32] # entry, decent1, decent2, decent3\n",
    "    'grid_size' : 18*18,\n",
    "    'criterion': torch.nn.CrossEntropyLoss(),# torch.nn.BCEWithLogitsLoss(),\n",
    "    'new_cc_mode' : True, # this is for using the new connection cost loss term\n",
    "    'reset_optimiser_at_update' : True,\n",
    "    'optimizer': \"sgd\", # sgd adamw\n",
    "    'base_lr': 0.001,\n",
    "    'min_lr' : 0.00001,\n",
    "    'momentum' : 0.9,\n",
    "    'lr_update' : 100,\n",
    "    # decentnet\n",
    "    'cc_weight': 5, # high weight as the cc doesn't change a lot\n",
    "    'cc_metric' : 'l2_torch', # connection cost metric (for loss) - distance metric # no idea how the torch works oops\n",
    "    'ci_metric' : 'l2', # todo: should be l2 # channel importance metric (for pruning)\n",
    "    'cm_metric' : 'not implemented yet', # 'count', # crossing minimisation \n",
    "    'update_every_nth_epoch' : 3, # 5\n",
    "    'pretrain_epochs' : 15, # 20\n",
    "    'prune_keep' : 0.95, # 0.97, # in each epoch\n",
    "    'prune_keep_total' : 0.4, # this number is not exact, depends on the prune_keep value\n",
    "}\n",
    "\n",
    "train_kwargs = {\n",
    "    'input_data_csv': [\"data_prep/data_octa500.csv\"],\n",
    "    'result_path': \"examples/example_results\", # \"example_results/lightning_logs\", # not in use??\n",
    "    'exp_name': \"every3_95\", # must include dataset name, otherwise mnist is used\n",
    "    'load_ckpt_file' : \"version_16/checkpoints/mu_epoch=8-val_f1_macro=0.64-unpruned=2373.ckpt\", # \"version_0/checkpoints/epoch=94-unpruned=1600-val_f1=0.67.ckpt\", # 'version_94/checkpoints/epoch=26-step=1080.ckpt', # change this for loading a file and using \"test\", if you want training, keep None\n",
    "    'load_mode' : False, # True, False\n",
    "    'dataset' : 'octmnist',\n",
    "    'epochs': 40, # including the pretrain epochs - no adding up\n",
    "    'img_size' : 28, #168, # keep mnist at original size, training didn't work when i increased the size ... # MNIST/MedMNIST 28 × 28 Pixel\n",
    "    'p_augment' : 0.2, # probabiliby of torchvision transforms of training data (doesn't apply to all transforms) # 0.1 low, 0.5 half, 1 always\n",
    "    'batch_size': 1, # laptop: 2, pc: 128, # the higher the batch_size the faster the training - every iteration adds A LOT OF comp cost\n",
    "    'log_every_n_steps' : 50, # lightning default: 50 # needs to be bigger than the amount of steps in an epoch (based on trainset size and batchsize)\n",
    "    'device': \"cuda\",\n",
    "    'num_workers' : 0, # 18, # 18 for seri computer, 0 or 8 for my laptop # make sure smaller than activate dataset sizes\n",
    "    'train_size' : -1, # total, none = 0, all = -1  (batch size * forward passes per epoch) # set 0 to skip training and just do testing\n",
    "    'val_size' : -1, # total, none = 0, all = -1 (batch size * forward passes per epoch) \n",
    "    'test_size' : -1, # total, none = 0, all = -1 (batch size * forward passes per epoch)\n",
    "    'octa500_id' : 200-1, # not in use - we use preselected data from a csv\n",
    "    'xai_done' : False, # DO NOT CHANGE, WILL BE CHANGED IN CODE\n",
    "}\n",
    "\n",
    "print(\"train kwargs\", train_kwargs)\n",
    "print(\"model kwargs\", model_kwargs)\n",
    "\n",
    "kwargs = {'train_kwargs':train_kwargs, 'model_kwargs':model_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "225b86e4-21a9-4784-afd3-cf23705d6934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\Prinzessin\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Prinzessin\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Prinzessin\\.medmnist\\octmnist.npz\n",
      "********** DECENT INFO: DataLoader infos **********\n",
      "python_class : OCTMNIST\n",
      "description : The OCTMNIST is based on a prior dataset of 109,309 valid optical coherence tomography (OCT) images for retinal diseases. The dataset is comprised of 4 diagnosis categories, leading to a multi-class classification task. We split the source training set with a ratio of 9:1 into training and validation set, and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−1,536)×(277−512). We center-crop the images and resize them into 1×28×28.\n",
      "url : https://zenodo.org/records/10519652/files/octmnist.npz?download=1\n",
      "MD5 : c68d92d5b585d8d81f7112f81e2d0842\n",
      "task : multi-class\n",
      "label : {'0': 'cnv', '1': 'dme', '2': 'drusen', '3': 'normal'}\n",
      "n_channels : 1\n",
      "n_samples : {'train': 97477, 'val': 10832, 'test': 1000}\n",
      "license : CC BY 4.0\n",
      "tensor([33484, 10213,  7754, 46026])\n",
      "Class Weights: tensor([0.1072, 0.3516, 0.4631, 0.0780])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "import sys \n",
    "sys.path.insert(0, \"../helper\")\n",
    "from data.octmnist import DataLoaderOCTMNIST\n",
    "\n",
    "dataloader = DataLoaderOCTMNIST(train_kwargs, model_kwargs)   \n",
    "\n",
    "# Example DataLoader (replace with your actual DataLoader)\n",
    "# Assumes labels are integers from 0 to num_classes-1\n",
    "\n",
    "all_labels = []\n",
    "# Extract all labels from the DataLoader\n",
    "for inputs, labels in dataloader.train_dataloader:\n",
    "    all_labels.append(labels.squeeze(0))\n",
    "# Concatenate all labels into a single tensor\n",
    "all_labels = torch.cat(all_labels)\n",
    "sorted_labels, sorted_indices = torch.sort(all_labels)\n",
    "# Count the occurrences of each class\n",
    "class_counts = torch.bincount(sorted_labels)\n",
    "# Calculate weights (inverse of class frequency)\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "# Normalize weights (optional, but recommended for stability)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "print(\"class_counts\", class_counts, \"class_weights:\", class_weights)\n",
    "\n",
    "# Pass the weights to CrossEntropyLoss\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2c476-9109-4c38-bc03-65cee8371ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
