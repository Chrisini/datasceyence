{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8ea6b-7e2f-4257-9875-25f651882f81",
   "metadata": {},
   "source": [
    "* https://github.com/MSKCC-Computational-Pathology/MIL-nature-medicine-2019/blob/master/MIL_train.py\n",
    "\n",
    "* https://github.com/binli123/dsmil-wsi/blob/master/attention_map.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b972ff66-723c-43a1-a9d9-80c43b450efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.utils import _single, _pair, _triple, _reverse_repeat_tuple\n",
    "from torch._torch_docs import reproducibility_notes\n",
    "\n",
    "from torch.nn.common_types import _size_1_t, _size_2_t, _size_3_t\n",
    "from typing import Optional, List, Tuple, Union\n",
    "\n",
    "__all__ = ['Conv1d', 'Conv2d', 'Conv3d', 'ConvTranspose1d', 'ConvTranspose2d', 'ConvTranspose3d',\n",
    "           'LazyConv1d', 'LazyConv2d', 'LazyConv3d', 'LazyConvTranspose1d', 'LazyConvTranspose2d',\n",
    "           'LazyConvTranspose3d']\n",
    "\n",
    "convolution_notes = \\\n",
    "    {\"groups_note\": r\"\"\"* :attr:`groups` controls the connections between inputs and outputs.\n",
    "      :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
    "      :attr:`groups`. For example,\n",
    "\n",
    "        * At groups=1, all inputs are convolved to all outputs.\n",
    "        * At groups=2, the operation becomes equivalent to having two conv\n",
    "          layers side by side, each seeing half the input channels\n",
    "          and producing half the output channels, and both subsequently\n",
    "          concatenated.\n",
    "        * At groups= :attr:`in_channels`, each input channel is convolved with\n",
    "          its own set of filters (of size\n",
    "          :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\"\"\",\n",
    "\n",
    "        \"depthwise_separable_note\": r\"\"\"When `groups == in_channels` and `out_channels == K * in_channels`,\n",
    "        where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
    "\n",
    "        In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
    "        a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
    "        :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\"\"\"}  # noqa: B950\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class _ConvNd(Module):\n",
    "\n",
    "    __constants__ = ['stride', 'padding', 'dilation', 'groups',\n",
    "                     'padding_mode', 'output_padding', 'in_channels',\n",
    "                     'out_channels', 'kernel_size']\n",
    "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]) -> Tensor:\n",
    "        ...\n",
    "\n",
    "    in_channels: int\n",
    "    _reversed_padding_repeated_twice: List[int]\n",
    "    out_channels: int\n",
    "    kernel_size: Tuple[int, ...]\n",
    "    stride: Tuple[int, ...]\n",
    "    padding: Union[str, Tuple[int, ...]]\n",
    "    dilation: Tuple[int, ...]\n",
    "    transposed: bool\n",
    "    output_padding: Tuple[int, ...]\n",
    "    groups: int\n",
    "    padding_mode: str\n",
    "    weight: Tensor\n",
    "    bias: Optional[Tensor]\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Tuple[int, ...],\n",
    "                 stride: Tuple[int, ...],\n",
    "                 padding: Tuple[int, ...],\n",
    "                 dilation: Tuple[int, ...],\n",
    "                 transposed: bool,\n",
    "                 output_padding: Tuple[int, ...],\n",
    "                 groups: int,\n",
    "                 bias: bool,\n",
    "                 padding_mode: str,\n",
    "                 device=None,\n",
    "                 dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        if groups <= 0:\n",
    "            raise ValueError('groups must be a positive integer')\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        valid_padding_strings = {'same', 'valid'}\n",
    "        if isinstance(padding, str):\n",
    "            if padding not in valid_padding_strings:\n",
    "                raise ValueError(\n",
    "                    \"Invalid padding string {!r}, should be one of {}\".format(\n",
    "                        padding, valid_padding_strings))\n",
    "            if padding == 'same' and any(s != 1 for s in stride):\n",
    "                raise ValueError(\"padding='same' is not supported for strided convolutions\")\n",
    "\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        # `_reversed_padding_repeated_twice` is the padding to be passed to\n",
    "        # `F.pad` if needed (e.g., for non-zero padding types that are\n",
    "        # implemented as two ops: padding + conv). `F.pad` accepts paddings in\n",
    "        # reverse order than the dimension.\n",
    "        if isinstance(self.padding, str):\n",
    "            self._reversed_padding_repeated_twice = [0, 0] * len(kernel_size)\n",
    "            if padding == 'same':\n",
    "                for d, k, i in zip(dilation, kernel_size,\n",
    "                                   range(len(kernel_size) - 1, -1, -1)):\n",
    "                    total_padding = d * (k - 1)\n",
    "                    left_pad = total_padding // 2\n",
    "                    self._reversed_padding_repeated_twice[2 * i] = left_pad\n",
    "                    self._reversed_padding_repeated_twice[2 * i + 1] = (\n",
    "                        total_padding - left_pad)\n",
    "        else:\n",
    "            self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2)\n",
    "\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (in_channels, out_channels // groups, *kernel_size), **factory_kwargs))\n",
    "        else:\n",
    "            self.weight = Parameter(torch.empty(\n",
    "                (out_channels, in_channels // groups, *kernel_size), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_channels, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            if fan_in != 0:\n",
    "                bound = 1 / math.sqrt(fan_in)\n",
    "                init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super().__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'\n",
    "\n",
    "\n",
    "class Conv2d(_ConvNd):\n",
    "    __doc__ = r\"\"\"Applies a 2D convolution over an input signal composed of several input\n",
    "    planes.\n",
    "\n",
    "    In the simplest case, the output value of the layer with input size\n",
    "    :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
    "    can be precisely described as:\n",
    "\n",
    "    .. math::\n",
    "        \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
    "        \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
    "\n",
    "\n",
    "    where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
    "    :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
    "    :math:`H` is a height of input planes in pixels, and :math:`W` is\n",
    "    width in pixels.\n",
    "    \"\"\" + r\"\"\"\n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
    "\n",
    "    * :attr:`stride` controls the stride for the cross-correlation, a single\n",
    "      number or a tuple.\n",
    "\n",
    "    * :attr:`padding` controls the amount of padding applied to the input. It\n",
    "      can be either a string {{'valid', 'same'}} or an int / a tuple of ints giving the\n",
    "      amount of implicit padding applied on both sides.\n",
    "\n",
    "    * :attr:`dilation` controls the spacing between the kernel points; also\n",
    "      known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
    "      has a nice visualization of what :attr:`dilation` does.\n",
    "\n",
    "    {groups_note}\n",
    "\n",
    "    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
    "\n",
    "        - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
    "        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
    "          and the second `int` for the width dimension\n",
    "\n",
    "    Note:\n",
    "        {depthwise_separable_note}\n",
    "\n",
    "    Note:\n",
    "        {cudnn_reproducibility_note}\n",
    "\n",
    "    Note:\n",
    "        ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
    "        the input so the output has the shape as the input. However, this mode\n",
    "        doesn't support any stride values other than 1.\n",
    "\n",
    "    Note:\n",
    "        This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int, tuple or str, optional): Padding added to all four sides of\n",
    "            the input. Default: 0\n",
    "        padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
    "            ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        groups (int, optional): Number of blocked connections from input\n",
    "            channels to output channels. Default: 1\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the\n",
    "            output. Default: ``True``\n",
    "    \"\"\".format(**reproducibility_notes, **convolution_notes) + r\"\"\"\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
    "        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
    "                        \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
    "                        \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
    "\n",
    "    Attributes:\n",
    "        weight (Tensor): the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
    "            :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
    "            The values of these weights are sampled from\n",
    "            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
    "        bias (Tensor):   the learnable bias of the module of shape\n",
    "            (out_channels). If :attr:`bias` is ``True``,\n",
    "            then the values of these weights are\n",
    "            sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> # With square kernels and equal stride\n",
    "        >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "        >>> # non-square kernels and unequal stride and with padding\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "        >>> # non-square kernels and unequal stride and with padding and dilation\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "        >>> input = torch.randn(20, 16, 50, 100)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    .. _cross-correlation:\n",
    "        https://en.wikipedia.org/wiki/Cross-correlation\n",
    "\n",
    "    .. _link:\n",
    "        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: _size_2_t,\n",
    "        stride: _size_2_t = 1,\n",
    "        padding: Union[str, _size_2_t] = 0,\n",
    "        dilation: _size_2_t = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        padding_mode: str = 'zeros',  # TODO: refine this type\n",
    "        device=None,\n",
    "        dtype=None\n",
    "    ) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        kernel_size_ = _pair(kernel_size)\n",
    "        stride_ = _pair(stride)\n",
    "        padding_ = padding if isinstance(padding, str) else _pair(padding)\n",
    "        dilation_ = _pair(dilation)\n",
    "        super().__init__(\n",
    "            in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n",
    "            False, _pair(0), groups, bias, padding_mode, **factory_kwargs)\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "        if self.padding_mode != 'zeros':\n",
    "            return F.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            weight, bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        return F.conv2d(input, weight, bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self._conv_forward(input, self.weight, self.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2823e218-5eb3-44d9-a277-2cf17b772c84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "sys.path.insert(0, \"/helper\")\n",
    "sys.path.insert(0, \"./helper\")\n",
    "sys.path.insert(0, \"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "# own module\n",
    "from visualisation.feature_map import *\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.K = 100 \n",
    "        self.L = 10 # last one\n",
    "        self.num_of_bases = 1 # 3rd dim\n",
    "        \n",
    "        self.conv1 = Conv2d(1, 32, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv2 = Conv2d(32, 64, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv3 = Conv2d(64, 128, kernel_size=3, stride=1, padding=0, dilation=3)\n",
    "        self.conv1x1 = Conv2d(128, 10, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        #self.dropout1 = nn.Dropout(0.25)\n",
    "        #self.dropout2 = nn.Dropout(0.5)\n",
    "        # 4x16384\n",
    "        # self.fc1 = nn.Linear(10*10*10, 10)\n",
    "        #self.fc2 = nn.Linear(10, 10)\n",
    "        \n",
    "        #self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc3 = nn.Linear(10, 10)\n",
    "        \n",
    "        self.mish1 = torch.nn.Mish()\n",
    "        self.mish2 = torch.nn.Mish()\n",
    "        self.mish3 = torch.nn.Mish()\n",
    "        self.mish1x1 = torch.nn.Mish()\n",
    "        \n",
    "        #self.sub_concept_pooling = nn.modules.MaxPool2d((self.K, 1), stride=(1,1))\n",
    "        #self.instance_pooling = nn.modules.MaxPool2d((opt.num_of_bases, 1), stride=(1,1))\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.mish1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.mish2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.mish3(x)\n",
    "        \n",
    "        x = self.conv1x1(x)\n",
    "        x = self.mish1x1(x)\n",
    "        \n",
    "        # print(x.shape)\n",
    "        \n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        #x = self.dropout1(x)\n",
    "        \n",
    "        #print(x.size())\n",
    "        #print(x.size()[2:])\n",
    "        \n",
    "        x = F.max_pool2d(x, kernel_size=x.size()[2:])\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # x = self.flat(x)\n",
    "        \n",
    "        #x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        #x = x.view(-1, self.L, self.K, 10)\n",
    "        \n",
    "        # input, kernel_size, stride, padding, dilation, ceil_mode\n",
    "        #x = self.sub_concept_pooling(x).view(-1, self.L, self.num_of_bases).permute(0,2,1).unsqueeze(1)\n",
    "        \n",
    "        output = F.sigmoid(x)\n",
    "        # x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        #x = torch.flatten(x, 1)\n",
    "        # x = self.fc1(x)\n",
    "        #x = F.relu(x)\n",
    "        \n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.fc2(x)\n",
    "        #output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "        \n",
    "        if batch_idx == -1:\n",
    "            print(data.shape) # torch.Size([4, 1, 28, 28])\n",
    "            print(target)\n",
    "            \"\"\"\n",
    "            tensor([[8],\n",
    "            [7],\n",
    "            [2],\n",
    "            [7]])\n",
    "            \"\"\"\n",
    "            print(target_multi_hot)\n",
    "            \"\"\"\n",
    "            tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "            [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "            [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
    "            \"\"\"\n",
    "        \n",
    "        loss = F.binary_cross_entropy(output, target_multi_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % (args.log_interval*1000) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.unsqueeze(1) # .to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            target_multi_hot = torch.zeros(target.size(0), 10).scatter_(1, target, 1.).to(device)\n",
    "            test_loss += F.binary_cross_entropy(output, target_multi_hot, reduction='mean').item()\n",
    "        \n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device).view_as(pred)).sum().item()\n",
    "            \n",
    "            if i == 0 and epoch % args.log_interval == 0:\n",
    "            # if False: # i == 0:\n",
    "                print(data.shape)\n",
    "                layer = model.conv1x1 # model.conv1[0] # model.stage2[0].branch1[2] # model.fusion_layer # conv\n",
    "                # run feature map\n",
    "                dd = FeatureMap(model=model, layer=layer, device=device, iterations=None, lr=None)\n",
    "                dd.run(data)\n",
    "                dd.plot(path=f\"example_results/feature_map_{epoch}.png\")\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "class Parser():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.test_batch_size = 1\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.1\n",
    "        self.gamma = 0.7\n",
    "        self.log_interval = 5\n",
    "        self.save_model = True\n",
    "        \n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    args = Parser()\n",
    "    \n",
    "    if True:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('example_data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('example_data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader, epoch)\n",
    "        #scheduler.step()\n",
    "        \n",
    "        \n",
    "        if args.save_model and epoch % args.log_interval == 0:\n",
    "            torch.save(model.state_dict(), f\"example_results/mnist_cnn_{epoch}.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da6083-0fe4-4c47-8171-7f010c18b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 3\n",
    "num_classes = 10\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "outputs_before_sigmoid = torch.randn(batch_size, num_classes)\n",
    "sigmoid_outputs = torch.sigmoid(outputs_before_sigmoid)\n",
    "\n",
    "# classes = [[2, 4, 7], [3, 6, 9]]\n",
    "labels = torch.tensor([[1], [9], [4]])\n",
    "# labels = labels.unsqueeze(0)\n",
    "target_classes = torch.zeros(labels.size(0), 10).scatter_(1, labels, 1.)\n",
    "\n",
    "\n",
    "# target_classes = torch.randint(0, 2, (batch_size, num_classes)).to(torch.float32)  # randints in [0, 2).\n",
    "\n",
    "loss = loss_fn(sigmoid_outputs, target_classes)\n",
    "\n",
    "# alternatively, use BCE with logits, on outputs before sigmoid.\n",
    "loss_fn_2 = torch.nn.BCEWithLogitsLoss()\n",
    "loss2 = loss_fn_2(outputs_before_sigmoid, target_classes)\n",
    "\n",
    "print(sigmoid_outputs)\n",
    "\n",
    "print(target_classes)\n",
    "\n",
    "print(loss)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591608c7-afbb-48fc-9a02-9da08a3e8fd1",
   "metadata": {},
   "source": [
    "# Multilabel\n",
    "https://github.com/rhgao/Deep-MIML-Network/blob/master/models/MIML.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d95199-2872-42d5-bdbc-23b11bdecc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from .base_model import BaseModel\n",
    "from . import networks\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "class MIMLModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'MIMLModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseModel.initialize(self, opt)\n",
    "        self.isTrain = opt.isTrain\n",
    "\n",
    "        if opt.using_multi_labels:\n",
    "            self.label = self.Tensor(opt.batchSize, opt.L)\n",
    "        else:\n",
    "            self.label = self.Tensor(opt.batchSize)\n",
    "        self.bases = self.Tensor(opt.batchSize, opt.F, opt.num_of_bases)\n",
    "\n",
    "        self.BasesNet = networks.BasesNet(opt)\n",
    "        self.sub_concept_pooling = nn.modules.MaxPool2d((opt.K, 1), stride=(1,1))\n",
    "        self.instance_pooling = nn.modules.MaxPool2d((opt.num_of_bases,1), stride=(1,1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if opt.using_multi_labels:\n",
    "            self.loss = nn.MultiLabelMarginLoss()\n",
    "        else:\n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        if(len(opt.gpu_ids)>0):\n",
    "            self.BasesNet.cuda(opt.gpu_ids[0])\n",
    "            self.sub_concept_pooling.cuda(opt.gpu_ids[0])\n",
    "            self.instance_pooling.cuda(opt.gpu_ids[0])\n",
    "            self.softmax.cuda(opt.gpu_ids[0])\n",
    "            self.sigmoid.cuda(opt.gpu_ids[0])\n",
    "            self.loss.cuda(opt.gpu_ids[0])\n",
    "\n",
    "        networks.init_weights(self.BasesNet, self.opt.init_type)\n",
    "\n",
    "        if(self.isTrain):\n",
    "            if opt.using_multi_labels:\n",
    "                self.optimizer = optim.Adam(list(self.BasesNet.parameters()), lr=opt.learning_rate, weight_decay=0.00001)\n",
    "            else:\n",
    "                self.optimizer = optim.Adam(list(self.BasesNet.parameters()), lr=opt.learning_rate, weight_decay=0.00001)\n",
    "        else:\n",
    "            self.BasesNet.eval()\n",
    "\n",
    "        self.batch_loss = []\n",
    "        self.batch_accuracy = []\n",
    "        self.batch_ap = []\n",
    "\n",
    "    def forward(self, input, volatile=False):\n",
    "        bases = input['bases'].unsqueeze(3) #add another dimension for 2D convolution, a trick to replace fc with 1x1conv\n",
    "        label = input['label']\n",
    "        self.bases.resize_(bases.size()).copy_(bases)\n",
    "        self.label.resize_(label.size()).copy_(label)\n",
    "\n",
    "        #print(self.bases.size())\n",
    "        # shape: (batchSize, L*K, num_of_bases)\n",
    "        basesnet_output = self.BasesNet(Variable(self.bases, requires_grad=False, volatile=volatile)).view(-1, self.opt.L, self.opt.K, self.opt.num_of_bases)\n",
    "        #print(\"sub_concept_layer_output:\",basesnet_output.size())\n",
    "        # shape: (batchSize, L, K, num_of_bases)\n",
    "        sub_concept_pooling_output = self.sub_concept_pooling(basesnet_output).view(-1, self.opt.L, self.opt.num_of_bases).permute(0,2,1).unsqueeze(1)\n",
    "        #print(\"sub_concept_pooling_output:\",sub_concept_pooling_output.size())\n",
    "        #softmax\n",
    "        if self.opt.with_softmax:\n",
    "            softmax_normalization_output = self.softmax(sub_concept_pooling_output)\n",
    "            self.output = self.instance_pooling(softmax_normalization_output).view(-1, self.opt.L)\n",
    "        else:\n",
    "            self.output = self.instance_pooling(sub_concept_pooling_output).view(-1, self.opt.L)\n",
    "\n",
    "    def getInstanceLabelRelation(self, input, volatile=True):\n",
    "        bases = input['bases'].unsqueeze(3) #add another dimension for 2D convolution, a trick to replace fc with 1x1conv\n",
    "        label = input['label']\n",
    "        self.bases.resize_(bases.size()).copy_(bases)\n",
    "        self.label.resize_(label.size()).copy_(label)\n",
    "\n",
    "        basesnet_output = self.BasesNet(Variable(self.bases, requires_grad=False, volatile=volatile)).view(-1, self.opt.L, self.opt.K, self.opt.num_of_bases)\n",
    "        instanceLabelRelation = self.sub_concept_pooling(basesnet_output).view(-1, self.opt.L, self.opt.num_of_bases).permute(0,2,1)\n",
    "        if self.opt.using_multi_labels:\n",
    "            self.output = self.instance_pooling(instanceLabelRelation.unsqueeze(1)).view(-1, self.opt.L)\n",
    "            prediction = np.zeros(self.output.size())\n",
    "            gt_label = np.zeros(self.output.size())\n",
    "            max_label = self.output.max(dim=1)[1].data\n",
    "            for i in range(gt_label.shape[0]):\n",
    "                prediction[i,max_label[i]] = 1\n",
    "            prediction[self.softmax(self.output).data.cpu().numpy() >= 0.3] = 1\n",
    "            for index, x in np.ndenumerate(self.label.cpu().numpy()):\n",
    "                if x == -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    gt_label[index[0],int(x)] = 1\n",
    "            return self.softmax(instanceLabelRelation).data.cpu().numpy(), gt_label, prediction\n",
    "        else:\n",
    "            if self.opt.with_softmax:\n",
    "                self.output = self.instance_pooling(self.softmax(instanceLabelRelation).unsqueeze(1)).view(-1, self.opt.L)\n",
    "            else:\n",
    "                self.output = self.instance_pooling(instanceLabelRelation.unsqueeze(1)).view(-1, self.opt.L)\n",
    "            prediction = self.output.max(dim=1)[1].data.float()\n",
    "            return self.softmax(instanceLabelRelation).data.cpu().numpy(), label, prediction\n",
    "\n",
    "    def decrease_learning_rate(self, times, factor):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.opt.learning_rate * pow(factor, times)\n",
    "        print(\"current learning rate:\",self.opt.learning_rate * pow(factor, times))\n",
    "\n",
    "    def backward(self):\n",
    "        if self.opt.using_multi_labels:\n",
    "            label = Variable(self.label, requires_grad=False).long()\n",
    "            prediction = np.zeros(self.output.size())\n",
    "            #construt ground-truth label to compute mAP\n",
    "            gt_label = np.zeros(self.output.size())\n",
    "            max_label = self.output.max(dim=1)[1].data\n",
    "            for i in range(gt_label.shape[0]):\n",
    "                prediction[i,max_label[i]] = 1\n",
    "            prediction[self.softmax(self.output).data.cpu().numpy() >= 0.3] = 1\n",
    "            for index, x in np.ndenumerate(self.label.cpu().numpy()):\n",
    "                if x == -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    gt_label[index[0],int(x)] = 1\n",
    "            ap = average_precision_score(gt_label.T, prediction.T)\n",
    "            self.batch_ap.append(ap)\n",
    "        else:\n",
    "            label = Variable(self.label, requires_grad=False).long()\n",
    "            prediction = self.output.max(dim=1)[1].data.float()\n",
    "            correct = (self.label.eq(prediction)).sum()\n",
    "            accuracy = correct*1.0/self.label.size()[0]\n",
    "            self.batch_accuracy.append(accuracy)\n",
    "        loss = self.loss(self.output, label)\n",
    "        self.batch_loss.append(loss.data[0]) \n",
    "        loss.backward()\n",
    "\n",
    "    def display_train(self, writer, index):\n",
    "        loss = sum(self.batch_loss)/len(self.batch_loss)\n",
    "        writer.add_scalar('data/loss', loss, index)\n",
    "        print('loss: ' + str(loss))\n",
    "        self.batch_loss = []\n",
    "        if self.opt.using_multi_labels:\n",
    "            ap = sum(self.batch_ap)/len(self.batch_ap)\n",
    "            writer.add_scalar('data/mAP', ap, index)\n",
    "            print('mAP: ' + str(ap))\n",
    "            self.batch_ap = []\n",
    "        else:\n",
    "            accuracy = sum(self.batch_accuracy)/len(self.batch_accuracy)\n",
    "            writer.add_scalar('data/accuracy', accuracy, index)\n",
    "            print('accuracy: ' + str(accuracy))\n",
    "            self.batch_accuracy = []\n",
    "\n",
    "    def display_val(self, writer, index, dataset_val):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        aps = []\n",
    "        for i, val_data in enumerate(dataset_val):\n",
    "            if i >= self.opt.validation_batches:\n",
    "                break\n",
    "            if self.opt.using_multi_labels:\n",
    "                ap, loss = self.test_multi_label(val_data)\n",
    "                aps.append(ap)\n",
    "            else:\n",
    "                accuracy,loss = self.test(val_data)\n",
    "                accuracies.append(accuracy)\n",
    "            losses.append(loss)\n",
    "        if self.opt.using_multi_labels:\n",
    "            ap = sum(aps) / len(aps)\n",
    "            writer.add_scalar('data/val_mAP', ap, index)\n",
    "            print('validation mAP is: ' + str(ap))\n",
    "        else:\n",
    "            accuracy = sum(accuracies)/len(accuracies)\n",
    "            writer.add_scalar('data/val_accuracy', accuracy, index)\n",
    "            print('validation accuracy is: ' + str(accuracy))\n",
    "        loss = sum(losses)/len(losses)\n",
    "        writer.add_scalar('data/val_loss', loss, index)\n",
    "        print('validation loss is: ' + str(loss))\n",
    "\n",
    "    def test(self, input):\n",
    "        self.forward(input, volatile=True)\n",
    "        prediction = self.output.max(dim=1)[1].data.float()\n",
    "        correct = (self.label.eq(prediction)).sum()\n",
    "        accuracy = correct*1.0/self.label.size()[0]\n",
    "        label = Variable(self.label.long(), requires_grad=False)\n",
    "        loss = self.loss(self.output, label).data.cpu().numpy()[0]\n",
    "        return accuracy, loss\n",
    "\n",
    "    def test_multi_label(self, input):\n",
    "        self.forward(input, volatile=True)\n",
    "        prediction = np.zeros(self.output.size())\n",
    "        gt_label = np.zeros(self.output.size())\n",
    "        max_label = self.output.max(dim=1)[1].data\n",
    "        for i in range(gt_label.shape[0]):\n",
    "            prediction[i,max_label[i]] = 1\n",
    "        prediction[self.softmax(self.output).data.cpu().numpy() >= 0.3] = 1\n",
    "        for index, x in np.ndenumerate(self.label.cpu().numpy()):\n",
    "            if x == -1:\n",
    "                continue\n",
    "            else:\n",
    "                gt_label[index[0],int(x)] = 1\n",
    "        ap = average_precision_score(gt_label.T, prediction.T)\n",
    "        label = Variable(self.label, requires_grad=False).long()\n",
    "        loss = self.loss(self.output, label).data.cpu().numpy()[0]\n",
    "        return ap, loss\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        self.backward()\n",
    "        self.optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
