{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfb8504-579a-470c-a65e-55e3406af507",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "https://github.com/hsiangyuzhao/Segmentation-Metrics-PyTorch/blob/master/metric.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3cb1be0-47a5-48b4-a946-bfcf8727e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../helper', './helper', '/helper', 'helper', 'C:\\\\Users\\\\Prinzessin\\\\projects\\\\decentnet\\\\datasceyence\\\\examples', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\python39.zip', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\DLLs', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta', '', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Prinzessin\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "import unittest\n",
    "\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, r\"helper\")\n",
    "sys.path.insert(0, r\"/helper\")\n",
    "sys.path.insert(0, r\"./helper\")\n",
    "sys.path.insert(0, r\"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "\n",
    "from dataset.meanteacher import *\n",
    "\n",
    "# relevant: import the UncertaintyMetric\n",
    "from compute.metric.segmentation import * \n",
    "from compute.metric.symmetric_hausdorff import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e321bb-900a-441b-804a-92e00a494aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next batch\n",
      "pred torch.Size([2, 512, 512])\n",
      "msk torch.Size([1, 512, 512])\n",
      "high torch.Size([2, 512])\n",
      "pred torch.Size([2, 512, 512])\n",
      "msk torch.Size([1, 512, 512])\n",
      "high torch.Size([2, 512])\n",
      "pred torch.Size([2, 512, 512])\n",
      "msk torch.Size([1, 512, 512])\n",
      "high torch.Size([2, 512])\n",
      "pred torch.Size([2, 512, 512])\n",
      "msk torch.Size([1, 512, 512])\n",
      "high torch.Size([2, 512])\n",
      "pred torch.Size([2, 512, 512])\n",
      "msk torch.Size([1, 512, 512])\n",
      "high torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "# preparation\n",
    "channels = 1\n",
    "n_output_neurons=2\n",
    "model = smp.UnetPlusPlus(\n",
    "                    encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                    encoder_weights=\"imagenet\",  # use `imagenet` pre-trained weights for encoder initialization\n",
    "                    in_channels=channels,          # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                    classes=n_output_neurons,         # model output channels (number of classes in your dataset)\n",
    "                )\n",
    "csv_filenames = glob.glob(r\"../data_prep/mt_*.csv\")\n",
    "# image size has to be dividable by 32!!\n",
    "dataset = MeanTeacherTrainDataset(mode=\"train\", channels=channels, image_size=512, csv_filenames=csv_filenames)\n",
    "train_loader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# relevant: create instance of class\n",
    "s = SegmentationMetrics()\n",
    "symhd = SymmetricHausdorffMetric()\n",
    "\n",
    "model_output = None\n",
    "# load one batch\n",
    "\n",
    "model_output_area = []\n",
    "ground_truth_area = []\n",
    "\n",
    "for idx, item in enumerate(train_loader):\n",
    "    \n",
    "    print(\"next batch\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model_output = model(item[\"img\"])\n",
    "\n",
    "        \n",
    "        # item[\"msk\"][0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        model_output_noise = model_output * item[\"msk\"]\n",
    "        \n",
    "        for msk, pred in zip(item[\"msk\"], model_output_noise):\n",
    "            \n",
    "            print(\"pred\", pred.shape)\n",
    "            print(\"msk\", msk.shape)\n",
    "            \n",
    "            _, highest_class = torch.max(pred, 1)  \n",
    "            \n",
    "            print(\"high\", highest_class.shape)\n",
    "\n",
    "            model_output_area.append(torch.sum(highest_class))\n",
    "\n",
    "            ground_truth_area.append(torch.sum(msk))\n",
    "\n",
    "    \n",
    "\n",
    "    if idx == 0:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c2b6f11-8d39-4e47-9e40-793a7aee7260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8981961441702951, 'fscore': 0.9455074572770071, 'prec': 0.8981961435495224, 'rec': 0.9980800245771599}\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512, 512])\n",
      "8.18535277187245\n",
      "8.774964387392123\n",
      "8.831760866327848\n",
      "0.0\n",
      "0.0\n",
      "5.158415605118484\n"
     ]
    }
   ],
   "source": [
    "# model_output_noise = model_output * item[\"msk\"]\n",
    "\n",
    "#print(model_output)\n",
    "\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "    \n",
    "print(s(y_true=item[\"msk\"], y_pred=model_output_noise))\n",
    "print(symhd(model_output_noise, item[\"msk\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baa80ac4-b362-455b-b683-14913fc2fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow( item[\"msk\"][0].permute(1, 2, 0).detach().cpu().numpy(), cmap=\"gray\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae7a138c-7ad2-4bec-b142-63592bc5b273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb1b6d-438d-445b-b585-7dc9353d1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_output.shape)\n",
    "\n",
    "_, highest_class = torch.max(model_output_noise, 1)   \n",
    "# highest_class = highest_class.detach().cpu().numpy()\n",
    "\n",
    "print(highest_class.shape)\n",
    "\n",
    "#redo = highest_class.permute(1, 2, 0)\n",
    "print(highest_class[0].shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(highest_class[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eff04e-20f1-4666-9bac-6af7dc01bb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af289db-d12d-485e-ab8e-adb830c14e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "max_num = max(max(model_output_area), max(ground_truth_area))\n",
    "\n",
    "c = [abs(ele1 - ele2) for ele1, ele2 in zip(model_output_area, ground_truth_area)]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"predicted area\")\n",
    "plt.ylabel(\"ground truth area\")\n",
    "plt.scatter(model_output_area, ground_truth_area, c=c, cmap='cool')\n",
    "plt.plot([0, max_num], [0, max_num], color = 'k')\n",
    "\n",
    "plt.savefig(\"example_results/area.png\", dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6d483-6dfe-46d9-b77c-7c6839390b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
