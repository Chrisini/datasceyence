{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd6dd50-e494-4d07-8969-4e1b97d32d8c",
   "metadata": {},
   "source": [
    "# 𝕃𝕠𝕤𝕤 𝕗𝕦𝕟𝕔𝕥𝕚𝕠𝕟𝕤 𝕗𝕠𝕣 𝕠𝕣𝕕𝕚𝕟𝕒𝕝 𝕣𝕖𝕘𝕣𝕖𝕤𝕤𝕚𝕠𝕟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd1addd-d3b8-4bdd-95f3-1f5b8434c3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../helper', './helper', '/helper', 'helper', '../helper', './helper', '/helper', 'helper', '../helper', './helper', '/helper', 'helper', 'C:\\\\Users\\\\Prinzessin\\\\projects\\\\ogygia_torch\\\\medical_ai\\\\examples', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\python39.zip', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\DLLs', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta', '', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Prinzessin\\\\anaconda3\\\\envs\\\\feta\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Prinzessin\\\\.ipython']\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "import unittest\n",
    "# test data\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# \"helper\" needs to be part of sys path\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "sys.path.insert(0, \"/helper\")\n",
    "sys.path.insert(0, \"./helper\")\n",
    "sys.path.insert(0, \"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own module\n",
    "from compute.loss import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0c0d57-8ebd-4023-8936-cba00ea429d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitTestLoss(unittest.TestCase):\n",
    "    \n",
    "    def test_kappa_loss(self):\n",
    "        # =============================================================================\n",
    "        # testing the Kappa loss function\n",
    "        # =============================================================================\n",
    "        n_classes = 3\n",
    "        criterion = KappaLoss(n_classes=n_classes)\n",
    "\n",
    "        # batch, dim1 (data)\n",
    "        model_outputs = [torch.tensor([[-0.1, -0.1, 5], [4, -0.1, -0.1], [-0.1, 6, -0.1], [-0.1, -0.1, 3]]), # good\n",
    "                         torch.tensor([[0.1, 0.1, 0.9], [0.9, 0.1, 0.1], [0.1, 0.9, 0.1], [0.1, 0.1, 0.9]]), # middle\n",
    "                         torch.tensor([[5, 0.1, 0.9], [0.9, 3, 0.1], [0.1, -0.3, 0.7], [0.7, 0.1, 0.1]])  # bad\n",
    "                        ]\n",
    "\n",
    "        ground_truth = torch.tensor([2, 0, 1, 2])\n",
    "\n",
    "        print('='*50)\n",
    "        print(\"Kappa Loss\")\n",
    "        for model_output in model_outputs:\n",
    "            loss = criterion(model_output=model_output, ground_truth=ground_truth)\n",
    "            print(round(loss.item(), 3))\n",
    "            \n",
    "    def test_cdw_loss_v1(self):\n",
    "        # =============================================================================\n",
    "        # testing the Class Distance Weighted loss function\n",
    "        # which version is most efficient - check for 100 loops e.g.\n",
    "        # =============================================================================\n",
    "        n_classes = 3\n",
    "        criterion = CDWLossChrisy(n_classes=n_classes)\n",
    "\n",
    "        # batch, dim1 (data)\n",
    "        model_outputs = [  torch.tensor([[-0.1, -0.1, 5], [4, -0.1, -0.1], [-0.1, 6, -0.1], [-0.1, -0.1, 3]]), # good\n",
    "                            torch.tensor([[0.1, 0.1, 0.9], [0.9, 0.1, 0.1], [0.1, 0.9, 0.1], [0.1, 0.1, 0.9]]), # middle\n",
    "                            torch.tensor([[5, 0.1, 0.9], [0.9, 3, 0.1], [0.1, -0.3, 0.7], [0.7, 0.1, 0.1]])  # bad\n",
    "        ]\n",
    "\n",
    "        ground_truth = torch.tensor([2, 0, 1, 2])\n",
    "\n",
    "        print('='*50)\n",
    "        print(\"Class Weighted Distance 1\")\n",
    "        for model_output in model_outputs:\n",
    "            loss = criterion(model_output=model_output, ground_truth=ground_truth)\n",
    "            print(round(loss.item(), 3))\n",
    "            \n",
    "    def test_cdw_loss_v1_1(self):\n",
    "        # =============================================================================\n",
    "        # testing the loss function\n",
    "        # =============================================================================\n",
    "        n_classes = 3\n",
    "        criterion = CDWLossRam(n_classes=n_classes)\n",
    "\n",
    "        # batch, dim1 (data)\n",
    "        model_outputs = [  torch.tensor([[-0.1, -0.1, 5], [4, -0.1, -0.1], [-0.1, 6, -0.1], [-0.1, -0.1, 3]]), # good\n",
    "                            torch.tensor([[0.1, 0.1, 0.9], [0.9, 0.1, 0.1], [0.1, 0.9, 0.1], [0.1, 0.1, 0.9]]), # middle\n",
    "                            torch.tensor([[5, 0.1, 0.9], [0.9, 3, 0.1], [0.1, -0.3, 0.7], [0.7, 0.1, 0.1]])  # bad\n",
    "        ]\n",
    "\n",
    "        ground_truth = torch.tensor([2, 0, 1, 2])\n",
    "        \n",
    "        print('='*50)\n",
    "        print(\"Class Weighted Distance 1.1\")\n",
    "        for model_output in model_outputs:\n",
    "            loss = criterion(model_output=model_output, ground_truth=ground_truth)\n",
    "            print(round(loss.item(), 3))\n",
    "            \n",
    "    def test_cdw_loss_v2(self):\n",
    "        # =============================================================================\n",
    "        # testing the loss function\n",
    "        # this implementation has better results for the bad result\n",
    "        # =============================================================================\n",
    "\n",
    "        n_classes = 3\n",
    "        criterion = ClassDistanceWeightedLoss(n_classes=n_classes)\n",
    "        \n",
    "        # batch, dim1 (data)\n",
    "        model_outputs = [ torch.tensor([[-0.1, -0.1, 5], [4, -0.1, -0.1], [-0.1, 6, -0.1], [-0.1, -0.1, 3]]), # good\n",
    "                          torch.tensor([[0.1, 0.1, 0.9], [0.9, 0.1, 0.1], [0.1, 0.9, 0.1], [0.1, 0.1, 0.9]]), # middle\n",
    "                          torch.tensor([[5, 0.1, 0.9], [0.9, 3, 0.1], [0.1, -0.3, 0.7], [0.7, 0.1, 0.1]])  # bad\n",
    "        ]\n",
    "\n",
    "        ground_truth = torch.tensor([2, 0, 1, 2])\n",
    "\n",
    "        print('='*50)\n",
    "        print(\"Class Weighted Distance 2\")\n",
    "        for model_output in model_outputs:\n",
    "            loss = criterion(model_output=model_output, ground_truth=ground_truth)\n",
    "            print(round(loss.item(), 3))\n",
    "            \n",
    "    def test_corn(self):\n",
    "        # =============================================================================\n",
    "        # testing the loss function\n",
    "        # 3 classes, 2 outputs!!!\n",
    "        # =============================================================================\n",
    "        n_classes = 3\n",
    "        criterion = CornLoss(n_classes=n_classes)\n",
    "\n",
    "        # batch, dim1 (data, with 2 output neurons but 3 classes)\n",
    "        model_outputs = [ torch.tensor([[2, 1], [-0.3, 0.0], [0.8, 0.1], [2, 0.8]]), # good\n",
    "                          torch.tensor([[0.1, 0.8], [0.1, 0.7], [0.8, 0.2], [0.7, 0.8]]), # mid\n",
    "                          torch.tensor([[0.2, 0.1], [2, 0.7], [0.7, 0.8], [0.0, 0.3]]) # bad\n",
    "        ]\n",
    "        \n",
    "        ground_truth = torch.tensor([2, 0, 1, 2])\n",
    "        \n",
    "        print('='*50)\n",
    "        print(\"CORN\")\n",
    "        print(\"GrTr label\", ground_truth)\n",
    "        for model_output in model_outputs:\n",
    "            m = criterion.get_predicted_label(model_output)\n",
    "            print(\"pred label\", m)\n",
    "            loss = criterion(model_output=model_output, ground_truth=ground_truth)\n",
    "            print(\"loss\", round(loss.item(), 3))\n",
    "            \n",
    "            \n",
    "    def test_cross_entropy(self):\n",
    "        \n",
    "        # Example of target with class indices\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        # batch, dim1 (data)\n",
    "        model_outputs = [ torch.tensor([[-0.1, -0.1, 5], [4, -0.1, -0.1], [-0.1, 6, -0.1], [-0.1, -0.1, 3]]), # good\n",
    "                          torch.tensor([[0.1, 0.1, 0.9], [0.9, 0.1, 0.1], [0.1, 0.9, 0.1], [0.1, 0.1, 0.9]]), # middle\n",
    "                          torch.tensor([[5, 0.1, 0.9], [0.9, 3, 0.1], [0.1, -0.3, 0.7], [0.7, 0.1, 0.1]])  # bad\n",
    "        ]\n",
    "\n",
    "        ground_truth = torch.tensor([2, 0, 1, 2])\n",
    "        \n",
    "\n",
    "        print('='*50)\n",
    "        print(\"Cross Entropy Loss\")\n",
    "\n",
    "        for model_output in model_outputs:\n",
    "            loss = criterion(model_output, ground_truth)\n",
    "            print(round(loss.item(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f49d733-23c5-405e-afd3-aec92358aa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.041s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Class Weighted Distance 1\n",
      "0.027\n",
      "0.383\n",
      "1.756\n",
      "==================================================\n",
      "Class Weighted Distance 1.1\n",
      "0.027\n",
      "0.383\n",
      "1.756\n",
      "==================================================\n",
      "Class Weighted Distance 2\n",
      "0.082\n",
      "1.148\n",
      "5.268\n",
      "==================================================\n",
      "CORN\n",
      "GrTr label tensor([2, 0, 1, 2])\n",
      "pred label tensor([2, 0, 1, 2])\n",
      "loss 0.373\n",
      "pred label tensor([1, 1, 1, 1])\n",
      "loss 0.529\n",
      "pred label tensor([1, 2, 1, 0])\n",
      "loss 0.884\n",
      "==================================================\n",
      "Cross Entropy Loss\n",
      "0.034\n",
      "0.641\n",
      "2.345\n",
      "==================================================\n",
      "Kappa Loss\n",
      "0.059\n",
      "0.716\n",
      "1.281\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7b560-af54-4e90-8263-71a03d547e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
