{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407cdac5-a23c-47a5-90d2-ae266fe84842",
   "metadata": {},
   "source": [
    "# Domain Adaptation with filters\n",
    "\n",
    "* [ ] need to track time \n",
    "\n",
    "other ideas: histogram matching, colour matching, intensity matching, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8934c-d9a7-4a72-922a-9adcadd97109",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 300\n",
    "\n",
    "import fda\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from timeit import default_timer\n",
    "# from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d as extract_patches\n",
    "\n",
    "from skimage.util import view_as_windows, random_noise\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from art2 import *\n",
    "from art2.style_transfer import *\n",
    "from art2.pca_nn import * \n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e724a58-3992-4a21-9c5e-a3718f5c8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_fundus(img, msk):\n",
    "    \n",
    "    # todo - resize to standard size at the start?? - keep dimensions\n",
    "    \n",
    "    if True:\n",
    "        gray = img.mean(axis=0).mean(axis=0) \n",
    "    else:\n",
    "        gray = (0,0,0)\n",
    "    \n",
    "    # image, recolour black part\n",
    "    img = cv2.copyMakeBorder(img, 400, 400, 400, 400, cv2.BORDER_CONSTANT, None, value = gray)\n",
    "    img[np.where((img==[0,0,0]).all(axis=2))] = gray\n",
    "\n",
    "    # get center point of RoI\n",
    "    msk = cv2.copyMakeBorder(msk, 400, 400, 400, 400, cv2.BORDER_REPLICATE)\n",
    "    msk = cv2.cvtColor(msk, cv2.COLOR_BGR2GRAY)\n",
    "    num_labels, labels_im = cv2.findContours(msk, cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)    \n",
    "    if len(num_labels) > 0:\n",
    "        max_area = max(num_labels, key = cv2.contourArea)\n",
    "        cv2.drawContours(msk,[max_area],0,255,-1)\n",
    "        # print(max_area)\n",
    "    # calculate moments of binary image\n",
    "    M = cv2.moments(msk)\n",
    "    # calculate x, y coordinate of center\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(msk, cmap=\"gray\")\n",
    "    plt.plot(cX, cY, 'ro', lw=3) \n",
    "    \n",
    "    # crop\n",
    "    img = img[cY-700:cY+700, cX-700:cX+700]\n",
    "    msk = msk[cY-700:cY+700, cX-700:cX+700]\n",
    "\n",
    "    # resize\n",
    "    img = cv2.resize(img, (im_size, im_size), interpolation = cv2.INTER_AREA)\n",
    "    msk = cv2.resize(msk, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "    \n",
    "    return img, msk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae205d9-f635-4bd8-81cb-f610b1d974f7",
   "metadata": {},
   "source": [
    "# Fourier Domain Adaption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f127f-7349-4736-b0bf-3acf51a381de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read source and target images\n",
    "if False:\n",
    "    domain1_img = cv2.imread(r'C:\\Users\\Prinzessin\\projects\\image_data\\iChallenge_AMD_OD_Fovea_lesions\\images_Non-AMD\\N0002.jpg')\n",
    "    domain1_msk = cv2.imread(r'C:\\Users\\Prinzessin\\projects\\image_data\\iChallenge_AMD_OD_Fovea_lesions\\Disc_Masks_bin\\N0002.bmp')\n",
    "    domain1_img, domain1_msk = crop_fundus(domain1_img, domain1_msk)\n",
    "else:\n",
    "    domain1_img = cv2.imread('example_data/texture/ple.tif')\n",
    "    domain1_img = cv2.resize(domain1_img, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "\n",
    "domain2_img = cv2.imread('example_data/texture/cir.tif')\n",
    "domain2_img = cv2.resize(domain2_img, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "\n",
    "\n",
    "# Perform domain adaptation\n",
    "if True:\n",
    "    adapted_im1 = fda.fda(domain1_img, domain2_img, beta=0.005)\n",
    "    adapted_im2 = fda.fda(domain2_img, domain1_img, beta=0.005)\n",
    "else:\n",
    "    adapted_im1 = domain1_img\n",
    "    adapted_im2 = domain2_img\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93cd68d-5d34-4a92-9704-f71709472b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "figure, axis = plt.subplots(1, 7, figsize=(25, 5))\n",
    "i = 0\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "axis[i].set_title(\"domain 1\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain2_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "axis[i].set_title(\"domain 2\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(adapted_im1.astype(np.uint8), cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "axis[i].set_title(\"D1 content + D2 style\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(adapted_im2.astype(np.uint8), cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "axis[i].set_title(\"D2 content + D1 style\")\n",
    "i+=1\n",
    "\n",
    "diff2 = 255 - cv2.absdiff(cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY), cv2.cvtColor(adapted_im1.astype(np.uint8), cv2.COLOR_BGR2GRAY))\n",
    "diff2 = cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY) - cv2.cvtColor(adapted_im1.astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "                                                                     \n",
    "axis[i].imshow(diff2, cmap=\"gray\")\n",
    "axis[i].set_title(\"Difference 1\")\n",
    "i+=1\n",
    "\n",
    "diff = 255 - cv2.absdiff(cv2.cvtColor(domain2_img, cv2.COLOR_BGR2GRAY), cv2.cvtColor(adapted_im2.astype(np.uint8), cv2.COLOR_BGR2GRAY))\n",
    "axis[i].imshow(diff, cmap=\"gray\")\n",
    "axis[i].set_title(\"Difference 2\")\n",
    "i+=1\n",
    "\n",
    "\n",
    "\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import normalized_mutual_information\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute SSIM between two images\n",
    "(score, diff) = structural_similarity(   cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY), cv2.cvtColor(adapted_im1.astype(np.uint8), cv2.COLOR_BGR2GRAY)   , full=True)\n",
    "# The diff image contains the actual image differences between the two images\n",
    "# and is represented as a floating point data type in the range [0,1] \n",
    "# so we must convert the array to 8-bit unsigned integers in the range\n",
    "# [0,255] before we can use it with OpenCV\n",
    "diff = (diff * 255).astype(\"uint8\")\n",
    "axis[i].imshow(diff, cmap=\"gray\")\n",
    "axis[i].set_title(\"structural sim\")\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a43c5-60c5-41fb-8402-46944987105c",
   "metadata": {},
   "source": [
    "# Style Transfer Using Texture Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605851f5-50ed-426e-a677-27ee21dac6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1609.03057.pdf https://github.com/DarkGeekMS/artistic-style-transfer-using-texture-synthesis/blob/master/src/style_transfer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3192f-d170-4c73-9973-6a81784fa46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_im = cv2.imread('example_data/AMD/A0001.jpg') \n",
    "#source_im = cv2.imread(r'C:\\Users\\Prinzessin\\projects\\image_data\\iChallenge_AMD_OD_Fovea_lesions\\images_Non-AMD\\N0067.jpg') # example_data/nonAMD/N0002.jpg') \n",
    "#source_im = cv2.imread('example_data/texture/ple.tif')\n",
    "#source_im = cv2.imread('example_data/texture/cir.tif')\n",
    "#target_im = cv2.imread('example_data/texture/cir.tif')\n",
    "#target_im = cv2.imread('example_data/texture/ple.tif')\n",
    "\n",
    "# output_img = style_transfer(source_im, t, num_pyramid_layers=3, patch_sizes=(50, 40, 30), patch_spacings=(10, 10, 10), num_iters=3, num_irls_iters=10, max_pixel_val=255)\n",
    "# num_pyramid_layers=3, patch_sizes=(33, 21, 13, 9), patch_spacings=(28, 18, 8, 5), num_iters=3, num_irls_iters=10, max_pixel_val=255\n",
    "\n",
    "\n",
    "# Read source and target images    \n",
    "if True:\n",
    "    domain1_img = cv2.imread(r'C:\\Users\\Prinzessin\\projects\\image_data\\iChallenge_AMD_OD_Fovea_lesions\\images_Non-AMD\\N0002.jpg')\n",
    "    domain1_msk = cv2.imread(r'C:\\Users\\Prinzessin\\projects\\image_data\\iChallenge_AMD_OD_Fovea_lesions\\Disc_Masks_bin\\N0002.bmp')\n",
    "    domain1_img, domain1_msk = crop_fundus(domain1_img, domain1_msk)\n",
    "    c_domain1_img = domain1_img\n",
    "else:\n",
    "    domain1_img = cv2.imread('example_data/texture/ple.tif')\n",
    "    domain1_img = cv2.resize(domain1_img, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "    c_domain1_img = domain1_img.copy()\n",
    "    c_domain1_img[:,:,0] = domain1_img[:,:,0] * 1.1 # if all channels have same value it does weird stuff\n",
    "    c_domain1_img[:,:,1] = domain1_img[:,:,2] * 0.9 # if all channels have same value it does weird stuff\n",
    "\n",
    "domain2_img = cv2.imread('example_data/texture/cir.tif')\n",
    "domain2_img = cv2.resize(domain2_img, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "c_domain2_img = domain2_img.copy()\n",
    "c_domain2_img[:,:,0] = c_domain2_img[:,:,0] * 1.1 # if all channels have same value it does weird stuff\n",
    "c_domain2_img[:,:,1] = c_domain2_img[:,:,2] * 0.9 # if all channels have same value it does weird stuff\n",
    "\n",
    "\n",
    "# Perform domain adaptation\n",
    "if True:\n",
    "    adapted_im1 = style_transfer(domain1_img, c_domain2_img, num_pyramid_layers=2, patch_sizes=(40,30,20), patch_spacings=(10, 10, 10), num_iters=3, num_irls_iters=3, max_pixel_val=255, im_size=im_size)\n",
    "    print(\"done adapted_im1\")\n",
    "    adapted_im2 = style_transfer(domain2_img, c_domain1_img, num_pyramid_layers=2, patch_sizes=(40,30,20), patch_spacings=(10, 10, 10), num_iters=3, num_irls_iters=3, max_pixel_val=255, im_size=im_size)\n",
    "    print(\"done adapted_im2\")\n",
    "else:\n",
    "    adapted_im1 = domain1_img\n",
    "    adapted_im2 = domain2_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5512c12-9db8-4c2d-a2a4-c1a5056a248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "figure, axis = plt.subplots(1, 4, figsize=(25, 5))\n",
    "i = 0\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain2_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "#axis[i].imshow(cv2.cvtColor(target2, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "#i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(adapted_im1.astype(np.uint8), cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(adapted_im2.astype(np.uint8), cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774f553-44f1-4c6c-9a47-a7f2d4fb6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "figure, axis = plt.subplots(1, 4, figsize=(25, 5))\n",
    "i = 0\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain2_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "#axis[i].imshow(cv2.cvtColor(target2, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "#i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(adapted_im1.astype(np.uint8), cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(adapted_im2.astype(np.uint8), cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e5beb-7785-45fa-ae3c-673947782eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colortrans\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from color_transfer import color_transfer\n",
    "\n",
    "from python_color_transfer.color_transfer import ColorTransfer\n",
    "\n",
    "# Load data\n",
    "if False:\n",
    "    domain1_img = cv2.imread('example_data/texture/ple.tif')\n",
    "    domain1_img = cv2.resize(domain1_img, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "    domain1_img[:,:,0] = domain1_img[:,:,0] * 0.99 # if all channels have same value it does weird stuff\n",
    "    domain1_img[:,:,2] = domain1_img[:,:,2] * 0.995 # if all channels have same value it does weird stuff\n",
    "\n",
    "else:\n",
    "    domain1_img = cv2.imread(r'C:\\Users\\Prinzessin\\projects\\image_data\\iChallenge_AMD_OD_Fovea_lesions\\images_Non-AMD\\N0009.jpg')\n",
    "    domain1_msk = cv2.imread(r'C:\\Users\\Prinzessin\\projects\\image_data\\iChallenge_AMD_OD_Fovea_lesions\\Disc_Masks_bin\\N0009.bmp')\n",
    "    domain1_img, domain1_msk = crop_fundus(domain1_img, domain1_msk)\n",
    "    domain1_img = cv2.resize(domain1_img, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "\n",
    "\n",
    "domain2_img = cv2.imread('example_data/texture/cir.tif')\n",
    "domain2_img = cv2.resize(domain2_img, (im_size, im_size), interpolation = cv2.INTER_AREA) \n",
    "\n",
    "domain2_img[:,:,0] = domain2_img[:,:,0] * 0.91 # if all channels have same value it does weird stuff\n",
    "domain2_img[:,:,2] = domain2_img[:,:,2] * 0.90 # if all channels have same value it does weird stuff\n",
    "\n",
    "\n",
    "# Transfer colors using different algorithms\n",
    "output_lhm = colortrans.transfer_lhm(domain1_img, domain2_img)\n",
    "output_pccm = colortrans.transfer_pccm(domain1_img, domain2_img)\n",
    "output_rein = colortrans.transfer_reinhard(domain1_img, domain2_img)\n",
    "outout_col = color_transfer(domain2_img, domain1_img)\n",
    "\n",
    "\n",
    "python_color_transfer = ColorTransfer()\n",
    "\n",
    "#img_arr_pdf_reg = python_color_transfer.pdf_tranfer(img_arr_in=domain1_img,\n",
    "#                             img_arr_ref=domain2_img,\n",
    "#                             regrain=True)\n",
    "# Mean std transfer\n",
    "img_arr_mt = python_color_transfer.mean_std_transfer(img_arr_in=domain1_img,\n",
    "                                  img_arr_ref=domain2_img)\n",
    "# Lab mean transfer\n",
    "img_arr_lt = python_color_transfer.lab_transfer(img_arr_in=domain1_img, img_arr_ref=domain2_img)\n",
    "\n",
    "print(\"*\")\n",
    "print(img_arr_lt.shape)\n",
    "print(\"*\")\n",
    "print(img_arr_mt.shape)\n",
    "print(\"*\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "figure, axis = plt.subplots(1, 8, figsize=(25, 5))\n",
    "i = 0\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(domain2_img, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(outout_col, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(img_arr_mt, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(img_arr_lt, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(output_lhm, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(output_pccm, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "axis[i].imshow(cv2.cvtColor(output_rein, cv2.COLOR_BGR2GRAY), cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "\"\"\"\n",
    "diff = 255 - cv2.absdiff(cv2.cvtColor(img_arr_mt, cv2.COLOR_BGR2GRAY), cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "print(diff)\n",
    "\n",
    "#diff = cv2.cvtColor(diff, cv2.COLOR_GRAY2RGB)\n",
    "#print(diff.shape)\n",
    "\n",
    "#diff[:,:,0] = diff[:,:,0] * 100\n",
    "\n",
    "#print(diff)\n",
    "\n",
    "#print(diff.shape)\n",
    "\n",
    "#\n",
    "\n",
    "axis[i].imshow(diff, cmap=\"gray\")\n",
    "i+=1\n",
    "\n",
    "(score, diff2) = structural_similarity(    cv2.cvtColor(img_arr_mt, cv2.COLOR_BGR2GRAY), cv2.cvtColor(domain1_img, cv2.COLOR_BGR2GRAY)   , full=True)\n",
    "# The diff image contains the actual image differences between the two images\n",
    "# and is represented as a floating point data type in the range [0,1] \n",
    "# so we must convert the array to 8-bit unsigned integers in the range\n",
    "# [0,255] before we can use it with OpenCV\n",
    "diff2 = (diff2 * 255).astype(\"uint8\")\n",
    "\n",
    "axis[i].imshow(diff2, cmap=\"gray\")\n",
    "i+=1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf2287-7d57-47e6-8aac-179350d3eee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
