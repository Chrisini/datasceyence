{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f61201-fe2f-43c2-bc80-2728ee7ee3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty((1,81))\n",
    "a = np.full(81, np.nan)\n",
    "geometry_array = a.reshape((9,9))\n",
    "geometry_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f936556-6eb7-4c6f-937f-73845476c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common pair at indices [1, 0]: (2, 2), (4, 4)\n",
      "Common pair at indices [2, 5]: (4, 4), (8, 8)\n",
      "[1 2]\n",
      "[0 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Two lists of data\n",
    "ms_in = [1, 2, 4]\n",
    "ns_in = [2, 4, 8]\n",
    "\n",
    "ms_x = [2, 2, 2, 5, 9, 4]\n",
    "ns = [4, 2, 2, 3, 6, 8]\n",
    "\n",
    "# Find the indices (IDs) of pairs that exist in both lists\n",
    "common_pairs = [[f, x] for f, (item1, item2) in enumerate(zip(ms_in, ns_in)) for x, (item3, item4) in enumerate(zip(ms_x, ns)) if (item1==item3 and item2==item4)]\n",
    "\n",
    "# Print the common pairs\n",
    "for pair in common_pairs:\n",
    "    print(f\"Common pair at indices {pair}: {ms_in[pair[0]], ms_x[pair[1]]}, {ns_in[pair[0]], ns[pair[1]]}\")\n",
    "    \n",
    "a = np.array(common_pairs)\n",
    "f_ids = a[:,0]\n",
    "x_ids = a[:,1]\n",
    "\n",
    "print(f_ids)\n",
    "print(x_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa4ed7-878e-4cec-85e4-baa9c4e88663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class X:\n",
    "    def __init__(self, value, m, n):\n",
    "        \n",
    "        self.m = m # list of integers\n",
    "        self.n = n # list of integers\n",
    "        self.channels = value # list of tensors\n",
    "                \n",
    "    def set(self, value, m, n):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.channels = value\n",
    "    \n",
    "    def get(self):\n",
    "        return self.channels, self.m, self.n\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'X(channels: ' + str(self.channels.shape) +' at position: m=' + str(self.m) + ', n=' + str(self.n) + ')'\n",
    "    __repr__ = __str__\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class Filter(torch.nn.Module):\n",
    "    def __init__(self, ms_in, ns_in, m_out, n_out, n_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ms_in = ms_in # list\n",
    "        self.ns_in = ns_in # list\n",
    "        self.m_out = m_out # single integer\n",
    "        self.n_out = n_out # single integer\n",
    "        self.weights = torch.autograd.Variable(torch.randn(1,n_channels,3,3))\n",
    "        \n",
    "    def forward(self, x_channels):\n",
    "        \n",
    "        #print(x.values())\n",
    "    \n",
    "        x_channels = torch.nn.functional.conv2d(x_channels, self.weights)\n",
    "        \n",
    "        #print(x.value)\n",
    "        \n",
    "        return x_channels\n",
    "    \n",
    "    def set(self, value, m_out, n_out):\n",
    "        self.ms_in = None # list\n",
    "        self.ns_in = None # list\n",
    "        self.m_out = m_out # single integer\n",
    "        self.n_out = n_out # single integer\n",
    "        self.weights = value # weights in this filter\n",
    "    \n",
    "    def get(self):\n",
    "        return self.m_out, self.n_out, self.weights\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'DecentFilter(weights: ' + str(self.weights.shape) + ' at position: m_out=' + str(self.m_out) + ', n_out=' + str(self.n_out) + ')' + \\\n",
    "    '\\n with inputs: ms_in= ' + ', '.join(str(m.item()) for m in self.ms_in) + ', ns_in= ' + ', '.join(str(n.item()) for n in self.ns_in) + ')'\n",
    "    __repr__ = __str__\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Layer(torch.nn.Module):  \n",
    "    def __init__(self, ms_in, ns_in, n_channels, n_filters):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ms_in = ms_in\n",
    "        self.ns_in = ns_in\n",
    "                \n",
    "        # use techniques from coo matrix\n",
    "        self.geometry_array = np.full(81, np.nan)\n",
    "        # plus 1 here cause of to_sparse array\n",
    "        self.geometry_array[0:n_filters] = range(1,n_filters+1)\n",
    "        np.random.shuffle(self.geometry_array)\n",
    "        self.geometry_array = self.geometry_array.reshape((9,9), order='C')\n",
    "        self.geometry_array = torch.tensor(self.geometry_array)\n",
    "        self.geometry_array = self.geometry_array.to_sparse(sparse_dim=2).to(\"cuda\")\n",
    "\n",
    "        print(self.geometry_array)\n",
    "        print(self.geometry_array.values())\n",
    "        \n",
    "        self.filter_list = torch.nn.ModuleList([])\n",
    "        for i_filter in range(n_filters):\n",
    "            # minus 1 here cause of to_sparse array\n",
    "            index = (self.geometry_array.values()-1 == i_filter).nonzero(as_tuple=True)[0]\n",
    "            m_out = self.geometry_array.indices()[0][index]\n",
    "            n_out = self.geometry_array.indices()[1][index]\n",
    "            self.filter_list.append(Filter(ms_in, ns_in, m_out, n_out, n_channels))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        print(\"the 1:\", x)\n",
    "        \n",
    "        output_list = []\n",
    "        for f in self.filter_list:\n",
    "            output_list.append(f(x.channels))\n",
    "        \n",
    "        # needs to be for each channel??\n",
    "        x.channels = torch.cat(output_list, dim=1)\n",
    "        # mean = torch.mean(out, 0, keepdim=True)\n",
    "        \n",
    "        print(\"the 2:\", x)\n",
    "        \n",
    "        return x #, pos\n",
    "    \n",
    "    def get_filter_positions(self):\n",
    "        \n",
    "        ms_out = []\n",
    "        ns_out = []\n",
    "        for f in self.filter_list:\n",
    "            ms_out.append(f.m_out)\n",
    "            ns_out.append(f.n_out)\n",
    "        \n",
    "        return ms_out, ns_out\n",
    "    \n",
    "    #def __str__(self):\n",
    "    #    return 'Layer(filters: )' #  + str(self.weights.shape) + ' at position: m_out=' + str(self.m_out) + ', n_out=' + str(self.n_out) + ')'\n",
    "    #__repr__ = __str__\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        dim = [1, 32, 48, 64, 10]\n",
    "        dim = [1, 8, 16, 24, 10]\n",
    "        assert not any(i > 81 for i in dim), \"filters need to be less than 81\"\n",
    "        \n",
    "        m0 = [torch.tensor(0)]\n",
    "        n0 = [torch.tensor(0)]\n",
    "        #self.layer0 = Layer(m,n)\n",
    "        #m,n = layer0.get_positions()\n",
    "        self.layer1 = Layer(m0, n0, dim[0], dim[1])\n",
    "        m1,n1 = self.layer1.get_filter_positions()\n",
    "        self.layer2 = Layer(m1, n1, dim[1], dim[2])\n",
    "        m2,n2 = self.layer2.get_filter_positions()\n",
    "        self.layer3 = Layer(m2, n2, dim[2], dim[-1])\n",
    "        \n",
    "        self.fc = torch.nn.Linear(dim[-1], dim[-1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # from here we need to use the channels\n",
    "        x = F.avg_pool2d(x.channels, kernel_size=x.channels.size()[2:])\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def update(self):\n",
    "        # measurement for updating\n",
    "        \n",
    "        # update layer by layer\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32009cf-3a70-4d3f-b0a8-c393b08f3670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4f63e-2451-4a74-9612-e1157e60b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412da17-0807-4dd8-b6a4-e49286737eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fd8d57-0a5e-4a66-8810-9a4515a7b146",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m)) \u001b[38;5;66;03m# batch x channel x width x height\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# dense_input.shape\u001b[39;00m\n\u001b[0;32m      4\u001b[0m dense_input \u001b[38;5;241m=\u001b[39m X(tmp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "tmp = torch.autograd.Variable(torch.randn(5, 1, 30, 30)) # batch x channel x width x height\n",
    "# dense_input.shape\n",
    "\n",
    "dense_input = X(tmp, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d857ef-1b6d-4c25-8ce2-f7a49b2a2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = n(dense_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370d7f5-d92f-44a9-8174-9435c6698fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(a, dim=1)\n",
    "# one prediction for each image in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f45aed-424e-446a-8d87-f6338fa70ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter([2, 3, 5], [8, 2, 4], 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8501f1-0f46-4c05-a3a1-d11a0efee297",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(a.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d0457-5dbd-47c2-8d67-47cf4c32c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.full(81, 0)\n",
    "print(arr)\n",
    "arr[0:10] = range(0,10)\n",
    "print(arr)\n",
    "np.random.shuffle(arr)\n",
    "arr = arr.reshape((9,9), order='C')\n",
    "print(arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f614ed-f334-4234-80a8-96f38d526b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_input = torch.tensor(arr)\n",
    "\n",
    "co = dense_input.to_sparse(sparse_dim=2).to(\"cuda\")\n",
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959f7f5-54c9-4f1f-9823-29e8ad03f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (co.values() == 3).nonzero(as_tuple=True)[0]\n",
    "co.indices()[0][index]\n",
    "co.indices()[1][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde21ee1-9bb2-4557-b883-bc83732af036",
   "metadata": {},
   "outputs": [],
   "source": [
    "co.indices()[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cd802-d731-4471-9a89-65344792499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "co.indices()[1][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e925c7f-f016-4930-98ac-ab23bb65b176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066d9dd-be21-4813-8ec5-1c05b197d22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a16072-f3ff-4b12-8eb2-7e86487747ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1adaa3-1e17-40a4-9f0c-56c5cfd05554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15a0b8-b533-4f23-9052-74e089a4b0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103496fb-958d-4dda-91ab-5122c16dea5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba62592-3595-4141-8a2e-0538d7c7e9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a266e-89b2-48ad-ae3a-e52df4ac93ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601cf41-d288-4eca-a9bc-b9bb01ce98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying with sparse ... doesn't work cause it gets applied on all dimensions or smthg ... I want a 9x9 matrix, not a 9x9x30x30 (grid, grid, img size, img size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fc1c3-e617-4b57-a1df-5e5b0f80e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Filter(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "class Layer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        a = 0\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(x.values())\n",
    "        \n",
    "        values = x.values()\n",
    "        w_channels = 1\n",
    "        weight = torch.autograd.Variable(torch.randn(1,w_channels,3,3))\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        values_conv = torch.nn.functional.conv2d(values, weight)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = torch.sparse_coo_tensor(x.indices(), values_conv, x.size())\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer0 = Layer()\n",
    "        self.layer1 = Layer()\n",
    "        self.layer2 = Layer()\n",
    "    def forward(self, x):\n",
    "        # x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a65d21-1174-40ca-8216-f7e0c7339f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b55620-8a1e-4f96-8c85-80266bbba81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_input = torch.autograd.Variable(torch.randn(1,30,30)) # one image in batch\n",
    "dense_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42519041-8f62-48c3-8bce-f7d4f9b77362",
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_input = dense_input.to_sparse(sparse_dim=2)\n",
    "coo_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfdb0c-a456-4a03-ba3b-f86f6f6ed882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coo_input.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473e85b-5bc6-4174-b496-23d9d07f3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = n(coo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f640f-f533-4f63-a698-dd1a141f846e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173d121-a7e6-4022-a245-28fd895b6d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
