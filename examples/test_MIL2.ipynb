{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dde33fa-7d10-40ac-b268-1a8a02155ad0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multiple-Instance Learning\n",
    "* https://github.com/rhgao/Deep-MIML-Network/blob/master/models/MIML.py\n",
    "* https://github.com/MSKCC-Computational-Pathology/MIL-nature-medicine-2019/blob/master/MIL_train.py\n",
    "* https://github.com/binli123/dsmil-wsi/blob/master/attention_map.py\n",
    "\n",
    "* https://github.com/jusiro/mil_histology/tree/main/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd706985-d7b3-432a-8619-13f23f0e4e47",
   "metadata": {},
   "source": [
    "# mil_histology "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbecfe-4905-4553-b269-65a6b6a5328e",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a924089-4e7a-4f56-9e53-7a40f095871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x232706ea110>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# image\n",
    "import skimage.transform\n",
    "import skimage.util\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# torch \n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(19)\n",
    "random.seed(19)\n",
    "torch.manual_seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf434021-d591-4cf2-bcf3-957e550e8a3e",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44406992-1b65-47cd-bc76-a26be39d3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        # self.dir_images = \"\"\n",
    "        self.dir_csv_data = \"C:/Users/Prinzessin/projects/decentnet/datasceyence/data_prep/mil*.csv\"\n",
    "        self.dir_results = \"results\"\n",
    "        self.criterion = \"z\"\n",
    "        self.experiment_name = \"tmp1\"\n",
    "        self.classes = [\"glaucoma\", \"faz\", \"onh\", \"dr\", \"healthy\"]\n",
    "        self.proportions = [\"Primary\", \"Secondary\"]\n",
    "        self.input_shape = [3, 224, 224]\n",
    "        self.epochs = 100\n",
    "        self.aggregation = \"max\"\n",
    "        self.mode = \"instance\"\n",
    "        self.include_background = True\n",
    "        self.lr = 1*1e-2\n",
    "        self.pMIL = False\n",
    "        \n",
    "        self.alpha_ce = 1\n",
    "        self.margin = 0.\n",
    "        self.alpha_ic = 1\n",
    "        self.alpha_pc = 1\n",
    "        self.alpha_H = 0\n",
    "        self.t_ic = 15\n",
    "        self.t_pc = 5\n",
    "        self.data_augmentation = True\n",
    "        self.iterations = 3\n",
    "        \n",
    "        self.early_stopping = True\n",
    "        self.scheduler = True\n",
    "        self.virtual_batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61ffeb-4337-467b-85de-9fa8a781c74e",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "334a27ff-6de8-46bb-b382-ae256a6af98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILDataset(object):\n",
    "\n",
    "    def __init__(self, csv_data, classes, bag_id='bag_name', input_shape=(3, 224, 224),\n",
    "                 data_augmentation=False, channel_first=True,\n",
    "                 pMIL=False, proportions=None, only_primary=False, dataframe_instances=False):\n",
    "\n",
    "        \"\"\"Dataset object for MIL.\n",
    "            Dataset object which aims to organize images and labels from a dataset in the form of bags.\n",
    "        Args:\n",
    "          x dir_images: (h, w, channels)\n",
    "          csv_data: pandas dataframe with ground truth information.\n",
    "                      Each bag is one raw, with 'bag_name' as identifier.\n",
    "          classes: list of classes of interest in data_fame (i.e. ['G3', 'G4', 'G5'])\n",
    "          input_shape: image input shape (channels first).\n",
    "          data_augmentation: whether to perform data augmentation (True) or not (False).\n",
    "\n",
    "        Returns:\n",
    "          MILDataset object\n",
    "        Last Updates: Julio Silva (19/03/21)\n",
    "        \"\"\"\n",
    "\n",
    "        'Internal states initialization'\n",
    "        # self.dir_images = dir_images\n",
    "        self.csv_data = csv_data\n",
    "        self.classes = classes\n",
    "        self.bag_id = bag_id\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.input_shape = input_shape\n",
    "        self.channel_first = channel_first\n",
    "        self.pMIL = pMIL\n",
    "        self.proportions = proportions\n",
    "        # self.images = os.listdir(dir_images)\n",
    "        self.only_primary = only_primary\n",
    "        self.dataframe_instances = dataframe_instances\n",
    "\n",
    "        # Filter patches whose slide is not in the dataframe\n",
    "        idx = np.in1d([ID.split('_')[0] for ID in self.images], self.csv_data[self.bag_id])\n",
    "        images = [self.images[i] for i in range(self.images.__len__()) if idx[i]]\n",
    "        self.images = images\n",
    "\n",
    "        # Filter slides in the dataframe whose patches are not in the images folder\n",
    "        self.csv_data = self.csv_data[\n",
    "            np.in1d(self.csv_data[self.bag_id], [ID.split('_')[0] for ID in images])]\n",
    "\n",
    "        # Organize bags in the form of dictionary: one key clusters indexes from all instances\n",
    "        self.D = dict()\n",
    "        for i, item in enumerate([ID.split('_')[0] for ID in self.images]):\n",
    "            if item not in self.D:\n",
    "                self.D[item] = [i]\n",
    "            else:\n",
    "                self.D[item].append(i)\n",
    "\n",
    "        self.y = self.csv_data[self.classes].values\n",
    "        self.indexes = np.arange(len(self.images))\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.images[self.indexes[index]]\n",
    "\n",
    "\n",
    "        # Load image\n",
    "        x = Image.open(os.path.join(self.dir_images, ID))\n",
    "        x = np.asarray(x)\n",
    "        # Normalization\n",
    "        x = self.image_normalization(x)\n",
    "\n",
    "        # data augmentation\n",
    "        if self.data_augmentation:\n",
    "            x_augm = self.image_transformation(x.copy())\n",
    "        else:\n",
    "            x_augm = None\n",
    "\n",
    "        return x, x_augm\n",
    "\n",
    "    def image_transformation(self, img):\n",
    "\n",
    "        if self.channel_first:\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "        if random.random() > 0.5:\n",
    "            img = np.flipud(img)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.random() * 60 - 30\n",
    "            img = skimage.transform.rotate(img, angle)\n",
    "        #if random.random() > 0.5:\n",
    "        #    img = skimage.util.random_noise(img, var=random.random() ** 2)\n",
    "        #if random.random() > 0.5:\n",
    "        #    img = img + random.random() - 0.5\n",
    "        #    img = np.clip(img, 0, 1)\n",
    "\n",
    "        if self.channel_first:\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "        return img\n",
    "\n",
    "    def image_normalization(self, x):\n",
    "        # image resize\n",
    "        x = cv2.resize(x, (self.input_shape[1], self.input_shape[2]))\n",
    "        # intensity normalization\n",
    "        x = x / 255.0\n",
    "        # channel first\n",
    "        if self.channel_first:\n",
    "            x = np.transpose(x, (2, 0, 1))\n",
    "        # numeric type\n",
    "        x.astype('float32')\n",
    "        return x\n",
    "\n",
    "    def plot_image(self, x, norm_intensity=False):\n",
    "        # channel first\n",
    "        if self.channel_first:\n",
    "            x = np.transpose(x, (1, 2, 0))\n",
    "        if norm_intensity:\n",
    "            x = x / 255.0\n",
    "\n",
    "        plt.imshow(x)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def cifar10_test_dataset(self, dir_dataset):\n",
    "        files = os.listdir(dir_dataset)\n",
    "        files = [iFile for iFile in files if iFile != 'Thumbs.db']\n",
    "\n",
    "        Y = []\n",
    "        X = []\n",
    "        for iFile in files:\n",
    "            if 'Other' in iFile:\n",
    "                y = 0\n",
    "            else:\n",
    "                y = int(iFile.split('_')[-2][-1])\n",
    "\n",
    "            # Load image\n",
    "            x = Image.open(os.path.join(dir_dataset, iFile))\n",
    "            x = np.asarray(x)\n",
    "            # Normalization\n",
    "            x = self.image_normalization(x)\n",
    "\n",
    "            Y.append(y)\n",
    "            X.append(x)\n",
    "\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    def ordering_matrix(self, p):\n",
    "\n",
    "        if not self.only_primary:\n",
    "            nRestrictions = len(np.where(np.array(p) > 0)[0])\n",
    "        else:\n",
    "            nRestrictions = len(np.where(np.array(p) > 0)[0]) - 1\n",
    "\n",
    "        if nRestrictions <= 0:\n",
    "            return [np.zeros((1, len(p))), np.zeros((1, len(p)))]\n",
    "\n",
    "        # p: numpy array with proportion of used classes\n",
    "        O = np.zeros((nRestrictions, len(p)))\n",
    "\n",
    "        # Sort proportion values\n",
    "        indexes = np.flip(np.argsort(p))\n",
    "\n",
    "        for i in np.arange(0, nRestrictions):\n",
    "            O[i, indexes[i]] = -1\n",
    "\n",
    "        # p: numpy array with proportion of used classes\n",
    "        if nRestrictions > 1:\n",
    "            O2 = np.zeros((nRestrictions-1, len(p)))\n",
    "            for i in np.arange(0, nRestrictions-1):\n",
    "                O2[i, indexes[i]] = -1\n",
    "                O2[i, indexes[i + 1]] = 1\n",
    "        else:\n",
    "            O2 = np.zeros((1, len(p)))\n",
    "\n",
    "        return [O, O2]\n",
    "\n",
    "\n",
    "class MILDataGenerator(object):\n",
    "\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, max_instances=512):\n",
    "\n",
    "        \"\"\"Data Generator object for MIL.\n",
    "            Process a MIL dataset object to output batches of instances and its respective labels.\n",
    "        Args:\n",
    "          dataset: MIL datasetdataset object.\n",
    "          batch_size: batch size (number of bags). It will be usually set to 1.\n",
    "          shuffle: whether to shuffle the bags (True) or not (False).\n",
    "          max_instances: maximum amount of instances allowed due to computational limitations.\n",
    "\n",
    "        Returns:\n",
    "          MILDataGenerator object\n",
    "        Last Updates: Julio Silva (19/03/21)\n",
    "        \"\"\"\n",
    "\n",
    "        'Internal states initialization'\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.dataset.csv_data))\n",
    "        self.max_instances = max_instances\n",
    "\n",
    "        self._idx = 0\n",
    "        self._reset()\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        N = len(self.indexes)\n",
    "        b = self.batch_size\n",
    "        return N // b + bool(N % b)\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "\n",
    "        # If dataset is completed, stop iterator\n",
    "        if self._idx >= len(self.dataset.csv_data):\n",
    "            self._reset()\n",
    "            raise StopIteration()\n",
    "\n",
    "        # Get samples of data frame to use in the batch\n",
    "        df_row = self.dataset.csv_data.iloc[self.indexes[self._idx]]\n",
    "\n",
    "        # Get bag-level label\n",
    "        Y = df_row[self.dataset.classes].to_list()\n",
    "        Y = np.expand_dims(np.array(Y), 0)\n",
    "\n",
    "        # Get ordering matrix\n",
    "        if self.dataset.pMIL:\n",
    "            O = self.dataset.O[self.indexes[self._idx]]\n",
    "\n",
    "        # Select instances from bag\n",
    "        ID = list(df_row[[self.dataset.bag_id]].values)[0]\n",
    "        images_id = self.dataset.D[ID]\n",
    "\n",
    "        # Memory limitation of patches in one slide\n",
    "        if len(images_id) > self.max_instances:\n",
    "            images_id = random.sample(images_id, self.N)\n",
    "        # Minimum number os patches in a slide (by precaution).\n",
    "        if len(images_id) < 4:\n",
    "            images_id.extend(images_id)\n",
    "\n",
    "        self.instances_indexes = images_id\n",
    "\n",
    "        # Load images and include into the batch\n",
    "        X = []\n",
    "        X_augm = []\n",
    "        for i in images_id:\n",
    "            x, x_augm = self.dataset.__getitem__(i)\n",
    "            X.append(x)\n",
    "            X_augm.append(x_augm)\n",
    "\n",
    "        # Update bag index iterator\n",
    "        self._idx += self.batch_size\n",
    "\n",
    "        if self.dataset.pMIL:\n",
    "            if self.dataset.data_augmentation:\n",
    "                return np.array(X).astype('float32'), np.array(Y).astype('float32'), O, np.array(X_augm).astype('float32')\n",
    "            else:\n",
    "                return np.array(X).astype('float32'), np.array(Y).astype('float32'), O, None\n",
    "        else:\n",
    "            if self.dataset.data_augmentation:\n",
    "                return np.array(X).astype('float32'), np.array(Y).astype('float32'), None, np.array(X_augm).astype('float32')\n",
    "            else:\n",
    "                return np.array(X).astype('float32'), np.array(Y).astype('float32'), None, None\n",
    "\n",
    "    def _reset(self):\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.indexes)\n",
    "        self._idx = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4367c08-19ce-40a6-be0c-73077657ba1a",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f188323a-6dda-47d7-8a19-3b800bce952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILArchitecture(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, classes, mode='embedding', aggregation='mean', backbone='VGG19', include_background=False):\n",
    "        super(MILArchitecture, self).__init__()\n",
    "\n",
    "        \"\"\"Data Generator object for MIL.\n",
    "            CNN based architecture for MIL classification.\n",
    "        Args:\n",
    "          classes: \n",
    "          mode:\n",
    "          aggregation: max, mean, attentionMIL, mcAttentionMIL\n",
    "          backbone:\n",
    "          include_background:\n",
    "\n",
    "        Returns:\n",
    "          MILDataGenerator object\n",
    "        Last Updates: Julio Silva (19/03/21)\n",
    "        \"\"\"\n",
    "\n",
    "        'Internal states initialization'\n",
    "\n",
    "        self.classes = classes\n",
    "        self.mode = mode\n",
    "        self.aggregation = aggregation\n",
    "        self.backbone = backbone\n",
    "        self.include_background = include_background\n",
    "        self.C = []\n",
    "        self.prototypical = False\n",
    "\n",
    "        if self.include_background:\n",
    "            self.nClasses = len(classes) + 1\n",
    "        else:\n",
    "            self.nClasses = len(classes)\n",
    "        self.eps = 1e-6\n",
    "\n",
    "        # Backbone\n",
    "        self.bb = Encoder(pretrained=True, backbone=backbone, aggregation=True)\n",
    "        \n",
    "        # Classifiers\n",
    "        self.classifier = torch.nn.Linear(512, self.nClasses)\n",
    "            \n",
    "        # MIL aggregation\n",
    "        self.milAggregation = MILAggregation(aggregation=aggregation, nClasses=self.nClasses, mode=self.mode)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # Patch-Level feature extraction\n",
    "        features = self.bb(images)\n",
    "\n",
    "        # if self.mode == 'instance':\n",
    "        # Classification\n",
    "        patch_classification = torch.softmax(self.classifier(torch.squeeze(features)), 1)\n",
    "\n",
    "        # MIL aggregation\n",
    "        global_classification = self.milAggregation(patch_classification)\n",
    "\n",
    "        if self.include_background:\n",
    "            global_classification = global_classification[1:]\n",
    "\n",
    "        return global_classification, patch_classification, features\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained=True, backbone='resnet18', aggregation=False):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.aggregation = aggregation\n",
    "        self.pretrained = pretrained\n",
    "        self.backbone = backbone\n",
    "\n",
    "        if backbone == 'resnet18':\n",
    "            resnet = torchvision.models.resnet18(pretrained=pretrained)\n",
    "            self.F = torch.nn.Sequential(resnet.conv1,\n",
    "                                         resnet.bn1,\n",
    "                                         resnet.relu,\n",
    "                                         resnet.maxpool,\n",
    "                                         resnet.layer1,\n",
    "                                         resnet.layer2,\n",
    "                                         resnet.layer3,\n",
    "                                         resnet.layer4)\n",
    "        elif backbone == 'vgg19':\n",
    "            vgg19 = torchvision.models.vgg16(pretrained=pretrained)\n",
    "            self.F = vgg19.features\n",
    "\n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.F(x)\n",
    "\n",
    "        # register the hook\n",
    "        h = out.register_hook(self.activations_hook)\n",
    "\n",
    "        if self.aggregation:\n",
    "            out = torch.nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)\n",
    "\n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "\n",
    "class MILAggregation(torch.nn.Module):\n",
    "    def __init__(self, aggregation='mean', nClasses=2, mode='embedding'):\n",
    "        super(MILAggregation, self).__init__()\n",
    "\n",
    "        \"\"\"Aggregation module for MIL.\n",
    "        Args:\n",
    "          aggregation:\n",
    "\n",
    "        Returns:\n",
    "          MILAggregation module for CNN MIL Architecture\n",
    "        Last Updates: Julio Silva (19/03/21)\n",
    "        \"\"\"\n",
    "\n",
    "        self.mode = mode\n",
    "        self.aggregation = aggregation\n",
    "        self.nClasses = nClasses\n",
    "\n",
    "\n",
    "    def forward(self, feats):\n",
    "\n",
    "        if self.aggregation == 'max':\n",
    "            embedding = torch.max(feats, dim=0)[0]\n",
    "            return embedding\n",
    "        elif self.aggregation == 'mean':\n",
    "            embedding = torch.mean(feats, dim=0)\n",
    "            return embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d922d1c-5b73-4edb-9d8c-649a3433b77f",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe4f5b5-d20e-4205-9599-9363741203da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILTrainer():\n",
    "    def __init__(self, dir_out, network, lr=1*1e-4, pMIL=False, margin=0, t_ic=10,\n",
    "                 t_pc=10, alpha_ic=1, alpha_pc=1, alpha_ce=1, id='', early_stopping=False,\n",
    "                 scheduler=False, virtual_batch_size=1, criterion='auc', alpha_H=0.01):\n",
    "\n",
    "        self.dir_results = dir_out\n",
    "        if not os.path.isdir(self.dir_results):\n",
    "            os.mkdir(self.dir_results)\n",
    "\n",
    "        # Other\n",
    "        self.best_auc = 0.\n",
    "        self.init_time = 0\n",
    "        self.lr = lr\n",
    "        self.L_epoch = 0\n",
    "        self.L_lc = []\n",
    "        self.Lce_lc_val = []\n",
    "        self.macro_auc_lc_val = []\n",
    "        self.macro_auc_lc_train = []\n",
    "        self.i_epoch = 0\n",
    "        self.epochs = 0\n",
    "        self.i_iteration = 0\n",
    "        self.iterations = 0\n",
    "        self.network = network\n",
    "        self.test_generator = []\n",
    "        self.train_generator = []\n",
    "        self.preds_train = []\n",
    "        self.refs_train = []\n",
    "        self.pMIL = pMIL\n",
    "        self.alpha_ce = alpha_ce\n",
    "        self.best_criterion = 0\n",
    "        self.best_epoch = 0\n",
    "        self.metrics = {}\n",
    "        self.id = id\n",
    "        self.early_stopping = early_stopping\n",
    "        self.scheduler = scheduler\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.constrain_cumpliment_lc = []\n",
    "        self.constrain_proportion_lc = []\n",
    "        self.criterion = criterion\n",
    "        self.alpha_H = alpha_H\n",
    "        self.H_iteration = 0.\n",
    "        self.H_epoch = 0.\n",
    "\n",
    "        # Set optimizers\n",
    "        self.params = list(self.network.parameters())\n",
    "\n",
    "        if self.pMIL:\n",
    "            self.Lp_iteration = 0\n",
    "            self.Lp_epoch = 0\n",
    "            self.Lp_lc = []\n",
    "            self.m = margin\n",
    "            self.t_ic = t_ic\n",
    "            self.t_pc = t_pc\n",
    "            self.alpha_ic = alpha_ic\n",
    "            self.alpha_pc = alpha_pc\n",
    "            self.constrain_cumpliment = 0.\n",
    "            self.constraint_proportion = 0.\n",
    "\n",
    "        self.opt = torch.optim.SGD(self.params, lr=self.lr)\n",
    "        #self.opt = torch.optim.Adam(self.params, lr=self.lr)\n",
    "\n",
    "        # Set losses\n",
    "        # if network.mode == 'instance':\n",
    "        self.L = torch.nn.BCELoss().cuda()\n",
    "\n",
    "    def train(self, train_generator, val_generator, test_generator, epochs):\n",
    "        self.epochs = epochs\n",
    "        self.iterations = len(train_generator)\n",
    "        self.train_generator = train_generator\n",
    "        self.val_generator = val_generator\n",
    "        self.test_generator = test_generator\n",
    "        self.preds_train = []\n",
    "        self.refs_train = []\n",
    "\n",
    "        # Move network to gpu\n",
    "        self.network.cuda()\n",
    "\n",
    "        self.init_time = timer()\n",
    "        for i_epoch in range(epochs):\n",
    "            self.i_epoch = i_epoch\n",
    "            # init epoch losses\n",
    "            self.L_epoch = 0\n",
    "            self.Lpc_iteration = 0\n",
    "            self.Lic_iteration = 0\n",
    "            self.Lic_epoch = 0\n",
    "            self.Lpc_epoch = 0\n",
    "            self.H_iteration = 0.\n",
    "            self.H_epoch = 0.\n",
    "            self.constrain_cumpliment_iteration = 0.\n",
    "            self.constrain_cumpliment_epoch = 0.\n",
    "            self.constrain_proportion_epoch = 0.\n",
    "            self.constrain_ic_proportion_epoch = 0.\n",
    "            self.j = 0.\n",
    "            self.jj = 0.\n",
    "            n = 0\n",
    "            nn = 0\n",
    "\n",
    "            if self.scheduler:\n",
    "                if (self.i_epoch + 1) % 50 == 0:\n",
    "                    for g in self.opt.param_groups:\n",
    "                        g['lr'] = self.lr / 2\n",
    "\n",
    "            # Loop over training dataset\n",
    "            print('[Training]: at bag level...')\n",
    "            for self.i_iteration, (X, Y, O, X_augm) in enumerate(self.train_generator):\n",
    "\n",
    "                X = torch.tensor(X).cuda().float()\n",
    "                if X_augm is None:\n",
    "                    X_augm = X\n",
    "                else:\n",
    "                    X_augm = torch.tensor(X_augm).cuda().float()\n",
    "                Y = torch.tensor(Y).cuda().float()\n",
    "\n",
    "                # Set model to training mode and clear gradients\n",
    "                self.network.train()\n",
    "\n",
    "                # Forward network\n",
    "                Yhat, yhat, features = self.network(X_augm)\n",
    "\n",
    "                # if self.network.mode == 'instance':\n",
    "                Yhat = torch.clip(Yhat, min=0.01, max=0.98)\n",
    "\n",
    "                # Estimate losses\n",
    "                Lce = self.L(Yhat, torch.squeeze(Y))\n",
    "\n",
    "                # Update overall losses\n",
    "                L = Lce * self.alpha_ce\n",
    "\n",
    "                if self.alpha_H > 0:\n",
    "                    H = torch.mean(-torch.sum(yhat * torch.log(yhat + 1e-12), dim=(-1)))\n",
    "                    self.H_iteration = H\n",
    "\n",
    "                    L += - self.alpha_H * self.H_iteration\n",
    "\n",
    "\n",
    "                # Backward gradients\n",
    "                L = L / self.virtual_batch_size\n",
    "                L.backward()\n",
    "\n",
    "                # Update weights and clear gradients\n",
    "                if ((self.i_epoch + 1) % self.virtual_batch_size) == 0:\n",
    "                    self.opt.step()\n",
    "                    self.opt.zero_grad()\n",
    "\n",
    "                ######################################\n",
    "                ## --- Iteration/Epoch end\n",
    "\n",
    "                # Save predictions\n",
    "                self.preds_train.append(Yhat.detach().cpu().numpy())\n",
    "                self.refs_train.append(Y.detach().cpu().numpy())\n",
    "\n",
    "                # Display losses per iteration\n",
    "                self.display_losses(self.i_epoch + 1, self.epochs, self.i_iteration + 1, self.iterations,\n",
    "                                    Lce.cpu().detach().numpy(),\n",
    "                                    end_line='\\r')\n",
    "\n",
    "                # Update epoch's losses\n",
    "                self.L_epoch += Lce.cpu().detach().numpy() / len(self.train_generator)\n",
    "                \n",
    "\n",
    "            # Epoch-end processes\n",
    "            \n",
    "\n",
    "            self.on_epoch_end()\n",
    "\n",
    "            if self.early_stopping:\n",
    "                if self.i_epoch + 1 == (self.best_epoch + 20):\n",
    "                    break\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        # Obtain epoch-level metrics\n",
    "        macro_auc = roc_auc_score(np.squeeze(np.array(self.refs_train)), np.array(self.preds_train), multi_class='ovr')\n",
    "        self.macro_auc_lc_train.append(macro_auc)\n",
    "\n",
    "        # Display losses\n",
    "        self.display_losses(self.i_epoch + 1, self.epochs, self.iterations, self.iterations, self.L_epoch, macro_auc,\n",
    "                            end_line='\\n')\n",
    "        # Update learning curves\n",
    "        self.L_lc.append(self.L_epoch)\n",
    "\n",
    "        # Obtain results on validation set\n",
    "        Lce_val, macro_auc_val = self.test_bag_level_classification(self.val_generator)\n",
    "\n",
    "        # Save loss value into learning curve\n",
    "        self.Lce_lc_val.append(Lce_val)\n",
    "        self.macro_auc_lc_val.append(macro_auc_val)\n",
    "\n",
    "        metrics = {'epoch': self.i_epoch + 1, 'AUCtrain': np.round(self.macro_auc_lc_train[-1], 4),\n",
    "                   'AUCval': np.round(self.macro_auc_lc_val[-1], 4)}\n",
    "        with open(self.dir_results + self.id + 'metrics.json', 'w') as fp:\n",
    "            json.dump(metrics, fp)\n",
    "        print(metrics)\n",
    "\n",
    "        if (self.i_epoch + 1) > 10:\n",
    "            if self.criterion == 'auc':\n",
    "                if self.best_criterion < self.macro_auc_lc_val[-1]:\n",
    "                    self.best_criterion = self.macro_auc_lc_val[-1]\n",
    "                    self.best_epoch = (self.i_epoch + 1)\n",
    "\n",
    "                    torch.save(self.network, self.dir_results + self.id + 'network_weights_best.pth')\n",
    "\n",
    "            elif self.criterion == 'z':\n",
    "                if self.best_criterion < (-self.constrain_proportion_epoch):\n",
    "                    self.best_criterion = -self.constrain_proportion_epoch\n",
    "                    self.best_epoch = (self.i_epoch + 1)\n",
    "\n",
    "                    torch.save(self.network, self.dir_results + self.id + 'network_weights_best.pth')\n",
    "\n",
    "        # Each xx epochs, test models and plot learning curves\n",
    "        if (self.i_epoch + 1) % 5 == 0:\n",
    "            # Save weights\n",
    "            torch.save(self.network, self.dir_results + self.id + 'network_weights.pth')\n",
    "\n",
    "            # Plot learning curve\n",
    "            self.plot_learning_curves()\n",
    "\n",
    "            # Test at instance level\n",
    "            X = self.test_generator.dataset.X[self.test_generator.dataset.y_instances[:, 0] != -1, :, :, :]\n",
    "            Y = self.test_generator.dataset.y_instances[self.test_generator.dataset.y_instances[:, 0] != -1, :]\n",
    "            acc, f1, k2 = self.test_instance_level_classification(X, Y, self.test_generator.dataset.classes)\n",
    "\n",
    "        if (self.epochs == (self.i_epoch + 1)) or (self.early_stopping and (self.i_epoch + 1 == (self.best_epoch + 20))):\n",
    "            print('-' * 20)\n",
    "            print('-' * 20)\n",
    "\n",
    "            self.network = torch.load(self.dir_results + self.id + 'network_weights_best.pth')\n",
    "\n",
    "            # Obtain results on validation set\n",
    "            Lce_val, macro_auc_val = self.test_bag_level_classification(self.val_generator)\n",
    "\n",
    "            # Obtain results on validation set\n",
    "            Lce_test, macro_auc_test = self.test_bag_level_classification(self.test_generator)\n",
    "\n",
    "            # Test at instance level\n",
    "            X = self.test_generator.dataset.X[self.test_generator.dataset.y_instances[:, 0] != -1, :, :, :]\n",
    "            Y = self.test_generator.dataset.y_instances[self.test_generator.dataset.y_instances[:, 0] != -1, :]\n",
    "            acc, f1, k2 = self.test_instance_level_classification(X, Y, self.test_generator.dataset.classes)\n",
    "\n",
    "            metrics = {'epoch': self.best_epoch, 'AUCtest': np.round(macro_auc_test, 4),\n",
    "                       'AUCval': np.round(macro_auc_val, 4), 'acc': np.round(acc, 4),\n",
    "                       'f1': np.round(f1, 4), 'k2': np.round(k2, 4),\n",
    "                       }\n",
    "\n",
    "            if self.alpha_pc:\n",
    "                metrics['constrain_cumpliment'] = np.round(self.constrain_cumpliment_lc[self.best_epoch-1], 4)\n",
    "                metrics['constrain_proportion'] = np.round(self.constrain_proportion_lc[self.best_epoch-1], 4)\n",
    "\n",
    "            with open(self.dir_results + self.id + 'best_metrics.json', 'w') as fp:\n",
    "                json.dump(metrics, fp)\n",
    "            print(metrics)\n",
    "\n",
    "            self.metrics = metrics\n",
    "            print('-' * 20)\n",
    "            print('-' * 20)\n",
    "\n",
    "    def plot_learning_curves(self):\n",
    "        def plot_subplot(axes, x, y, y_axis):\n",
    "            axes.grid()\n",
    "            for i in range(x.shape[0]):\n",
    "                axes.plot(x[i, :], y[i, :], 'o-')\n",
    "            axes.set_ylabel(y_axis)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(20, 15))\n",
    "        plot_subplot(axes[0], np.tile(np.arange(self.i_epoch + 1), (2, 1)) + 1, np.array([self.L_lc, self.Lce_lc_val]), \"Lce\")\n",
    "        plot_subplot(axes[1], np.tile(np.arange(self.i_epoch + 1), (2, 1)) + 1, np.array([self.macro_auc_lc_train, self.macro_auc_lc_val]), \"mAUC\")\n",
    "\n",
    "        plt.savefig(self.dir_results + self.id + 'learning_curve.png')\n",
    "\n",
    "    def display_losses(self, i_epoch, epochs, iteration, total_iterations, Lce, macro_auc=0, end_line=''):\n",
    "\n",
    "        info = \"[INFO] Epoch {}/{}  -- Step {}/{}: Lce={:.4f} ; AUC={:.4f}\".format(\n",
    "                i_epoch, epochs, iteration, total_iterations, Lce, macro_auc)\n",
    "\n",
    "        if self.alpha_H > 0:\n",
    "            if end_line == '\\n':\n",
    "                info += ' ; H=' + str(np.round(self.H_epoch, 4))\n",
    "            else:\n",
    "                info += ' ; H=' + str(np.round(self.H_iteration.cpu().detach().numpy(), 4))\n",
    "\n",
    "        if self.pMIL and end_line == '\\n':\n",
    "            if self.alpha_pc > 0:\n",
    "                info += ' ; IC=' + str(np.round(self.Lic_epoch, 4))\n",
    "                info += '{' + str(np.round(self.constrain_ic_proportion_epoch, 4)) + '}'\n",
    "            if self.alpha_ic > 0:\n",
    "                info += ' ; PC=' + str(np.round(self.Lpc_epoch, 4))\n",
    "                info += '{' + str(np.round(self.constrain_cumpliment_epoch, 4)) + '}'\n",
    "                info += '{' + str(np.round(self.constrain_proportion_epoch, 4)) + '}  '\n",
    "        if self.pMIL and end_line == '\\r':\n",
    "            if self.alpha_pc > 0:\n",
    "                info += ' ; IC=' + str(np.round(self.Lic_iteration.cpu().detach().numpy(), 4))\n",
    "            if self.alpha_ic > 0:\n",
    "                info += ' ; PC=' + str(np.round(self.Lpc_iteration.cpu().detach().numpy(), 4))\n",
    "                info += '{' + str(np.round(self.constrain_cumpliment_iteration, 4)) + '}  '\n",
    "\n",
    "        # Print losses\n",
    "        et = str(datetime.timedelta(seconds=timer() - self.init_time))\n",
    "        print(info + ',ET=' + et, end=end_line)\n",
    "\n",
    "    def test_instance_level_classification(self, X, Y, classes):\n",
    "        classes = ['NC'] + classes\n",
    "\n",
    "        self.network.eval()\n",
    "        print(['INFO: Testing at instance level...'])\n",
    "\n",
    "        Yhat = []\n",
    "        for iInstance in np.arange(0, X.shape[0]):\n",
    "            print(str(iInstance+1) + '/' + str(X.shape[0]), end='\\r')\n",
    "\n",
    "            # Tensorize input\n",
    "            x = torch.tensor(X[iInstance, :, :, :]).cuda().float()\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "            \n",
    "            # Make prediction\n",
    "            yhat = torch.softmax(- torch.cdist(torch.squeeze(self.network.bb(x)).unsqueeze(0), self.network.C, p=2.0), 1)\n",
    "            yhat = torch.argmax(yhat).detach().cpu().numpy()\n",
    "\n",
    "            Yhat.append(yhat)\n",
    "        Yhat = np.array(Yhat)\n",
    "        Y = np.argmax(Y, 1)\n",
    "\n",
    "        cr = classification_report(Y, Yhat, target_names=classes, digits=4)\n",
    "        acc = accuracy_score(Y, Yhat)\n",
    "        f1 = f1_score(Y, Yhat, average='macro')\n",
    "        cm = confusion_matrix(Y, Yhat)\n",
    "        k2 = cohen_kappa_score(Y, Yhat, weights='quadratic')\n",
    "\n",
    "        print('Instance Level kappa: ' + str(np.round(k2, 4)), end='\\n')\n",
    "\n",
    "        f = open(self.dir_results + self.id + 'report.txt', 'w')\n",
    "        f.write('Title\\n\\nClassification Report\\n\\n{}\\n\\nConfusion Matrix\\n\\n{}\\n\\nKappa\\n\\n{}\\n'.format(cr, cm, k2))\n",
    "        f.close()\n",
    "\n",
    "        return acc, f1, k2\n",
    "\n",
    "    def test_bag_level_classification(self, test_generator, binary=False):\n",
    "        self.network.eval()\n",
    "        print('[VALIDATION]: at bag level...')\n",
    "\n",
    "        # Loop over training dataset\n",
    "        Y_all = []\n",
    "        Yhat_all = []\n",
    "        Lce_e = 0\n",
    "        for self.i_iteration, (X, Y, O, _) in enumerate(test_generator):\n",
    "            X = torch.tensor(X).cuda().float()\n",
    "            Y = torch.tensor(Y).cuda().float()\n",
    "\n",
    "            # Set model to training mode and clear gradients\n",
    "\n",
    "            # Forward network\n",
    "            Yhat, _, _ = self.network(X)\n",
    "            # Estimate losses\n",
    "            Lce = self.L(Yhat, torch.squeeze(Y))\n",
    "            Lce_e += Lce.cpu().detach().numpy() / len(test_generator)\n",
    "\n",
    "            Y_all.append(Y.detach().cpu().numpy())\n",
    "            Yhat_all.append(Yhat.detach().cpu().numpy())\n",
    "\n",
    "            # Display losses per iteration\n",
    "            self.display_losses(self.i_epoch + 1, self.epochs, self.i_iteration + 1, len(test_generator),\n",
    "                                Lce.cpu().detach().numpy(),\n",
    "                                end_line='\\r')\n",
    "        # Obtain overall metrics\n",
    "        Yhat_all = np.array(Yhat_all)\n",
    "        Y_all = np.squeeze(np.array(Y_all))\n",
    "\n",
    "        if binary:\n",
    "            Yhat_all = np.max(Yhat_all, 1)\n",
    "            Y_all = np.max(Y_all, 1)\n",
    "\n",
    "        macro_auc = roc_auc_score(Y_all, Yhat_all, multi_class='ovr')\n",
    "\n",
    "        # Display losses per epoch\n",
    "        self.display_losses(self.i_epoch + 1, self.epochs, self.i_iteration + 1, len(test_generator),\n",
    "                            Lce_e, macro_auc,\n",
    "                            end_line='\\n')\n",
    "\n",
    "        return Lce_e, macro_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c33488-4b58-46bf-8095-e9afe9128a26",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "669fbc9d-e4b2-4acd-8762-a5304d806eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/Prinzessin/projects/decentnet/datasceyence/data_prep\\\\mil_data_octa500_unknown.csv', 'C:/Users/Prinzessin/projects/decentnet/datasceyence/data_prep\\\\mil_data_ravir_unknown.csv']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MILDataset' object has no attribute 'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25220\\4157409647.py\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25220\\4157409647.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args, reduced_data)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Set data generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     dataset_train = MILDataset(csv_data[csv_data['mode'] == 'train'], args.classes,\n\u001b[0m\u001b[0;32m     28\u001b[0m                                \u001b[0mbag_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'slide_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                \u001b[0mdata_augmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_augmentation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25220\\2583121407.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, csv_data, classes, bag_id, input_shape, data_augmentation, channel_first, pMIL, proportions, only_primary, dataframe_instances)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Filter patches whose slide is not in the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbag_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MILDataset' object has no attribute 'images'"
     ]
    }
   ],
   "source": [
    "def main(args, reduced_data=False):\n",
    "\n",
    "    metrics = []\n",
    "    #for i_iteration in np.arange(0, args.iterations):\n",
    "    # why 3 times???\n",
    "    #    id = str(i_iteration) + '_'      \n",
    "    \n",
    "    \n",
    "    print(glob.glob(args.dir_csv_data))\n",
    "\n",
    "    csv_list = []\n",
    "    for i, filename in enumerate(glob.glob(args.dir_csv_data)):\n",
    "        df = pd.read_csv(filename, delimiter=\";\")\n",
    "        # df[\"dataset_type\"] = [i]*len(df.index)\n",
    "        csv_list.append(df)\n",
    "    csv_data = pd.concat(csv_list, axis=0, ignore_index=False)\n",
    "\n",
    "    # csv_data = csv_data[self.csv_data[\"mode\"].str.contains(mode)]\n",
    "\n",
    "    if reduced_data:\n",
    "        csv_data = csv_data.sample(frac=1).reset_index(drop=True)\n",
    "        csv_data = csv_data.head(200)\n",
    "\n",
    "\n",
    "\n",
    "    # Set data generators\n",
    "    dataset_train = MILDataset(csv_data[csv_data['mode'] == 'train'], args.classes,\n",
    "                               bag_id='slide_name', input_shape=args.input_shape,\n",
    "                               data_augmentation=args.data_augmentation,\n",
    "                               pMIL=args.pMIL, proportions=args.proportions)\n",
    "    data_generator_train = MILDataGenerator(dataset_train, batch_size=1, shuffle=True, max_instances=512)\n",
    "\n",
    "    dataset_val = MILDataset(csv_data[csv_data['mode'] == 'val'], args.classes,\n",
    "                             bag_id='slide_name', input_shape=args.input_shape,\n",
    "                             data_augmentation=args.data_augmentation,\n",
    "                             pMIL=args.pMIL, proportions=args.proportions)\n",
    "    data_generator_val = MILDataGenerator(dataset_val, batch_size=1, shuffle=False, max_instances=512)\n",
    "\n",
    "    dataset_test = MILDataset(csv_data[csv_data['mode'] == 'test'], args.classes,\n",
    "                              bag_id='slide_name', input_shape=args.input_shape,\n",
    "                              data_augmentation=args.data_augmentation,\n",
    "                              pMIL=args.pMIL, proportions=args.proportions)\n",
    "    data_generator_test = MILDataGenerator(dataset_test, batch_size=1, shuffle=False, max_instances=512)\n",
    "\n",
    "    # Set network architecture\n",
    "    network = MILArchitecture(args.classes, mode=args.mode, aggregation=args.aggregation,\n",
    "                              backbone='vgg19', include_background=args.include_background)\n",
    "\n",
    "    # Perform training\n",
    "    trainer = MILTrainer(args.dir_results + args.experiment_name + '/', network,\n",
    "                         lr=args.lr, pMIL=args.pMIL, margin=args.margin,\n",
    "                         alpha_ic=args.alpha_ic, alpha_pc=args.alpha_pc, t_ic=args.t_ic,\n",
    "                         t_pc=args.t_pc, alpha_ce=args.alpha_ce, id=id,\n",
    "                         early_stopping=args.early_stopping, scheduler=args.scheduler,\n",
    "                         virtual_batch_size=args.virtual_batch_size,\n",
    "                         criterion=args.criterion,\n",
    "                         alpha_H=args.alpha_H)\n",
    "    trainer.train(train_generator=data_generator_train, val_generator=data_generator_val,\n",
    "                  test_generator=data_generator_test, epochs=args.epochs)\n",
    "\n",
    "    metrics.append([list(trainer.metrics.values())[1:]])\n",
    "\n",
    "    # Get overall metrics\n",
    "    metrics = np.squeeze(np.array(metrics))\n",
    "\n",
    "    mu = np.mean(metrics, axis=0)\n",
    "    std = np.std(metrics, axis=0)\n",
    "\n",
    "    info = \"AUCtest={:.4f}({:.4f}) ; AUCval={:.4f}({:.4f})  ; acc={:.4f}({:.4f}) ; f1-score={:.4f}({:.4f}) ; k2={:.4f}({:.4f})\".format(\n",
    "          mu[0], std[0], mu[1], std[1], mu[2], std[2], mu[3], std[3], mu[4], std[4])\n",
    "    if args.alpha_pc > 0:\n",
    "        info += \" ; constrain_cumpliment={:.4f}({:.4f}) ; constrain_proportion={:.4f}({:.4f})\".format(\n",
    "          mu[5], std[5], mu[6], std[6])\n",
    "\n",
    "    f = open(args.dir_results + args.experiment_name + '/' + 'method_metrics.txt', 'w')\n",
    "    f.write(info)\n",
    "    f.close()        \n",
    "\n",
    "args = Arguments()\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a36486-e959-468c-8a80-ffb2f89c1056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9043458-a66b-4a20-bd02-ee81962a9da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
