{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3c6274-2e43-4dd4-828f-82b305e6d2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../helper', './helper', '/helper', 'helper', 'C:\\\\Users\\\\Christina\\\\Documents\\\\datasceyence\\\\examples', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\python39.zip', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\DLLs', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy', '', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\pixelssl-0.1.4-py3.9.egg', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\Christina\\\\anaconda3\\\\envs\\\\chrisy\\\\lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "import unittest\n",
    "\n",
    "# model and transform\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import shufflenet_v2_x1_0, ShuffleNet_V2_X1_0_Weights\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "# \"helper\" needs to be part of sys path\n",
    "import sys\n",
    "sys.path.insert(0, \"helper\")\n",
    "sys.path.insert(0, \"/helper\")\n",
    "sys.path.insert(0, \"./helper\")\n",
    "sys.path.insert(0, \"../helper\")\n",
    "print(sys.path)\n",
    "\n",
    "device=\"cpu\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own module\n",
    "from visualisation.deepdream import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2080e42f-3d09-46e6-8bca-485aeec64dad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes .ipynb_checkpoints, MNIST. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get one example image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ichallenge_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexample_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m img, label \u001b[38;5;241m=\u001b[39m ichallenge_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mimg=Image.effect_noise((500, 500), 25).convert('RGB') \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m    144\u001b[0m classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[1;32m--> 145\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m extensions\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torchvision\\datasets\\folder.py:189\u001b[0m, in \u001b[0;36mDatasetFolder.make_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torchvision\\datasets\\folder.py:102\u001b[0m, in \u001b[0;36mmake_dataset\u001b[1;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    101\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextensions\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(extensions,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m instances\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Found no valid file for the classes .ipynb_checkpoints, MNIST. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "\"\"\"\n",
    "img=Image.effect_noise((500, 500), 25).convert('RGB') \n",
    "\"\"\"\n",
    "# tensor preparation\n",
    "resize = transforms.Resize(128)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img = resize(img)\n",
    "fig = plt.figure(figsize = (5 , 5))\n",
    "plt.imshow(img)\n",
    "img = to_tensor(img).to(device)\n",
    "\n",
    "# model preparation\n",
    "#model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "from model.decent_block import *\n",
    "#model = DecentBlock(None, None, 2, device)\n",
    "model = DecentBlock(\"example_ckpt\", \"exp_1_mlp_c0_ep46_1.5189.ckpt\", 2, device)\n",
    "\n",
    "# layer to focus on\n",
    "print(\"*\"*50)\n",
    "print(\"example graph nodes:\", get_graph_node_names(model)[0][10:20])\n",
    "print(\"*\"*50)\n",
    "layer = model.decent_block.decent_block_116[2][3].branch2[0]\n",
    "# model.decent_block.decent_block_reduction[0] # model.stage4[0].branch1[2] # model.fusion_layer # conv\n",
    "\n",
    "# run deep dream\n",
    "dd = DeepDream(model=model, layer=layer, device=device, iterations=1000, lr=0.1)\n",
    "dd.run(img)\n",
    "dd.plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46fa62d-44c1-45d1-8016-18dba5ba8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "img=Image.effect_noise((500, 500), 25).convert('RGB') \n",
    "\n",
    "# tensor preparation\n",
    "resize = transforms.Resize(128)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img = resize(img)\n",
    "fig = plt.figure(figsize = (5 , 5))\n",
    "plt.imshow(img)\n",
    "img = to_tensor(img).to(device)\n",
    "\n",
    "# model preparation\n",
    "#model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "from model.decent_block import *\n",
    "model = DecentBlock(\"example_ckpt\", \"exp_1_mlp_c3_ep43_1.2093.ckpt\", 2, device)\n",
    "\n",
    "# layer to focus on\n",
    "print(\"*\"*50)\n",
    "print(\"example graph nodes:\", get_graph_node_names(model)[0][10:20])\n",
    "print(\"*\"*50)\n",
    "layer = model.decent_block.decent_block_116[2][3].branch2[0]\n",
    "# model.decent_block.decent_block_reduction[0] # model.stage4[0].branch1[2] # model.fusion_layer # conv\n",
    "\n",
    "# run deep dream\n",
    "dd = DeepDream(model=model, layer=layer, device=device, iterations=1000, lr=0.1)\n",
    "dd.run(img)\n",
    "dd.plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ef020-2ed8-476a-8d7b-ea34016b0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one example image\n",
    "ichallenge_data = torchvision.datasets.ImageFolder('example_data')\n",
    "img, label = ichallenge_data.__getitem__(1)\n",
    "\n",
    "img=Image.effect_noise((500, 500), 25).convert('RGB') \n",
    "\n",
    "# tensor preparation\n",
    "resize = transforms.Resize(128)\n",
    "to_tensor = transforms.ToTensor()\n",
    "img = resize(img)\n",
    "fig = plt.figure(figsize = (5 , 5))\n",
    "plt.imshow(img)\n",
    "img = to_tensor(img).to(device)\n",
    "\n",
    "# model preparation\n",
    "#model = shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "from model.decent_block import *\n",
    "model = DecentBlock(\"example_ckpt\", \"exp_1_mlp_c5_ep36_1.1963.ckpt\", 2, device)\n",
    "\n",
    "# layer to focus on\n",
    "print(\"*\"*50)\n",
    "print(\"example graph nodes:\", get_graph_node_names(model)[0][10:20])\n",
    "print(\"*\"*50)\n",
    "layer = model.decent_block.decent_block_116[2][3].branch2[0]\n",
    "# model.decent_block.decent_block_reduction[0] # model.stage4[0].branch1[2] # model.fusion_layer # conv model.stage4[0].branch1[2] # \n",
    "\n",
    "# run deep dream\n",
    "dd = DeepDream(model=model, layer=layer, device=device, iterations=5000, lr=0.01)\n",
    "dd.run(img)\n",
    "dd.plot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33ad56-d235-43f1-a799-01de3e802314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
