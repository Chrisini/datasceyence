{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b8cafc-dc1e-4c18-901a-652e305948ef",
   "metadata": {},
   "source": [
    "# ùïÑùï†ùïïùïñùïù ùï•ùïñùï§ùï•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e450b2-f916-4c97-8d28-3d453e6cdbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prinzessin\\anaconda3\\envs\\feta\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.insert(0, r\"../helper\")\n",
    "\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f459fe-1b91-41c6-8830-668905bf420b",
   "metadata": {},
   "source": [
    "## DecentNet\n",
    "Basic init of a decentnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b771cc-ee72-436b-9690-55b1ed1e5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.decentnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53b3643-ecf5-4bcd-8a7b-e56273b0c887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: example_results\\lightning_logs\\experiment_name\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {\n",
    "    'in_channels' : 1, # not in use yet\n",
    "    'n_classes': None, # filled in the dataset\n",
    "    'out_dim' :  [1, 4, 4, 8], # [1, 8, 16, 32], #[1, 16, 24, 32] # entry, decent1, decent2, decent3\n",
    "    'grid_size' : 18*18,\n",
    "    'criterion': torch.nn.CrossEntropyLoss(),# torch.nn.BCEWithLogitsLoss(),\n",
    "    'optimizer': \"sgd\", # sgd adamw\n",
    "    'base_lr': 0.001,\n",
    "    'min_lr' : 0.00001,\n",
    "    'momentum' : 0.9,\n",
    "    'lr_update' : 100,\n",
    "    # decentnet\n",
    "    'cc_weight': 10,\n",
    "    'cc_metric' : 'l2', # connection cost metric (for loss) - distance metric\n",
    "    'ci_metric' : 'l2', # channel importance metric (for pruning)\n",
    "    'cm_metric' : 'not implemented yet', # 'count', # crossing minimisation \n",
    "    'update_every_nth_epoch' : 1, # 5\n",
    "    'pretrain_epochs' : 1, # 20\n",
    "    'prune_keep' : 0.7, # 0.97, # in each epoch\n",
    "    'prune_keep_total' : 0.4, # this number is not exact, depends on the prune_keep value\n",
    "}\n",
    "\n",
    "train_kwargs = {\n",
    "    'result_path': \"example_results\", # \"example_results/lightning_logs\", # not in use??\n",
    "    'exp_name': \"experiment_name\", # must include oct or retina\n",
    "    'load_ckpt_file' : 'version_18/checkpoints/epoch=4-unpruned=192-val_f1=0.12.ckpt', # \"version_0/checkpoints/epoch=94-unpruned=1600-val_f1=0.67.ckpt\", # 'version_94/checkpoints/epoch=26-step=1080.ckpt', # change this for loading a file and using \"test\", if you want training, keep None\n",
    "    'epochs': 3, # including the pretrain epochs - no adding up\n",
    "    'img_size' : 28, #168, # keep mnist at original size, training didn't work when i increased the size ... # MNIST/MedMNIST 28 √ó 28 Pixel\n",
    "    'batch_size': 2, # 128, # the higher the batch_size the faster the training - every iteration adds A LOT OF comp cost\n",
    "    'log_every_n_steps' : 4, # lightning default: 50 # needs to be bigger than the amount of steps in an epoch (based on trainset size and batchsize)\n",
    "    'device': \"cuda\",\n",
    "    'num_workers' : 0, # 18, # 18 for computer, 0 for laptop\n",
    "    'train_size' : (2 * 4), # total or percentage\n",
    "    'val_size' : (2 * 4), # total or percentage\n",
    "    'test_size' : 8, # total or percentage - 0 for all\n",
    "}\n",
    "\n",
    "logger = CSVLogger(os.path.join(train_kwargs[\"result_path\"], 'lightning_logs'), name=train_kwargs[\"exp_name\"])\n",
    "log_dir = logger.log_dir\n",
    "\n",
    "# should be filled by dataset\n",
    "model_kwargs['n_classes'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026b8036-ba37-4642-8d5f-fc0125d1a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECENT INFO: dimensions are entry, decent1, decent2, decent3, decent1x1 == out [1, 4, 4, 8, 5]\n",
      "[5.]\n",
      "[15.]\n"
     ]
    }
   ],
   "source": [
    "model = DecentNet(model_kwargs=model_kwargs, log_dir=log_dir).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960b5d4-7960-494e-9db8-8ae0f98ea78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
