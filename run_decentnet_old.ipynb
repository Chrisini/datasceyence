{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8ea6b-7e2f-4257-9875-25f651882f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 𝔻𝕖𝕔𝕖𝕟𝕥ℕ𝕖𝕥: 𝕕𝕚𝕤𝕖𝕟𝕥𝕒𝕟𝕘𝕝𝕖𝕕 𝕟𝕖𝕥\n",
    "\n",
    "Goal: create a sparse and modular ConvNet\n",
    "\n",
    "Todos: \n",
    "* [ ] delete node (filter) if either no input or no output edges\n",
    "* [ ]\n",
    "\n",
    "\n",
    "Notes:\n",
    "* additionally needed: position, activated channels, connection between channels\n",
    "* within this layer, a whole filter can be deactivated\n",
    "* within a filter, single channels can be deactivated\n",
    "* within this layer, filters can be swapped\n",
    "     \n",
    "* pruning actually doesn\"t work: https://discuss.pytorch.org/t/pruning-doesnt-affect-speed-nor-memory-for-resnet-101/75814   \n",
    "* fine tune a pruned model: https://stackoverflow.com/questions/73103144/how-to-fine-tune-the-pruned-model-in-pytorch\n",
    "* an actual pruning mechanism: https://arxiv.org/pdf/2002.08258.pdf\n",
    "\n",
    "pip install:\n",
    "* pytorch_lightning\n",
    "\n",
    "\n",
    "warnings:\n",
    "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:211: You called `self.log('unpruned', ...)` in your `on_train_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
    "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:211: You called `self.log('unpruned_state', ...)` in your `on_train_epoch_end` but the value needs to be floating point. Converting it to torch.float32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e73a26-f239-466f-901d-559d192f61de",
   "metadata": {},
   "source": [
    "![uml of code](examples/example_vis/uml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd77a1f-a306-47cc-9905-993793aee5be",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f2bf02-f53b-4688-bf18-5b8075397e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# alphabetic order misc\n",
    "# =============================================================================\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys \n",
    "sys.path.insert(0, \"helper\")\n",
    "from typing import Optional, List, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "# =============================================================================\n",
    "# torch\n",
    "# =============================================================================\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.utils import _single, _pair, _triple, _reverse_repeat_tuple\n",
    "from torch.nn.common_types import _size_1_t, _size_2_t, _size_3_t\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch._torch_docs import reproducibility_notes\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# =============================================================================\n",
    "# datasceyence\n",
    "# =============================================================================\n",
    "from helper.visualisation.feature_map import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b397b450-c5c6-4da1-b630-7bf80e46891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "torch 2.0.0 == True\n",
      "tl 2.1.0 == True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(19)\n",
    "torch.cuda.manual_seed(19)\n",
    "random.seed(19)\n",
    "np.random.seed(19)\n",
    "\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "debug_model = False\n",
    "\n",
    "print('torch 2.0.0 ==', torch.__version__=='2.0.0')\n",
    "print('tl 2.1.0 ==', pl.__version__=='2.1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419b0be-245d-49c0-88b4-d94167f7da90",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97670e82-0d27-4b7f-91df-874acf9974a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    'n_classes': 10,\n",
    "    'out_dim' :  [1, 8, 16, 32], # [1, 8, 16, 32], #[1, 16, 24, 32]\n",
    "    'grid_size' : 18*18,\n",
    "    'criterion': torch.nn.CrossEntropyLoss(),# torch.nn.BCEWithLogitsLoss(),\n",
    "    'optimizer': \"sgd\", # sgd adamw\n",
    "    'base_lr': 0.001,\n",
    "    'min_lr' : 0.00001,\n",
    "    'momentum' : 0.9,\n",
    "    'lr_update' : 100,\n",
    "    'cc_weight': 10,\n",
    "    'cc_metric' : 'l2', # connection cost metric (for loss) - distance metric\n",
    "    'ci_metric' : 'l2', # channel importance metric (for pruning)\n",
    "    'cm_metric' : 'not implemented yet', # 'count', # crossing minimisation \n",
    "    'update_every_nth_epoch' : 5, # 5\n",
    "    'pretrain_epochs' : 20, # 20\n",
    "    'prune_keep' : 0.95, # 0.97, # in each epoch\n",
    "    'prune_keep_total' : 0.5, # this number is not exact, depends on the prune_keep value\n",
    "}\n",
    "\n",
    "train_kwargs = {\n",
    "    'result_path': \"examples/example_results\", # \"example_results/lightning_logs\", # not in use??\n",
    "    'exp_name': \"exp1_oct_no_fc_ci_l2_095\", # must include oct or retina\n",
    "    'load_ckpt_file' : \"xversion_22/checkpoints/epoch=0-unpruned=10942-val_f1=0.06.ckpt\", # 'version_94/checkpoints/epoch=26-step=1080.ckpt', # change this for loading a file and using \"test\", if you want training, keep None\n",
    "    'epochs': 100, # including the pretrain epochs - no adding up\n",
    "    'img_size' : 28, #168, # keep mnist at original size, training didn't work when i increased the size ... # MNIST/MedMNIST 28 × 28 Pixel\n",
    "    'batch_size': 128, # 128, # the higher the batch_size the faster the training - every iteration adds A LOT OF comp cost\n",
    "    'log_every_n_steps' : 4, # lightning default: 50 # needs to be bigger than the amount of steps in an epoch (based on trainset size and batchsize)\n",
    "    'device': \"cuda\",\n",
    "    'num_workers' : 18, # 18, # 18 for computer, 0 for laptop\n",
    "    'train_size' : (128 * 32), # total or percentage\n",
    "    'val_size' : (128 * 4), # total or percentage\n",
    "    'test_size' : 24, # total or percentage - 0 for all\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ee3d0-9c79-4917-a355-093f1daf4855",
   "metadata": {},
   "source": [
    "## check the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d5ff36-c015-4bd6-8b12-c4d0e3b64b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 5700\n",
      "26 5415\n",
      "31 5144\n",
      "36 4886\n",
      "41 4641\n",
      "46 4408\n",
      "51 4187\n",
      "56 3977\n",
      "61 3778\n",
      "66 3589\n",
      "71 3409\n",
      "76 3238\n",
      "81 3076\n",
      "86 2922\n",
      "stop: 3000.0\n",
      "you need at least this many epochs: 87\n",
      "you currently have this many epochs: 100\n",
      "recommended to add 2*update_every_nth_epoch\n"
     ]
    }
   ],
   "source": [
    "breaking = 6000*model_kwargs['prune_keep_total']\n",
    "weights = 6000 # this value is an estimate for a model [1, 8, 16, 32]\n",
    "# 'unpruned' is the logger variable for the value\n",
    "\n",
    "for i in range(train_kwargs['epochs']):\n",
    "    \n",
    "    if (weights < breaking): # weights*model_kwargs['prune_keep']\n",
    "        print(\"stop:\", breaking)\n",
    "        print('you need at least this many epochs:', i)\n",
    "        print('you currently have this many epochs:', train_kwargs['epochs'])\n",
    "        print(\"recommended to add 2*update_every_nth_epoch\")\n",
    "        break\n",
    "    \n",
    "    # not sure whether -1 is correct, have to check\n",
    "    if i > model_kwargs['pretrain_epochs'] and ((i-1)%model_kwargs['update_every_nth_epoch'] == 0):\n",
    "        weights = int(weights*model_kwargs['prune_keep'])\n",
    "    \n",
    "        print(i, weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f898ba-2323-4628-a0e3-70ee44ce0b0d",
   "metadata": {},
   "source": [
    "# DecentNet trial and error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd6da2-32d7-4727-af6d-cee380d01b5f",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d607d8fb-4ac1-4fad-848c-11d189a62637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\Christina\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Christina\\.medmnist\\octmnist.npz\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(size=train_kwargs[\"img_size\"]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    #transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])   \n",
    "\n",
    "rgb_transform=transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(size=train_kwargs[\"img_size\"]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    #transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])   \n",
    "    \n",
    "if 'oct' in train_kwargs['exp_name']:\n",
    "    from medmnist import OCTMNIST\n",
    "    dataset = OCTMNIST(split=\"train\", transform=transform, download=True)\n",
    "    testset = OCTMNIST(split=\"test\", transform=transform, download=True) \n",
    "    model_kwargs['n_classes'] = 4\n",
    "    \n",
    "    indices = np.arange(len(dataset))  \n",
    "    train_indices, val_indices = train_test_split(indices, train_size=train_kwargs[\"train_size\"], test_size=train_kwargs[\"val_size\"], stratify=dataset.labels)\n",
    "    \n",
    "elif 'retina' in train_kwargs['exp_name']:\n",
    "    from medmnist import RetinaMNIST\n",
    "    dataset = RetinaMNIST(split=\"train\", transform=rgb_transform, download=True)\n",
    "    testset = RetinaMNIST(split=\"test\", transform=rgb_transform, download=True) \n",
    "    model_kwargs['n_classes'] = 5\n",
    "    \n",
    "    indices = np.arange(len(dataset))  \n",
    "    train_indices, val_indices = train_test_split(indices, train_size=train_kwargs[\"train_size\"], test_size=train_kwargs[\"val_size\"], stratify=dataset.labels)\n",
    "    \n",
    "else:\n",
    "    dataset = torchvision.datasets.MNIST(root=\"examples/example_data\", train=True, transform=transform, download=True)\n",
    "    testset = torchvision.datasets.MNIST(root=\"examples/example_data\", train=False, transform=transform, download=True)\n",
    "    model_kwargs['n_classes'] = 10\n",
    "    \n",
    "    indices = np.arange(len(dataset))  \n",
    "    train_indices, val_indices = train_test_split(indices, train_size=train_kwargs[\"train_size\"], test_size=train_kwargs[\"val_size\"], stratify=dataset.targets)\n",
    "\n",
    "\n",
    "train_subset = torch.utils.data.Subset(dataset, train_indices)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_subset, shuffle=True, batch_size=train_kwargs[\"batch_size\"], num_workers=train_kwargs[\"num_workers\"])\n",
    "\n",
    "val_subset = torch.utils.data.Subset(dataset, val_indices)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_subset, shuffle=False, batch_size=train_kwargs[\"batch_size\"], num_workers=train_kwargs[\"num_workers\"]) # , persistent_workers=True)\n",
    "\n",
    "# batch size has to be 1\n",
    "if train_kwargs[\"test_size\"] > 0:\n",
    "    testset = torch.utils.data.Subset(testset, range(train_kwargs[\"test_size\"]))\n",
    "xai_dataloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=1, num_workers=train_kwargs[\"num_workers\"]) # , persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a51afc1-0512-43ac-9e43-582b0a21e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python_class': 'OCTMNIST', 'description': 'The OCTMNIST is based on a prior dataset of 109,309 valid optical coherence tomography (OCT) images for retinal diseases. The dataset is comprised of 4 diagnosis categories, leading to a multi-class classification task. We split the source training set with a ratio of 9:1 into training and validation set, and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−1,536)×(277−512). We center-crop the images and resize them into 1×28×28.', 'url': 'https://zenodo.org/record/6496656/files/octmnist.npz?download=1', 'MD5': 'c68d92d5b585d8d81f7112f81e2d0842', 'task': 'multi-class', 'label': {'0': 'choroidal neovascularization', '1': 'diabetic macular edema', '2': 'drusen', '3': 'normal'}, 'n_channels': 1, 'n_samples': {'train': 97477, 'val': 10832, 'test': 1000}, 'license': 'CC BY 4.0'}\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "info = INFO['octmnist']\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63827d6-1e9f-4537-a86f-00515d8578cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a0bf5e-8191-4182-a682-d1c34495a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bac8cc05-fbe0-4125-910d-55c171f68101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.tensor(dataset.labels).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd40000-1da6-4f92-b9e4-ace7a184a19a",
   "metadata": {},
   "source": [
    "## X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c8a8868-9d8f-47cf-a42b-5ab72f44b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class X:\n",
    "    # =============================================================================\n",
    "    #\n",
    "    # an object with image representations and their positions\n",
    "    # amout of channels need to have same length as m and n lists\n",
    "    #\n",
    "    # =============================================================================\n",
    "    \n",
    "    def __init__(self, data, ms_x, ns_x):\n",
    "        self.data = data # list of tensors (image representations)\n",
    "        self.ms_x = ms_x # list of integers (m position of each image representation)\n",
    "        self.ns_x = ns_x # list of integers (n position of each image representation)\n",
    "                \n",
    "    def setter(self, data, ms_x, ns_x):\n",
    "        self.data = data\n",
    "        self.ms_x = ms_x\n",
    "        self.ns_x = ns_x\n",
    "        \n",
    "    def getter(self):\n",
    "        return self.data, self.m, self.n\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'X(data: ' + str(self.data.shape) +' at positions: ms_x= ' + ', '.join(str(m.item()) for m in self.ms_x) + ', ns_x= ' + ', '.join(str(n.item()) for n in self.ns_x) + ')'\n",
    "    __repr__ = __str__\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfa123-54e1-4053-94c3-52b45ec0859c",
   "metadata": {},
   "source": [
    "## DecentFilter\n",
    "* conv2d problem: https://stackoverflow.com/questions/61269421/expected-stride-to-be-a-single-integer-value-or-a-list-of-1-values-to-match-the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62bc1f3c-5f40-445c-b5f1-4ca6387eb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentFilter(torch.nn.Module):\n",
    "    # =============================================================================\n",
    "    #\n",
    "    # convolution happens in here\n",
    "    # one filter has multiple channels (aka weights)\n",
    "    #\n",
    "    # =============================================================================\n",
    "    \n",
    "    def __init__(self, ms_in, ns_in, m_this, n_this,\n",
    "                 kernel_size=3, \n",
    "                 stride=1, \n",
    "                 padding=0, \n",
    "                 padding_mode=\"zeros\",\n",
    "                 dilation=3, \n",
    "                 # transposed=None, \n",
    "                 device=None, \n",
    "                 dtype=None):\n",
    "        \n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        \n",
    "        # padding\n",
    "        padding = padding if isinstance(padding, str) else _pair(padding)\n",
    "        valid_padding_strings = {'same', 'valid'}\n",
    "        if isinstance(padding, str):\n",
    "            if padding not in valid_padding_strings:\n",
    "                raise ValueError(\n",
    "                    \"Invalid padding string {!r}, should be one of {}\".format(\n",
    "                        padding, valid_padding_strings))\n",
    "            if padding == 'same' and any(s != 1 for s in stride):\n",
    "                raise ValueError(\"padding='same' is not supported for strided convolutions\")\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "        \n",
    "         \n",
    "        # convolution\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = stride\n",
    "        self.padding_mode = padding_mode\n",
    "        self.padding = padding\n",
    "        self.dilation = _pair(dilation)\n",
    "        #self.transposed = transposed\n",
    "        \n",
    "        # weights\n",
    "        assert len(ms_in) == len(ns_in), \"ms_in and ns_in are not of same length\"\n",
    "        self.n_weights = len(ms_in)\n",
    "        \n",
    "        # position, currently not trainable \n",
    "        # self.non_trainable_param = nn.Parameter(torch.Tensor([1.0]), requires_grad=False)\n",
    "        self.ms_in = nn.Parameter(torch.Tensor(ms_in), requires_grad=False) # ms_in # list\n",
    "        self.ns_in = nn.Parameter(torch.Tensor(ns_in), requires_grad=False) # ns_in # list\n",
    "        self.m_this = nn.Parameter(torch.Tensor([m_this]), requires_grad=False) # m_this # single integer\n",
    "        self.n_this = nn.Parameter(torch.Tensor([n_this]), requires_grad=False) # n_this # single integer\n",
    "        \n",
    "        # weight\n",
    "        # filters x channels x kernel x kernel\n",
    "        # self.weights = torch.autograd.Variable(torch.randn(1,n_weights,*self.kernel_size)).to(\"cuda\")\n",
    "        # self.weights = torch.nn.Parameter(torch.randn(1,n_weights,*self.kernel_size))\n",
    "        self.weights = torch.nn.Parameter(torch.empty((1, self.n_weights, *self.kernel_size), **factory_kwargs))\n",
    "        \n",
    "        #print(\"weight shape init\")\n",
    "        #print(self.weights.shape)\n",
    "            \n",
    "        # bias    \n",
    "        if False: \n",
    "            # bias:\n",
    "            # where should the bias be???\n",
    "            self.bias = Parameter(torch.empty(1, **factory_kwargs))\n",
    "        else:\n",
    "            #self.bias = False\n",
    "            # we only use bias via instance normalisation\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # reset weights and bias in filter\n",
    "        self.reset_parameters()\n",
    "            \n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*self.kernel_size)\n",
    "        # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\n",
    "        torch.nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))        \n",
    "        \n",
    "    def forward(self, x:X) -> Tensor:\n",
    "        # =============================================================================\n",
    "        # first, we have to remove channels in X\n",
    "        # this is because some channels in the filter are pruned (aka gone)\n",
    "        # then we can apply convolution\n",
    "        # parameters:\n",
    "        #    x = batch x channels x width x height\n",
    "        # returns:\n",
    "        #    x_data: batch x filters x width x height\n",
    "        # saves:\n",
    "        #    self.weights = 1 filter x channels x kernel x kernel\n",
    "        # =============================================================================\n",
    "        \n",
    "        \n",
    "        # POSITION MATCHER\n",
    "        # Find the indices (IDs) of channel pairs that exist in both the X and then filter\n",
    "        common_pairs = [[i_in, i_x] for i_in, (m_in, n_in) in enumerate(zip(self.ms_in, self.ns_in)) for i_x, (m_x, n_x) in enumerate(zip(x.ms_x, x.ns_x)) if (m_in==m_x and n_in==n_x)]\n",
    "        \n",
    "        if False:\n",
    "            print(common_pairs)\n",
    "            print(len(self.ms_in))\n",
    "            print(len(self.ns_in))\n",
    "            print(len(x.ms_x))\n",
    "            print(len(x.ns_x))\n",
    "\n",
    "            for pair in common_pairs:\n",
    "                print(f\"Common pair at indices {pair}: {self.ms_in[pair[0]], tmp_ms[pair[1]]}, {self.ns_in[pair[0]], tmp_ns[pair[1]]}\")\n",
    "        \n",
    "        common_pairs_a = np.array(common_pairs)\n",
    "        try:\n",
    "            f_ids = common_pairs_a[:,0]\n",
    "            x_ids = common_pairs_a[:,1]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            \"\"\"\n",
    "            print(\"error: no common pairs\")\n",
    "            print(\"pairs\", common_pairs_a)\n",
    "            print(\"pairs shape\", common_pairs_a.shape)\n",
    "            print(\"len ms in\", len(self.ms_in))\n",
    "            print(\"len ns in\", len(self.ns_in))\n",
    "            print(\"len ms x\", len(x.ms_x))\n",
    "            print(\"len ns x\", len(x.ns_x))\n",
    "            print(e)\n",
    "            \"\"\"\n",
    "            \n",
    "            # in this case the whole filter should be removed\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        # filter data and weights based on common pairs of data and weights\n",
    "        tmp_d = x.data[:, x_ids, :, :]\n",
    "        tmp_w = self.weights[:, f_ids, :, :]\n",
    "        \n",
    "        # the final convolution\n",
    "        if self.padding_mode != 'zeros':\n",
    "            # this is written in c++\n",
    "            x_data = torch.nn.functional.conv2d(F.pad(tmp_d, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            tmp_w, self.bias, self.stride,\n",
    "                            _pair(0), self.dilation, groups=1)\n",
    "        else:\n",
    "            # this is written in c++\n",
    "            x_data = torch.nn.functional.conv2d(tmp_d, tmp_w, self.bias, self.stride, self.padding, self.dilation, groups=1)\n",
    "        \n",
    "        #print(\"tmp_w\", tmp_w.shape)\n",
    "        \n",
    "        # print(x_data.shape, \"- batch x filters x width x height\")\n",
    "        return x_data\n",
    "    \n",
    "    def setter(self, value, m_this, n_this):\n",
    "        # preliminary, not in use\n",
    "        self.weights = value # weights in this filter\n",
    "        self.m_this = m_this # single integer\n",
    "        self.n_this = n_this # single integer\n",
    "    \n",
    "    def getter(self):\n",
    "        # preliminary, not in use\n",
    "        return self.weights, self.m_this, self.n_this\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'DecentFilter(weights: ' + str(self.weights.shape) + ' at position: m_this=' + str(self.m_this) + ', n_this=' + str(self.n_this) + ')' + \\\n",
    "    '\\n with inputs: ms_in= ' + ', '.join(str(int(m.item())) for m in self.ms_in) + ', ns_in= ' + ', '.join(str(int(n.item())) for n in self.ns_in) + ')'\n",
    "    __repr__ = __str__\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ffdab4-e0b0-4523-882f-dad3ebf06090",
   "metadata": {},
   "source": [
    "## DecentLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fddb74c7-5940-424d-aab8-2c75efd914bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentLayer(torch.nn.Module):\n",
    "    # =============================================================================\n",
    "    #\n",
    "    # we save filters of the layer in the self.filter_list\n",
    "    # each filter has a position (m_this, n_this)\n",
    "    # each filter has input positions (ms_in, ns_in)\n",
    "    #    - these vary between filters, as some are pruned\n",
    "    # at the moment we have to loop through the filter list\n",
    "    # convolution is applied to each filter separately which makes this very slow\n",
    "    #\n",
    "    # =============================================================================\n",
    "    __constants__ = ['stride', 'padding', 'dilation', # 'groups',\n",
    "                     'padding_mode', # 'n_channels', #  'output_padding', # 'n_filters',\n",
    "                     'kernel_size']\n",
    "    __annotations__ = {'bias': Optional[torch.Tensor]}\n",
    "                \n",
    "    def __init__(self, ms_in:list, ns_in:list, n_filters:int,\n",
    "                 kernel_size: _size_2_t,  \n",
    "                 stride: _size_2_t = 1,  \n",
    "                 padding: Union[str, _size_2_t] = 0,  \n",
    "                 dilation: _size_2_t = 1,\n",
    "                 model_kwargs=None,\n",
    "                 layer_name=None,\n",
    "                 #prune_keep:float = 0.9,\n",
    "                 #prune_keep_total:float = 0.5,\n",
    "                 #transposed: bool = False, \n",
    "                 #grid_size:int=81,\n",
    "                 #ci_metric=\"l2\",\n",
    "                 #output_padding: Tuple[int, ...] = _pair(0),\n",
    "                 #groups: int = 1,\n",
    "                 bias: bool = True,  # not in use\n",
    "                 padding_mode: str = \"zeros\",  # not in use\n",
    "                 device=None,  # not in use\n",
    "                 dtype=None) -> None:\n",
    "        # =============================================================================\n",
    "        # initialisation\n",
    "        # parameters:\n",
    "        #    a lot.\n",
    "        # =============================================================================\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_name = layer_name\n",
    "        \n",
    "        # prune numbers\n",
    "        self.prune_keep = model_kwargs[\"prune_keep\"] # in each update [0.0:1.0]\n",
    "        self.prune_keep_total = model_kwargs[\"prune_keep_total\"] # total [0.0:1.0]\n",
    "        \n",
    "        # importance metric for pruning\n",
    "        self.ci_metric = model_kwargs[\"ci_metric\"]\n",
    "        # distance metric for loss\n",
    "        self.cc_metric = model_kwargs[\"cc_metric\"]\n",
    "        \n",
    "        # from prev layer\n",
    "        self.ms_in = ms_in\n",
    "        self.ns_in = ns_in\n",
    "        \n",
    "        self.original_size = len(self.ms_in) * n_filters\n",
    "        \n",
    "        \n",
    "        self.grid_size = model_kwargs[\"grid_size\"]\n",
    "        self.grid_sqrt = math.sqrt(self.grid_size)\n",
    "        assert self.grid_sqrt == int(self.grid_sqrt), f\"square root ({self.grid_sqrt}) from grid size {self.grid_size} not possible; possible exampes: 81 (9*9), 144 (12*12)\"\n",
    "        self.grid_sqrt = int(self.grid_sqrt)\n",
    "        \n",
    "        # use techniques from coo matrix\n",
    "        self.geometry_array = np.full(self.grid_size, np.nan)\n",
    "        # plus 1 here cause of to_sparse array\n",
    "        self.geometry_array[0:n_filters] = range(1,n_filters+1)\n",
    "        np.random.shuffle(self.geometry_array)\n",
    "        self.geometry_array = self.geometry_array.reshape((self.grid_sqrt,self.grid_sqrt), order='C')\n",
    "        self.geometry_array = torch.tensor(self.geometry_array)\n",
    "        self.geometry_array = self.geometry_array.to_sparse(sparse_dim=2).to(\"cuda\")\n",
    "\n",
    "        #print(self.geometry_array)\n",
    "        #print(self.geometry_array.values())\n",
    "\n",
    "        self.filter_list = torch.nn.ModuleList([])\n",
    "        for i_filter in range(n_filters):\n",
    "            # minus 1 here cause of to_sparse array\n",
    "            index = (self.geometry_array.values()-1 == i_filter).nonzero(as_tuple=True)[0]\n",
    "            m_this = self.geometry_array.indices()[0][index]\n",
    "            n_this = self.geometry_array.indices()[1][index]\n",
    "            f = DecentFilter(ms_in, ns_in, m_this, n_this, \n",
    "                             kernel_size=kernel_size, \n",
    "                             stride=stride, padding=padding, dilation=dilation)\n",
    "            self.filter_list.append(f)\n",
    "            # self.register_parameter(f\"filter {i_filter}\", f.weights)\n",
    "            \n",
    "            #torch.nn.Parameter(torch.empty((1, n_channels, *kernel_size), **factory_kwargs))\n",
    "    \n",
    "    def run_layer_connection_cost(self) -> Tensor:\n",
    "        # =============================================================================\n",
    "        # compute connection cost for this layer - based on distance\n",
    "        # returns:\n",
    "        #    connection cost for the loss function\n",
    "        # notes:\n",
    "        #    currently using l2 norm, doesn't work that well\n",
    "        # sources:\n",
    "        #    adapted from BIMT: https://github.com/KindXiaoming/BIMT/blob/main/mnist_3.5.ipynb\n",
    "        #    https://stackoverflow.com/questions/74086766/how-to-find-total-cost-of-each-path-in-graph-using-dictionary-in-python\n",
    "        # nonsense?\n",
    "        #    i don't even know what the following comments are about ... \n",
    "        #    based on previous layer (cause I only have input ms_in, n_in information)\n",
    "        #    mean( sum( of connection cost between this filter and all incoming filters\n",
    "        #    need it for loss - aka all layers, all filters together\n",
    "        #    need it for swapping - this layer, all filters\n",
    "        #    only the active ones (we need to use the indices for that)\n",
    "        #    for swapping i need ??\n",
    "        # =============================================================================\n",
    "         \n",
    "        from scipy.spatial.distance import cdist\n",
    "        \n",
    "        # connection cost list\n",
    "        cc = []\n",
    "        \n",
    "        \n",
    "        for f in self.filter_list:\n",
    "            # for each filter we use the current position and all incoming positions\n",
    "\n",
    "            #mn = torch.cat([torch.tensor(f.m_this), torch.tensor(f.n_this)])\n",
    "            #print(mn.shape)\n",
    "            #msns = torch.cat([torch.tensor(f.ms_in), torch.tensor(f.ns_in)]) # .transpose(1,0)\n",
    "            #print(msns.shape)\n",
    "            #cc.append(torch.cdist(mn.unsqueeze(dim=0), msns.transpose(1,0), 'euclidean') / 8) # number comes from 9*9 = 81 [0-8]\n",
    "\n",
    "            mn = torch.cat([f.m_this.unsqueeze(0), f.n_this.unsqueeze(0)]).transpose(1,0)\n",
    "            msns = torch.cat([f.ms_in.unsqueeze(0), f.ns_in.unsqueeze(0)]).transpose(1,0)\n",
    "            #print(mn)\n",
    "            #print(msns)\n",
    "\n",
    "            # mean ( l2 norm as distance metric / normalisation term for l2 norm)\n",
    "            # mean of distances\n",
    "            # normalise with max=grid square root, min=0\n",
    "            # mean from all non-nan values\n",
    "            # \n",
    "            \n",
    "            if self.cc_metric == 'l1':\n",
    "                cc.append(torch.nanmean( torch.tensor( scipy.spatial.distance.cdist(mn.detach().cpu().numpy(), msns.detach().cpu().numpy(), 'cityblock') /self.grid_sqrt ) ))\n",
    "            elif self.cc_metric == 'l2':\n",
    "                cc.append(torch.nanmean( torch.tensor( scipy.spatial.distance.cdist(mn.detach().cpu().numpy(), msns.detach().cpu().numpy(), 'euclidean') /self.grid_sqrt ) ))\n",
    "            elif self.cc_metric == 'l2_torch':\n",
    "                cc.append(torch.nanmean( torch.cdist( a=mn.float(), b=msns.float(), p=2) /self.grid_sqrt ))\n",
    "            elif self.cc_metric == 'linf':\n",
    "                cc.append(torch.nanmean( torch.tensor( scipy.spatial.distance.cdist(mn.detach().cpu().numpy(), msns.detach().cpu().numpy(), 'chebyshev') /self.grid_sqrt ) ))\n",
    "            elif self.cc_metric == 'cos':\n",
    "                cc.append(torch.nanmean( torch.tensor( scipy.spatial.distance.cdist(mn.detach().cpu().numpy(), msns.detach().cpu().numpy(), 'cosine') /self.grid_sqrt ) ))\n",
    "            elif self.cc_metric == 'jac':\n",
    "                cc.append(torch.nanmean( torch.tensor( scipy.spatial.distance.cdist(mn.detach().cpu().numpy(), msns.detach().cpu().numpy(), 'jaccard') /self.grid_sqrt ) ))\n",
    "            elif self.cc_metric == 'cor':\n",
    "                cc.append(torch.nanmean( torch.tensor( scipy.spatial.distance.cdist(mn.detach().cpu().numpy(), msns.detach().cpu().numpy(), 'correlation') /self.grid_sqrt ) ))\n",
    "                \n",
    "\n",
    "        # mean connection cost of a layer\n",
    "        # mean from all non-nan values\n",
    "        return torch.nanmean(torch.tensor(cc))\n",
    "    \n",
    "    def run_channel_importance(self, i_f:int) -> list:\n",
    "        # =============================================================================\n",
    "        # compute channel importance metric for pruning\n",
    "        # calculate the norm of each weight in filter with id i_f\n",
    "        # we need to call this in a loop to go through each filter\n",
    "        # returns:\n",
    "        #     ci: channel importance list of a filter\n",
    "        # notes:\n",
    "        #     based on l2 norm = magnitude = euclidean distance\n",
    "        # nonsense?\n",
    "        #    maybe the kernel trigger todo\n",
    "        #    print(self.filter_list[i_f].weights.shape)\n",
    "        #    print(self.filter_list[i_f].weights[:,i_w].shape)\n",
    "        # =============================================================================\n",
    "        \n",
    "        ci = []\n",
    "        \n",
    "        # print(\"DECENT NOTE: weight shape\", self.filter_list[i_f].weights.shape)\n",
    "        \n",
    "        for i_w in range(self.filter_list[i_f].weights.shape[1]): # todo, sure this is 1 and not 0???\n",
    "            # importance of a kernel in a layer\n",
    "            \n",
    "            if self.ci_metric == 'l1':\n",
    "                # weight dependent - filter norm\n",
    "                print(\"nooooooooooooooooo\")\n",
    "                pass\n",
    "                \n",
    "                # ci.append(self.filter_list[i_f].weights[:,i_w].norm(2).detach().cpu().numpy())\n",
    "                \n",
    "            elif self.ci_metric == 'l2':\n",
    "                # weight dependent - filter norm\n",
    "                ci.append(self.filter_list[i_f].weights[:,i_w].norm(2).detach().cpu().numpy()) # .detach().cpu().numpy()\n",
    "                pass\n",
    "            \n",
    "            elif self.ci_metric == '':\n",
    "                # weight dependent - filter correlation\n",
    "                print(\"nooooooooooooooooo\")\n",
    "                pass\n",
    "            \n",
    "            elif self.ci_metric == '':\n",
    "                # activation-based\n",
    "                print(\"nooooooooooooooooo\")\n",
    "                pass\n",
    "                \n",
    "            elif self.ci_metric == '':\n",
    "                # mutual information\n",
    "                print(\"nooooooooooooooooo\")\n",
    "                pass\n",
    "                \n",
    "            elif self.ci_metric == '':\n",
    "                # Hessian matrix / Taylor\n",
    "                print(\"nooooooooooooooooo\")\n",
    "                pass\n",
    "                \n",
    "            elif self.ci_metric == '':\n",
    "                print(\"nooooooooooooooooo\")\n",
    "                pass\n",
    "                \n",
    "            elif self.ci_metric == 'random':\n",
    "                ci.append( np.array(random.random()) )\n",
    "\n",
    "        \n",
    "        return ci \n",
    "    \n",
    "    def run_swap_filter(self):\n",
    "        # =============================================================================\n",
    "        # not working yet\n",
    "        # we swap filters within the layer\n",
    "        # based on connection cost\n",
    "        # filter can move a maximum of two positions per swap\n",
    "        # change positions\n",
    "        # change\n",
    "        # =============================================================================\n",
    "        print(\"swap here\")\n",
    "        self.m_this = self.m_this # single integer\n",
    "        self.n_this = self.n_this # single integer\n",
    "        pass\n",
    "    \n",
    "    def run_grow_filter(self) -> None:\n",
    "        # =============================================================================\n",
    "        # not working yet\n",
    "        # introduce new filters in a layer\n",
    "        # based on \n",
    "        # algorithmic growth process \n",
    "        # =============================================================================\n",
    "        pass\n",
    "    \n",
    "    def run_grow_channel(self) -> None:\n",
    "        # =============================================================================\n",
    "        # not working yet\n",
    "        # introduce new channel in a layer\n",
    "        # based on connection cost??\n",
    "        # algorithmic growth process \n",
    "        # =============================================================================\n",
    "        pass\n",
    "    \n",
    "    def run_prune_filter(self) -> None:\n",
    "        # =============================================================================\n",
    "        # not working yet\n",
    "        # delete filter in a layer\n",
    "        # =============================================================================\n",
    "        pass\n",
    "    \n",
    "    def run_prune_channel(self, i_f:int, keep_ids:list) -> None:\n",
    "        # =============================================================================\n",
    "        # delete channels in a filter based on keep_ids\n",
    "        # based on importance score\n",
    "        # only keep \"the best\" weights\n",
    "        # pruning based on a metric\n",
    "        # nonsense?\n",
    "        #    delete layer with id\n",
    "        #    delete channels in each layer with id\n",
    "        #    channel deactivation\n",
    "        #    require_grad = False/True for each channel\n",
    "        #    deactivate_ids = [1, 2, 6]\n",
    "        #    self.active[deactivate_ids] = False\n",
    "        #    print(\"weight\")\n",
    "        #    print(self.weight.shape)\n",
    "        #    print(self.weight[:,self.active,:,:].shape)\n",
    "        #    this is totally wrong - iterative will break after first iteration\n",
    "        #    print()\n",
    "        #    Good to hear it’s working, although I would think you’ll get an error at some point in your code, as the cuda() call creates a non-leaf tensor.\n",
    "        #    self.weight = torch.nn.Parameter(  self.weight[:,self.active,:,:] ) # .detach().cpu().numpy()\n",
    "        #    self.weight = self.weight.cuda()\n",
    "        #    print(self.weight.shape)\n",
    "        #    print(self.active)\n",
    "        #    print(\"prune here\")\n",
    "        #    for f in self.filter_list:\n",
    "        #        f.update()\n",
    "        # =============================================================================\n",
    "        \n",
    "        if False:\n",
    "            for i in keep_ids:\n",
    "                print(i)\n",
    "                print(self.filter_list[i_f].ms_in[i])\n",
    "                print(torch.nn.Parameter(self.filter_list[i_f].ms_in[keep_ids]) )\n",
    "        \n",
    "        if random.randint(1, 100) == 5:\n",
    "            print()\n",
    "            print(\"info at random intervals\")\n",
    "            print(keep_ids)\n",
    "            print(self.filter_list[i_f].weights[:, keep_ids, :, :].shape)\n",
    "            print(self.filter_list[i_f].weights.shape)        \n",
    "        \n",
    "        # todo: check, this may create more parameters ...\n",
    "        \n",
    "        # prune weights, ms and ns based on the 'keep ids'\n",
    "        self.filter_list[i_f].weights = torch.nn.Parameter(self.filter_list[i_f].weights[:, keep_ids, :, :])\n",
    "        self.filter_list[i_f].ms_in = torch.nn.Parameter(self.filter_list[i_f].ms_in[keep_ids], requires_grad=False) # this becomes a grad here, hence turn off again with False\n",
    "        #[self.filter_list[i_f].ms_in[i] for i in keep_ids] # self.ms_in[remove_ids]\n",
    "        self.filter_list[i_f].ns_in = torch.nn.Parameter(self.filter_list[i_f].ns_in[keep_ids], requires_grad=False)\n",
    "        # [self.filter_list[i_f].ns_in[i] for i in keep_ids] # self.ns_in[remove_ids]\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x: X) -> Tensor:\n",
    "        # =============================================================================\n",
    "        # calculate representation x for each filter in this layer\n",
    "        # =============================================================================\n",
    "        \n",
    "        output_list = []\n",
    "        m_list = []\n",
    "        n_list = []\n",
    "        for f in self.filter_list:\n",
    "            # output = filter(input)\n",
    "            out = f(x)\n",
    "            # if filter has no channels left\n",
    "            if out is not None:\n",
    "                output_list.append(out)\n",
    "                m_list.append(f.m_this)\n",
    "                n_list.append(f.n_this)\n",
    "        x.ms_x = m_list\n",
    "        x.ns_x = n_list\n",
    "        x.data = torch.cat(output_list, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def get_filter_positions(self):\n",
    "        # =============================================================================\n",
    "        # in use for next layer input (initialisation of the model)\n",
    "        # =============================================================================\n",
    "        \n",
    "        ms_this = []\n",
    "        ns_this = []\n",
    "        for f in self.filter_list:\n",
    "            ms_this.append(f.m_this)\n",
    "            ns_this.append(f.n_this)\n",
    "        \n",
    "        return ms_this, ns_this\n",
    "    \n",
    "    def get_everything(self):\n",
    "        \n",
    "        sources = [] # source m,n,l-1\n",
    "        targets = [] # target m,n,l\n",
    "        target_groups = []\n",
    "        values = [] # connection value = ci value of channel in target connected to ms[i], ns[i] \n",
    "        \n",
    "        # for each filter\n",
    "        for i_f, f in enumerate(self.filter_list):\n",
    "            # for each channel\n",
    "            \n",
    "            # print(\"ms_in shape\", f.ms_in.shape)\n",
    "            for i_s in range(len(f.ms_in)):\n",
    "                \n",
    "                s = str(int(f.ms_in[i_s].item()))+'_'+str(int(f.ns_in[i_s].item()))\n",
    "                sources.append(s)\n",
    "\n",
    "                t = str(int(f.m_this.item()))+'_'+str(int(f.n_this.item()))\n",
    "                targets.append(t)\n",
    "\n",
    "                target_groups.append(self.layer_name)\n",
    "            \n",
    "            # get all channel importances\n",
    "            ci = np.array(self.run_channel_importance(i_f)).flatten()\n",
    "            #print(\"CI\"*50)\n",
    "            #print(ci)\n",
    "            values.extend(ci)\n",
    "            \n",
    "            \"\"\"\n",
    "            try:\n",
    "                values.append( [val.item() for tmp in ci for val in tmp] )\n",
    "            except:\n",
    "                try:\n",
    "                    a = [val.item() for val in ci]\n",
    "                    values.append(  [val for tmp in a for val in tmp])\n",
    "                except:\n",
    "                    print(\"empty channel importance??\")\n",
    "                    values = []\n",
    "                    \n",
    "            \"\"\"\n",
    "            \n",
    "        #print(\"lengths note:\", len(sources), len(targets), len(target_groups), len(values))\n",
    "        \n",
    "        return {'source':sources, 'target':targets, 'target_group':target_groups, 'value':values}\n",
    "            \n",
    "    \n",
    "    def update(self):\n",
    "        # =============================================================================\n",
    "        # currently: calculate importance metric for the prune_channel method\n",
    "        # remove channels based on self.prune_keep\n",
    "        # layerwise pruning - percentage of layer\n",
    "        # =============================================================================\n",
    "        \n",
    "        all_ci = []\n",
    "        all_len = 0\n",
    "        for i_f in range(len(self.filter_list)):\n",
    "            all_len += len(self.filter_list[i_f].ms_in)\n",
    "            # list of lists\n",
    "            all_ci.append(self.run_channel_importance(i_f))\n",
    "            #tmp_ids = sorted(range(len(all_ci)), key=lambda sub: all_ci[sub])\n",
    "          \n",
    "        #print(all_len) # this is the size of the previous pruning\n",
    "        #print(self.original_size)\n",
    "        #print(self.prune_keep_total)\n",
    "        #print(int(self.original_size * self.prune_keep_total))\n",
    "        \n",
    "        #self.log(f'{self.original_size}_active_channels', all_len, on_step=True, on_epoch=True)\n",
    "        \n",
    "        if all_len < int(self.original_size * self.prune_keep_total):\n",
    "            # if n percent have been pruned, stop this layer\n",
    "            print(\"pruning done for this layer\")\n",
    "        else:\n",
    "            # pruning\n",
    "            n = int(all_len*self.prune_keep)\n",
    "            all_ci_flatten = [item for row in all_ci for item in row] # don't have equal lengths, so no numpy possible\n",
    "            index = sorted(range(all_len), key=lambda sub: all_ci_flatten[sub])[-n] # error, out of range\n",
    "            threshold_value = all_ci_flatten[index]\n",
    "\n",
    "            for i_f in range(len(self.filter_list)):\n",
    "\n",
    "                # channel importance list for this filter\n",
    "                ci = all_ci[i_f] # self.run_channel_importance(i_f)\n",
    "\n",
    "                #print(ci)\n",
    "                #print(threshold_value)\n",
    "                # torch.where()\n",
    "                            \n",
    "                indices = np.where(ci >= threshold_value)[0] # just need the x axis\n",
    "\n",
    "                # indices should be list/np/detached\n",
    "                self.run_prune_channel(i_f, indices)\n",
    "                \n",
    "                #print(\"prune done\")\n",
    "                # ci = ci[indices] # probably not useful\n",
    "        \n",
    "            \n",
    "            # print(\"channel importance ci\", ci)\n",
    "            # keep_ids = random.sample(range(0, 8), 5)\n",
    "            #keep_ids = sorted(range(len(ci)), key=lambda sub: ci[sub])[amout_remove:]\n",
    "            #print(keep_ids)\n",
    "\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31232158-b0fb-4e80-856e-94f8808cf414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[324, 23, 324, 23]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "x.extend([324, 23]) # Nothing is printed because the return value is None\n",
    "x.extend([324, 23])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "109208ab-bed3-4f9b-aa56-eb61aebc3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(np.array(random.random()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af56675d-9098-4244-8170-519cc3d4076a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.67712583),\n",
       " array(0.78491136),\n",
       " array(0.52046616),\n",
       " array(0.5114917),\n",
       " array(0.39353466)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0510096-312f-4ae3-8192-8165b649199c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6771258268002703,\n",
       " 0.7849113560871108,\n",
       " 0.5204661572030815,\n",
       " 0.5114917024932601,\n",
       " 0.39353466292596484]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "[tmp.item() for tmp in a]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c186cf1-c7db-45da-b779-f7ab88f3896f",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## DecentNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd6a2811-6313-41cc-82a0-78cdb812c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentNet(nn.Module):\n",
    "    def __init__(self, model_kwargs, log_dir=\"\") -> None:\n",
    "        super(DecentNet, self).__init__()\n",
    "        \n",
    "        self.n_classes = model_kwargs[\"n_classes\"]\n",
    "        out_dim = model_kwargs[\"out_dim\"]\n",
    "        out_dim.append(self.n_classes) # out_dim = [1, 32, 48, 64, 10]     \n",
    "        \n",
    "        grid_size = model_kwargs[\"grid_size\"]\n",
    "        assert not any(i > grid_size for i in out_dim), f\"filters need to be less than {grid_size}\"\n",
    "        self.grid_sqrt = int(math.sqrt(grid_size))\n",
    "        \n",
    "        self.ci_metric = model_kwargs[\"ci_metric\"]\n",
    "        \n",
    "        self.log_dir = log_dir\n",
    "\n",
    "        # backbone\n",
    "        \n",
    "        # initialise input positions of first layer\n",
    "        ms_in_1 = [torch.tensor(0)]\n",
    "        ns_in_1 = [torch.tensor(0)]\n",
    "        assert out_dim[0] == len(ms_in_1), f\"x data (out_dim[0]={out_dim[0]}) needs to match (ms_in_1={len(ms_in_1)})\"\n",
    "        assert out_dim[0] == len(ns_in_1), f\"x data (out_dim[0]={out_dim[0]}) needs to match (ns_in_1={len(ns_in_1)})\"\n",
    "        self.decent1 = DecentLayer(ms_in=ms_in_1, ns_in=ns_in_1, n_filters=out_dim[1], kernel_size=3, stride=1, padding=0, dilation=1, model_kwargs=model_kwargs, layer_name='decent1')\n",
    "        \n",
    "        # get position of previous layer as input for this layer\n",
    "        ms_in_2,ns_in_2 = self.decent1.get_filter_positions()\n",
    "        assert out_dim[1] == len(ms_in_2), f\"x data (out_dim[1]={out_dim[1]}) needs to match (ms_in_2={len(ms_in_2)})\"\n",
    "        assert out_dim[1] == len(ns_in_2), f\"x data (out_dim[1]={out_dim[1]}) needs to match (ns_in_2={len(ns_in_2)})\"\n",
    "        self.decent2 = DecentLayer(ms_in=ms_in_2, ns_in=ns_in_2, n_filters=out_dim[2], kernel_size=3, stride=1, padding=0, dilation=1, model_kwargs=model_kwargs, layer_name='decent2')\n",
    "        \n",
    "        ms_in_3,ns_in_3 = self.decent2.get_filter_positions()\n",
    "        assert out_dim[2] == len(ms_in_3), f\"x data (out_dim[2]={out_dim[2]}) needs to match (ms_in_3={len(ms_in_3)})\"\n",
    "        assert out_dim[2] == len(ns_in_3), f\"x data (out_dim[2]={out_dim[2]}) needs to match (ns_in_3={len(ns_in_3)})\"\n",
    "        self.decent3 = DecentLayer(ms_in=ms_in_3, ns_in=ns_in_3, n_filters=out_dim[3], kernel_size=3, stride=1, padding=0, dilation=1, model_kwargs=model_kwargs, layer_name='decent3')\n",
    "        \n",
    "        ms_in_1x1,ns_in_1x1 = self.decent3.get_filter_positions()\n",
    "        assert out_dim[3] == len(ms_in_1x1), f\"x data (out_dim[3]={out_dim[3]}) needs to match (ms_in_1x1={len(ms_in_1x1)})\"\n",
    "        assert out_dim[3] == len(ns_in_1x1), f\"x data (out_dim[3]={out_dim[3]}) needs to match (ns_in_1x1={len(ns_in_1x1)})\"\n",
    "        self.decent1x1 = DecentLayer(ms_in=ms_in_1x1, ns_in=ns_in_1x1, n_filters=out_dim[-1], kernel_size=1, stride=1, padding=0, dilation=1, model_kwargs=model_kwargs, layer_name='decent1x1')\n",
    "        \n",
    "        #self.tmp = torchvision.models.squeezenet1_0(torchvision.models.SqueezeNet1_0_Weights.IMAGENET1K_V1)\n",
    "        #self.tmp.classifier[1] = torch.nn.Conv2d(512, 10, kernel_size=(3,3))\n",
    "        \n",
    "        # head\n",
    "        self.fc = torch.nn.Linear(out_dim[-1], out_dim[-1])\n",
    "    \n",
    "        # activation\n",
    "        self.mish1 = torch.nn.Mish()\n",
    "        self.mish2 = torch.nn.Mish()\n",
    "        self.mish3 = torch.nn.Mish()\n",
    "        self.mish1x1 = torch.nn.Mish()\n",
    "        \n",
    "        # bias\n",
    "        self.bias1 = torch.nn.InstanceNorm2d(out_dim[1])\n",
    "        self.bias2 = torch.nn.InstanceNorm2d(out_dim[2])\n",
    "        self.bias3 = torch.nn.InstanceNorm2d(out_dim[3])\n",
    "        self.bias1x1 = torch.nn.InstanceNorm2d(out_dim[-1])\n",
    "        \n",
    "        # activation\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # init connection cost\n",
    "        self.cc = []\n",
    "        self.update_connection_cost()\n",
    "        \n",
    "        # get a position in filter list\n",
    "        self.m_l2_plot = self.decent2.filter_list[0].m_this.detach().cpu().numpy()\n",
    "        self.n_l2_plot = self.decent2.filter_list[0].n_this.detach().cpu().numpy()  \n",
    "        \n",
    "        print(self.m_l2_plot)\n",
    "        print(self.n_l2_plot)\n",
    "        \n",
    "        \"\"\"\n",
    "        with open(os.path.join(self.log_dir, 'logger.txt'), 'a') as f:\n",
    "                f.write(\"\\n# plot #\\n\")\n",
    "                for p in self.model.parameters():\n",
    "                    if p.requires_grad:\n",
    "                        f.write('m:' + str(self.m_l2_plot) + ', n: ' + str(self.n_l2_plot) + '\\n')\n",
    "        \"\"\"\n",
    "        # self.plot_layer_of_1_channel(current_epoch=0) - not working here, dir not created yet\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "        \n",
    "    def forward(self, x, mode=\"grad\"):\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        x = self.decent1(x)\n",
    "        x.data = self.mish1(x.data)\n",
    "        x.data = self.bias1(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        x = self.decent2(x)\n",
    "        x.data = self.mish2(x.data)\n",
    "        x.data = self.bias2(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        x = self.decent3(x)\n",
    "        x.data = self.mish3(x.data)\n",
    "        x.data = self.bias3(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        x = self.decent1x1(x)\n",
    "        x.data = self.mish1x1(x.data)\n",
    "        x.data = self.bias1x1(x.data)\n",
    "        \n",
    "        #print(x)\n",
    "        \n",
    "        # hook on the data (for gradcam or something similar)\n",
    "        # https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82\n",
    "        if mode == 'explain':\n",
    "            output = x.data.register_hook(self.activations_hook)\n",
    "            #'cannot register a hook on a tensor that doesn't require gradient'\n",
    "        \n",
    "        \n",
    "        # global max pooling for MIL\n",
    "        # https://discuss.pytorch.org/t/global-max-pooling/1345\n",
    "        # Global Average Pooling is a pooling operation designed to replace fully connected layers in classical CNNs. \n",
    "        # The idea is to generate one feature map for each corresponding category of the classification task in the last mlpconv layer.\n",
    "        # Similar to global average pooling, to implement global max pooling in PyTorch, \n",
    "        # one needs to use the regular max pooling class with a kernel size equal to the size of the feature map at that point\n",
    "        x.data = F.max_pool2d(x.data, kernel_size=x.data.size()[2:])\n",
    "        \n",
    "        # or flatten\n",
    "        x.data = x.data.reshape(x.data.size(0), -1)\n",
    "        \n",
    "        # we still want the fc ???\n",
    "        # x.data = self.fc(x.data) \n",
    "        \n",
    "        # x.data = self.sigmoid(x.data)\n",
    "        \n",
    "        # x.data = self.tmp(x.data)\n",
    "        \n",
    "        return x.data\n",
    "    \n",
    "    \n",
    "    def activations_hook(self, grad):\n",
    "        # hook for the gradients of the activations\n",
    "        self.gradients = grad\n",
    "    def get_activations_gradient(self):\n",
    "        # method for the gradient extraction\n",
    "        return self.gradients\n",
    "    def get_activations(self, x):\n",
    "        # method for the activation exctraction\n",
    "        \n",
    "        #print('0', x)\n",
    "        \n",
    "        x = self.decent1(x)\n",
    "        x.data = self.mish1(x.data)\n",
    "        x.data = self.bias1(x.data)\n",
    "        #print('1', x)\n",
    "\n",
    "        x = self.decent2(x)\n",
    "        x.data = self.mish2(x.data)\n",
    "        x.data = self.bias2(x.data)\n",
    "        #print('2', x)\n",
    "        \n",
    "        x = self.decent3(x)\n",
    "        x.data = self.mish3(x.data)\n",
    "        x.data = self.bias3(x.data)\n",
    "        #print('3', x)\n",
    "        \n",
    "        x = self.decent1x1(x)\n",
    "        x.data = self.mish1x1(x.data)\n",
    "        x.data = self.bias1x1(x.data)\n",
    "        #print('1x1', x)\n",
    "        \n",
    "        return x.data\n",
    "    \n",
    "    def plot_incoming_connections(self, current_epoch=0):\n",
    "        # analyse incoming conenctions\n",
    "        # which kernels were pruned in this filter\n",
    "        # decent3 = orange\n",
    "        # decent2 = cyan\n",
    "        # decent1 = pink\n",
    "        \n",
    "        # get each filter position that has a channel that matches\n",
    "        ms = []; ns = []\n",
    "        \n",
    "        #print(self.decent2.filter_list)\n",
    "        #print(\"**********************\")\n",
    "        #print(self.decent3.filter_list)\n",
    "\n",
    "        \n",
    "        # use first filter in the list of this layer\n",
    "        this_filter = self.decent2.filter_list[0] # orange\n",
    "        \n",
    "        m_tmp = this_filter.m_this.detach().cpu().numpy()\n",
    "        n_tmp = this_filter.n_this.detach().cpu().numpy()\n",
    "        ms_tmp = this_filter.ms_in.detach().cpu().numpy()\n",
    "        ns_tmp = this_filter.ns_in.detach().cpu().numpy()\n",
    "                \n",
    "        # visualising the previous and current layer neurons\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        ax.scatter(m_tmp, n_tmp, s=100000, color='tab:cyan', alpha=0.1) # previous layer\n",
    "        ax.scatter(m_tmp, n_tmp, s=50000, color='tab:cyan',alpha=0.2) # previous layer\n",
    "        ax.scatter(m_tmp, n_tmp, s=25000, color='tab:cyan',alpha=0.3) # previous layer\n",
    "        ax.scatter(m_tmp, n_tmp, s=500, color='tab:cyan') # previous layer\n",
    "        ax.scatter(ms_tmp, ns_tmp, color='tab:pink') # next layer\n",
    "        plt.xlim(0, self.grid_sqrt) # m coordinate of grid_size field\n",
    "        plt.ylim(0, self.grid_sqrt) # n coordinate of grid_size field\n",
    "        ax.grid() # enable grid line\n",
    "        fig.savefig(os.path.join(self.log_dir, f\"in_{self.ci_metric}_m{int(self.m_l2_plot[0])}_n{int(self.n_l2_plot[0])}_{str(current_epoch)}.png\"))\n",
    "    \n",
    "    def plot_outgoing_connections(self, current_epoch=0): # plot_layer_of_1_channel\n",
    "        # analyse outgoing conenctions\n",
    "        # which filters in the next layer are influenced by this filter\n",
    "        \n",
    "        # get each filter position that has a channel that matches\n",
    "        ms = []; ns = []\n",
    "        \n",
    "        #print(self.decent2.filter_list)\n",
    "        #print(\"**********************\")\n",
    "        #print(self.decent3.filter_list)\n",
    "\n",
    "        \n",
    "        # go through all filters in this layer\n",
    "        for f in self.decent3.filter_list:\n",
    "            \n",
    "            # if filter position in prev layer matches any channel in this layer\n",
    "            if any(pair == (self.m_l2_plot, self.n_l2_plot) for pair in zip(f.ms_in.detach().cpu().numpy(), f.ns_in.detach().cpu().numpy())):\n",
    "                \n",
    "                #print('match', f.m_this, f.n_this)\n",
    "                \n",
    "                # save position of each filter in this layer\n",
    "                ms.append(f.m_this.detach().cpu().numpy())\n",
    "                ns.append(f.n_this.detach().cpu().numpy())\n",
    "              \n",
    "            if False:\n",
    "                    print(\"nooooooooooooooo\")\n",
    "                    print(f.ms_in)\n",
    "                    print(self.m_l2_plot)\n",
    "                    print(f.ns_in)\n",
    "                    print(self.n_l2_plot)\n",
    "\n",
    "                    print((self.m_l2_plot, self.n_l2_plot))\n",
    "                \n",
    "        # visualising the previous and current layer neurons\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        ax.scatter(self.m_l2_plot, self.n_l2_plot, s=100000, color='tab:cyan', alpha=0.1) # previous layer\n",
    "        ax.scatter(self.m_l2_plot, self.n_l2_plot, s=50000, color='tab:cyan',alpha=0.2) # previous layer\n",
    "        ax.scatter(self.m_l2_plot, self.n_l2_plot, s=25000, color='tab:cyan',alpha=0.3) # previous layer\n",
    "        ax.scatter(self.m_l2_plot, self.n_l2_plot, s=500, color='tab:cyan') # previous layer\n",
    "        ax.scatter(ms, ns, color='tab:orange') # next layer\n",
    "        plt.xlim(0, self.grid_sqrt) # m coordinate of grid_size field\n",
    "        plt.ylim(0, self.grid_sqrt) # n coordinate of grid_size field\n",
    "        ax.grid() # enable grid line\n",
    "        fig.savefig(os.path.join(self.log_dir, f\"out_{self.ci_metric}_m{int(self.m_l2_plot[0])}_n{int(self.n_l2_plot[0])}_{str(current_epoch)}.png\"))\n",
    "    \n",
    "    def update_connection_cost(self):\n",
    "        self.cc = []\n",
    "        # self.cc.append(self.decent1.run_layer_connection_cost()) # maybe not even needed ...\n",
    "        self.cc.append(self.decent2.run_layer_connection_cost())\n",
    "        self.cc.append(self.decent3.run_layer_connection_cost())\n",
    "        self.cc.append(self.decent1x1.run_layer_connection_cost())\n",
    "        self.cc = torch.mean(torch.tensor(self.cc))\n",
    "\n",
    "    def update(self, current_epoch):\n",
    "        # =============================================================================\n",
    "        # update_every_nth_epoch\n",
    "        # adapted from BIMT: https://github.com/KindXiaoming/BIMT/blob/main/mnist_3.5.ipynb\n",
    "        # =============================================================================\n",
    "        \n",
    "        # update decent layers\n",
    "        \n",
    "        #self.decent1.update()\n",
    "        self.decent2.update()\n",
    "        self.decent3.update()\n",
    "        self.decent1x1.update()\n",
    "        \n",
    "        # visualisation\n",
    "        self.plot_incoming_connections(current_epoch)\n",
    "        self.plot_outgoing_connections(current_epoch)\n",
    "    \n",
    "        # connection cost has to be calculated after pruning\n",
    "        # self.cc which is updated is used for loss function\n",
    "        self.update_connection_cost()\n",
    "        \n",
    "    def get_everything(self, current_epoch):\n",
    "        \n",
    "        d1 = self.decent1.get_everything()\n",
    "        d2 = self.decent2.get_everything()\n",
    "        d3 = self.decent3.get_everything()\n",
    "        d1x1 = self.decent1x1.get_everything()\n",
    "        \n",
    "        #print(d1)\n",
    "        #print(d2)\n",
    "        #print(d3)\n",
    "        \n",
    "        df1 = pd.DataFrame(d1)\n",
    "        #print(df1.head())\n",
    "        \n",
    "        df2 = pd.DataFrame(d2)\n",
    "        #print(df2.head())\n",
    "        \n",
    "        df3 = pd.DataFrame(d3)\n",
    "        #print(df3.head())\n",
    "        \n",
    "        df1x1 = pd.DataFrame(d1x1)\n",
    "        \n",
    "        frames = [df1, df2, df3, df1x1]\n",
    "        result = pd.concat(frames)\n",
    "        \n",
    "        result.to_csv(os.path.join(self.log_dir, f'out_{str(current_epoch)}.csv'), index=False)  \n",
    "        \n",
    "        # return d1, d2, d3, d1x1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238bf19-b053-46ce-b0b4-228ead91f827",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b6ec5f3-4f08-421c-9137-53ab5908d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.model_checkpoint import *\n",
    "\n",
    "class DecentModelCheckpoint(ModelCheckpoint):\n",
    "\n",
    "    def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        # =============================================================================\n",
    "        # costum model checkpoint\n",
    "        # Save a checkpoint at the end of the training epoch.\n",
    "        # parameters:\n",
    "        #    trainer\n",
    "        #    module\n",
    "        # saves:\n",
    "        #    the checkpoint model\n",
    "        # sources:\n",
    "        #    https://github.com/Lightning-AI/pytorch-lightning/blob/master/src/lightning/pytorch/callbacks/model_checkpoint.py\n",
    "        # =============================================================================\n",
    "        \n",
    "        if (\n",
    "            not self._should_skip_saving_checkpoint(trainer) \n",
    "            and self._should_save_on_train_epoch_end(trainer)\n",
    "        ):\n",
    "            monitor_candidates = self._monitor_candidates(trainer)\n",
    "            monitor_candidates[\"epoch\"] = monitor_candidates[\"epoch\"]\n",
    "            print(\"DECENT NOTE: callback on_train_epoch_end\", monitor_candidates[\"epoch\"])\n",
    "            if monitor_candidates[\"epoch\"] > 0:\n",
    "                if monitor_candidates[\"unpruned_state\"] != -1:\n",
    "                    print(\"DECENT NOTE: save model\", monitor_candidates[\"epoch\"])\n",
    "                    if self._every_n_epochs >= 1 and ((trainer.current_epoch + 1) % self._every_n_epochs) == 0:\n",
    "                        self._save_topk_checkpoint(trainer, monitor_candidates)\n",
    "                    self._save_last_checkpoint(trainer, monitor_candidates)\n",
    "                    \n",
    "                    pl_module.model.get_everything(current_epoch=trainer.current_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60bdf0-147c-4bfe-83c0-4a330c7f9bfc",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90dfcd-c00f-4f9d-8c24-bbac8c6af17b",
   "metadata": {},
   "source": [
    "## DecentLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92509f06-c9fb-4084-843e-b80b3552c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentLightning(pl.LightningModule):\n",
    "    # =============================================================================\n",
    "    #\n",
    "    # Lightning Module consists of functions that define the training routine\n",
    "    # train, val, test: before epoch, step, after epoch, ...\n",
    "    # https://github.com/Lightning-AI/pytorch-lightning/blob/master/src/lightning/pytorch/core/module.py\n",
    "    # order for the instance methods:\n",
    "    # https://pytorch-lightning.readthedocs.io/en/1.7.2/common/lightning_module.html#hooks\n",
    "    # \n",
    "    # =============================================================================\n",
    "\n",
    "    def __init__(self, kwargs, log_dir):\n",
    "        super().__init__()\n",
    "        \n",
    "        # print(\"the kwargs: \", kwargs)\n",
    "        \n",
    "        # keep kwargs for saving hyperparameters\n",
    "        model_kwargs = kwargs['model_kwargs']\n",
    "        \n",
    "        self.log_dir = log_dir\n",
    "    \n",
    "        # n_classes=self.n_classes, grid_size=self.grid_size, out_dim=self.out_dim, prune_keep=self.prune_keep, prune_keep_total=self.prune_keep_total, cc_metric=self.cc_metric\n",
    "        self.model = DecentNet(model_kwargs=model_kwargs, log_dir=log_dir).to(\"cuda\")\n",
    "        \n",
    "        self.n_classes = model_kwargs[\"n_classes\"]\n",
    "        self.cc_weight = model_kwargs[\"cc_weight\"]\n",
    "        self.criterion = model_kwargs[\"criterion\"]\n",
    "        self.optimizer = model_kwargs[\"optimizer\"]\n",
    "        self.base_lr = model_kwargs[\"base_lr\"]\n",
    "        self.min_lr = model_kwargs[\"min_lr\"]\n",
    "        self.lr_update = model_kwargs[\"lr_update\"]\n",
    "        self.momentum = model_kwargs[\"momentum\"]\n",
    "        self.update_every_nth_epoch = model_kwargs[\"update_every_nth_epoch\"]\n",
    "        self.pretrain_epochs = model_kwargs[\"pretrain_epochs\"]\n",
    "        \n",
    "        # needed for hparams.yaml file\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        if False:\n",
    "            self.metric = { \"train_acc\" : torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes),\n",
    "                     \"train_f1\" : torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes),\n",
    "                     \"val_acc\" : torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes),\n",
    "                     \"val_f1\" : torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes)\n",
    "                   }\n",
    "        else:\n",
    "            self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.train_prec =  torchmetrics.Precision(task=\"multiclass\", average='macro', num_classes=self.n_classes)\n",
    "            self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.val_prec =  torchmetrics.Precision(task=\"multiclass\", average='macro', num_classes=self.n_classes)\n",
    "            self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.n_classes)\n",
    "            self.test_prec =  torchmetrics.Precision(task=\"multiclass\", average='macro', num_classes=self.n_classes)\n",
    "\n",
    "            \n",
    "    def forward(self, x, mode=\"grad\"):\n",
    "        # =============================================================================\n",
    "        # we make it possible to use model_output = self(image)\n",
    "        # =============================================================================\n",
    "        return self.model(x, mode)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def load_from_checkpoint(cls, checkpoint_path, **kwargs):\n",
    "        # todo, need to overwrite this somehow\n",
    "    \n",
    "        #Always use self for the first argument to instance methods.\n",
    "        #Always use cls for the first argument to class methods.\n",
    "    \n",
    "        loaded = cls._load_from_checkpoint(\n",
    "            cls,  # type: ignore[arg-type]\n",
    "            checkpoint_path,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return cast(Self, loaded)\n",
    "    \n",
    "    # todo, need to overwrite this somehow\n",
    "    @classmethod\n",
    "    def _load_from_checkpoint(\n",
    "        cls,\n",
    "        checkpoint_path,\n",
    "        **kwargs):\n",
    "        \n",
    "        map_location = None\n",
    "        with pl_legacy_patch():\n",
    "            checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
    "\n",
    "        # convert legacy checkpoints to the new format\n",
    "        checkpoint = _pl_migrate_checkpoint(\n",
    "            checkpoint, checkpoint_path=(checkpoint_path if isinstance(checkpoint_path, (str, Path)) else None)\n",
    "        )\n",
    "\n",
    "        if hparams_file is not None:\n",
    "            extension = str(hparams_file).split(\".\")[-1]\n",
    "            if extension.lower() == \"csv\":\n",
    "                hparams = load_hparams_from_tags_csv(hparams_file)\n",
    "            elif extension.lower() in (\"yml\", \"yaml\"):\n",
    "                hparams = load_hparams_from_yaml(hparams_file)\n",
    "            else:\n",
    "                raise ValueError(\".csv, .yml or .yaml is required for `hparams_file`\")\n",
    "\n",
    "            # overwrite hparams by the given file\n",
    "            checkpoint[cls.CHECKPOINT_HYPER_PARAMS_KEY] = hparams\n",
    "\n",
    "        # TODO: make this a migration:\n",
    "        # for past checkpoint need to add the new key\n",
    "        checkpoint.setdefault(cls.CHECKPOINT_HYPER_PARAMS_KEY, {})\n",
    "        # override the hparams with values that were passed in\n",
    "        checkpoint[cls.CHECKPOINT_HYPER_PARAMS_KEY].update(kwargs)\n",
    "\n",
    "        if issubclass(cls, pl.LightningDataModule):\n",
    "            return _load_state(cls, checkpoint, **kwargs)\n",
    "        if issubclass(cls, pl.LightningModule):\n",
    "            model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n",
    "            state_dict = checkpoint[\"state_dict\"]\n",
    "            if not state_dict:\n",
    "                rank_zero_warn(f\"The state dict in {checkpoint_path!r} contains no parameters.\")\n",
    "                return model\n",
    "\n",
    "            device = next((t for t in state_dict.values() if isinstance(t, torch.Tensor)), torch.tensor(0)).device\n",
    "            assert isinstance(model, pl.LightningModule)\n",
    "            return model.to(device)\n",
    "\n",
    "        raise NotImplementedError(f\"Unsupported {cls}\")\n",
    "    \"\"\"\n",
    "           \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # =============================================================================\n",
    "        # returns:\n",
    "        #    optimiser and lr scheduler\n",
    "        # =============================================================================  \n",
    "        print(\"DECENT NOTE: configure_optimizers\")\n",
    "        \n",
    "        if self.optimizer == \"adamw\":\n",
    "            optimiser = optim.AdamW(self.parameters(), lr=self.base_lr)\n",
    "            lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimiser, milestones=[50,100], gamma=0.1)\n",
    "            return [optimiser], [lr_scheduler]\n",
    "        else:\n",
    "            optimiser = optim.SGD(self.parameters(), lr=self.base_lr, momentum=self.momentum)\n",
    "            lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimiser, \n",
    "                                                                              T_0 = self.lr_update, # number of iterations for the first restart.\n",
    "                                                                              eta_min = self.min_lr\n",
    "                                                                               )\n",
    "            return [optimiser], [lr_scheduler]\n",
    "        \n",
    "    def on_train_epoch_start(self):\n",
    "        # =============================================================================\n",
    "        # initial plot of circular layer\n",
    "        # updates model every nth epoch\n",
    "        # =============================================================================  \n",
    "        print(\"DECENT NOTE: on_train_epoch_start\", self.current_epoch)\n",
    "        \n",
    "        # plot random layer (the circular plot)\n",
    "        if self.current_epoch == 0:\n",
    "            self.model.plot_incoming_connections(current_epoch=0)\n",
    "            self.model.plot_outgoing_connections(current_epoch=0)\n",
    "\n",
    "        # update model\n",
    "         # don't update unless pretrain epochs is reached\n",
    "        if (self.current_epoch % self.update_every_nth_epoch) == 0 and self.current_epoch >= self.pretrain_epochs:\n",
    "            print(\"DECENT NOTE: update model\", self.current_epoch)        \n",
    "            if debug_model:\n",
    "                print(\"DECENT NOTE: before update\")\n",
    "                print(self.model)\n",
    "            self.model.update(current_epoch = self.current_epoch)\n",
    "            if debug_model: \n",
    "                print(\"DECENT NOTE: after update\")\n",
    "                print(self.model)\n",
    "                \n",
    "            print(\"DECENT NOTE: model updated\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # =============================================================================\n",
    "        # calculates loss for a batch # 1\n",
    "        # parameters:\n",
    "        #    batch\n",
    "        #    batch id\n",
    "        # returns:\n",
    "        #    loss\n",
    "        # notes:\n",
    "        #    calling gradcam like self.gradcam(batch) is dangerous cause changes gradients\n",
    "        # =============================================================================     \n",
    "        if False: # batch_idx < 2: # print first two steps\n",
    "            print(\"DECENT NOTE: training_step\", batch_idx)\n",
    "\n",
    "        # calculate loss\n",
    "        # loss = torch.tensor(1)\n",
    "        loss = self.run_loss_n_metrics(batch, mode=\"train\")\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # =============================================================================\n",
    "        # calculate loss for logging # 2\n",
    "        # =============================================================================\n",
    "        if False: # batch_idx < 2:\n",
    "            print(\"DECENT NOTE: validation_step\", batch_idx)\n",
    "        \n",
    "        self.run_loss_n_metrics(batch, mode=\"val\")\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        # =============================================================================\n",
    "        # currently nothing # 3\n",
    "        # =============================================================================\n",
    "        print(\"DECENT NOTE: on_validation_epoch_end\")\n",
    "        pass\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        # =============================================================================\n",
    "        # save model if next iteration model is pruned # 4 \n",
    "        # this needs to be called before callback \n",
    "        # - if internal pytorch lightning convention changes, this will stop working\n",
    "        # =============================================================================\n",
    "        print(\"DECENT NOTE: on_train_epoch_end\", self.current_epoch)\n",
    "               \n",
    "        if False:\n",
    "            print(\"current epoch\")\n",
    "            print(((self.current_epoch+1) % self.update_every_nth_epoch) == 0)\n",
    "            print(self.current_epoch+1)\n",
    "            print(self.current_epoch)\n",
    "            print(self.update_every_nth_epoch)\n",
    "        \n",
    "        # numel: returns the total number of elements in the input tensor\n",
    "        unpruned = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        self.log(f'unpruned', unpruned, on_step=False, on_epoch=True) \n",
    "        \n",
    "        if ((self.current_epoch+1) % self.update_every_nth_epoch) == 0 and self.current_epoch != 0:\n",
    "            # if next epoch is an update, set unpruned flag            \n",
    "            self.log(f'unpruned_state', 1, on_step=False, on_epoch=True)\n",
    "            \n",
    "            # save file\n",
    "            with open(os.path.join(self.log_dir, 'logger.txt'), 'a') as f:\n",
    "                f.write(\"\\n# parameter requires grad shape #\\n\")\n",
    "                for p in self.model.parameters():\n",
    "                    if p.requires_grad:\n",
    "                        f.write(str(p.shape))\n",
    "            \n",
    "        else:\n",
    "            # else set unpruned flag to -1, then model won't be saved\n",
    "            self.log(f'unpruned_state', -1, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        self.model.get_everything(current_epoch='final_test')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # =============================================================================\n",
    "        # calculate loss for logging, plot gradcam\n",
    "        # =============================================================================\n",
    "        if batch_idx < 2:\n",
    "            print(\"DECENT NOTE: test_step\", batch_idx)\n",
    "\n",
    "        self.run_loss_n_metrics(batch, mode=\"test\")\n",
    "\n",
    "                # .requires_grad_()\n",
    "        \n",
    "                \n",
    "        \"\"\"\n",
    "        with torch.enable_grad():\n",
    "            grad_preds = preds.requires_grad_()\n",
    "            preds2 = self.layer2(grad_preds)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            with torch.set_grad_enabled(True): # torch.set_grad_enabled(True):\n",
    "                self.run_xai_gradcam(batch, batch_idx, mode='explain')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"batch size has to be 1\")\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            \n",
    "            layer = self.model.decent1\n",
    "            # this line seems to be useless, always same output no matter what\n",
    "            layer_str = 'decent1' # 'decent3'  model.model.decent3' # .filter_list[7]weights\n",
    "            self.run_xai_feature_map(batch, batch_idx, layer, layer_str, device='cuda')\n",
    "            \n",
    "            layer = self.model.decent2\n",
    "            # this line seems to be useless, always same output no matter what\n",
    "            layer_str = 'decent2' # 'decent3'  model.model.decent3' # .filter_list[7]weights\n",
    "            self.run_xai_feature_map(batch, batch_idx, layer, layer_str, device='cuda')\n",
    "            \n",
    "            layer = self.model.decent3\n",
    "            # this line seems to be useless, always same output no matter what\n",
    "            layer_str = 'decent3' # 'decent3'  model.model.decent3' # .filter_list[7]weights\n",
    "            self.run_xai_feature_map(batch, batch_idx, layer, layer_str, device='cuda')\n",
    "            \n",
    "            layer = self.model.decent1x1\n",
    "            # this line seems to be useless, always same output no matter what\n",
    "            layer_str = 'decent1x1' # 'decent3'  model.model.decent3' # .filter_list[7]weights\n",
    "            self.run_xai_feature_map(batch, batch_idx, layer, layer_str, device='cuda')\n",
    "            \n",
    "    def on_test_epoch_end(self):\n",
    "        # =============================================================================\n",
    "        # currently nothing\n",
    "        # =============================================================================\n",
    "        print(\"DECENT NOTE: on_test_epoch_end\", self.current_epoch)\n",
    "        pass\n",
    "    \n",
    "    def run_xai_feature_map(self, batch, batch_idx, layer, layer_str, device='cuda'):\n",
    "        # https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/5\n",
    " \n",
    "        # img, label = testset.__getitem__(0) # batch x channel x width x height, class\n",
    "\n",
    "        # img = X(img.to(device).unsqueeze(0), [torch.tensor(0)], [torch.tensor(0)])\n",
    "        \n",
    "        img, ground_truth = batch\n",
    "        \n",
    "        # make it an X object, init with position 0/0 as input for first layer\n",
    "        tmp_img = X(img.to(\"cuda\"), [torch.tensor(0)], [torch.tensor(0)])\n",
    "\n",
    "        # print(img.data.shape)\n",
    "\n",
    "        # run feature map\n",
    "        # model, layer, layer_str, log_dir, device=\"cpu\"\n",
    "        fm = FeatureMap(model=self.model, layer=layer, layer_str=layer_str, log_dir=self.log_dir, device=device)\n",
    "        fm.run(tmp_img, batch_idx)\n",
    "        fm.log()\n",
    "    \n",
    "    def run_xai_gradcam(self, batch, batch_idx, mode='explain'):\n",
    "        # =============================================================================\n",
    "        # grad cam - or just cam?? idk\n",
    "        # todo error: RuntimeError: cannot register a hook on a tensor that doesn't require gradient\n",
    "        # BATCH SIZE HAS TO BE ONE!!!\n",
    "        # grad enable in test mode:\n",
    "        # https://github.com/Project-MONAI/MONAI/discussions/1598\n",
    "        # https://lightning.ai/docs/pytorch/stable/common/trainer.html\n",
    "        # =============================================================================\n",
    "    \n",
    "        img, ground_truth = batch\n",
    "\n",
    "        # make it an X object, init with position 0/0 as input for first layer\n",
    "        tmp_img1 = X(img.to(\"cuda\"), [torch.tensor(0)], [torch.tensor(0)]) # .requires_grad_()\n",
    "        tmp_img2 = X(img.to(\"cuda\"), [torch.tensor(0)], [torch.tensor(0)])\n",
    "\n",
    "        #print(\"nooooooooooo grad, whyyyyy\")\n",
    "        #print(tmp_img1)\n",
    "        #print(img)\n",
    "\n",
    "        #print('b1', tmp_img1)\n",
    "        #print('b2', tmp_img2)\n",
    "\n",
    "        model_output = self(tmp_img1, mode)\n",
    "\n",
    "        #print('c1', tmp_img1)\n",
    "        #print('c2', tmp_img2)\n",
    "\n",
    "        # get the gradient of the output with respect to the parameters of the model\n",
    "        #pred[:, 386].backward()\n",
    "\n",
    "        # get prediction value\n",
    "        pred_max = model_output.argmax(dim=1)\n",
    "\n",
    "        #print('d1', tmp_img1)\n",
    "\n",
    "        #print(\"mo\", model_output)\n",
    "        #print(\"max\", pred_max)\n",
    "        #print(\"backprop\", model_output[:, pred_max])\n",
    "\n",
    "        # backpropagate for gradient tracking\n",
    "        model_output[:, pred_max].backward()\n",
    "\n",
    "        # pull the gradients out of the model\n",
    "        gradients = self.model.get_activations_gradient()\n",
    "\n",
    "        # pool the gradients across the channels\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "        #print('e2', tmp_img2)\n",
    "\n",
    "        # get the activations of the last convolutional layer\n",
    "        activations = self.model.get_activations(tmp_img2).detach()\n",
    "\n",
    "        # weight the channels by corresponding gradients\n",
    "        for i in range(self.n_classes):\n",
    "            activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "        # average the channels of the activations\n",
    "        heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "        #print(\"hm\", heatmap.shape)\n",
    "\n",
    "        # relu on top of the heatmap\n",
    "        # expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "        #heatmap = torch.max(heatmap, 0)\n",
    "\n",
    "        # normalize the heatmap\n",
    "        #heatmap /= torch.max(heatmap)\n",
    "\n",
    "        #print(\"hm\", heatmap.shape)\n",
    "\n",
    "        # draw the heatmap\n",
    "        # plt.matshow(heatmap.detach().cpu().numpy().squeeze())\n",
    "        # fig.savefig(os.path.join(self.log_dir, f\"{self.ci_metric}_m{int(self.m_l2_plot[0])}_n{int(self.n_l2_plot[0])}_{str(current_epoch)}.png\"))\n",
    "\n",
    "        plt.imsave(os.path.join( self.log_dir, f\"plt_cam_id{batch_idx}_mo{pred_max.detach().cpu().numpy().squeeze()}_gt{ground_truth.detach().cpu().numpy().squeeze()}.png\" ), heatmap.detach().cpu().numpy().squeeze())\n",
    "\n",
    "\n",
    "        heatmap *= 255.0 / heatmap.max()\n",
    "        pil_heatmap = Image.fromarray(heatmap.detach().cpu().numpy().squeeze()).convert('RGB')\n",
    "        pil_heatmap.save(os.path.join( self.log_dir, f\"pil_cam_id{batch_idx}_mo{pred_max.detach().cpu().numpy().squeeze()}_gt{ground_truth.detach().cpu().numpy().squeeze()}.png\" ) ) \n",
    "            \n",
    "    def run_loss_n_metrics(self, batch, mode=\"train\"):\n",
    "        # =============================================================================\n",
    "        # put image through model, calculate loss and metrics\n",
    "        # use cc term that has been calculated previously\n",
    "        # =============================================================================\n",
    "        \n",
    "        img, ground_truth = batch\n",
    "        # make it an X object\n",
    "        \n",
    "        #print(img.shape)\n",
    "        \n",
    "        # init with position 0/0 as input for first layer\n",
    "        img = X(img.to(\"cuda\"), [torch.tensor(0)], [torch.tensor(0)])\n",
    "        \n",
    "        model_output = self(img, mode) # cause of the forward function\n",
    "        \n",
    "        # ground_truth = ground_truth\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"gt\", ground_truth)\n",
    "        print(\"gt shape\", ground_truth.shape)\n",
    "        print(\"gt type\", ground_truth.type())\n",
    "        print(torch.zeros(ground_truth.size(0), self.n_classes))\n",
    "        \n",
    "        if len(ground_truth.shape) < 2:\n",
    "            ground_truth_tmp_tmp = ground_truth.unsqueeze(1)\n",
    "        else:\n",
    "            ground_truth = ground_truth.transpose(1, 0)\n",
    "        ground_truth_multi_hot = torch.zeros(ground_truth_tmp.size(0), self.n_classes).scatter_(1, ground_truth_tmp.to(\"cpu\"), 1.).to(\"cuda\")\n",
    "        \n",
    "        # this needs fixing\n",
    "        # ground_truth_multi_hot = torch.zeros(ground_truth.size(0), 10).to(\"cuda\").scatter_(torch.tensor(1).to(\"cuda\"), ground_truth.to(\"cuda\"), torch.tensor(1.).to(\"cuda\")).to(\"cuda\")\n",
    "        \"\"\"\n",
    "\n",
    "        ground_truth = ground_truth.squeeze()\n",
    "        if len(ground_truth.shape) < 1:\n",
    "            ground_truth = ground_truth.unsqueeze(0)\n",
    "        loss = self.criterion(model_output, ground_truth.long()) # ground_truth_multi_hot)\n",
    "        cc = torch.mean(self.model.cc) * self.cc_weight\n",
    "        \n",
    "        # print(cc)\n",
    "        # from BIMT\n",
    "        # loss_train = loss_fn(mlp(x.to(device)), one_hots[label])\n",
    "        # cc = mlp.get_cc(weight_factor=2.0, no_penalize_last=True)\n",
    "        # total_loss = loss_train + lamb*cc\n",
    "        \n",
    "        pred_value, pred_i  = torch.max(model_output, 1)\n",
    "        \n",
    "        #print(model_output)\n",
    "        #print(pred_i)\n",
    "        #print(ground_truth)\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            ta = self.train_acc(preds=pred_i, target=ground_truth) # (model_output.argmax(dim=-1) == ground_truth).float().mean()\n",
    "            tf = self.train_f1(preds=pred_i, target=ground_truth) \n",
    "            tp = self.train_prec(preds=pred_i, target=ground_truth) \n",
    "            \n",
    "            self.log(f'{mode}_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_f1', self.train_f1, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_prec', self.train_prec, on_step=False, on_epoch=True)\n",
    "            \n",
    "            if random.randint(1, 50) == 5:\n",
    "                print()\n",
    "                print(\"train info at random intervals\")\n",
    "                print(\"p\", pred_i)\n",
    "                print(\"g\", ground_truth)\n",
    "                print(\"a\", ta)\n",
    "                print(\"f\", tf)\n",
    "                print(\"p\", tp)\n",
    "                print(\"l\", loss)\n",
    "                \n",
    "        elif mode == \"val\":\n",
    "            va = self.val_acc(preds=pred_i, target=ground_truth) # (model_output.argmax(dim=-1) == ground_truth).float().mean()\n",
    "            vf = self.val_f1(preds=pred_i, target=ground_truth) \n",
    "            vp = self.val_prec(preds=pred_i, target=ground_truth) \n",
    "            \n",
    "            self.log(f'{mode}_acc', self.val_acc, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_f1', self.val_f1, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_prec', self.val_prec, on_step=False, on_epoch=True)\n",
    "            \n",
    "            if random.randint(1, 50) == 5:\n",
    "                print()\n",
    "                print(\"val info at random intervals\")\n",
    "                print(\"p\", pred_i)\n",
    "                print(\"g\", ground_truth)\n",
    "                print(\"a\", va)\n",
    "                print(\"f\", vf)\n",
    "                print(\"p\", vp)\n",
    "                print(\"l\", loss)\n",
    "                \n",
    "        else:\n",
    "            ta = self.test_acc(preds=pred_i, target=ground_truth) # (model_output.argmax(dim=-1) == ground_truth).float().mean()\n",
    "            tf = self.test_f1(preds=pred_i, target=ground_truth) \n",
    "            tp = self.test_prec(preds=pred_i, target=ground_truth) \n",
    "            \n",
    "            self.log(f'{mode}_acc', self.test_acc, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_f1', self.test_f1, on_step=False, on_epoch=True)\n",
    "            self.log(f'{mode}_prec', self.test_prec, on_step=False, on_epoch=True)\n",
    "            \n",
    "            \n",
    "        self.log(f'{mode}_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'{mode}_cc', cc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        # loss + connection cost term\n",
    "        return loss + cc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afaef32c-9dc5-40c3-813b-0b9a9c69b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([5]).squeeze().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed2906-61b6-4f3a-b2fa-7aeeaa12e7e1",
   "metadata": {},
   "source": [
    "## run dev routine ****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d36c8d-87e6-4f01-8e52-cdcea768df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kwargs {'result_path': 'examples/example_results', 'exp_name': 'exp1_oct_no_fc_ci_l2_095', 'load_ckpt_file': 'xversion_22/checkpoints/epoch=0-unpruned=10942-val_f1=0.06.ckpt', 'epochs': 100, 'img_size': 28, 'batch_size': 128, 'log_every_n_steps': 4, 'device': 'cuda', 'num_workers': 18, 'train_size': 4096, 'val_size': 512, 'test_size': 24}\n",
      "model kwargs {'n_classes': 4, 'out_dim': [1, 8, 16, 32], 'grid_size': 324, 'criterion': CrossEntropyLoss(), 'optimizer': 'sgd', 'base_lr': 0.001, 'min_lr': 1e-05, 'momentum': 0.9, 'lr_update': 100, 'cc_weight': 10, 'cc_metric': 'l2', 'ci_metric': 'l2', 'cm_metric': 'not implemented yet', 'update_every_nth_epoch': 5, 'pretrain_epochs': 20, 'prune_keep': 0.95, 'prune_keep_total': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 19\n",
      "Missing logger folder: examples/example_results\\lightning_logs\\exp1_oct_no_fc_ci_l2_095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.]\n",
      "[5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name       | Type                | Params\n",
      "----------------------------------------------------\n",
      "0  | model      | DecentNet           | 7.7 K \n",
      "1  | criterion  | CrossEntropyLoss    | 0     \n",
      "2  | train_acc  | MulticlassAccuracy  | 0     \n",
      "3  | train_f1   | MulticlassF1Score   | 0     \n",
      "4  | train_prec | MulticlassPrecision | 0     \n",
      "5  | val_acc    | MulticlassAccuracy  | 0     \n",
      "6  | val_f1     | MulticlassF1Score   | 0     \n",
      "7  | val_prec   | MulticlassPrecision | 0     \n",
      "8  | test_acc   | MulticlassAccuracy  | 0     \n",
      "9  | test_f1    | MulticlassF1Score   | 0     \n",
      "10 | test_prec  | MulticlassPrecision | 0     \n",
      "----------------------------------------------------\n",
      "6.0 K     Trainable params\n",
      "1.7 K     Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECENT NOTE: configure_optimizers\n",
      "Sanity Checking: |                                                                               | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████████████████████████████████████████████████| 2/2 [00:05<00:00,  0.38it/s]DECENT NOTE: on_validation_epoch_end\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                  | 0/32 [00:00<?, ?it/s]DECENT NOTE: on_train_epoch_start 0\n",
      "Epoch 0:  84%|██████████████████████████████████████████████████████          | 27/32 [00:25<00:04,  1.04it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0,\n",
      "        0, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3,\n",
      "        3, 3, 3, 1, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 3, 3, 0,\n",
      "        3, 3, 0, 1, 0, 3, 0, 3, 3, 3, 0, 3, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 3, 3], device='cuda:0')\n",
      "g tensor([0, 1, 0, 0, 3, 3, 3, 2, 0, 0, 3, 3, 3, 1, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "        0, 3, 3, 0, 0, 3, 3, 2, 0, 1, 3, 2, 1, 1, 0, 3, 0, 3, 3, 0, 0, 3, 3, 0,\n",
      "        2, 1, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 2, 0, 3, 0, 0, 0, 3, 3, 0, 3, 1, 0,\n",
      "        3, 3, 3, 0, 3, 0, 0, 3, 3, 1, 0, 3, 0, 3, 2, 3, 2, 2, 1, 0, 3, 3, 1, 1,\n",
      "        3, 3, 0, 3, 3, 3, 2, 0, 3, 3, 3, 3, 3, 1, 3, 0, 3, 0, 3, 0, 1, 3, 0, 0,\n",
      "        1, 3, 1, 0, 0, 0, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6250, device='cuda:0')\n",
      "f tensor(0.6250, device='cuda:0')\n",
      "p tensor(0.3353, device='cuda:0')\n",
      "l tensor(1.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 0: 100%|████████████████████████████████████████████████████████████████| 32/32 [00:30<00:00,  1.05it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.85it/s]\u001b[A\n",
      "val info at random intervals\n",
      "p tensor([3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 3, 1, 0,\n",
      "        3, 0, 0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 1, 0, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3,\n",
      "        3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3,\n",
      "        3, 2, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 2, 3, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3,\n",
      "        3, 0, 0, 0, 3, 1, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 3, 0, 3, 0,\n",
      "        3, 0, 3, 0, 3, 3, 0, 0], device='cuda:0')\n",
      "g tensor([3, 3, 3, 0, 0, 0, 3, 3, 3, 1, 3, 1, 2, 3, 3, 0, 3, 3, 3, 0, 0, 0, 1, 1,\n",
      "        3, 0, 3, 2, 3, 3, 1, 2, 3, 3, 0, 0, 1, 0, 3, 0, 3, 3, 0, 3, 0, 0, 3, 0,\n",
      "        3, 3, 3, 3, 3, 2, 0, 3, 0, 3, 3, 0, 3, 0, 3, 3, 0, 1, 3, 0, 0, 0, 2, 0,\n",
      "        3, 3, 0, 0, 2, 0, 3, 3, 3, 3, 1, 0, 0, 3, 0, 0, 0, 1, 3, 3, 0, 1, 3, 3,\n",
      "        0, 1, 1, 0, 3, 3, 3, 0, 3, 0, 3, 1, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 2, 0,\n",
      "        3, 0, 0, 0, 3, 1, 0, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.5938, device='cuda:0')\n",
      "f tensor(0.5938, device='cuda:0')\n",
      "p tensor(0.4665, device='cuda:0')\n",
      "l tensor(1.0404, device='cuda:0')\n",
      "\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.87it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.88it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 0: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:44<00:00,  0.31it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 0\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(0)\n",
      "Epoch 1:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:211: You called `self.log('unpruned', ...)` in your `on_train_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "C:\\Users\\Christina\\anaconda3\\envs\\chrisy\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:211: You called `self.log('unpruned_state', ...)` in your `on_train_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:39<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.03it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.05it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:53<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 1\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(1)\n",
      "Epoch 2:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 2\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:43<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.86it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:59<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 2\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(2)\n",
      "Epoch 3:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 3\n",
      "Epoch 3:   3%|██                                                               | 1/32 [01:11<37:08,  0.01it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 3, 3, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0,\n",
      "        0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 0, 0,\n",
      "        3, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3,\n",
      "        3, 3, 0, 0, 0, 3, 1, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0,\n",
      "        3, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 3,\n",
      "        0, 3, 3, 0, 3, 3, 3, 0], device='cuda:0')\n",
      "g tensor([0, 1, 1, 0, 2, 1, 0, 3, 2, 3, 0, 0, 1, 3, 1, 3, 3, 0, 3, 3, 3, 3, 3, 0,\n",
      "        3, 3, 0, 3, 3, 0, 3, 0, 0, 3, 3, 1, 0, 3, 0, 3, 0, 3, 2, 0, 3, 0, 0, 0,\n",
      "        1, 3, 3, 0, 0, 0, 0, 3, 3, 1, 3, 3, 3, 3, 0, 2, 0, 0, 1, 3, 3, 3, 3, 3,\n",
      "        3, 3, 0, 0, 0, 3, 2, 2, 3, 1, 0, 0, 3, 2, 0, 0, 0, 3, 3, 3, 3, 3, 0, 3,\n",
      "        3, 2, 3, 0, 0, 2, 1, 0, 0, 0, 3, 3, 0, 3, 3, 1, 0, 3, 0, 3, 3, 0, 3, 3,\n",
      "        0, 3, 0, 0, 3, 3, 3, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7344, device='cuda:0')\n",
      "f tensor(0.7344, device='cuda:0')\n",
      "p tensor(0.3716, device='cuda:0')\n",
      "l tensor(0.8140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 3:  28%|██████████████████▎                                              | 9/32 [01:19<03:22,  0.11it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 0,\n",
      "        3, 3, 3, 0, 0, 3, 3, 3, 2, 3, 3, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "        0, 0, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3,\n",
      "        3, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 0, 3,\n",
      "        3, 3, 3, 3, 0, 0, 0, 0], device='cuda:0')\n",
      "g tensor([3, 3, 3, 0, 0, 0, 3, 0, 3, 3, 1, 0, 1, 0, 3, 3, 1, 0, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 1, 3, 3, 3, 0, 0, 0, 0, 1, 2, 3, 1, 0, 0, 1, 3, 3, 3, 0, 2,\n",
      "        1, 3, 3, 3, 0, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 1, 0, 1,\n",
      "        0, 3, 2, 0, 3, 3, 2, 0, 3, 3, 1, 3, 3, 3, 3, 3, 0, 2, 1, 3, 3, 3, 0, 3,\n",
      "        2, 3, 0, 0, 3, 3, 0, 3, 3, 3, 0, 1, 1, 3, 3, 2, 0, 0, 3, 0, 3, 3, 0, 3,\n",
      "        3, 3, 3, 3, 0, 0, 0, 1], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6484, device='cuda:0')\n",
      "f tensor(0.6484, device='cuda:0')\n",
      "p tensor(0.3164, device='cuda:0')\n",
      "l tensor(0.8881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 3:  59%|██████████████████████████████████████                          | 19/32 [01:28<01:00,  0.21it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 0, 3, 0, 3, 3, 0, 0, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 1, 3, 0, 1, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3,\n",
      "        3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3,\n",
      "        3, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3,\n",
      "        3, 0, 0, 3, 0, 0, 3, 1, 3, 3, 0, 1, 1, 3, 3, 3, 0, 0, 3, 3, 1, 3, 0, 0,\n",
      "        0, 3, 0, 0, 3, 0, 0, 3], device='cuda:0')\n",
      "g tensor([0, 0, 2, 0, 3, 3, 2, 0, 1, 3, 3, 2, 3, 1, 3, 0, 3, 0, 3, 1, 0, 0, 1, 3,\n",
      "        3, 0, 3, 3, 3, 3, 3, 3, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 1, 0, 0, 3, 3,\n",
      "        3, 0, 0, 1, 3, 3, 0, 3, 0, 3, 1, 3, 1, 3, 3, 3, 3, 3, 0, 0, 3, 3, 1, 0,\n",
      "        0, 1, 1, 0, 3, 0, 1, 3, 2, 3, 0, 3, 3, 2, 3, 3, 3, 3, 0, 3, 0, 2, 0, 3,\n",
      "        3, 0, 3, 0, 0, 0, 3, 0, 3, 2, 0, 1, 3, 3, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0,\n",
      "        0, 3, 0, 1, 2, 2, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6953, device='cuda:0')\n",
      "f tensor(0.6953, device='cuda:0')\n",
      "p tensor(0.4501, device='cuda:0')\n",
      "l tensor(0.8169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 3:  97%|██████████████████████████████████████████████████████████████  | 31/32 [01:40<00:03,  0.31it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 0, 3, 0, 1, 0, 3, 0, 3, 3,\n",
      "        0, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3,\n",
      "        0, 3, 0, 1, 0, 0, 1, 3, 3, 3, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 3, 0, 3, 0,\n",
      "        0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 0, 3,\n",
      "        3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 1, 3, 3, 3, 3, 3, 0, 3, 0,\n",
      "        0, 0, 3, 3, 3, 3, 0, 3], device='cuda:0')\n",
      "g tensor([0, 0, 0, 0, 3, 0, 0, 3, 1, 3, 0, 3, 3, 0, 3, 0, 2, 0, 1, 2, 3, 0, 2, 3,\n",
      "        0, 0, 0, 0, 3, 3, 0, 3, 3, 1, 3, 0, 3, 2, 1, 1, 3, 3, 3, 3, 3, 1, 0, 2,\n",
      "        0, 3, 0, 1, 0, 3, 0, 0, 3, 3, 3, 0, 2, 3, 2, 0, 0, 3, 3, 0, 3, 1, 2, 0,\n",
      "        0, 0, 3, 2, 3, 3, 0, 3, 0, 0, 3, 1, 3, 0, 2, 3, 1, 3, 0, 3, 2, 0, 0, 3,\n",
      "        3, 3, 3, 1, 3, 3, 3, 0, 3, 3, 3, 2, 3, 0, 2, 1, 0, 3, 2, 3, 2, 0, 3, 3,\n",
      "        0, 0, 3, 0, 3, 3, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6875, device='cuda:0')\n",
      "f tensor(0.6875, device='cuda:0')\n",
      "p tensor(0.5360, device='cuda:0')\n",
      "l tensor(0.8811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.06it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.06it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:57<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 3\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(3)\n",
      "Epoch 4:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 4\n",
      "Epoch 4:  69%|████████████████████████████████████████████                    | 22/32 [01:32<00:42,  0.24it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 3, 1, 0, 0, 0, 3, 0, 3, 3,\n",
      "        3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 3,\n",
      "        3, 3, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3,\n",
      "        3, 3, 3, 0, 0, 0, 3, 3, 3, 1, 3, 0, 0, 1, 0, 3, 0, 3, 0, 0, 3, 3, 3, 3,\n",
      "        3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 2, 3, 3, 3, 0, 0, 3, 0, 0, 3,\n",
      "        0, 0, 3, 3, 0, 3, 0, 3], device='cuda:0')\n",
      "g tensor([3, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 1, 0, 3, 2, 2, 0, 3, 0, 3, 0, 1, 1,\n",
      "        3, 3, 0, 3, 0, 0, 1, 0, 0, 0, 1, 1, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 0,\n",
      "        3, 2, 0, 0, 0, 1, 3, 1, 0, 3, 1, 3, 3, 2, 3, 1, 3, 1, 3, 3, 1, 3, 0, 3,\n",
      "        3, 0, 1, 3, 0, 2, 3, 3, 3, 0, 3, 1, 0, 1, 0, 3, 0, 3, 2, 3, 3, 1, 1, 3,\n",
      "        3, 0, 2, 3, 0, 0, 3, 0, 0, 3, 0, 0, 1, 1, 0, 0, 3, 3, 1, 0, 3, 0, 0, 3,\n",
      "        2, 2, 3, 3, 3, 3, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6406, device='cuda:0')\n",
      "f tensor(0.6406, device='cuda:0')\n",
      "p tensor(0.4104, device='cuda:0')\n",
      "l tensor(0.9421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.87it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 4\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(4)\n",
      "DECENT NOTE: save model tensor(4)\n",
      "Epoch 5:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 5\n",
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:43<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.80it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.82it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:59<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 5\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(5)\n",
      "Epoch 6:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 6\n",
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.85it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 6\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(6)\n",
      "Epoch 7:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 7\n",
      "Epoch 7:  69%|████████████████████████████████████████████                    | 22/32 [01:33<00:42,  0.24it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 1, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 3, 1, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3,\n",
      "        0, 0, 3, 0, 3, 0, 3, 0, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 3, 0, 3, 0, 0, 0,\n",
      "        0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 1, 0, 0, 0, 3, 3, 0, 3, 3,\n",
      "        0, 0, 0, 0, 3, 3, 3, 0], device='cuda:0')\n",
      "g tensor([3, 1, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 2, 3, 0, 3, 2, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 3, 3, 0, 0, 0, 0, 3, 3, 2, 3, 0, 3, 0, 3, 2, 1, 0, 0, 3, 3, 1, 3, 1,\n",
      "        0, 2, 0, 3, 3, 3, 3, 3, 2, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3,\n",
      "        3, 0, 1, 2, 3, 0, 1, 0, 3, 0, 3, 3, 0, 3, 0, 1, 3, 3, 3, 0, 1, 1, 0, 0,\n",
      "        0, 3, 3, 2, 3, 3, 3, 2, 2, 3, 0, 0, 0, 3, 0, 1, 0, 0, 0, 3, 3, 0, 3, 1,\n",
      "        0, 0, 0, 0, 3, 3, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7656, device='cuda:0')\n",
      "f tensor(0.7656, device='cuda:0')\n",
      "p tensor(0.6292, device='cuda:0')\n",
      "l tensor(0.6894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:43<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.03it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.05it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 7\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(7)\n",
      "Epoch 8:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 8\n",
      "Epoch 8:  44%|████████████████████████████                                    | 14/32 [01:26<01:50,  0.16it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 3, 3, 1, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 1, 3, 3,\n",
      "        3, 3, 0, 3, 3, 0, 1, 3, 1, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3,\n",
      "        3, 3, 0, 0, 3, 2, 3, 3, 0, 3, 0, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3,\n",
      "        3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 0, 0, 3, 0, 3, 0, 1,\n",
      "        3, 0, 0, 0, 0, 3, 0, 3, 3, 1, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 0,\n",
      "        3, 3, 3, 0, 3, 0, 3, 0], device='cuda:0')\n",
      "g tensor([3, 0, 1, 3, 1, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 1, 3, 3,\n",
      "        0, 3, 0, 3, 3, 3, 1, 3, 1, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 2, 3,\n",
      "        3, 2, 0, 0, 3, 0, 1, 2, 0, 3, 0, 2, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3,\n",
      "        3, 3, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 3, 0, 3, 1, 0,\n",
      "        3, 0, 1, 0, 0, 3, 0, 3, 3, 1, 3, 3, 3, 0, 0, 0, 3, 3, 0, 3, 2, 3, 3, 0,\n",
      "        1, 3, 2, 0, 3, 0, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7969, device='cuda:0')\n",
      "f tensor(0.7969, device='cuda:0')\n",
      "p tensor(0.6120, device='cuda:0')\n",
      "l tensor(0.6113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:43<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.10it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.09it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:59<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 8\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(8)\n",
      "Epoch 9:   0%|                                                                         | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 9\n",
      "Epoch 9:  53%|██████████████████████████████████                              | 17/32 [01:28<01:18,  0.19it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 0, 1, 3, 0, 3, 0, 3, 3, 3, 3, 1, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 3,\n",
      "        3, 3, 3, 1, 0, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 1, 3,\n",
      "        0, 0, 0, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3,\n",
      "        3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 0, 3, 1, 3, 0, 1, 0, 3, 1, 3, 3, 3,\n",
      "        1, 3, 3, 0, 1, 0, 0, 1, 0, 0, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 3, 0, 3, 3,\n",
      "        3, 0, 0, 0, 3, 0, 0, 3], device='cuda:0')\n",
      "g tensor([3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 2, 2, 3, 0, 0, 0, 3, 3,\n",
      "        3, 1, 3, 1, 0, 3, 2, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3,\n",
      "        0, 0, 0, 3, 3, 3, 3, 0, 0, 3, 0, 1, 0, 0, 0, 0, 3, 0, 3, 0, 3, 1, 3, 3,\n",
      "        3, 3, 3, 0, 0, 1, 0, 0, 3, 3, 3, 1, 0, 3, 1, 3, 0, 0, 0, 3, 1, 3, 2, 3,\n",
      "        1, 1, 3, 0, 1, 0, 0, 1, 0, 0, 3, 0, 2, 3, 3, 2, 0, 3, 0, 3, 3, 0, 3, 3,\n",
      "        3, 0, 2, 0, 3, 0, 3, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.8125, device='cuda:0')\n",
      "f tensor(0.8125, device='cuda:0')\n",
      "p tensor(0.5907, device='cuda:0')\n",
      "l tensor(0.6249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████| 32/32 [01:42<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.02it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.02it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████| 32/32 [02:57<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 9\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(9)\n",
      "DECENT NOTE: save model tensor(9)\n",
      "Epoch 10:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 10\n",
      "Epoch 10:  41%|█████████████████████████▌                                     | 13/32 [01:23<02:02,  0.16it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0,\n",
      "        1, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 1, 0,\n",
      "        3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3,\n",
      "        3, 0, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0,\n",
      "        0, 0, 0, 0, 0, 3, 3, 0], device='cuda:0')\n",
      "g tensor([0, 3, 0, 1, 0, 3, 0, 0, 1, 0, 0, 1, 3, 3, 3, 3, 3, 3, 3, 1, 0, 3, 0, 0,\n",
      "        1, 2, 0, 0, 0, 3, 3, 3, 0, 3, 3, 0, 3, 1, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3,\n",
      "        3, 3, 1, 0, 3, 3, 0, 0, 3, 3, 0, 2, 3, 2, 3, 0, 3, 3, 1, 3, 0, 2, 3, 0,\n",
      "        3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 1, 3, 2, 3,\n",
      "        0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 2, 3, 1, 3, 0, 3, 3, 3, 3, 3, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 3, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.8125, device='cuda:0')\n",
      "f tensor(0.8125, device='cuda:0')\n",
      "p tensor(0.5417, device='cuda:0')\n",
      "l tensor(0.6156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 10:  56%|███████████████████████████████████▍                           | 18/32 [01:28<01:08,  0.20it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 0, 3, 3, 3, 0, 0, 1, 3, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0,\n",
      "        3, 3, 0, 3, 3, 1, 0, 0, 1, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0,\n",
      "        0, 0, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 3,\n",
      "        0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 3, 3, 1, 3, 3, 0, 1, 3, 3, 0, 3, 0, 3, 3,\n",
      "        0, 3, 1, 3, 3, 0, 0, 3, 0, 3, 3, 3, 0, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 3,\n",
      "        3, 0, 0, 3, 0, 3, 3, 0], device='cuda:0')\n",
      "g tensor([0, 3, 3, 3, 2, 0, 0, 3, 3, 0, 0, 2, 0, 1, 0, 3, 0, 3, 0, 2, 2, 0, 0, 0,\n",
      "        3, 3, 0, 3, 1, 1, 0, 0, 1, 3, 0, 3, 3, 3, 3, 2, 0, 3, 2, 3, 3, 0, 3, 1,\n",
      "        1, 0, 0, 0, 0, 3, 3, 0, 0, 1, 0, 3, 3, 0, 1, 0, 2, 0, 0, 3, 1, 0, 0, 3,\n",
      "        0, 3, 3, 0, 3, 1, 0, 3, 0, 0, 1, 3, 1, 3, 2, 0, 3, 3, 3, 2, 3, 3, 0, 2,\n",
      "        0, 3, 0, 3, 3, 3, 0, 3, 0, 3, 0, 1, 0, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3,\n",
      "        3, 0, 3, 3, 0, 3, 2, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7188, device='cuda:0')\n",
      "f tensor(0.7188, device='cuda:0')\n",
      "p tensor(0.4912, device='cuda:0')\n",
      "l tensor(0.7861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 10:  78%|█████████████████████████████████████████████████▏             | 25/32 [01:34<00:26,  0.26it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 1, 0, 3, 3, 0, 3, 3, 0, 3, 0, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 3, 0, 0,\n",
      "        3, 0, 0, 0, 3, 3, 3, 0, 1, 3, 0, 3, 3, 0, 3, 3, 3, 0, 1, 3, 0, 0, 0, 3,\n",
      "        3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 3, 0, 2, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 1, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3,\n",
      "        3, 0, 1, 3, 3, 0, 3, 3, 0, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3,\n",
      "        3, 2, 3, 0, 0, 0, 3, 0], device='cuda:0')\n",
      "g tensor([3, 1, 0, 1, 3, 0, 1, 3, 0, 0, 0, 3, 0, 0, 0, 1, 2, 0, 0, 3, 3, 3, 0, 0,\n",
      "        3, 0, 3, 1, 3, 3, 3, 0, 1, 3, 0, 3, 1, 0, 3, 3, 3, 0, 1, 3, 0, 3, 0, 0,\n",
      "        3, 3, 1, 3, 0, 3, 0, 3, 3, 3, 1, 3, 0, 2, 3, 1, 2, 1, 0, 0, 0, 3, 2, 1,\n",
      "        3, 2, 3, 3, 3, 1, 0, 2, 3, 3, 3, 1, 0, 1, 0, 3, 3, 0, 0, 0, 3, 3, 0, 3,\n",
      "        3, 0, 1, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 2, 0, 3, 2,\n",
      "        3, 0, 3, 0, 0, 0, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7266, device='cuda:0')\n",
      "f tensor(0.7266, device='cuda:0')\n",
      "p tensor(0.6221, device='cuda:0')\n",
      "l tensor(0.7825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 10: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.87it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 10: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:56<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 10\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(10)\n",
      "Epoch 11:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 11\n",
      "Epoch 11: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "val info at random intervals\n",
      "p tensor([0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 0, 0, 3, 3,\n",
      "        3, 3, 0, 3, 3, 2, 3, 3, 3, 1, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3,\n",
      "        0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 3,\n",
      "        0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 0, 3, 0, 3, 0, 0, 3, 3, 3,\n",
      "        3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 1, 0, 1, 0, 0, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 3, 3, 3, 3, 0, 3, 0], device='cuda:0')\n",
      "g tensor([1, 3, 3, 0, 2, 3, 3, 0, 0, 2, 3, 0, 3, 3, 0, 2, 0, 2, 0, 3, 0, 2, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 2, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 2, 3,\n",
      "        1, 3, 3, 0, 1, 0, 0, 1, 3, 1, 0, 0, 0, 3, 3, 3, 1, 0, 0, 0, 3, 0, 0, 3,\n",
      "        2, 3, 0, 0, 3, 2, 2, 0, 0, 1, 2, 3, 0, 3, 3, 0, 3, 2, 3, 0, 0, 3, 3, 0,\n",
      "        3, 0, 0, 1, 3, 2, 3, 0, 3, 3, 3, 1, 1, 0, 1, 1, 2, 3, 3, 3, 0, 0, 3, 3,\n",
      "        3, 2, 3, 2, 0, 0, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7031, device='cuda:0')\n",
      "f tensor(0.7031, device='cuda:0')\n",
      "p tensor(0.5223, device='cuda:0')\n",
      "l tensor(0.8367, device='cuda:0')\n",
      "\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.87it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 11: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 11\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(11)\n",
      "Epoch 12:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 12\n",
      "Epoch 12:  34%|█████████████████████▋                                         | 11/32 [01:22<02:37,  0.13it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 3, 0, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0, 0,\n",
      "        3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 1, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3,\n",
      "        0, 3, 3, 0, 3, 0, 0, 0, 0, 3, 3, 0, 2, 0, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
      "        0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 0, 2, 3, 0, 2, 3, 0, 3, 0, 3, 3, 0, 0,\n",
      "        3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 0, 0, 0,\n",
      "        0, 0, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "g tensor([0, 0, 0, 0, 3, 0, 3, 3, 3, 2, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0, 0,\n",
      "        3, 0, 3, 1, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3,\n",
      "        1, 3, 3, 0, 3, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 2, 3, 0, 2, 3,\n",
      "        0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 2, 2, 3, 1, 2, 3, 0, 2, 0, 3, 3, 0, 0,\n",
      "        3, 0, 3, 2, 1, 1, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 0, 2, 3, 0, 3, 3, 0, 0,\n",
      "        2, 3, 2, 2, 3, 0, 3, 2], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7578, device='cuda:0')\n",
      "f tensor(0.7578, device='cuda:0')\n",
      "p tensor(0.5526, device='cuda:0')\n",
      "l tensor(0.7113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 12:  72%|█████████████████████████████████████████████▎                 | 23/32 [01:33<00:36,  0.25it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 1, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 1, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0,\n",
      "        3, 3, 0, 3, 3, 3, 3, 0, 1, 3, 0, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3,\n",
      "        0, 3, 3, 3, 0, 1, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 0,\n",
      "        0, 3, 3, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 1, 0, 3,\n",
      "        0, 1, 3, 0, 0, 3, 0, 3], device='cuda:0')\n",
      "g tensor([0, 1, 0, 2, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 0, 3, 1, 3, 3, 3, 2, 0,\n",
      "        1, 3, 1, 3, 3, 3, 3, 0, 3, 1, 0, 3, 1, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 3,\n",
      "        1, 3, 3, 1, 0, 0, 3, 3, 0, 0, 1, 0, 0, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 0,\n",
      "        0, 3, 2, 3, 1, 1, 3, 0, 3, 1, 3, 3, 0, 3, 3, 2, 3, 0, 3, 3, 0, 3, 2, 3,\n",
      "        3, 3, 1, 0, 3, 3, 3, 0, 0, 1, 0, 2, 0, 0, 0, 3, 3, 1, 0, 2, 3, 1, 0, 3,\n",
      "        0, 2, 3, 0, 0, 2, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7188, device='cuda:0')\n",
      "f tensor(0.7188, device='cuda:0')\n",
      "p tensor(0.4460, device='cuda:0')\n",
      "l tensor(0.7046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 12: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:42<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.11it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.08it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 12: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:57<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 12\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(12)\n",
      "Epoch 13:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 13\n",
      "Epoch 13:  41%|█████████████████████████▌                                     | 13/32 [01:24<02:03,  0.15it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 3, 3, 0,\n",
      "        3, 3, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 0,\n",
      "        3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 0, 3, 3, 1, 0, 0, 3,\n",
      "        0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 3,\n",
      "        0, 3, 0, 3, 0, 3, 0, 3, 3, 3, 1, 3, 3, 3, 0, 1, 3, 3, 1, 3, 3, 3, 0, 3,\n",
      "        3, 3, 0, 3, 3, 0, 0, 0], device='cuda:0')\n",
      "g tensor([3, 1, 3, 2, 3, 0, 3, 1, 3, 0, 0, 3, 3, 0, 1, 3, 1, 2, 1, 0, 0, 1, 3, 0,\n",
      "        2, 3, 0, 0, 3, 2, 0, 3, 0, 0, 1, 0, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3,\n",
      "        3, 1, 2, 0, 3, 3, 3, 1, 3, 2, 0, 3, 3, 0, 2, 0, 2, 0, 2, 3, 3, 0, 3, 3,\n",
      "        0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 3, 0, 3, 1, 0, 3, 0, 2, 0, 3, 0, 2, 3, 3,\n",
      "        0, 3, 1, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 3, 0, 1, 2, 3, 1, 3, 3, 3, 3, 3,\n",
      "        3, 3, 0, 3, 2, 0, 2, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7266, device='cuda:0')\n",
      "f tensor(0.7266, device='cuda:0')\n",
      "p tensor(0.5675, device='cuda:0')\n",
      "l tensor(0.7873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 13: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:42<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.81it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.82it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 13: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 13\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(13)\n",
      "Epoch 14:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 14\n",
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:42<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.85it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 14\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(14)\n",
      "DECENT NOTE: save model tensor(14)\n",
      "Epoch 15:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 15\n",
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "val info at random intervals\n",
      "p tensor([0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 0, 3, 0, 3, 0, 0, 3, 3,\n",
      "        3, 3, 0, 3, 3, 2, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3,\n",
      "        0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 3,\n",
      "        0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 0, 3, 0, 3, 0, 0, 3, 3, 3,\n",
      "        3, 0, 0, 3, 3, 0, 3, 0, 3, 0, 3, 3, 1, 0, 1, 0, 0, 3, 3, 3, 0, 0, 3, 3,\n",
      "        3, 3, 3, 3, 0, 0, 3, 0], device='cuda:0')\n",
      "g tensor([1, 3, 3, 0, 2, 3, 3, 0, 0, 2, 3, 0, 3, 3, 0, 2, 0, 2, 0, 3, 0, 2, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 2, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 2, 3,\n",
      "        1, 3, 3, 0, 1, 0, 0, 1, 3, 1, 0, 0, 0, 3, 3, 3, 1, 0, 0, 0, 3, 0, 0, 3,\n",
      "        2, 3, 0, 0, 3, 2, 2, 0, 0, 1, 2, 3, 0, 3, 3, 0, 3, 2, 3, 0, 0, 3, 3, 0,\n",
      "        3, 0, 0, 1, 3, 2, 3, 0, 3, 3, 3, 1, 1, 0, 1, 1, 2, 3, 3, 3, 0, 0, 3, 3,\n",
      "        3, 2, 3, 2, 0, 0, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7422, device='cuda:0')\n",
      "f tensor(0.7422, device='cuda:0')\n",
      "p tensor(0.6207, device='cuda:0')\n",
      "l tensor(0.7975, device='cuda:0')\n",
      "\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.07it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.08it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:56<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 15\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(15)\n",
      "Epoch 16:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 16\n",
      "Epoch 16:  31%|███████████████████▋                                           | 10/32 [01:20<02:56,  0.12it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 3, 0, 3, 0, 3, 0, 3, 0, 1, 3, 3, 0, 0, 3, 0, 1, 3, 0, 3, 3, 3, 3,\n",
      "        3, 3, 0, 0, 0, 0, 3, 3, 3, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3,\n",
      "        0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 1, 0, 1, 3, 3, 0, 0, 1, 3, 3, 0, 0, 3,\n",
      "        0, 3, 3, 3, 3, 3, 0, 1, 3, 3, 0, 0, 3, 2, 3, 3, 3, 3, 3, 1, 3, 3, 3, 0,\n",
      "        3, 3, 3, 0, 0, 0, 0, 2, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 1, 3, 3, 3,\n",
      "        3, 0, 3, 0, 3, 0, 1, 3], device='cuda:0')\n",
      "g tensor([3, 3, 3, 0, 2, 0, 3, 0, 3, 3, 1, 3, 3, 2, 0, 3, 0, 3, 3, 0, 3, 3, 3, 2,\n",
      "        3, 3, 0, 0, 3, 0, 3, 2, 3, 1, 0, 0, 3, 2, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3,\n",
      "        0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 0, 1, 3, 3, 2, 0, 0, 3, 3, 3, 0, 3,\n",
      "        3, 3, 3, 3, 3, 3, 0, 3, 1, 3, 0, 0, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 0,\n",
      "        3, 3, 2, 0, 0, 1, 0, 0, 0, 2, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 3,\n",
      "        3, 1, 3, 2, 3, 3, 3, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7812, device='cuda:0')\n",
      "f tensor(0.7812, device='cuda:0')\n",
      "p tensor(0.5268, device='cuda:0')\n",
      "l tensor(0.6267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 16:  34%|█████████████████████▋                                         | 11/32 [01:21<02:34,  0.14it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 0,\n",
      "        0, 0, 0, 3, 0, 3, 1, 3, 0, 0, 3, 0, 3, 0, 3, 0, 3, 1, 3, 3, 0, 3, 0, 0,\n",
      "        3, 3, 3, 3, 0, 3, 1, 0, 0, 0, 3, 0, 3, 3, 0, 3, 0, 0, 3, 1, 3, 0, 3, 0,\n",
      "        1, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 1, 3, 3, 3, 3, 1,\n",
      "        3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3,\n",
      "        3, 3, 3, 0, 3, 3, 3, 3], device='cuda:0')\n",
      "g tensor([1, 1, 3, 3, 1, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 0, 0, 3, 2, 3, 0,\n",
      "        0, 0, 1, 3, 0, 3, 1, 3, 0, 0, 3, 0, 2, 0, 3, 0, 3, 0, 3, 2, 2, 3, 0, 3,\n",
      "        0, 3, 3, 3, 0, 3, 1, 2, 0, 0, 2, 0, 3, 3, 0, 3, 0, 0, 3, 2, 3, 0, 3, 0,\n",
      "        0, 0, 0, 3, 3, 2, 1, 1, 0, 0, 3, 0, 2, 3, 3, 0, 0, 1, 1, 3, 1, 2, 2, 1,\n",
      "        3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3,\n",
      "        3, 3, 1, 0, 3, 3, 3, 2], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7969, device='cuda:0')\n",
      "f tensor(0.7969, device='cuda:0')\n",
      "p tensor(0.5489, device='cuda:0')\n",
      "l tensor(0.6036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 16: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:40<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.86it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 16: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:56<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 16\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(16)\n",
      "Epoch 17:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 17\n",
      "Epoch 17: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  1.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.08it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.06it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 17: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:56<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 17\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(17)\n",
      "Epoch 18:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 18\n",
      "Epoch 18:  97%|█████████████████████████████████████████████████████████████  | 31/32 [01:43<00:03,  0.30it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 0, 3, 3, 0, 3, 3, 3, 3, 1, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 2, 0, 0, 0, 3, 3, 0, 3, 0, 3, 3, 0, 1, 3, 3, 3, 1, 0, 3, 0, 3, 1, 0,\n",
      "        0, 0, 3, 0, 1, 3, 0, 1, 3, 3, 3, 3, 3, 0, 1, 3, 0, 3, 0, 1, 0, 3, 3, 3,\n",
      "        0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 0,\n",
      "        0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 0, 0], device='cuda:0')\n",
      "g tensor([0, 2, 3, 3, 1, 3, 3, 0, 3, 1, 0, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 2,\n",
      "        3, 1, 3, 0, 2, 3, 3, 2, 3, 0, 3, 3, 0, 1, 3, 3, 3, 0, 0, 3, 2, 3, 2, 1,\n",
      "        0, 1, 3, 0, 1, 1, 0, 3, 2, 3, 2, 3, 3, 0, 1, 3, 0, 1, 0, 3, 0, 3, 3, 3,\n",
      "        0, 1, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 2, 3, 0, 3, 3, 3, 0, 0, 3, 0, 0,\n",
      "        3, 3, 3, 0, 0, 0, 3, 3, 3, 1, 0, 1, 2, 2, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3,\n",
      "        1, 3, 3, 3, 1, 3, 0, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7500, device='cuda:0')\n",
      "f tensor(0.7500, device='cuda:0')\n",
      "p tensor(0.5042, device='cuda:0')\n",
      "l tensor(0.6526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:44<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.87it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.87it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████| 32/32 [03:01<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 18\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(18)\n",
      "Epoch 19:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 19\n",
      "Epoch 19:  62%|███████████████████████████████████████▍                       | 20/32 [01:31<00:54,  0.22it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 1, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 0, 1, 0, 3, 3, 3, 0, 3, 0, 3,\n",
      "        1, 1, 3, 3, 3, 0, 3, 3, 3, 3, 3, 1, 0, 3, 3, 0, 0, 0, 3, 0, 3, 3, 3, 3,\n",
      "        0, 3, 3, 0, 0, 0, 0, 2, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3,\n",
      "        0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 2, 0, 0, 3, 3, 3, 0, 3, 3,\n",
      "        3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 0, 0, 3, 1, 3,\n",
      "        3, 0, 3, 0, 0, 3, 3, 3], device='cuda:0')\n",
      "g tensor([1, 1, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 3, 3, 0, 1, 0, 3, 3, 3, 0, 3, 0, 3,\n",
      "        0, 3, 3, 0, 3, 0, 3, 3, 0, 3, 0, 1, 1, 3, 0, 0, 0, 0, 3, 0, 3, 2, 3, 1,\n",
      "        0, 3, 3, 0, 0, 0, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 3, 3, 3, 0, 3, 3, 3, 3,\n",
      "        0, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 0, 0, 2, 3, 0, 0, 0, 2,\n",
      "        3, 0, 3, 3, 3, 0, 0, 3, 2, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 0, 0, 3, 1, 2,\n",
      "        3, 0, 3, 0, 0, 3, 3, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7891, device='cuda:0')\n",
      "f tensor(0.7891, device='cuda:0')\n",
      "p tensor(0.5878, device='cuda:0')\n",
      "l tensor(0.5829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:42<00:00,  0.31it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.05it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.08it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:59<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 19\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(19)\n",
      "DECENT NOTE: save model tensor(19)\n",
      "Epoch 20:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 20\n",
      "DECENT NOTE: update model 20\n",
      "DECENT NOTE: model updated\n",
      "Epoch 20:  53%|█████████████████████████████████▍                             | 17/32 [01:28<01:17,  0.19it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 3, 3, 3, 3, 3, 0, 0, 1, 0, 3, 3, 3, 0, 3, 3, 0, 0, 1, 3, 3, 3, 3, 3,\n",
      "        0, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 1, 3, 1, 0, 3, 3,\n",
      "        1, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 0, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 0, 3, 0,\n",
      "        3, 0, 3, 0, 3, 0, 3, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3, 0,\n",
      "        3, 3, 3, 0, 3, 3, 0, 1], device='cuda:0')\n",
      "g tensor([3, 2, 3, 3, 2, 2, 0, 0, 1, 0, 3, 2, 3, 0, 3, 3, 0, 0, 1, 3, 3, 3, 0, 3,\n",
      "        2, 0, 3, 1, 0, 3, 3, 0, 3, 3, 0, 0, 3, 1, 3, 2, 0, 0, 1, 3, 1, 2, 2, 3,\n",
      "        1, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3, 2, 3, 0, 2, 0, 0, 0, 0,\n",
      "        0, 1, 0, 3, 0, 3, 0, 2, 3, 0, 3, 3, 2, 3, 3, 3, 1, 3, 3, 3, 3, 1, 3, 0,\n",
      "        3, 1, 2, 0, 3, 0, 3, 0, 2, 3, 1, 3, 3, 3, 0, 2, 0, 3, 3, 3, 3, 0, 3, 0,\n",
      "        3, 0, 1, 0, 3, 3, 0, 1], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7891, device='cuda:0')\n",
      "f tensor(0.7891, device='cuda:0')\n",
      "p tensor(0.6390, device='cuda:0')\n",
      "l tensor(0.6563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 20: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.89it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.89it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 20: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:57<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 20\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(20)\n",
      "Epoch 21:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 21\n",
      "Epoch 21: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.92it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.92it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 21: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:55<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 21\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(21)\n",
      "Epoch 22:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 22\n",
      "Epoch 22: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:37<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.91it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 22: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:51<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 22\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(22)\n",
      "Epoch 23:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 23\n",
      "Epoch 23: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:39<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.91it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 23: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:53<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 23\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(23)\n",
      "Epoch 24:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 24\n",
      "Epoch 24:  69%|███████████████████████████████████████████▎                   | 22/32 [01:30<00:41,  0.24it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0,\n",
      "        3, 3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 1, 0, 0, 0, 3, 3, 0,\n",
      "        0, 0, 3, 0, 3, 3, 0, 3, 1, 0, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0,\n",
      "        3, 0, 3, 3, 0, 1, 0, 0, 0, 3, 3, 0, 1, 0, 2, 0, 0, 0, 3, 3, 3, 0, 0, 3,\n",
      "        0, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 3, 1, 0, 3, 0, 2, 2, 3, 0, 0, 3, 3, 3,\n",
      "        0, 0, 0, 0, 3, 3, 0, 2], device='cuda:0')\n",
      "g tensor([3, 1, 3, 3, 3, 3, 3, 0, 0, 3, 3, 2, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0,\n",
      "        3, 3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 0, 2, 3, 3, 3, 0, 1, 0, 0, 0, 3, 3, 1,\n",
      "        0, 0, 2, 0, 3, 3, 0, 3, 1, 0, 3, 2, 0, 3, 3, 3, 3, 1, 3, 3, 0, 0, 1, 0,\n",
      "        3, 3, 3, 3, 0, 1, 0, 0, 0, 3, 3, 2, 1, 1, 2, 2, 0, 0, 3, 3, 3, 3, 0, 3,\n",
      "        1, 3, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 1, 0, 3, 0, 0, 2, 3, 0, 0, 2, 1, 3,\n",
      "        0, 0, 0, 3, 3, 3, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.8203, device='cuda:0')\n",
      "f tensor(0.8203, device='cuda:0')\n",
      "p tensor(0.7847, device='cuda:0')\n",
      "l tensor(0.5268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 24: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:39<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.02it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.03it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 24: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:54<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 24\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(24)\n",
      "DECENT NOTE: save model tensor(24)\n",
      "Epoch 25:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 25\n",
      "DECENT NOTE: update model 25\n",
      "DECENT NOTE: model updated\n",
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:41<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.10it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 25\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(25)\n",
      "Epoch 26:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 26\n",
      "Epoch 26: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:40<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.93it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 26: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:55<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 26\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(26)\n",
      "Epoch 27:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 27\n",
      "Epoch 27:  91%|█████████████████████████████████████████████████████████      | 29/32 [01:37<00:10,  0.30it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3,\n",
      "        2, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 0, 3, 0,\n",
      "        3, 1, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 0, 0, 3, 0,\n",
      "        3, 0, 0, 0, 0, 3, 2, 0, 0, 3, 3, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0, 1, 0, 3,\n",
      "        3, 3, 0, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0,\n",
      "        3, 3, 0, 3, 3, 0, 1, 3], device='cuda:0')\n",
      "g tensor([0, 3, 2, 0, 3, 3, 2, 0, 0, 3, 0, 3, 1, 3, 3, 0, 0, 0, 3, 0, 3, 0, 3, 3,\n",
      "        2, 1, 3, 0, 3, 3, 3, 3, 1, 3, 3, 2, 2, 3, 1, 3, 0, 3, 3, 3, 3, 1, 3, 0,\n",
      "        3, 1, 3, 2, 1, 0, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 2, 0, 1, 0, 3, 0,\n",
      "        2, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 2, 2, 3, 3, 0, 0, 3, 3, 0, 2, 0, 2,\n",
      "        3, 3, 2, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 3, 0,\n",
      "        3, 3, 0, 3, 2, 2, 1, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7969, device='cuda:0')\n",
      "f tensor(0.7969, device='cuda:0')\n",
      "p tensor(0.6968, device='cuda:0')\n",
      "l tensor(0.6401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 27: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:40<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "val info at random intervals\n",
      "p tensor([0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 0, 0, 3, 0, 3, 0, 2, 0, 3, 0, 0, 3, 3,\n",
      "        3, 3, 0, 3, 3, 1, 3, 2, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3,\n",
      "        2, 3, 3, 0, 0, 0, 0, 3, 3, 3, 0, 0, 2, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 3,\n",
      "        0, 2, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 0, 0, 2, 3, 3,\n",
      "        3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 3, 3, 3, 0, 0, 3, 0], device='cuda:0')\n",
      "g tensor([1, 3, 3, 0, 2, 3, 3, 0, 0, 2, 3, 0, 3, 3, 0, 2, 0, 2, 0, 3, 0, 2, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 2, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 2, 3,\n",
      "        1, 3, 3, 0, 1, 0, 0, 1, 3, 1, 0, 0, 0, 3, 3, 3, 1, 0, 0, 0, 3, 0, 0, 3,\n",
      "        2, 3, 0, 0, 3, 2, 2, 0, 0, 1, 2, 3, 0, 3, 3, 0, 3, 2, 3, 0, 0, 3, 3, 0,\n",
      "        3, 0, 0, 1, 3, 2, 3, 0, 3, 3, 3, 1, 1, 0, 1, 1, 2, 3, 3, 3, 0, 0, 3, 3,\n",
      "        3, 2, 3, 2, 0, 0, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7031, device='cuda:0')\n",
      "f tensor(0.7031, device='cuda:0')\n",
      "p tensor(0.4098, device='cuda:0')\n",
      "l tensor(0.8242, device='cuda:0')\n",
      "\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.97it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.96it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 27: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:55<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 27\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(27)\n",
      "Epoch 28:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 28\n",
      "Epoch 28: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:40<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.09it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.12it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 28: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 28\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(28)\n",
      "Epoch 29:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 29\n",
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:39<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.10it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.14it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 29: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:54<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 29\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(29)\n",
      "DECENT NOTE: save model tensor(29)\n",
      "Epoch 30:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 30\n",
      "DECENT NOTE: update model 30\n",
      "DECENT NOTE: model updated\n",
      "Epoch 30:  97%|█████████████████████████████████████████████████████████████  | 31/32 [01:52<00:03,  0.27it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 3, 0, 0, 3, 0, 1, 0, 3, 3, 3, 0, 3, 0, 3, 2, 3, 3, 2, 3, 0, 2, 0,\n",
      "        3, 0, 0, 3, 3, 0, 3, 0, 2, 3, 3, 2, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 0, 0, 3, 3, 0, 0, 1, 3, 3, 0, 0, 3, 3, 0, 1, 3, 0, 0,\n",
      "        3, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 2, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3, 3, 2,\n",
      "        3, 3, 0, 3, 3, 3, 0, 2, 3, 3, 3, 3, 2, 3, 0, 3, 0, 1, 0, 2, 3, 3, 3, 0,\n",
      "        0, 3, 3, 3, 0, 3, 0, 0], device='cuda:0')\n",
      "g tensor([3, 3, 0, 0, 0, 3, 0, 1, 0, 2, 3, 3, 0, 3, 0, 2, 0, 2, 1, 3, 3, 0, 1, 0,\n",
      "        3, 0, 0, 3, 2, 0, 3, 0, 0, 3, 3, 0, 3, 2, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 3, 2, 0, 0, 3, 3, 0, 1, 3, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0,\n",
      "        3, 3, 0, 0, 1, 0, 0, 3, 3, 0, 1, 1, 0, 2, 3, 0, 1, 0, 3, 0, 3, 3, 3, 2,\n",
      "        1, 3, 2, 3, 3, 3, 0, 2, 2, 3, 2, 2, 2, 3, 0, 3, 2, 3, 3, 2, 3, 3, 3, 0,\n",
      "        0, 3, 3, 3, 0, 3, 2, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7422, device='cuda:0')\n",
      "f tensor(0.7422, device='cuda:0')\n",
      "p tensor(0.5643, device='cuda:0')\n",
      "l tensor(0.7321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 30: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:54<00:00,  0.28it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "val info at random intervals\n",
      "p tensor([0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 2, 0, 3, 0, 0, 3, 3,\n",
      "        3, 3, 0, 3, 3, 2, 3, 2, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3,\n",
      "        1, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 2, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 3,\n",
      "        2, 2, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 0, 0, 2, 3, 3,\n",
      "        3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 3, 3, 3, 0, 0, 3, 0], device='cuda:0')\n",
      "g tensor([1, 3, 3, 0, 2, 3, 3, 0, 0, 2, 3, 0, 3, 3, 0, 2, 0, 2, 0, 3, 0, 2, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 2, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 2, 3,\n",
      "        1, 3, 3, 0, 1, 0, 0, 1, 3, 1, 0, 0, 0, 3, 3, 3, 1, 0, 0, 0, 3, 0, 0, 3,\n",
      "        2, 3, 0, 0, 3, 2, 2, 0, 0, 1, 2, 3, 0, 3, 3, 0, 3, 2, 3, 0, 0, 3, 3, 0,\n",
      "        3, 0, 0, 1, 3, 2, 3, 0, 3, 3, 3, 1, 1, 0, 1, 1, 2, 3, 3, 3, 0, 0, 3, 3,\n",
      "        3, 2, 3, 2, 0, 0, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7188, device='cuda:0')\n",
      "f tensor(0.7188, device='cuda:0')\n",
      "p tensor(0.6917, device='cuda:0')\n",
      "l tensor(0.8293, device='cuda:0')\n",
      "\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.95it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.98it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 30: 100%|███████████████████████████████████████████████████████████████| 32/32 [03:12<00:00,  0.17it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 30\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(30)\n",
      "Epoch 31:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 31\n",
      "Epoch 31:   6%|████                                                            | 2/32 [01:15<18:56,  0.03it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 2, 3, 0, 3, 0, 3, 0, 3, 3, 0, 3, 0, 3,\n",
      "        3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 0, 0,\n",
      "        3, 0, 0, 3, 3, 0, 0, 3, 3, 0, 3, 2, 3, 0, 0, 3, 3, 3, 1, 3, 0, 0, 3, 0,\n",
      "        3, 0, 3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 3, 2, 3, 0, 0, 0, 0, 3, 0, 0, 3,\n",
      "        3, 3, 0, 0, 3, 0, 2, 3], device='cuda:0')\n",
      "g tensor([3, 2, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 0, 3, 1, 1, 3, 0, 3, 0, 3,\n",
      "        0, 3, 0, 3, 3, 1, 0, 2, 0, 1, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3,\n",
      "        3, 0, 3, 3, 1, 1, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 1, 0, 2, 3, 1, 0, 0,\n",
      "        3, 1, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 0, 0, 1, 3, 3, 3, 3, 0, 0, 3, 0,\n",
      "        1, 0, 3, 0, 0, 3, 2, 1, 3, 1, 3, 0, 3, 3, 0, 3, 0, 3, 0, 1, 3, 1, 0, 3,\n",
      "        3, 3, 1, 1, 3, 0, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7266, device='cuda:0')\n",
      "f tensor(0.7266, device='cuda:0')\n",
      "p tensor(0.3744, device='cuda:0')\n",
      "l tensor(0.7504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 31:  12%|████████                                                        | 4/32 [01:17<09:02,  0.05it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 0, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 0, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 0, 0, 2, 2, 0, 3, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0,\n",
      "        0, 3, 3, 0, 2, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3,\n",
      "        3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3,\n",
      "        0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 2, 3, 2, 3, 0, 3, 3,\n",
      "        0, 0, 3, 0, 0, 3, 0, 3], device='cuda:0')\n",
      "g tensor([3, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 1, 3, 0, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 2, 3, 3, 0, 0, 1, 3, 0, 3, 3, 1, 1, 1, 0, 3, 0, 3, 3, 3, 0, 0, 3,\n",
      "        0, 2, 3, 3, 0, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 2, 2, 0, 0, 3, 3,\n",
      "        3, 1, 3, 3, 3, 3, 0, 0, 3, 0, 0, 3, 0, 2, 3, 3, 0, 3, 0, 0, 3, 3, 3, 2,\n",
      "        3, 1, 3, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 3,\n",
      "        0, 1, 3, 0, 1, 3, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7891, device='cuda:0')\n",
      "f tensor(0.7891, device='cuda:0')\n",
      "p tensor(0.4477, device='cuda:0')\n",
      "l tensor(0.6178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 31: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:40<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.95it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.97it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 31: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:57<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 31\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(31)\n",
      "Epoch 32:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 32\n",
      "Epoch 32: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:39<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.25it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.27it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 32: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:54<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 32\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(32)\n",
      "Epoch 33:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 33\n",
      "Epoch 33: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:46<00:00,  0.30it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:03<00:01,  0.96it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  0.96it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 33: 100%|███████████████████████████████████████████████████████████████| 32/32 [03:08<00:00,  0.17it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 33\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(33)\n",
      "Epoch 34:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 34\n",
      "Epoch 34: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:36<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:02<00:02,  0.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.01it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.03it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 34: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:52<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 34\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(34)\n",
      "DECENT NOTE: save model tensor(34)\n",
      "Epoch 35:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 35\n",
      "DECENT NOTE: update model 35\n",
      "DECENT NOTE: model updated\n",
      "Epoch 35: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:37<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.04it/s]\u001b[A\n",
      "val info at random intervals\n",
      "p tensor([3, 3, 3, 0, 0, 0, 3, 3, 3, 1, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 3,\n",
      "        3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 1, 3, 0, 3, 3, 0, 3, 3, 0, 3, 0,\n",
      "        3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 2, 3, 3, 0, 0, 3, 0, 0, 0, 3, 0,\n",
      "        3, 3, 0, 0, 2, 0, 3, 3, 3, 3, 0, 0, 0, 3, 2, 0, 0, 0, 3, 3, 2, 1, 3, 3,\n",
      "        0, 1, 0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 3, 3, 1, 0, 1, 3, 3, 0, 3, 0,\n",
      "        0, 0, 0, 0, 3, 0, 0, 3], device='cuda:0')\n",
      "g tensor([3, 3, 3, 0, 0, 0, 3, 3, 3, 1, 3, 1, 2, 3, 3, 0, 3, 3, 3, 0, 0, 0, 1, 1,\n",
      "        3, 0, 3, 2, 3, 3, 1, 2, 3, 3, 0, 0, 1, 0, 3, 0, 3, 3, 0, 3, 0, 0, 3, 0,\n",
      "        3, 3, 3, 3, 3, 2, 0, 3, 0, 3, 3, 0, 3, 0, 3, 3, 0, 1, 3, 0, 0, 0, 2, 0,\n",
      "        3, 3, 0, 0, 2, 0, 3, 3, 3, 3, 1, 0, 0, 3, 0, 0, 0, 1, 3, 3, 0, 1, 3, 3,\n",
      "        0, 1, 1, 0, 3, 3, 3, 0, 3, 0, 3, 1, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 2, 0,\n",
      "        3, 0, 0, 0, 3, 1, 0, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7656, device='cuda:0')\n",
      "f tensor(0.7656, device='cuda:0')\n",
      "p tensor(0.5842, device='cuda:0')\n",
      "l tensor(0.6924, device='cuda:0')\n",
      "\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.04it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 35: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:52<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 35\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(35)\n",
      "Epoch 36:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 36\n",
      "Epoch 36:  16%|██████████                                                      | 5/32 [01:18<07:04,  0.06it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 3, 0, 0, 0, 3, 0, 0, 2, 3, 3, 0, 0, 3, 0, 3, 3, 3, 0, 2, 3, 3, 3, 3,\n",
      "        0, 0, 0, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 0, 0,\n",
      "        1, 0, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 0, 3, 3, 3, 1, 1, 3, 1, 0, 3, 3,\n",
      "        3, 0, 0, 0, 3, 3, 0, 1, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 3, 1, 3, 3, 3, 3,\n",
      "        0, 3, 3, 3, 3, 3, 1, 0, 0, 3, 0, 0, 0, 1, 0, 1, 3, 0, 3, 3, 3, 3, 3, 0,\n",
      "        3, 0, 3, 0, 3, 0, 0, 3], device='cuda:0')\n",
      "g tensor([0, 3, 0, 0, 0, 3, 0, 0, 1, 3, 3, 2, 0, 3, 0, 3, 3, 3, 0, 0, 3, 2, 1, 3,\n",
      "        0, 0, 0, 3, 0, 3, 0, 3, 1, 2, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0,\n",
      "        1, 0, 1, 0, 3, 0, 2, 0, 3, 3, 0, 0, 3, 0, 2, 3, 3, 1, 1, 2, 1, 2, 2, 3,\n",
      "        3, 1, 0, 0, 3, 3, 0, 1, 0, 2, 2, 1, 2, 3, 0, 0, 1, 3, 3, 3, 3, 3, 3, 2,\n",
      "        0, 3, 3, 3, 2, 3, 0, 0, 0, 3, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0,\n",
      "        3, 0, 3, 0, 3, 0, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7578, device='cuda:0')\n",
      "f tensor(0.7578, device='cuda:0')\n",
      "p tensor(0.5809, device='cuda:0')\n",
      "l tensor(0.7383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 36: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:39<00:00,  0.32it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.30it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.30it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 36: 100%|███████████████████████████████████████████████████████████████| 32/32 [03:06<00:00,  0.17it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 36\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(36)\n",
      "Epoch 37:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 37\n",
      "Epoch 37: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:35<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.09it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.14it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 37: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:49<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 37\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(37)\n",
      "Epoch 38:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 38\n",
      "Epoch 38: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:36<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:01<00:03,  0.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.05it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.07it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 38: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:50<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 38\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(38)\n",
      "Epoch 39:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 39\n",
      "Epoch 39:  31%|███████████████████▋                                           | 10/32 [01:18<02:53,  0.13it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 0, 0, 3, 3, 3, 3, 3,\n",
      "        3, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3,\n",
      "        0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 3, 0, 3, 3, 2, 3, 0, 3, 0, 3, 0, 0, 3, 3,\n",
      "        0, 0, 3, 0, 0, 3, 3, 1, 3, 0, 0, 1, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0,\n",
      "        3, 3, 0, 0, 3, 3, 2, 3, 0, 0, 3, 3, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 3,\n",
      "        3, 3, 3, 3, 0, 3, 3, 0], device='cuda:0')\n",
      "g tensor([1, 3, 0, 3, 2, 3, 3, 0, 0, 2, 3, 1, 0, 3, 0, 0, 3, 0, 0, 3, 3, 3, 1, 3,\n",
      "        3, 0, 3, 2, 0, 0, 2, 0, 3, 3, 0, 2, 3, 0, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3,\n",
      "        0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 3, 0, 3, 3, 3, 3, 1, 3, 3, 1, 0, 0, 3, 3,\n",
      "        0, 0, 0, 0, 0, 3, 3, 3, 1, 0, 1, 1, 3, 0, 3, 2, 3, 3, 3, 3, 0, 0, 0, 0,\n",
      "        3, 3, 0, 0, 3, 1, 0, 3, 0, 0, 1, 3, 0, 0, 0, 2, 3, 0, 3, 0, 3, 0, 3, 3,\n",
      "        3, 3, 3, 0, 0, 3, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7891, device='cuda:0')\n",
      "f tensor(0.7891, device='cuda:0')\n",
      "p tensor(0.5325, device='cuda:0')\n",
      "l tensor(0.6537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 39:  94%|███████████████████████████████████████████████████████████    | 30/32 [01:34<00:06,  0.32it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 0, 3, 0, 3, 2, 3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 3, 3, 0, 1, 3,\n",
      "        3, 0, 0, 0, 3, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0,\n",
      "        3, 3, 3, 0, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 3, 3, 3, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 3, 1, 3, 3, 3, 0, 0, 3, 3, 3,\n",
      "        0, 3, 0, 3, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 0, 3, 3, 0, 0, 3, 3,\n",
      "        3, 0, 0, 3, 3, 1, 3, 0], device='cuda:0')\n",
      "g tensor([0, 0, 3, 0, 3, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 0, 0, 3,\n",
      "        3, 0, 0, 0, 3, 0, 3, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0,\n",
      "        2, 3, 3, 0, 2, 0, 2, 1, 3, 3, 3, 0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 3, 3, 3, 0, 0, 0, 0, 1, 0, 2, 0, 3, 3, 3, 1, 3, 3, 0, 0, 0, 3, 3, 3,\n",
      "        3, 3, 0, 3, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 0, 3, 3, 0, 3, 3, 3,\n",
      "        3, 0, 0, 3, 3, 2, 2, 2], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.8516, device='cuda:0')\n",
      "f tensor(0.8516, device='cuda:0')\n",
      "p tensor(0.5402, device='cuda:0')\n",
      "l tensor(0.5546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 39: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:35<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.02it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.03it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 39: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:49<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 39\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(39)\n",
      "DECENT NOTE: save model tensor(39)\n",
      "Epoch 40:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 40\n",
      "DECENT NOTE: update model 40\n",
      "\n",
      "info at random intervals\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20 22 23]\n",
      "torch.Size([1, 21, 1, 1])\n",
      "torch.Size([1, 24, 1, 1])\n",
      "DECENT NOTE: model updated\n",
      "Epoch 40: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:36<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.12it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 40: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:49<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 40\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(40)\n",
      "Epoch 41:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 41\n",
      "Epoch 41: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:34<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.11it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.11it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 41: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:48<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 41\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(41)\n",
      "Epoch 42:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 42\n",
      "Epoch 42: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:34<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.12it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 42: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:47<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 42\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(42)\n",
      "Epoch 43:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 43\n",
      "Epoch 43:  53%|█████████████████████████████████▍                             | 17/32 [01:25<01:15,  0.20it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([0, 0, 3, 0, 2, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 2, 2,\n",
      "        3, 3, 3, 0, 0, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3, 3, 3, 0, 0, 3, 3,\n",
      "        0, 3, 3, 0, 3, 0, 3, 0, 3, 3, 2, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3,\n",
      "        3, 3, 3, 0, 0, 0, 1, 0, 3, 3, 0, 0, 0, 1, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3,\n",
      "        3, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 0, 3, 1, 0, 3, 3, 3, 0, 0, 0, 3,\n",
      "        3, 0, 3, 0, 3, 0, 3, 3], device='cuda:0')\n",
      "g tensor([0, 0, 2, 3, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "        1, 1, 3, 0, 0, 3, 3, 0, 0, 3, 3, 2, 0, 3, 3, 0, 0, 3, 1, 3, 3, 0, 3, 3,\n",
      "        0, 2, 3, 0, 3, 2, 2, 1, 3, 3, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 2, 0, 3,\n",
      "        3, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3,\n",
      "        1, 1, 1, 3, 1, 0, 2, 1, 0, 0, 3, 0, 3, 0, 1, 1, 0, 3, 3, 2, 0, 3, 0, 3,\n",
      "        3, 0, 3, 0, 3, 0, 3, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7500, device='cuda:0')\n",
      "f tensor(0.7500, device='cuda:0')\n",
      "p tensor(0.5550, device='cuda:0')\n",
      "l tensor(0.6737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 43: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:36<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.11it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.13it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 43: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:50<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 43\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(43)\n",
      "Epoch 44:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 44\n",
      "Epoch 44: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:37<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.12it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 44: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:52<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 44\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(44)\n",
      "DECENT NOTE: save model tensor(44)\n",
      "Epoch 45:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 45\n",
      "DECENT NOTE: update model 45\n",
      "\n",
      "info at random intervals\n",
      "[0 2 3]\n",
      "torch.Size([1, 3, 3, 3])\n",
      "torch.Size([1, 5, 3, 3])\n",
      "DECENT NOTE: model updated\n",
      "Epoch 45: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:35<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.14it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.13it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 45: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:51<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 45\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(45)\n",
      "Epoch 46:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 46\n",
      "Epoch 46:  34%|█████████████████████▋                                         | 11/32 [01:22<02:36,  0.13it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 3, 3, 1,\n",
      "        3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 1, 3, 3, 0, 1, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0,\n",
      "        3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 0,\n",
      "        3, 0, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 0, 1, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
      "        3, 0, 3, 3, 3, 3, 0, 3], device='cuda:0')\n",
      "g tensor([3, 3, 3, 1, 0, 0, 0, 3, 3, 1, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 2, 1,\n",
      "        3, 3, 0, 3, 3, 2, 3, 0, 3, 0, 0, 3, 3, 0, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2,\n",
      "        3, 3, 0, 3, 3, 1, 0, 0, 0, 3, 1, 2, 3, 3, 2, 2, 1, 3, 1, 0, 3, 2, 3, 0,\n",
      "        3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 2, 3, 3, 0, 3, 0, 0, 0,\n",
      "        3, 0, 3, 0, 3, 3, 1, 0, 1, 3, 3, 2, 0, 1, 3, 3, 0, 3, 3, 2, 0, 3, 0, 2,\n",
      "        3, 0, 3, 3, 3, 2, 0, 1], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7734, device='cuda:0')\n",
      "f tensor(0.7734, device='cuda:0')\n",
      "p tensor(0.5319, device='cuda:0')\n",
      "l tensor(0.6720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 46:  50%|███████████████████████████████▌                               | 16/32 [01:25<01:25,  0.19it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 1, 0, 0, 0, 3, 3, 0, 1, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 0, 1, 3, 3, 0,\n",
      "        3, 3, 3, 3, 1, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 1, 3, 3, 0, 3, 0, 3, 0, 0,\n",
      "        3, 0, 3, 3, 0, 3, 3, 0, 3, 0, 1, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 0, 3,\n",
      "        0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 3, 3, 3, 0, 3, 3, 0, 3, 0, 0, 0,\n",
      "        3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 3, 0,\n",
      "        3, 3, 0, 0, 3, 3, 0, 3], device='cuda:0')\n",
      "g tensor([3, 3, 2, 0, 0, 3, 0, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 1, 1, 3, 1, 0,\n",
      "        3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 2, 3, 3, 0, 0, 3, 1, 0, 3, 1, 3, 0, 0,\n",
      "        3, 0, 3, 3, 0, 0, 1, 0, 3, 0, 1, 2, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 0, 1,\n",
      "        0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 1, 3, 3, 3, 0, 3, 3, 0, 3, 0, 0, 0,\n",
      "        3, 3, 2, 3, 3, 3, 3, 0, 1, 3, 3, 3, 0, 0, 1, 3, 0, 3, 3, 0, 0, 0, 3, 0,\n",
      "        3, 3, 0, 2, 3, 0, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.8125, device='cuda:0')\n",
      "f tensor(0.8125, device='cuda:0')\n",
      "p tensor(0.5015, device='cuda:0')\n",
      "l tensor(0.6257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 46: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:36<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.15it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.15it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 46: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:53<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 46\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(46)\n",
      "Epoch 47:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 47\n",
      "Epoch 47:  41%|█████████████████████████▌                                     | 13/32 [01:20<01:58,  0.16it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0,\n",
      "        1, 3, 0, 0, 0, 3, 0, 3, 0, 3, 3, 3, 3, 0, 0, 0, 2, 3, 3, 1, 0, 3, 0, 3,\n",
      "        0, 3, 0, 0, 1, 1, 1, 1, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 0, 0, 1,\n",
      "        3, 3, 3, 0, 3, 0, 3, 0, 3, 0, 0, 1, 3, 3, 0, 3, 3, 3, 3, 3, 0, 1, 0, 3,\n",
      "        0, 3, 3, 0, 3, 0, 3, 0, 3, 0, 3, 3, 3, 1, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0,\n",
      "        3, 0, 3, 3, 0, 3, 3, 0], device='cuda:0')\n",
      "g tensor([3, 3, 1, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 2, 3, 0, 3, 0, 3, 0, 2, 3, 0,\n",
      "        3, 3, 0, 3, 0, 3, 0, 1, 0, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3,\n",
      "        0, 1, 0, 0, 3, 1, 1, 1, 1, 0, 1, 2, 1, 3, 0, 3, 0, 3, 3, 0, 3, 0, 0, 0,\n",
      "        3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 2, 2, 3, 3, 0, 2, 2, 3, 3, 3, 3, 3, 0, 3,\n",
      "        1, 3, 1, 0, 3, 0, 3, 0, 3, 0, 3, 3, 1, 1, 2, 3, 3, 3, 0, 3, 0, 1, 2, 0,\n",
      "        3, 0, 3, 3, 0, 3, 3, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7344, device='cuda:0')\n",
      "f tensor(0.7344, device='cuda:0')\n",
      "p tensor(0.4862, device='cuda:0')\n",
      "l tensor(0.8085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 47: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:34<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.39it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.43it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 47: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:51<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 47\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(47)\n",
      "Epoch 48:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 48\n",
      "Epoch 48: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:37<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.42it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.41it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 48: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:56<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 48\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(48)\n",
      "Epoch 49:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 49\n",
      "Epoch 49: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:38<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.10it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.14it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 49: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:56<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 49\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(49)\n",
      "DECENT NOTE: save model tensor(49)\n",
      "Epoch 50:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 50\n",
      "DECENT NOTE: update model 50\n",
      "\n",
      "info at random intervals\n",
      "[ 0  1  2  3  4  6  7  8  9 10 11 12]\n",
      "torch.Size([1, 12, 3, 3])\n",
      "torch.Size([1, 13, 3, 3])\n",
      "DECENT NOTE: model updated\n",
      "Epoch 50: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:36<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.21it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.23it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 50: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:53<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 50\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(50)\n",
      "Epoch 51:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 51\n",
      "Epoch 51:  50%|███████████████████████████████▌                               | 16/32 [01:25<01:25,  0.19it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 1, 3, 0, 1, 0, 0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0, 3, 3, 3,\n",
      "        3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 1, 3, 3, 1, 0, 3, 3, 3,\n",
      "        0, 0, 3, 3, 0, 1, 0, 3, 3, 0, 0, 1, 3, 3, 3, 3, 3, 3, 1, 0, 2, 0, 3, 3,\n",
      "        3, 1, 3, 3, 0, 3, 3, 3, 1, 0, 3, 0, 0, 3, 3, 0, 3, 3, 0, 3, 0, 0, 3, 3,\n",
      "        0, 1, 0, 3, 3, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 1, 0, 3, 0, 3,\n",
      "        0, 0, 0, 0, 3, 0, 3, 3], device='cuda:0')\n",
      "g tensor([3, 3, 2, 0, 1, 1, 2, 3, 3, 3, 0, 3, 3, 3, 3, 0, 1, 1, 0, 0, 0, 2, 1, 1,\n",
      "        2, 2, 3, 3, 3, 3, 1, 3, 3, 0, 3, 0, 0, 3, 3, 3, 1, 2, 1, 3, 0, 0, 3, 3,\n",
      "        1, 1, 3, 3, 0, 0, 1, 2, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 0, 3, 0, 3, 3,\n",
      "        3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 0, 3, 3, 0, 1, 3, 0, 3, 3, 1, 3, 0,\n",
      "        1, 1, 0, 3, 3, 0, 0, 3, 3, 3, 0, 0, 1, 0, 0, 3, 0, 0, 2, 3, 0, 0, 3, 3,\n",
      "        1, 0, 0, 0, 3, 0, 3, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6797, device='cuda:0')\n",
      "f tensor(0.6797, device='cuda:0')\n",
      "p tensor(0.4272, device='cuda:0')\n",
      "l tensor(0.8474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 51: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:36<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.46it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.50it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 51: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:52<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 51\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(51)\n",
      "Epoch 52:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 52\n",
      "Epoch 52:  38%|███████████████████████▋                                       | 12/32 [01:20<02:14,  0.15it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3,\n",
      "        0, 0, 3, 3, 1, 3, 0, 0, 3, 0, 3, 3, 0, 0, 1, 3, 1, 0, 3, 0, 0, 0, 3, 0,\n",
      "        3, 3, 0, 3, 0, 3, 0, 0, 0, 3, 3, 0, 3, 3, 3, 0, 1, 0, 3, 0, 3, 0, 0, 3,\n",
      "        0, 0, 3, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 1, 3,\n",
      "        0, 1, 3, 0, 0, 0, 1, 3, 0, 0, 0, 3, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 0, 0,\n",
      "        3, 0, 3, 0, 3, 0, 0, 0], device='cuda:0')\n",
      "g tensor([3, 0, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 0, 0, 0, 1, 3, 3, 3, 0, 0, 3, 0, 3,\n",
      "        0, 0, 3, 2, 1, 3, 1, 2, 1, 2, 3, 3, 2, 0, 3, 2, 2, 0, 3, 3, 3, 0, 3, 0,\n",
      "        3, 3, 0, 3, 0, 2, 0, 0, 0, 3, 3, 0, 3, 3, 3, 1, 1, 1, 0, 1, 3, 0, 3, 2,\n",
      "        0, 3, 3, 0, 1, 1, 3, 3, 0, 0, 3, 3, 0, 3, 3, 0, 0, 0, 0, 2, 1, 3, 0, 1,\n",
      "        0, 0, 2, 0, 0, 0, 1, 3, 0, 0, 0, 3, 3, 0, 3, 2, 1, 1, 3, 2, 0, 3, 1, 1,\n",
      "        3, 0, 3, 0, 3, 0, 2, 0], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6875, device='cuda:0')\n",
      "f tensor(0.6875, device='cuda:0')\n",
      "p tensor(0.4602, device='cuda:0')\n",
      "l tensor(0.8013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 52: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:34<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.23it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 52: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:50<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 52\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(52)\n",
      "Epoch 53:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 53\n",
      "Epoch 53:  56%|███████████████████████████████████▍                           | 18/32 [01:23<01:04,  0.22it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 0, 0, 3, 0, 0, 3, 3, 1, 1, 1, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
      "        3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 0, 2, 0, 3, 0, 0, 3, 0, 3, 3, 3, 3, 0, 0,\n",
      "        3, 3, 0, 3, 0, 3, 0, 0, 1, 3, 0, 0, 3, 0, 0, 3, 0, 0, 1, 3, 0, 3, 3, 0,\n",
      "        3, 3, 1, 1, 3, 0, 3, 3, 3, 3, 0, 0, 3, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 3,\n",
      "        3, 3, 0, 0, 0, 0, 0, 3], device='cuda:0')\n",
      "g tensor([3, 0, 0, 0, 3, 0, 0, 3, 3, 1, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 0, 3, 0, 3,\n",
      "        3, 0, 1, 3, 1, 0, 2, 3, 2, 3, 0, 3, 3, 3, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 2, 3, 0, 0, 3, 0, 1, 0, 1, 2, 0, 3, 0, 0, 3, 0, 2, 3, 3, 3, 3, 2,\n",
      "        1, 1, 0, 1, 3, 3, 0, 0, 1, 1, 0, 0, 3, 0, 0, 0, 3, 0, 1, 3, 0, 3, 3, 0,\n",
      "        3, 3, 3, 2, 3, 0, 3, 3, 3, 0, 0, 0, 3, 0, 0, 2, 1, 3, 0, 1, 2, 0, 3, 3,\n",
      "        3, 3, 0, 0, 3, 1, 1, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7344, device='cuda:0')\n",
      "f tensor(0.7344, device='cuda:0')\n",
      "p tensor(0.7331, device='cuda:0')\n",
      "l tensor(0.7291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 53: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:32<00:00,  0.35it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.31it/s]\u001b[A\n",
      "val info at random intervals\n",
      "p tensor([3, 1, 3, 0, 3, 0, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 3, 0, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 0, 1, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 0, 1, 0, 3, 3, 0, 3, 3,\n",
      "        0, 3, 3, 2, 3, 3, 3, 3, 3, 3, 0, 1, 3, 0, 0, 3, 0, 3, 0, 0, 3, 0, 3, 3,\n",
      "        0, 3, 0, 3, 1, 0, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3,\n",
      "        1, 3, 3, 3, 1, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 3, 3, 0, 3, 3, 3, 3, 0,\n",
      "        0, 3, 0, 0, 3, 0, 3, 1], device='cuda:0')\n",
      "g tensor([2, 0, 3, 1, 3, 2, 3, 0, 0, 3, 3, 3, 2, 1, 3, 1, 2, 3, 0, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 1, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0, 0, 3, 2, 3, 3, 3, 3, 3,\n",
      "        0, 3, 3, 3, 3, 3, 3, 2, 0, 0, 0, 1, 3, 0, 0, 3, 0, 3, 0, 0, 3, 1, 2, 3,\n",
      "        0, 3, 0, 3, 1, 1, 3, 0, 0, 2, 1, 3, 3, 2, 3, 3, 3, 0, 0, 3, 3, 0, 0, 3,\n",
      "        1, 3, 3, 3, 0, 1, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 2, 1, 0,\n",
      "        0, 3, 1, 0, 3, 0, 3, 1], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7344, device='cuda:0')\n",
      "f tensor(0.7344, device='cuda:0')\n",
      "p tensor(0.4976, device='cuda:0')\n",
      "l tensor(0.7965, device='cuda:0')\n",
      "\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.39it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 53: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:49<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 53\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(53)\n",
      "Epoch 54:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 54\n",
      "Epoch 54: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:38<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.49it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.49it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 54: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:57<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 54\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(54)\n",
      "DECENT NOTE: save model tensor(54)\n",
      "Epoch 55:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 55\n",
      "DECENT NOTE: update model 55\n",
      "DECENT NOTE: model updated\n",
      "Epoch 55:  84%|█████████████████████████████████████████████████████▏         | 27/32 [01:27<00:16,  0.31it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 3, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
      "        0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 0,\n",
      "        0, 0, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3, 0, 3, 0, 3, 0,\n",
      "        3, 3, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 0, 3,\n",
      "        3, 0, 3, 0, 1, 3, 3, 0, 3, 3, 0, 3, 0, 1, 3, 0, 0, 0, 3, 3, 3, 0, 3, 3,\n",
      "        1, 3, 0, 0, 0, 0, 0, 3], device='cuda:0')\n",
      "g tensor([2, 3, 0, 1, 0, 3, 0, 2, 0, 3, 0, 0, 0, 2, 0, 3, 1, 3, 3, 3, 0, 2, 3, 3,\n",
      "        0, 3, 0, 3, 2, 3, 3, 1, 2, 3, 3, 0, 0, 3, 0, 3, 3, 3, 1, 3, 3, 3, 3, 0,\n",
      "        0, 0, 3, 0, 3, 2, 3, 0, 0, 3, 0, 0, 0, 0, 3, 2, 3, 0, 3, 0, 3, 3, 3, 0,\n",
      "        0, 3, 2, 2, 3, 0, 3, 1, 0, 0, 0, 1, 3, 0, 3, 0, 3, 0, 2, 2, 3, 3, 0, 1,\n",
      "        3, 0, 2, 3, 2, 3, 3, 0, 3, 3, 1, 0, 2, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 3,\n",
      "        3, 3, 1, 0, 0, 3, 0, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.6562, device='cuda:0')\n",
      "f tensor(0.6562, device='cuda:0')\n",
      "p tensor(0.3365, device='cuda:0')\n",
      "l tensor(0.9307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 55: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:31<00:00,  0.35it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.44it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.50it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 55: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:45<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 55\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(55)\n",
      "Epoch 56:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 56\n",
      "Epoch 56: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:37<00:00,  0.33it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.24it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.27it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 56: 100%|███████████████████████████████████████████████████████████████| 32/32 [03:02<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 56\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(56)\n",
      "Epoch 57:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 57\n",
      "Epoch 57:  62%|███████████████████████████████████████▍                       | 20/32 [01:24<00:50,  0.24it/s, v_num=0]\n",
      "train info at random intervals\n",
      "p tensor([3, 0, 3, 0, 3, 0, 0, 0, 3, 1, 1, 3, 1, 0, 3, 0, 0, 3, 0, 3, 0, 3, 3, 3,\n",
      "        3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 0,\n",
      "        0, 0, 0, 0, 3, 3, 0, 0, 1, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 0,\n",
      "        3, 3, 0, 0, 3, 3, 3, 0, 0, 0, 1, 0, 0, 0, 3, 3, 3, 0, 3, 1, 3, 1, 3, 0,\n",
      "        3, 3, 3, 3, 3, 1, 0, 0], device='cuda:0')\n",
      "g tensor([1, 1, 1, 0, 3, 3, 0, 0, 2, 3, 1, 3, 0, 0, 1, 0, 0, 3, 0, 3, 1, 3, 3, 3,\n",
      "        1, 3, 1, 0, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3,\n",
      "        2, 3, 3, 0, 2, 3, 3, 0, 3, 0, 0, 3, 3, 0, 0, 3, 0, 0, 1, 3, 1, 2, 3, 3,\n",
      "        3, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 3,\n",
      "        0, 3, 3, 1, 2, 3, 0, 0, 0, 0, 1, 0, 0, 0, 3, 3, 3, 0, 0, 1, 3, 3, 0, 1,\n",
      "        3, 2, 3, 3, 3, 0, 1, 3], device='cuda:0', dtype=torch.int32)\n",
      "a tensor(0.7109, device='cuda:0')\n",
      "f tensor(0.7109, device='cuda:0')\n",
      "p tensor(0.4601, device='cuda:0')\n",
      "l tensor(0.7956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "Epoch 57: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:32<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.31it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.38it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 57: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:49<00:00,  0.19it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 57\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(57)\n",
      "Epoch 58:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 58\n",
      "Epoch 58: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:34<00:00,  0.34it/s, v_num=0]\n",
      "Validation: |                                                                                    | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██████████████▊                                            | 1/4 [00:00<00:02,  1.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████████████████████████▌                             | 2/4 [00:01<00:01,  1.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|████████████████████████████████████████████▎              | 3/4 [00:02<00:00,  1.43it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|███████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.50it/s]\u001b[ADECENT NOTE: on_validation_epoch_end\n",
      "\n",
      "Epoch 58: 100%|███████████████████████████████████████████████████████████████| 32/32 [02:58<00:00,  0.18it/s, v_num=0]\u001b[ADECENT NOTE: on_train_epoch_end 58\n",
      "DECENT NOTE: callback on_train_epoch_end tensor(58)\n",
      "Epoch 59:   0%|                                                                        | 0/32 [00:00<?, ?it/s, v_num=0]DECENT NOTE: on_train_epoch_start 59\n",
      "Epoch 59: 100%|███████████████████████████████████████████████████████████████| 32/32 [01:51<00:00,  0.29it/s, v_num=0]"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# this is the main function, run this cell!!!\n",
    "\n",
    "# dataset\n",
    "# logger\n",
    "# trainer\n",
    "# trainer.fit\n",
    "# trainer.test\n",
    "# =============================================================================\n",
    "\n",
    "print(\"train kwargs\", train_kwargs)\n",
    "print(\"model kwargs\", model_kwargs)\n",
    "\n",
    "kwargs = {'train_kwargs':train_kwargs, 'model_kwargs':model_kwargs}\n",
    "\n",
    "# \"examples/example_results/lightning_logs\"\n",
    "logger = CSVLogger(os.path.join(train_kwargs[\"result_path\"], 'lightning_logs'), name=train_kwargs[\"exp_name\"])\n",
    "trainer = pl.Trainer(default_root_dir=train_kwargs[\"result_path\"],\n",
    "                     accelerator=\"gpu\" if str(train_kwargs[\"device\"]).startswith(\"cuda\") else \"cpu\",\n",
    "                     devices=[0],\n",
    "                     # inference_mode=False, # do grad manually\n",
    "                     log_every_n_steps=train_kwargs[\"log_every_n_steps\"],\n",
    "                     logger=logger,\n",
    "                     check_val_every_n_epoch=1,\n",
    "                     max_epochs=train_kwargs[\"epochs\"],\n",
    "                     callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_f1\",\n",
    "                                               filename='{epoch}-{val_f1:.2f}-{unpruned:.0f}'),\n",
    "                                DecentModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"unpruned\", save_top_k=-1, save_on_train_epoch_end=True,\n",
    "                                                filename='{epoch}-{unpruned:.0f}-{val_f1:.2f}'),\n",
    "                                LearningRateMonitor(\"epoch\")])\n",
    "\n",
    "trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "# Check whether pretrained model exists. If yes, load it and skip training\n",
    "pretrained_filename = os.path.join(*[train_kwargs[\"result_path\"], \"lightning_logs\", train_kwargs[\"exp_name\"], train_kwargs[\"load_ckpt_file\"]])\n",
    "if os.path.isfile(pretrained_filename):\n",
    "    print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "    light = DecentLightning.load_from_checkpoint(pretrained_filename, model_kwargs=model_kwargs, log_dir=\"example_results/lightning_logs\") # Automatically loads the model with the saved hyperparameters\n",
    "else:\n",
    "    pl.seed_everything(19) # To be reproducable\n",
    "\n",
    "    # Initialize the LightningModule and LightningDataModule\n",
    "    light = DecentLightning(kwargs=kwargs, log_dir=logger.log_dir)\n",
    "\n",
    "\n",
    "    # Train the model using a Trainer\n",
    "    trainer.fit(light, train_dataloader, val_dataloader)\n",
    "\n",
    "    # we don't save the positions here ...\n",
    "    # light = DecentLightning.load_from_checkpoint(trainer.checkpoint_callback.best_model_path, kwargs=kwargs) # Load best checkpoint after training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66262489-1c4a-439e-9673-32a40c5c52f1",
   "metadata": {},
   "source": [
    "## run test routine ****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9f7ff-a6f1-4947-bcf9-07b9141fd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test best model on test set\n",
    "\n",
    "# we want the grad to work in test, hence: inference_mode=False\n",
    "# logger_x = CSVLogger(os.path.join(train_kwargs[\"result_path\"], 'lightning_logs'), name='dumpster')\n",
    "explainer = pl.Trainer(default_root_dir=train_kwargs[\"result_path\"],\n",
    "                     accelerator=\"gpu\" if str(train_kwargs[\"device\"]).startswith(\"cuda\") else \"cpu\",\n",
    "                     devices=[0],\n",
    "                     logger=logger,\n",
    "                     inference_mode=False)\n",
    "\n",
    "test_result = explainer.test(light, xai_dataloader, verbose=False)\n",
    "\n",
    "try:\n",
    "    result = {\"test accuracy on valset\": test_result[0][\"test_acc\"]}\n",
    "except:\n",
    "    result = 0\n",
    "\n",
    "try:     \n",
    "    layer = light.model.decent2 # .filter_list[7]weights\n",
    "    run_explain(light, layer, device='cuda')\n",
    "except Exception as e:\n",
    "    print(\"DecentError: layer not working, run not defined\" )\n",
    "    print(e)\n",
    "    pass\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccb396-da0e-4942-998b-676d1fb8234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[np.array(0.7212581)], [np.array(0.7065036)]]\n",
    "\n",
    "for e in a:\n",
    "    for i in e:\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "flattened = [val.item() for tmp in a for val in tmp] \n",
    " \n",
    "\n",
    "a\n",
    "a\n",
    "\n",
    "flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee6f3b-11df-4ef3-9fd9-a110fa996159",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [[0.2847180664539337, 0.29257622361183167, 0.2561589181423187, 0.2416810840368271, 0.2306821644306183], [0.24937507510185242, 0.294414222240448, 0.2743309736251831, 0.2431085854768753, 0.23851336538791656], [0.30998995900154114, 0.2402188777923584, 0.22844929993152618, 0.2568821907043457], [0.28166717290878296, 0.22486495971679688, 0.2940433919429779, 0.26794517040252686]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48391f-1f3e-4d78-aa61-79dc7eeac5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    a=np.array([np.array(0.69074845)])\n",
    "\n",
    "    print(a.flatten())\n",
    "\n",
    "    flattened = [val for tmp in a for val in tmp] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f165e1d-6d72-47d1-bf97-bfcd334b0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0696de4a-76ea-4b95-9d11-e1cf8a733a42",
   "metadata": {},
   "source": [
    "# random nonsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3d0e6-ce41-4a30-b68f-7c70bbf92113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005a8f1-b68b-42f8-a653-cd905542361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing yet - currently part of the main running dev thingi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5d6dd-be92-4db7-bdd8-40d886f10adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43468c27-f130-4118-8d11-275282921c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d301c-cbad-4154-a053-137a3263c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# useless, always the same filters\n",
    "\n",
    "for i_filter in range(100):\n",
    "    try:\n",
    "        layer = model.model.decent2.filter_list[i_filter] # i_filter] # .filter_list[7]weights\n",
    "        run_explain(model, layer, device='cuda')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2568e15-95ba-4c8c-9a51-b8cb5050ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "layer = model.model.decent2 # .filter_list[7]weights\n",
    "run_explain(model, layer, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f4513-419a-433b-97ff-6f54c5a6d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b09e4-644a-4cca-9da3-a47986de1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca471c2c-819f-44aa-a8f9-e318aacf3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"example_results/lightning_logs/tmp/version_22/checkpoints/epoch=4-unpruned=10815-val_f1=0.12.ckpt\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfa186-0125-4a4b-adc6-c748cb2587c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"example_results/lightning_logs/tmp/version_22/checkpoints/epoch=4-unpruned=10815-val_f1=0.12.ckpt\")['loops'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e68578-ec3f-417e-8144-1e8ff14b20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"example_results/lightning_logs/tmp/version_22/checkpoints/epoch=4-unpruned=10815-val_f1=0.12.ckpt\")['state_dict'].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
